{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE - Use Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "import dill\n",
    "import os\n",
    "\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from window_based_tagger_config import get_config\n",
    "from FindFiles import find_files\n",
    "from DirUtils import dir_exists\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Settings import Settings\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = mcnemar([[1,2],[3,1]], exact=True)\n",
    "# result.statistic, result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_str(s, files, exclude=False):   \n",
    "    return  [f for f in files if (s in f) != exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n",
      "94\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "print(len(all_files))\n",
    "files = filter_by_str(\"_TAGGING_\", all_files)\n",
    "files = filter_by_str(\"_CR_\", files, exclude=True)\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "print(len(files))\n",
    "files = filter_by_str(\"2019\", files, exclude=True)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_YS.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_files = filter_by_str(\"_SC_\", files)\n",
    "cb_files = filter_by_str(\"_CB_\", files)\n",
    "len(cb_files), len(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "filters = OrderedDict({\n",
    "    \"WINDOW_CLASSIFIER\":\"WINDOW_CLASSIFIER\",\n",
    "    \"CRF\": \"_CRF_\",\n",
    "    \"HMM\" : \"_HMM_\",\n",
    "    \"PERCEPTRON\":\"PERCEPTRON\",\n",
    "    \"RNN\" : \"_RNN_\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def load_predictions(input_files):\n",
    "    algo2preds = dict()\n",
    "    pred_files = filter_by_str(\"_PREDS\", input_files)\n",
    "    for algo_name, fltr in filters.items():\n",
    "        f_files = filter_by_str(fltr, pred_files)\n",
    "        assert len(f_files) == 1\n",
    "        fname = FOLDER + f_files[0]\n",
    "        with open(fname, \"rb+\") as f:\n",
    "            algo2preds[algo_name] = dill.load(f)\n",
    "    return algo2preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = load_predictions(cb_files)\n",
    "sc_preds = load_predictions(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FOLDER + \"TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    cb_ysbytag = dill.load(f)\n",
    "    \n",
    "with open(FOLDER + \"TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    sc_ysbytag = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(predsbytag):\n",
    "    all_p = []\n",
    "    for k, vals in sorted(predsbytag.items(), key = lambda tpl: tpl[0]):\n",
    "        all_p.extend(vals)\n",
    "    return all_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb, alternative='two-sided'):\n",
    "    assert len(ysbytag.keys()) == len(predsbytaga.keys()), (len(ysbytag.keys()),len(predsbytaga.keys())) \n",
    "    assert len(ysbytag.keys()) == len(predsbytagb.keys()), (len(ysbytag.keys()),len(predsbytagb.keys())) \n",
    "\n",
    "    first = list(ysbytag.keys())[0]\n",
    "    assert len(ysbytag[first]) == len(predsbytaga[first])\n",
    "    assert len(ysbytag[first]) == len(predsbytagb[first])\n",
    "\n",
    "    ys = get_all_preds(ysbytag)\n",
    "    aas = get_all_preds(predsbytaga)\n",
    "    bbs = get_all_preds(predsbytagb)\n",
    "\n",
    "    assert len(ys) == len(aas) == len(bbs)\n",
    "\n",
    "    successes = defaultdict(int)\n",
    "    both_correct, both_wrong, a_correct_only, b_correct_only = 0,0,0,0\n",
    "    for y,a,b in zip(ys,aas,bbs):\n",
    "        if a == b:\n",
    "            if a == y:\n",
    "                both_correct +=1\n",
    "            else:\n",
    "                both_wrong += 1        \n",
    "        else: # a != b\n",
    "            if a == y:\n",
    "                successes[\"a\"] += 1\n",
    "                a_correct_only += 1\n",
    "            else:\n",
    "                successes[\"b\"] += 1\n",
    "                b_correct_only +=1\n",
    "\n",
    "\n",
    "    mcn_result = mcnemar([[both_correct, a_correct_only],[b_correct_only, both_wrong]], exact=True)\n",
    "#     p_value = stats.binom_test(successes[\"a\"], sum(successes.values()), p=0.5, alternative=alternative)\n",
    "    return mcn_result.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Predicted Tags from Labelled Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(tag, expected_tag_set):\n",
    "    if tag in expected_tag_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_wd_level_lbs(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sent in e.sentences:\n",
    "            for wd, tag_set in sent:\n",
    "                for etag in expected_tags:\n",
    "                    ysbycode[etag].append(get_label(etag, tag_set))\n",
    "    return ysbycode    \n",
    "\n",
    "# for pred tags\n",
    "def get_wd_level_preds(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sentix in range(len(e.sentences)):\n",
    "            p_ccodes = e.pred_tagged_sentences[sentix]            \n",
    "            for wordix in range(len(p_ccodes)):\n",
    "                ptag_set = set([p_ccodes[wordix]])\n",
    "                assert len(ptag_set) >=1, \"No tags found\"\n",
    "                for exp_tag in expected_tags:\n",
    "                    ysbycode[exp_tag].append(get_label(exp_tag, ptag_set))    \n",
    "    return ysbycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    cb_essays = dill.load(f)\n",
    "    \n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    sc_essays = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_preds[\"RNN\"] = get_wd_level_preds(cb_essays, cb_ysbytag.keys())\n",
    "# sc_preds[\"RNN\"] = get_wd_level_preds(sc_essays, sc_ysbytag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparison(ysbytag, algo2preds, alternative=\"two-sided\", stats_only=False):\n",
    "    algo2metrics = {}\n",
    "    for algo, preds in algo2preds.items():\n",
    "        mean_metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)\n",
    "        algo2metrics[algo] = mean_metrics[__MICRO_F1__]\n",
    "\n",
    "    matrix = dict()\n",
    "    for algo_name_a, predsbytaga in algo2preds.items():\n",
    "        for algo_name_b, predsbytagb in algo2preds.items():\n",
    "            if algo_name_a == algo_name_b:\n",
    "                continue\n",
    "            f1_a = algo2metrics[algo_name_a][\"f1_score\"]\n",
    "            f1_b = algo2metrics[algo_name_b][\"f1_score\"]\n",
    "            pval = compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb, alternative)\n",
    "            if stats_only:\n",
    "                print(f\"{algo_name_a.ljust(20)} \\t{algo_name_b.ljust(20)}\\t {pval}\")\n",
    "            else:\n",
    "                print(f\"{algo_name_a.ljust(20)} {f1_a:.4f}\\t{algo_name_b.ljust(20)} {f1_b:.4f}\\t {pval}\")\n",
    "            matrix[(algo_name_a, algo_name_b)] = pval\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    0.8413\tCRF                  0.8380\t 0.16554440323794242\n",
      "WINDOW_CLASSIFIER    0.8413\tHMM                  0.7471\t 6.539263608822287e-216\n",
      "WINDOW_CLASSIFIER    0.8413\tPERCEPTRON           0.8399\t 0.5990715121670374\n",
      "WINDOW_CLASSIFIER    0.8413\tRNN                  0.8435\t 0.03867648862259766\n",
      "\n",
      "CRF                  0.8380\tWINDOW_CLASSIFIER    0.8413\t 0.16554440323794242\n",
      "CRF                  0.8380\tHMM                  0.7471\t 3.4081766479273455e-186\n",
      "CRF                  0.8380\tPERCEPTRON           0.8399\t 0.3953317058722892\n",
      "CRF                  0.8380\tRNN                  0.8435\t 0.36217171402654597\n",
      "\n",
      "HMM                  0.7471\tWINDOW_CLASSIFIER    0.8413\t 6.539263608822287e-216\n",
      "HMM                  0.7471\tCRF                  0.8380\t 3.4081766479273455e-186\n",
      "HMM                  0.7471\tPERCEPTRON           0.8399\t 1.840272414942264e-204\n",
      "HMM                  0.7471\tRNN                  0.8435\t 3.905881832528089e-160\n",
      "\n",
      "PERCEPTRON           0.8399\tWINDOW_CLASSIFIER    0.8413\t 0.5990715121670374\n",
      "PERCEPTRON           0.8399\tCRF                  0.8380\t 0.3953317058722892\n",
      "PERCEPTRON           0.8399\tHMM                  0.7471\t 1.840272414942264e-204\n",
      "PERCEPTRON           0.8399\tRNN                  0.8435\t 0.09259548941837153\n",
      "\n",
      "RNN                  0.8435\tWINDOW_CLASSIFIER    0.8413\t 0.03867648862259766\n",
      "RNN                  0.8435\tCRF                  0.8380\t 0.36217171402654597\n",
      "RNN                  0.8435\tHMM                  0.7471\t 3.905881832528089e-160\n",
      "RNN                  0.8435\tPERCEPTRON           0.8399\t 0.09259548941837153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#perceptron and CRF differ somewhat from prior run\n",
    "print_comparison(cb_ysbytag, cb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    0.8144\tCRF                  0.8043\t 0.003608884280891862\n",
      "WINDOW_CLASSIFIER    0.8144\tHMM                  0.6754\t 0.0\n",
      "WINDOW_CLASSIFIER    0.8144\tPERCEPTRON           0.8148\t 0.45153921840005645\n",
      "WINDOW_CLASSIFIER    0.8144\tRNN                  0.8375\t 7.626212024075683e-12\n",
      "\n",
      "CRF                  0.8043\tWINDOW_CLASSIFIER    0.8144\t 0.003608884280891862\n",
      "CRF                  0.8043\tHMM                  0.6754\t 3.4009044173226684e-281\n",
      "CRF                  0.8043\tPERCEPTRON           0.8148\t 0.0007131169075950804\n",
      "CRF                  0.8043\tRNN                  0.8375\t 7.752171243018439e-19\n",
      "\n",
      "HMM                  0.6754\tWINDOW_CLASSIFIER    0.8144\t 0.0\n",
      "HMM                  0.6754\tCRF                  0.8043\t 3.4009044173226684e-281\n",
      "HMM                  0.6754\tPERCEPTRON           0.8148\t 0.0\n",
      "HMM                  0.6754\tRNN                  0.8375\t 0.0\n",
      "\n",
      "PERCEPTRON           0.8148\tWINDOW_CLASSIFIER    0.8144\t 0.45153921840005645\n",
      "PERCEPTRON           0.8148\tCRF                  0.8043\t 0.0007131169075950804\n",
      "PERCEPTRON           0.8148\tHMM                  0.6754\t 0.0\n",
      "PERCEPTRON           0.8148\tRNN                  0.8375\t 7.5997163162173e-10\n",
      "\n",
      "RNN                  0.8375\tWINDOW_CLASSIFIER    0.8144\t 7.626212024075683e-12\n",
      "RNN                  0.8375\tCRF                  0.8043\t 7.752171243018439e-19\n",
      "RNN                  0.8375\tHMM                  0.6754\t 0.0\n",
      "RNN                  0.8375\tPERCEPTRON           0.8148\t 7.5997163162173e-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN only differs\n",
    "print_comparison(sc_ysbytag, sc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    \tCRF                 \t 0.16554440323794242\n",
      "WINDOW_CLASSIFIER    \tHMM                 \t 6.539263608822287e-216\n",
      "WINDOW_CLASSIFIER    \tPERCEPTRON          \t 0.5990715121670374\n",
      "WINDOW_CLASSIFIER    \tRNN                 \t 0.03867648862259766\n",
      "\n",
      "CRF                  \tWINDOW_CLASSIFIER   \t 0.16554440323794242\n",
      "CRF                  \tHMM                 \t 3.4081766479273455e-186\n",
      "CRF                  \tPERCEPTRON          \t 0.3953317058722892\n",
      "CRF                  \tRNN                 \t 0.36217171402654597\n",
      "\n",
      "HMM                  \tWINDOW_CLASSIFIER   \t 6.539263608822287e-216\n",
      "HMM                  \tCRF                 \t 3.4081766479273455e-186\n",
      "HMM                  \tPERCEPTRON          \t 1.840272414942264e-204\n",
      "HMM                  \tRNN                 \t 3.905881832528089e-160\n",
      "\n",
      "PERCEPTRON           \tWINDOW_CLASSIFIER   \t 0.5990715121670374\n",
      "PERCEPTRON           \tCRF                 \t 0.3953317058722892\n",
      "PERCEPTRON           \tHMM                 \t 1.840272414942264e-204\n",
      "PERCEPTRON           \tRNN                 \t 0.09259548941837153\n",
      "\n",
      "RNN                  \tWINDOW_CLASSIFIER   \t 0.03867648862259766\n",
      "RNN                  \tCRF                 \t 0.36217171402654597\n",
      "RNN                  \tHMM                 \t 3.905881832528089e-160\n",
      "RNN                  \tPERCEPTRON          \t 0.09259548941837153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_comparison(cb_ysbytag, cb_preds, stats_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    \tCRF                 \t 0.003608884280891862\n",
      "WINDOW_CLASSIFIER    \tHMM                 \t 0.0\n",
      "WINDOW_CLASSIFIER    \tPERCEPTRON          \t 0.45153921840005645\n",
      "WINDOW_CLASSIFIER    \tRNN                 \t 7.626212024075683e-12\n",
      "\n",
      "CRF                  \tWINDOW_CLASSIFIER   \t 0.003608884280891862\n",
      "CRF                  \tHMM                 \t 3.4009044173226684e-281\n",
      "CRF                  \tPERCEPTRON          \t 0.0007131169075950804\n",
      "CRF                  \tRNN                 \t 7.752171243018439e-19\n",
      "\n",
      "HMM                  \tWINDOW_CLASSIFIER   \t 0.0\n",
      "HMM                  \tCRF                 \t 3.4009044173226684e-281\n",
      "HMM                  \tPERCEPTRON          \t 0.0\n",
      "HMM                  \tRNN                 \t 0.0\n",
      "\n",
      "PERCEPTRON           \tWINDOW_CLASSIFIER   \t 0.45153921840005645\n",
      "PERCEPTRON           \tCRF                 \t 0.0007131169075950804\n",
      "PERCEPTRON           \tHMM                 \t 0.0\n",
      "PERCEPTRON           \tRNN                 \t 7.5997163162173e-10\n",
      "\n",
      "RNN                  \tWINDOW_CLASSIFIER   \t 7.626212024075683e-12\n",
      "RNN                  \tCRF                 \t 7.752171243018439e-19\n",
      "RNN                  \tHMM                 \t 0.0\n",
      "RNN                  \tPERCEPTRON          \t 7.5997163162173e-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_comparison(sc_ysbytag, sc_preds, stats_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Closest Perceptron Results for CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_23-28.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-52.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-6.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-22.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_23-15.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_23-42.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_23-3.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-5_9-43.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-36.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-5_9-55.dill']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "perc_files = filter_by_str(\"_CB_\", all_files)\n",
    "perc_files = filter_by_str(\"_VD_\", perc_files)\n",
    "perc_files = filter_by_str(\"_PREDS_\", perc_files)\n",
    "perc_files = filter_by_str(\"_PERCEPTRON_\", perc_files)\n",
    "perc_files = filter_by_str(\"_2019\", perc_files)\n",
    "perc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>data_points</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fname</th>\n",
       "      <th>num_codes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994813</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.839932</td>\n",
       "      <td>10-5_9-55.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.884528</td>\n",
       "      <td>0.799617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994843</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>10-6_23-3.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.885254</td>\n",
       "      <td>0.800795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994831</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.841100</td>\n",
       "      <td>10-6_23-15.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.881925</td>\n",
       "      <td>0.803887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994848</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.841529</td>\n",
       "      <td>10-5_9-43.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.883048</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994876</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.842632</td>\n",
       "      <td>10-6_23-28.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882637</td>\n",
       "      <td>0.806095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994881</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>10-6_22-6.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882799</td>\n",
       "      <td>0.806243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.994883</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.842947</td>\n",
       "      <td>10-6_23-42.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882448</td>\n",
       "      <td>0.806832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.843409</td>\n",
       "      <td>10-6_22-22.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882931</td>\n",
       "      <td>0.807273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994911</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.844093</td>\n",
       "      <td>10-6_22-52.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.881796</td>\n",
       "      <td>0.809482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994953</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.845220</td>\n",
       "      <td>10-6_22-36.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.884084</td>\n",
       "      <td>0.809629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  data_points  f1_score            fname  num_codes  precision  \\\n",
       "9  0.994813     399087.0  0.839932   10-5_9-55.dill     6792.0   0.884528   \n",
       "6  0.994843     399087.0  0.840909   10-6_23-3.dill     6792.0   0.885254   \n",
       "4  0.994831     399087.0  0.841100  10-6_23-15.dill     6792.0   0.881925   \n",
       "7  0.994848     399087.0  0.841529   10-5_9-43.dill     6792.0   0.883048   \n",
       "0  0.994876     399087.0  0.842632  10-6_23-28.dill     6792.0   0.882637   \n",
       "2  0.994881     399087.0  0.842786   10-6_22-6.dill     6792.0   0.882799   \n",
       "5  0.994883     399087.0  0.842947  10-6_23-42.dill     6792.0   0.882448   \n",
       "3  0.994898     399087.0  0.843409  10-6_22-22.dill     6792.0   0.882931   \n",
       "1  0.994911     399087.0  0.844093  10-6_22-52.dill     6792.0   0.881796   \n",
       "8  0.994953     399087.0  0.845220  10-6_22-36.dill     6792.0   0.884084   \n",
       "\n",
       "     recall  \n",
       "9  0.799617  \n",
       "6  0.800795  \n",
       "4  0.803887  \n",
       "7  0.803740  \n",
       "0  0.806095  \n",
       "2  0.806243  \n",
       "5  0.806832  \n",
       "3  0.807273  \n",
       "1  0.809482  \n",
       "8  0.809629  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ysbytag = cb_ysbytag\n",
    "f2preds = dict()\n",
    "rows = []\n",
    "for f in perc_files:\n",
    "    with open(FOLDER + f, \"rb+\") as fin:\n",
    "        preds = dill.load(fin)\n",
    "    metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)[__MICRO_F1__]\n",
    "    metrics[\"fname\"] = f.split(\"2019-\")[-1]\n",
    "    rows.append(metrics)\n",
    "df = pd.DataFrame(rows).sort_values(\"f1_score\")\n",
    "df # 0.837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_2-27.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-6_23-17.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-6_21-1.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_2-59.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_0-13.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_0-52.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-6_22-33.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_1-34.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS__2019-10-7_3-48.dill']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "perc_files = filter_by_str(\"_SC_\", all_files)\n",
    "perc_files = filter_by_str(\"_VD_\", perc_files)\n",
    "perc_files = filter_by_str(\"_PREDS_\", perc_files)\n",
    "perc_files = filter_by_str(\"_RNN_\", perc_files)\n",
    "perc_files = filter_by_str(\"_2019\", perc_files)\n",
    "perc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>data_points</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fname</th>\n",
       "      <th>num_codes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992697</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.826796</td>\n",
       "      <td>10-6_21-1.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.848327</td>\n",
       "      <td>0.806330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992806</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.830973</td>\n",
       "      <td>10-7_2-59.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.844424</td>\n",
       "      <td>0.817944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.992822</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.832589</td>\n",
       "      <td>10-7_0-13.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.839657</td>\n",
       "      <td>0.825639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992850</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.834303</td>\n",
       "      <td>10-6_23-17.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.836006</td>\n",
       "      <td>0.832607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993123</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.835769</td>\n",
       "      <td>10-7_3-48.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.863939</td>\n",
       "      <td>0.809379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993167</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.837307</td>\n",
       "      <td>10-7_1-34.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.862775</td>\n",
       "      <td>0.813298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993155</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.837493</td>\n",
       "      <td>10-7_2-27.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.815912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.993026</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.837597</td>\n",
       "      <td>10-7_0-52.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.843391</td>\n",
       "      <td>0.831882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.993123</td>\n",
       "      <td>318618.0</td>\n",
       "      <td>0.838434</td>\n",
       "      <td>10-6_22-33.dill</td>\n",
       "      <td>6888.0</td>\n",
       "      <td>0.851941</td>\n",
       "      <td>0.825348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  data_points  f1_score            fname  num_codes  precision  \\\n",
       "2  0.992697     318618.0  0.826796   10-6_21-1.dill     6888.0   0.848327   \n",
       "3  0.992806     318618.0  0.830973   10-7_2-59.dill     6888.0   0.844424   \n",
       "4  0.992822     318618.0  0.832589   10-7_0-13.dill     6888.0   0.839657   \n",
       "1  0.992850     318618.0  0.834303  10-6_23-17.dill     6888.0   0.836006   \n",
       "8  0.993123     318618.0  0.835769   10-7_3-48.dill     6888.0   0.863939   \n",
       "7  0.993167     318618.0  0.837307   10-7_1-34.dill     6888.0   0.862775   \n",
       "0  0.993155     318618.0  0.837493   10-7_2-27.dill     6888.0   0.860248   \n",
       "5  0.993026     318618.0  0.837597   10-7_0-52.dill     6888.0   0.843391   \n",
       "6  0.993123     318618.0  0.838434  10-6_22-33.dill     6888.0   0.851941   \n",
       "\n",
       "     recall  \n",
       "2  0.806330  \n",
       "3  0.817944  \n",
       "4  0.825639  \n",
       "1  0.832607  \n",
       "8  0.809379  \n",
       "7  0.813298  \n",
       "0  0.815912  \n",
       "5  0.831882  \n",
       "6  0.825348  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ysbytag = sc_ysbytag\n",
    "f2preds = dict()\n",
    "rows = []\n",
    "for f in perc_files:\n",
    "    with open(FOLDER + f, \"rb+\") as fin:\n",
    "        preds = dill.load(fin)\n",
    "    metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)[__MICRO_F1__]\n",
    "    metrics[\"fname\"] = f.split(\"2019-\")[-1]\n",
    "    rows.append(metrics)\n",
    "df = pd.DataFrame(rows).sort_values(\"f1_score\")\n",
    "df # 0.837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
