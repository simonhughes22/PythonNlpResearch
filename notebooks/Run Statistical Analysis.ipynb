{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE - Use Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "import dill\n",
    "import os\n",
    "\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from window_based_tagger_config import get_config\n",
    "from FindFiles import find_files\n",
    "from DirUtils import dir_exists\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_by_str(s, files, exclude=False):   \n",
    "    return  [f for f in files if (s in f) != exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "50\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(FOLDER)\n",
    "print(len(files))\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "print(len(files))\n",
    "files = filter_by_str(\"2019\", files, exclude=True)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_files = filter_by_str(\"_SC_\", files)\n",
    "cb_files = filter_by_str(\"_CB_\", files)\n",
    "len(cb_files), len(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = {\n",
    "    \"PERCEPTRON\":\"PERCEPTRON\",\n",
    "    \"WINDOW_CLASSIFIER\":\"WINDOW_CLASSIFIER\",\n",
    "    \"CRF\": \"_CRF_\",\n",
    "    \"HMM\" : \"_HMM_\",\n",
    "    \"RNN\" : \"_RNN_\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def load_predictions(input_files):\n",
    "    algo2preds = dict()\n",
    "    pred_files = filter_by_str(\"_PREDS\", input_files)\n",
    "    for algo_name, fltr in filters.items():\n",
    "        f_files = filter_by_str(fltr, pred_files)\n",
    "        assert len(f_files) == 1\n",
    "        fname = FOLDER + f_files[0]\n",
    "        with open(fname, \"rb+\") as f:\n",
    "            algo2preds[algo_name] = dill.load(f)\n",
    "    return algo2preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb_preds = load_predictions(cb_files)\n",
    "# sc_preds = load_predictions(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(FOLDER + \"TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    cb_ysbytag = dill.load(f)\n",
    "    \n",
    "with open(FOLDER + \"TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    sc_ysbytag = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_preds(predsbytag):\n",
    "    all_p = []\n",
    "    for k, vals in sorted(predsbytag.items(), key = lambda tpl: tpl[0]):\n",
    "        all_p.extend(vals)\n",
    "    return all_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb, alternative='two-sided'):\n",
    "    assert len(ysbytag.keys()) == len(predsbytaga.keys()), (len(ysbytag.keys()),len(predsbytaga.keys())) \n",
    "    assert len(ysbytag.keys()) == len(predsbytagb.keys()), (len(ysbytag.keys()),len(predsbytagb.keys())) \n",
    "\n",
    "    first = list(ysbytag.keys())[0]\n",
    "    assert len(ysbytag[first]) == len(predsbytaga[first])\n",
    "    assert len(ysbytag[first]) == len(predsbytagb[first])\n",
    "\n",
    "    ys = get_all_preds(ysbytag)\n",
    "    aas = get_all_preds(predsbytaga)\n",
    "    bbs = get_all_preds(predsbytagb)\n",
    "\n",
    "    assert len(ys) == len(aas) == len(bbs)\n",
    "\n",
    "    successes = defaultdict(int)\n",
    "    for y,a,b in zip(ys,aas,bbs):    \n",
    "        if a != b:\n",
    "            if a == y:\n",
    "                successes[\"a\"] += 1\n",
    "            else:\n",
    "                successes[\"b\"] += 1\n",
    "\n",
    "    p_value = stats.binom_test(successes[\"a\"], sum(successes.values()), p=0.5, alternative=alternative)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Predicted Tags from Labelled Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(tag, expected_tag_set):\n",
    "    if tag in expected_tag_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_wd_level_lbs(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sent in e.sentences:\n",
    "            for wd, tag_set in sent:\n",
    "                for etag in expected_tags:\n",
    "                    ysbycode[etag].append(get_label(etag, tag_set))\n",
    "    return ysbycode    \n",
    "\n",
    "# for pred tags\n",
    "def get_wd_level_preds(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sentix in range(len(e.sentences)):\n",
    "            p_ccodes = e.pred_tagged_sentences[sentix]            \n",
    "            for wordix in range(len(p_ccodes)):\n",
    "                ptag_set = set([p_ccodes[wordix]])\n",
    "                assert len(ptag_set) >=1, \"No tags found\"\n",
    "                for exp_tag in expected_tags:\n",
    "                    ysbycode[exp_tag].append(get_label(exp_tag, ptag_set))    \n",
    "    return ysbycode  \n",
    "\n",
    "def compute_metrics_from_essays(tagged_esssays, expected_tags):\n",
    "    #TODO - get predicted ccodes and anaphora labels, merge into one set of preds and filter by expected_tags.\n",
    "    # this give flexibility to look at anaphora, cc or both\n",
    "    act_ys_bycode  = get_wd_level_lbs(  tagged_esssays, expected_tags)\n",
    "    pred_ys_bycode = get_wd_level_preds(tagged_esssays, expected_tags)\n",
    "\n",
    "    assert len(act_ys_bycode.keys()) == len(pred_ys_bycode.keys()) == len(expected_tags), \"Miss-matched codes\"\n",
    "    first_tag = list(expected_tags)[0]\n",
    "    last_tag  = list(expected_tags)[-1]\n",
    "    assert len(act_ys_bycode[first_tag]) == len(pred_ys_bycode[first_tag]), \"Different numbers of words\"\n",
    "    assert len(act_ys_bycode[last_tag])  == len(pred_ys_bycode[last_tag]), \"Different numbers of words\"\n",
    "\n",
    "    #print(len(act_ys_bycode), len(act_ys_bycode[first_tag]), len(pred_ys_bycode), len(pred_ys_bycode[first_tag]))\n",
    "    \n",
    "#     metrics = ResultsProcessor.compute_metrics(act_ys_bycode, pred_ys_bycode)\n",
    "    mean_metrics = ResultsProcessor.compute_mean_metrics(act_ys_bycode, pred_ys_bycode)\n",
    "    return mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    cb_essays = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    sc_essays = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cb_preds[\"RNN\"] = get_wd_level_preds(cb_essays, cb_ysbytag.keys())\n",
    "# sc_preds[\"RNN\"] = get_wd_level_preds(sc_essays, sc_ysbytag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_comparison(ysbytag, algo2preds):\n",
    "    algo2metrics = {}\n",
    "    for algo, preds in algo2preds.items():\n",
    "        mean_metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)\n",
    "        algo2metrics[algo] = mean_metrics[__MICRO_F1__]\n",
    "\n",
    "    matrix = dict()\n",
    "    for algo_name_a, predsbytaga in algo2preds.items():\n",
    "        for algo_name_b, predsbytagb in algo2preds.items():\n",
    "            if algo_name_a == algo_name_b:\n",
    "                continue\n",
    "            f1_a = algo2metrics[algo_name_a][\"f1_score\"]\n",
    "            f1_b = algo2metrics[algo_name_b][\"f1_score\"]\n",
    "            pval = compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb)\n",
    "            print(f\"{algo_name_a.ljust(20)} {f1_a:.4f}\\t{algo_name_b.ljust(20)} {f1_b:.4f}\\t {pval}\")\n",
    "            matrix[(algo_name_a, algo_name_b)] = pval\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCEPTRON           0.8399\tWINDOW_CLASSIFIER    0.8413\t 0.5990715121670374\n",
      "PERCEPTRON           0.8399\tCRF                  0.8380\t 0.3953317058722892\n",
      "PERCEPTRON           0.8399\tHMM                  0.7471\t 1.840272414942264e-204\n",
      "PERCEPTRON           0.8399\tRNN                  0.8422\t 0.46371986491039574\n",
      "\n",
      "WINDOW_CLASSIFIER    0.8413\tPERCEPTRON           0.8399\t 0.5990715121670374\n",
      "WINDOW_CLASSIFIER    0.8413\tCRF                  0.8380\t 0.16554440323794242\n",
      "WINDOW_CLASSIFIER    0.8413\tHMM                  0.7471\t 6.539263608822287e-216\n",
      "WINDOW_CLASSIFIER    0.8413\tRNN                  0.8422\t 0.23461093020583862\n",
      "\n",
      "CRF                  0.8380\tPERCEPTRON           0.8399\t 0.3953317058722892\n",
      "CRF                  0.8380\tWINDOW_CLASSIFIER    0.8413\t 0.16554440323794242\n",
      "CRF                  0.8380\tHMM                  0.7471\t 3.4081766479273455e-186\n",
      "CRF                  0.8380\tRNN                  0.8422\t 0.9570199756080899\n",
      "\n",
      "HMM                  0.7471\tPERCEPTRON           0.8399\t 1.840272414942264e-204\n",
      "HMM                  0.7471\tWINDOW_CLASSIFIER    0.8413\t 6.539263608822287e-216\n",
      "HMM                  0.7471\tCRF                  0.8380\t 3.4081766479273455e-186\n",
      "HMM                  0.7471\tRNN                  0.8422\t 1.265374305879553e-188\n",
      "\n",
      "RNN                  0.8422\tPERCEPTRON           0.8399\t 0.46371986491039574\n",
      "RNN                  0.8422\tWINDOW_CLASSIFIER    0.8413\t 0.23461093020583862\n",
      "RNN                  0.8422\tCRF                  0.8380\t 0.9570199756080899\n",
      "RNN                  0.8422\tHMM                  0.7471\t 1.265374305879553e-188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_comparison(cb_ysbytag, cb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERCEPTRON           0.8064\tWINDOW_CLASSIFIER    0.8144\t 0.02561138530508483\n",
      "PERCEPTRON           0.8064\tCRF                  0.8043\t 0.4171435908787128\n",
      "PERCEPTRON           0.8064\tHMM                  0.6754\t 1.8570135796000486e-301\n",
      "PERCEPTRON           0.8064\tRNN                  0.7894\t 1.508910809355667e-36\n",
      "\n",
      "WINDOW_CLASSIFIER    0.8144\tPERCEPTRON           0.8064\t 0.02561138530508483\n",
      "WINDOW_CLASSIFIER    0.8144\tCRF                  0.8043\t 0.003608884280891862\n",
      "WINDOW_CLASSIFIER    0.8144\tHMM                  0.6754\t 0.0\n",
      "WINDOW_CLASSIFIER    0.8144\tRNN                  0.7894\t 1.6224648439134976e-47\n",
      "\n",
      "CRF                  0.8043\tPERCEPTRON           0.8064\t 0.4171435908787128\n",
      "CRF                  0.8043\tWINDOW_CLASSIFIER    0.8144\t 0.003608884280891862\n",
      "CRF                  0.8043\tHMM                  0.6754\t 3.4009044173226684e-281\n",
      "CRF                  0.8043\tRNN                  0.7894\t 4.478991686048078e-32\n",
      "\n",
      "HMM                  0.6754\tPERCEPTRON           0.8064\t 1.8570135796000486e-301\n",
      "HMM                  0.6754\tWINDOW_CLASSIFIER    0.8144\t 0.0\n",
      "HMM                  0.6754\tCRF                  0.8043\t 3.4009044173226684e-281\n",
      "HMM                  0.6754\tRNN                  0.7894\t 5.895410863876102e-148\n",
      "\n",
      "RNN                  0.7894\tPERCEPTRON           0.8064\t 1.508910809355667e-36\n",
      "RNN                  0.7894\tWINDOW_CLASSIFIER    0.8144\t 1.6224648439134976e-47\n",
      "RNN                  0.7894\tCRF                  0.8043\t 4.478991686048078e-32\n",
      "RNN                  0.7894\tHMM                  0.6754\t 5.895410863876102e-148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_comparison(sc_ysbytag, sc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
