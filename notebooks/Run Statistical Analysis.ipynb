{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE - Use Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "import dill\n",
    "import os\n",
    "\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from window_based_tagger_config import get_config\n",
    "from FindFiles import find_files\n",
    "from DirUtils import dir_exists\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_by_str(s, files, exclude=False):   \n",
    "    return  [f for f in files if (s in f) != exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "58\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "print(len(all_files))\n",
    "files = filter_by_str(\"_VD_\", all_files)\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "print(len(files))\n",
    "files = filter_by_str(\"2019\", files, exclude=True)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_CRF_MOST_COMMON_TAG_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_FIXED_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_RNN_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_CRF_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_HMM_MOST_COMMON_TAG_MULTICLASS_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_RNN_MOST_COMMON_TAG_YS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_PREDS_.dill',\n",
       " 'TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_files = filter_by_str(\"_SC_\", files)\n",
    "cb_files = filter_by_str(\"_CB_\", files)\n",
    "len(cb_files), len(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "filters = OrderedDict({\n",
    "    \"WINDOW_CLASSIFIER\":\"WINDOW_CLASSIFIER\",\n",
    "    \"CRF\": \"_CRF_\",\n",
    "    \"HMM\" : \"_HMM_\",\n",
    "    \"PERCEPTRON\":\"PERCEPTRON\",\n",
    "    \"RNN\" : \"_RNN_\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def load_predictions(input_files):\n",
    "    algo2preds = dict()\n",
    "    pred_files = filter_by_str(\"_PREDS\", input_files)\n",
    "    for algo_name, fltr in filters.items():\n",
    "        f_files = filter_by_str(fltr, pred_files)\n",
    "        assert len(f_files) == 1\n",
    "        fname = FOLDER + f_files[0]\n",
    "        with open(fname, \"rb+\") as f:\n",
    "            algo2preds[algo_name] = dill.load(f)\n",
    "    return algo2preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cb_preds = load_predictions(cb_files)\n",
    "sc_preds = load_predictions(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(FOLDER + \"TEST_CB_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    cb_ysbytag = dill.load(f)\n",
    "    \n",
    "with open(FOLDER + \"TEST_SC_TAGGING_VD_WINDOW_CLASSIFIER_MOST_COMMON_TAG_MULTICLASS_YS_.dill\", \"rb+\") as f:\n",
    "    sc_ysbytag = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_preds(predsbytag):\n",
    "    all_p = []\n",
    "    for k, vals in sorted(predsbytag.items(), key = lambda tpl: tpl[0]):\n",
    "        all_p.extend(vals)\n",
    "    return all_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb, alternative='two-sided'):\n",
    "    assert len(ysbytag.keys()) == len(predsbytaga.keys()), (len(ysbytag.keys()),len(predsbytaga.keys())) \n",
    "    assert len(ysbytag.keys()) == len(predsbytagb.keys()), (len(ysbytag.keys()),len(predsbytagb.keys())) \n",
    "\n",
    "    first = list(ysbytag.keys())[0]\n",
    "    assert len(ysbytag[first]) == len(predsbytaga[first])\n",
    "    assert len(ysbytag[first]) == len(predsbytagb[first])\n",
    "\n",
    "    ys = get_all_preds(ysbytag)\n",
    "    aas = get_all_preds(predsbytaga)\n",
    "    bbs = get_all_preds(predsbytagb)\n",
    "\n",
    "    assert len(ys) == len(aas) == len(bbs)\n",
    "\n",
    "    successes = defaultdict(int)\n",
    "    for y,a,b in zip(ys,aas,bbs):    \n",
    "        if a != b:\n",
    "            if a == y:\n",
    "                successes[\"a\"] += 1\n",
    "            else:\n",
    "                successes[\"b\"] += 1\n",
    "\n",
    "    p_value = stats.binom_test(successes[\"a\"], sum(successes.values()), p=0.5, alternative=alternative)\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Predicted Tags from Labelled Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label(tag, expected_tag_set):\n",
    "    if tag in expected_tag_set:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_wd_level_lbs(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sent in e.sentences:\n",
    "            for wd, tag_set in sent:\n",
    "                for etag in expected_tags:\n",
    "                    ysbycode[etag].append(get_label(etag, tag_set))\n",
    "    return ysbycode    \n",
    "\n",
    "# for pred tags\n",
    "def get_wd_level_preds(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sentix in range(len(e.sentences)):\n",
    "            p_ccodes = e.pred_tagged_sentences[sentix]            \n",
    "            for wordix in range(len(p_ccodes)):\n",
    "                ptag_set = set([p_ccodes[wordix]])\n",
    "                assert len(ptag_set) >=1, \"No tags found\"\n",
    "                for exp_tag in expected_tags:\n",
    "                    ysbycode[exp_tag].append(get_label(exp_tag, ptag_set))    \n",
    "    return ysbycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    cb_essays = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "# used as inputs to parsing model\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    sc_essays = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cb_preds[\"RNN\"] = get_wd_level_preds(cb_essays, cb_ysbytag.keys())\n",
    "# sc_preds[\"RNN\"] = get_wd_level_preds(sc_essays, sc_ysbytag.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_comparison(ysbytag, algo2preds):\n",
    "    algo2metrics = {}\n",
    "    for algo, preds in algo2preds.items():\n",
    "        mean_metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)\n",
    "        algo2metrics[algo] = mean_metrics[__MICRO_F1__]\n",
    "\n",
    "    matrix = dict()\n",
    "    for algo_name_a, predsbytaga in algo2preds.items():\n",
    "        for algo_name_b, predsbytagb in algo2preds.items():\n",
    "            if algo_name_a == algo_name_b:\n",
    "                continue\n",
    "            f1_a = algo2metrics[algo_name_a][\"f1_score\"]\n",
    "            f1_b = algo2metrics[algo_name_b][\"f1_score\"]\n",
    "            pval = compute_p_value_binomial_test(ysbytag, predsbytaga, predsbytagb)\n",
    "            print(f\"{algo_name_a.ljust(20)} {f1_a:.4f}\\t{algo_name_b.ljust(20)} {f1_b:.4f}\\t {pval}\")\n",
    "            matrix[(algo_name_a, algo_name_b)] = pval\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    0.8413\tCRF                  0.8380\t 0.16554440323794242\n",
      "WINDOW_CLASSIFIER    0.8413\tHMM                  0.7471\t 6.539263608822287e-216\n",
      "WINDOW_CLASSIFIER    0.8413\tPERCEPTRON           0.8399\t 0.5990715121670374\n",
      "WINDOW_CLASSIFIER    0.8413\tRNN                  0.8422\t 0.23461093020583862\n",
      "\n",
      "CRF                  0.8380\tWINDOW_CLASSIFIER    0.8413\t 0.16554440323794242\n",
      "CRF                  0.8380\tHMM                  0.7471\t 3.4081766479273455e-186\n",
      "CRF                  0.8380\tPERCEPTRON           0.8399\t 0.3953317058722892\n",
      "CRF                  0.8380\tRNN                  0.8422\t 0.9570199756080899\n",
      "\n",
      "HMM                  0.7471\tWINDOW_CLASSIFIER    0.8413\t 6.539263608822287e-216\n",
      "HMM                  0.7471\tCRF                  0.8380\t 3.4081766479273455e-186\n",
      "HMM                  0.7471\tPERCEPTRON           0.8399\t 1.840272414942264e-204\n",
      "HMM                  0.7471\tRNN                  0.8422\t 1.265374305879553e-188\n",
      "\n",
      "PERCEPTRON           0.8399\tWINDOW_CLASSIFIER    0.8413\t 0.5990715121670374\n",
      "PERCEPTRON           0.8399\tCRF                  0.8380\t 0.3953317058722892\n",
      "PERCEPTRON           0.8399\tHMM                  0.7471\t 1.840272414942264e-204\n",
      "PERCEPTRON           0.8399\tRNN                  0.8422\t 0.46371986491039574\n",
      "\n",
      "RNN                  0.8422\tWINDOW_CLASSIFIER    0.8413\t 0.23461093020583862\n",
      "RNN                  0.8422\tCRF                  0.8380\t 0.9570199756080899\n",
      "RNN                  0.8422\tHMM                  0.7471\t 1.265374305879553e-188\n",
      "RNN                  0.8422\tPERCEPTRON           0.8399\t 0.46371986491039574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#perceptron and CRF differ somewhat from prior run\n",
    "print_comparison(cb_ysbytag, cb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOW_CLASSIFIER    0.8144\tCRF                  0.8043\t 0.003608884280891862\n",
      "WINDOW_CLASSIFIER    0.8144\tHMM                  0.6754\t 0.0\n",
      "WINDOW_CLASSIFIER    0.8144\tPERCEPTRON           0.8148\t 0.45153921840005645\n",
      "WINDOW_CLASSIFIER    0.8144\tRNN                  0.8268\t 0.001295431695570259\n",
      "\n",
      "CRF                  0.8043\tWINDOW_CLASSIFIER    0.8144\t 0.003608884280891862\n",
      "CRF                  0.8043\tHMM                  0.6754\t 3.4009044173226684e-281\n",
      "CRF                  0.8043\tPERCEPTRON           0.8148\t 0.0007131169075950804\n",
      "CRF                  0.8043\tRNN                  0.8268\t 7.617716382544424e-08\n",
      "\n",
      "HMM                  0.6754\tWINDOW_CLASSIFIER    0.8144\t 0.0\n",
      "HMM                  0.6754\tCRF                  0.8043\t 3.4009044173226684e-281\n",
      "HMM                  0.6754\tPERCEPTRON           0.8148\t 0.0\n",
      "HMM                  0.6754\tRNN                  0.8268\t 5e-324\n",
      "\n",
      "PERCEPTRON           0.8148\tWINDOW_CLASSIFIER    0.8144\t 0.45153921840005645\n",
      "PERCEPTRON           0.8148\tCRF                  0.8043\t 0.0007131169075950804\n",
      "PERCEPTRON           0.8148\tHMM                  0.6754\t 0.0\n",
      "PERCEPTRON           0.8148\tRNN                  0.8268\t 0.011130643902171012\n",
      "\n",
      "RNN                  0.8268\tWINDOW_CLASSIFIER    0.8144\t 0.001295431695570259\n",
      "RNN                  0.8268\tCRF                  0.8043\t 7.617716382544424e-08\n",
      "RNN                  0.8268\tHMM                  0.6754\t 5e-324\n",
      "RNN                  0.8268\tPERCEPTRON           0.8148\t 0.011130643902171012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RNN only differs\n",
    "print_comparison(sc_ysbytag, sc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Closest Perceptron Results for CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-6.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-6_22-22.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-5_9-43.dill',\n",
       " 'TEST_CB_TAGGING_VD_AVG_PERCEPTRON_MOST_COMMON_TAG_PREDS__2019-10-5_9-55.dill']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "perc_files = filter_by_str(\"_CB_\", all_files)\n",
    "perc_files = filter_by_str(\"_VD_\", perc_files)\n",
    "perc_files = filter_by_str(\"_PREDS_\", perc_files)\n",
    "perc_files = filter_by_str(\"_PERCEPTRON_\", perc_files)\n",
    "perc_files = filter_by_str(\"_2019\", perc_files)\n",
    "perc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>data_points</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fname</th>\n",
       "      <th>num_codes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994813</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.839932</td>\n",
       "      <td>10-5_9-55.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.884528</td>\n",
       "      <td>0.799617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994848</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.841529</td>\n",
       "      <td>10-5_9-43.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.883048</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994881</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.842786</td>\n",
       "      <td>10-6_22-6.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882799</td>\n",
       "      <td>0.806243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994898</td>\n",
       "      <td>399087.0</td>\n",
       "      <td>0.843409</td>\n",
       "      <td>10-6_22-22.dill</td>\n",
       "      <td>6792.0</td>\n",
       "      <td>0.882931</td>\n",
       "      <td>0.807273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  data_points  f1_score            fname  num_codes  precision  \\\n",
       "3  0.994813     399087.0  0.839932   10-5_9-55.dill     6792.0   0.884528   \n",
       "2  0.994848     399087.0  0.841529   10-5_9-43.dill     6792.0   0.883048   \n",
       "0  0.994881     399087.0  0.842786   10-6_22-6.dill     6792.0   0.882799   \n",
       "1  0.994898     399087.0  0.843409  10-6_22-22.dill     6792.0   0.882931   \n",
       "\n",
       "     recall  \n",
       "3  0.799617  \n",
       "2  0.803740  \n",
       "0  0.806243  \n",
       "1  0.807273  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ysbytag = cb_ysbytag\n",
    "f2preds = dict()\n",
    "rows = []\n",
    "for f in perc_files:\n",
    "    with open(FOLDER + f, \"rb+\") as fin:\n",
    "        preds = dill.load(fin)\n",
    "    metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)[__MICRO_F1__]\n",
    "    metrics[\"fname\"] = f.split(\"2019-\")[-1]\n",
    "    rows.append(metrics)\n",
    "df = pd.DataFrame(rows).sort_values(\"f1_score\")\n",
    "df # 0.837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
