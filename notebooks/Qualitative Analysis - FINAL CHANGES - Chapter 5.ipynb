{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE - Use Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pymongo\n",
    "import dill\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from window_based_tagger_config import get_config\n",
    "from FindFiles import find_files\n",
    "from DirUtils import dir_exists\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Predictions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_str(filters, files, exclude=False):\n",
    "    if type(filters) != list:\n",
    "        filters = [filters]\n",
    "    flt = files\n",
    "    for fltr in filters:\n",
    "        files = [f for f in files if (fltr in f) != exclude]\n",
    "    return  files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202\n",
      "163\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(FOLDER)\n",
    "print(len(all_files))\n",
    "files = list(all_files)\n",
    "# files = filter_by_str(\"_TAGGING_\", files, exclude=True)\n",
    "files = filter_by_str(\"_FINAL_RUN_\", files, exclude=True) # this is the sentence CREL parser (sentence level)\n",
    "files = filter_by_str(\"_TAGGING_\", files, exclude=True) # this is the sentence CREL parser (sentence level)\n",
    "files = filter_by_str(\"_STACKED_\", files, exclude=True) # this is the sentence CREL parser (sentence level)\n",
    "files = filter_by_str(\"_PA_\", files, exclude=True) # this is the sentence CREL parser (sentence level)\n",
    "# files = filter_by_str(\"_CR_\", files) \n",
    "files = filter_by_str(\"TEST_\", files)\n",
    "files = filter_by_str(\"_VD_\", files)\n",
    "print(len(files))\n",
    "files = filter_by_str(\"2019\", files, exclude=True)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD_PREDS__.dill',\n",
       " 'SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD_YS_.dill',\n",
       " 'SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD_2_PREDS_.dill',\n",
       " 'SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD_2_YS_.dill',\n",
       " 'TEST_CB_STR_PCPTRN_RE-RANKER_VD_PREDS.dill',\n",
       " 'TEST_CB_STR_PCPTRN_RE-RANKER_VD_YS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_PREDS__.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD_PREDS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD_YS_.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_PREDS__.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS_.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS__.dill',\n",
       " 'TEST_SC_STR_PCPTRN_RE-RANKER_VD_2_PREDS__.dill',\n",
       " 'TEST_SC_STR_PCPTRN_RE-RANKER_VD_2_YS_.dill']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_files = filter_by_str(\"_SC_\", files)\n",
    "cb_files = filter_by_str(\"_CB_\", files)\n",
    "len(cb_files), len(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD_YS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_VD_PREDS_.dill',\n",
       " 'SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD_YS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_PREDS__.dill',\n",
       " 'SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD_PREDS__.dill',\n",
       " 'TEST_CB_STR_PCPTRN_RE-RANKER_VD_YS_.dill',\n",
       " 'TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS_.dill',\n",
       " 'TEST_CB_STR_PCPTRN_RE-RANKER_VD_PREDS.dill']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD_2_PREDS_.dill',\n",
       " 'SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD_2_YS_.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS_.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_YS__.dill',\n",
       " 'TEST_SC_STR_PCPTRN_RE-RANKER_VD_2_YS_.dill',\n",
       " 'TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD_PREDS__.dill',\n",
       " 'TEST_SC_STR_PCPTRN_RE-RANKER_VD_2_PREDS__.dill']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "filters = OrderedDict({\n",
    "    \"SENT_PARSER\":  [\"SENT_\", \"_PARSER_\"],\n",
    "    \"ESSAY_PARSER\": \"SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2\",\n",
    "    \"RE-RANKER\":    \"STR_PCPTRN_RE-RANKER\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def load_predictions(input_files):\n",
    "    algo2preds = dict()\n",
    "    pred_files = filter_by_str(\"_PREDS\", input_files)\n",
    "    for algo_name, fltr in filters.items():\n",
    "        f_files = filter_by_str(fltr, pred_files)\n",
    "        assert len(f_files) == 1, (algo_name,f_files)\n",
    "        fname = FOLDER + f_files[0]\n",
    "        with open(fname, \"rb+\") as f:\n",
    "            algo2preds[algo_name] = dill.load(f)\n",
    "    return algo2preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = load_predictions(cb_files)\n",
    "sc_preds = load_predictions(sc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FOLDER + \"SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD_YS_.dill\", \"rb+\") as f:\n",
    "    cb_ysbytag = dill.load(f)\n",
    "    \n",
    "with open(FOLDER + \"SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD_2_YS_.dill\", \"rb+\") as f:\n",
    "    sc_ysbytag = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_preds(predsbytag, k_filter=None):\n",
    "    if k_filter is None:\n",
    "        k_filter = set(predsbytag.keys())\n",
    "    all_p = []\n",
    "    \n",
    "    for k, vals in sorted(predsbytag.items(), key = lambda tpl: tpl[0]):\n",
    "        if k not in k_filter:\n",
    "            continue\n",
    "        all_p.extend(vals)\n",
    "    return all_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Predicted Tags from Labelled Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comparison(ysbytag, algo2preds):\n",
    "    algo2metrics = {}\n",
    "    for algo, preds in algo2preds.items():\n",
    "        mean_metrics = ResultsProcessor.compute_mean_metrics(ysbytag, preds)\n",
    "        algo2metrics[algo] = mean_metrics[__MICRO_F1__]\n",
    "\n",
    "    for algo_name_a, predsbytaga in algo2preds.items():\n",
    "        f1_a = algo2metrics[algo_name_a][\"f1_score\"]\n",
    "        rec_a = algo2metrics[algo_name_a][\"recall\"]\n",
    "        prec_a = algo2metrics[algo_name_a][\"precision\"]\n",
    "        print(f\"{algo_name_a.ljust(20)} {f1_a:.4f} {rec_a:.4f} {prec_a:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT_PARSER          0.7366 0.7642 0.7109\n",
      "ESSAY_PARSER         0.7393 0.7258 0.7533\n",
      "RE-RANKER            0.7500 0.7404 0.7598\n"
     ]
    }
   ],
   "source": [
    "#perceptron and CRF differ somewhat from prior run\n",
    "print_comparison(cb_ysbytag, cb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT_PARSER          0.8271 0.7989 0.8573\n",
      "ESSAY_PARSER         0.8210 0.8165 0.8256\n",
      "RE-RANKER            0.8292 0.8055 0.8543\n"
     ]
    }
   ],
   "source": [
    "# RNN only differs\n",
    "print_comparison(sc_ysbytag, sc_preds)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:stats_test]",
   "language": "python",
   "name": "conda-env-stats_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
