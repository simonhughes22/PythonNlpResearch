{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from load_data import load_process_essays\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from window_based_tagger_config import get_config\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "data_set = \"SkinCancer\"\n",
    "# data_set = \"CoralBleaching\"\n",
    "\n",
    "root_folder = settings.data_directory + data_set + \"/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + data_set + \"/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/Bi-LSTM/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870 files found\n",
      "870 essays processed\n",
      "CPU times: user 29.2 s, sys: 425 ms, total: 29.7 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "train_essays = load_process_essays(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 files found\n",
      "218 essays processed\n",
      "CPU times: user 7.58 s, sys: 82.2 ms, total: 7.66 s\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = get_config(test_folder)\n",
    "test_essays = load_process_essays(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay_stats(essays, lbl):\n",
    "    tag_freq = defaultdict(int)\n",
    "    unique_words = set()\n",
    "    num_wds = 0\n",
    "    num_sents = 0\n",
    "    \n",
    "    for essay in essays:\n",
    "        for sentence in essay.sentences:\n",
    "            num_sents += 1\n",
    "            for word, tags in sentence:\n",
    "                num_wds += 1\n",
    "                unique_words.add(word)\n",
    "    return {\n",
    "        \"dataset\": lbl,\n",
    "        \"num_essays\": len(essays),\n",
    "        \"num_sents\": num_sents,\n",
    "        \"num_words\": num_wds,\n",
    "        \"vocab\": len(unique_words)        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_essays</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>870</td>\n",
       "      <td>8573</td>\n",
       "      <td>145471</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>218</td>\n",
       "      <td>2097</td>\n",
       "      <td>35402</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>1088</td>\n",
       "      <td>10670</td>\n",
       "      <td>180873</td>\n",
       "      <td>1623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  num_essays  num_sents  num_words  vocab\n",
       "0   train         870       8573     145471   1582\n",
       "1    test         218       2097      35402    899\n",
       "2     all        1088      10670     180873   1623"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_essays = train_essays + test_essays\n",
    "\n",
    "a = get_essay_stats(train_essays, \"train\")\n",
    "b = get_essay_stats(test_essays,  \"test\")\n",
    "c = get_essay_stats(all_essays,    \"all\")\n",
    "\n",
    "pd.DataFrame([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CB\n",
    "\n",
    "# dataset\t    num_essys\tnum_sents\tnum_words\tvocab\n",
    "# 0\ttrain\t    901     \t8280    \t136948  \t1641\n",
    "# 1\ttest\t    226     \t1918    \t30699   \t927\n",
    "# 2\tall     \t1127    \t10198   \t167647  \t1677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC\n",
    "\n",
    "# dataset\tnum_essays\tnum_sents\tnum_words\tvocab\n",
    "# 0\ttrain\t870     \t8573    \t145471  \t1582\n",
    "# 1\ttest\t218     \t2097    \t35402   \t899\n",
    "# 2\tall \t1088    \t10670   \t180873  \t1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
