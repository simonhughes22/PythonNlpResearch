{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from load_data import load_process_essays\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"CoralBleaching\"\n",
    "# DATASET = \"SkinCancer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 files found\n",
      "901 essays processed\n"
     ]
    }
   ],
   "source": [
    "folder = settings.data_directory + DATASET + \"/Thesis_Dataset/Training\"\n",
    "br_train_essays = load_bratt_essays(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 files found\n",
      "226 essays processed\n"
     ]
    }
   ],
   "source": [
    "folder = settings.data_directory + DATASET + \"/Thesis_Dataset/Test\"\n",
    "br_test_essays = load_bratt_essays(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1127"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br_essays = br_train_essays + br_test_essays\n",
    "len(br_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from window_based_tagger_config import get_config\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "# data_set = \"SkinCancer\"\n",
    "data_set = \"CoralBleaching\"\n",
    "\n",
    "root_folder = settings.data_directory + data_set + \"/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + data_set + \"/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/Bi-LSTM/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 files found\n",
      "901 essays processed\n",
      "CPU times: user 43.3 s, sys: 203 ms, total: 43.5 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "train_essays = load_process_essays(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 files found\n",
      "226 essays processed\n",
      "CPU times: user 14.8 s, sys: 95.2 ms, total: 14.9 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config = get_config(test_folder)\n",
    "test_essays = load_process_essays(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import BrattEssay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essay_stats(essays, lbl):\n",
    "    tag_freq = defaultdict(int)\n",
    "    unique_words = set()\n",
    "    num_wds = 0\n",
    "    num_sents = 0\n",
    "    \n",
    "    is_bratt_essay = (type(essays[0]) == BrattEssay.Essay)\n",
    "    if is_bratt_essay:\n",
    "        get_sents = lambda e: e.tagged_sentences\n",
    "    else:\n",
    "        get_sents = lambda e: e.sentences\n",
    "    \n",
    "    for essay in essays:\n",
    "        for sentence in get_sents(essay):\n",
    "            num_sents += 1\n",
    "            for word, tags in sentence:\n",
    "                num_wds += 1\n",
    "                unique_words.add(word)\n",
    "    return {\n",
    "        \"dataset\": lbl,\n",
    "        \"num_essays\": len(essays),\n",
    "        \"num_sents\": num_sents,\n",
    "        \"num_words\": num_wds,\n",
    "        \"vocab\": len(unique_words)        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_essays</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>901</td>\n",
       "      <td>8280</td>\n",
       "      <td>136948</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>226</td>\n",
       "      <td>1918</td>\n",
       "      <td>30699</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>1127</td>\n",
       "      <td>10198</td>\n",
       "      <td>167647</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  num_essays  num_sents  num_words  vocab\n",
       "0   train         901       8280     136948   1641\n",
       "1    test         226       1918      30699    927\n",
       "2     all        1127      10198     167647   1677"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_essays = train_essays + test_essays\n",
    "\n",
    "a = get_essay_stats(train_essays, \"train\")\n",
    "b = get_essay_stats(test_essays,  \"test\")\n",
    "c = get_essay_stats(all_essays,    \"all\")\n",
    "\n",
    "pd.DataFrame([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1127, 1127)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_essays), len(br_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = br_essays[0]\n",
    "# e.tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_essays</th>\n",
       "      <th>num_sents</th>\n",
       "      <th>num_words</th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bratt Essays</td>\n",
       "      <td>1127</td>\n",
       "      <td>10198</td>\n",
       "      <td>167656</td>\n",
       "      <td>4770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  num_essays  num_sents  num_words  vocab\n",
       "0  Bratt Essays        1127      10198     167656   4770"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([get_essay_stats(br_essays, \"Bratt Essays\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CB\n",
    "\n",
    "# dataset\t    num_essys\tnum_sents\tnum_words\tvocab\n",
    "# 0\ttrain\t    901     \t8280    \t136948  \t1641\n",
    "# 1\ttest\t    226     \t1918    \t30699   \t927\n",
    "# 2\tall     \t1127    \t10198   \t167647  \t1677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC\n",
    "\n",
    "# dataset\tnum_essays\tnum_sents\tnum_words\tvocab\n",
    "# 0\ttrain\t870     \t8573    \t145471  \t1582\n",
    "# 1\ttest\t218     \t2097    \t35402   \t899\n",
    "# 2\tall \t1088    \t10670   \t180873  \t1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
