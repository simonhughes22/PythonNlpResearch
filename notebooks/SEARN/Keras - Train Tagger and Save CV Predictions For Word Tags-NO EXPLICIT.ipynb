{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is based on this code: https://github.com/codekansas/keras-language-modeling/blob/master/keras_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Check mongo is running\n",
    "import pymongo\n",
    "client = pymongo.MongoClient()\n",
    "db = client.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Note - To Get this working:\n",
    "\n",
    "* Install CUDA and associated libraries, setup path\n",
    "* Install bleeding edge theano (from src)\n",
    "* Make sure the THEANO_FLAGS are set correctly via the environment var, or via the ~/.theanorc file\n",
    "* Install and compile bleeding edge Keras (from src)\n",
    "* `export KERAS_BACKEND=theano`\n",
    "* `export KERAS_IMAGE_DIM_ORDERING='th'`\n",
    "* `sh <project_root>/shell_scipts/setup_environment.sh` to install additional dependencies\n",
    "* **DO NOT SET UNROLL=True** when creating RNN's - causes max recursion issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trouble-Shooting\n",
    "\n",
    "* You may need to clean the theano cache. To do so thoroughly, run this command from the shell:\n",
    " * `theano-cache purge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import dill\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, TimeDistributedDense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from Metrics import rpf1\n",
    "from load_data import load_process_essays\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from IdGenerator import IdGenerator as idGen\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Rpfa import micro_rpfa\n",
    "from collections import defaultdict\n",
    "\n",
    "import Settings\n",
    "import logging\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from Settings import Settings\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/Bi-LSTM-4-SEARN/\"\n",
    "predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "cv_folder = root_folder + \"CV_Data_Pickled_SEARN/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "processor = ResultsProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/Bi-LSTM-4-SEARN/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_folder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "tagged_essays_tmp = load_process_essays(**config)\n",
    "\n",
    "with open(training_pickled, \"wb+\") as f:\n",
    "    pickle.dump(tagged_essays_tmp, f)\n",
    "del tagged_essays_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 files found\n",
      "226 essays processed\n"
     ]
    }
   ],
   "source": [
    "test_config = get_config(test_folder)\n",
    "tagged_essays_test = load_process_essays(**test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2018-01-08 08:52:36.294596\n"
     ]
    }
   ],
   "source": [
    "import datetime, logging\n",
    "print(\"Started at: \" + str(datetime.datetime.now()))\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "#shuffle(tagged_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677, 88)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit()))\n",
    "#regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit() or t == \"explicit\"))\n",
    "cr_tags = list((t for t in tag_freq.keys() if ( \"->\" in t) and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "\n",
    "vtags = set(regular_tags)\n",
    "vtags.add(EMPTY_TAG)\n",
    "\n",
    "len(unique_words), len(cr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '11', '12', '13', '14', '2', '3', '4', '5', '50', '5b', '6', '7']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(regular_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '5b',\n",
       " '6',\n",
       " '7',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Transform Essays into Training Data (Word Ids)\n",
    "\n",
    "* Computes `xs`, `ys`, `ys_bytag` and `seq_lens`\n",
    "* `ys_bytag` includes **all tags** and does **not** focus only on the most common tag\n",
    "* `ys` only includes the most common tag (so we can use cross entropy)\n",
    "* `seq_lens` is without the start and end tags included (so we have to map back and forth to maintain mappings)\n",
    "* `ys_bytag` also excludes the START and END tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get Max Sequence Length, Generate All Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2tag = {}\n",
    "for ix, t in enumerate(vtags):\n",
    "    ix2tag[ix] = t\n",
    "    \n",
    "generator = idGen(seed=1) # important as we zero pad sequences\n",
    "\n",
    "maxlen = 0\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "        \n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "\n",
    "def ids2tags(ids):\n",
    "    return [generator.get_key(j) for j in ids]\n",
    "\n",
    "def lbls2tags(ixs):\n",
    "    return [ix2tag[ix] for ix in ixs]\n",
    "        \n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1                             ', '1'),\n",
       " ('11                            ', '11'),\n",
       " ('12                            ', '12'),\n",
       " ('13                            ', '13'),\n",
       " ('14                            ', '14'),\n",
       " ('2                             ', '2'),\n",
       " ('3                             ', '3'),\n",
       " ('4                             ', '4'),\n",
       " ('5                             ', '5'),\n",
       " ('50                            ', '50'),\n",
       " ('5b                            ', '5b'),\n",
       " ('6                             ', '6'),\n",
       " ('7                             ', '7'),\n",
       " ('Anaphor                       ', 'Anaphor'),\n",
       " ('COMPILED                      ', 'COMPILED'),\n",
       " ('Causer                        ', 'Causer'),\n",
       " ('Causer:1                      ', '1'),\n",
       " ('Causer:1->Result:11           ', '1->11'),\n",
       " ('Causer:1->Result:13           ', '1->13'),\n",
       " ('Causer:1->Result:14           ', '1->14'),\n",
       " ('Causer:1->Result:2            ', '1->2'),\n",
       " ('Causer:1->Result:3            ', '1->3'),\n",
       " ('Causer:1->Result:4            ', '1->4'),\n",
       " ('Causer:1->Result:5            ', '1->5'),\n",
       " ('Causer:1->Result:50           ', '1->50'),\n",
       " ('Causer:1->Result:6            ', '1->6'),\n",
       " ('Causer:1->Result:7            ', '1->7'),\n",
       " ('Causer:1->Result:Anaphor      ', '1->Anaphor'),\n",
       " ('Causer:1->Result:other        ', '1->other'),\n",
       " ('Causer:1->Result:rhetorical   ', '1->rhetorical'),\n",
       " ('Causer:11                     ', '11'),\n",
       " ('Causer:11->Result:11          ', '11->11'),\n",
       " ('Causer:11->Result:12          ', '11->12'),\n",
       " ('Causer:11->Result:13          ', '11->13'),\n",
       " ('Causer:11->Result:14          ', '11->14'),\n",
       " ('Causer:11->Result:3           ', '11->3'),\n",
       " ('Causer:11->Result:4           ', '11->4'),\n",
       " ('Causer:11->Result:50          ', '11->50'),\n",
       " ('Causer:11->Result:6           ', '11->6'),\n",
       " ('Causer:11->Result:Anaphor     ', '11->Anaphor'),\n",
       " ('Causer:11->Result:rhetorical  ', '11->rhetorical'),\n",
       " ('Causer:12                     ', '12'),\n",
       " ('Causer:12->Result:11          ', '12->11'),\n",
       " ('Causer:12->Result:13          ', '12->13'),\n",
       " ('Causer:12->Result:14          ', '12->14'),\n",
       " ('Causer:12->Result:50          ', '12->50'),\n",
       " ('Causer:12->Result:5b          ', '12->5b'),\n",
       " ('Causer:12->Result:7           ', '12->7'),\n",
       " ('Causer:13                     ', '13'),\n",
       " ('Causer:13->Result:11          ', '13->11'),\n",
       " ('Causer:13->Result:12          ', '13->12'),\n",
       " ('Causer:13->Result:14          ', '13->14'),\n",
       " ('Causer:13->Result:4           ', '13->4'),\n",
       " ('Causer:13->Result:5           ', '13->5'),\n",
       " ('Causer:13->Result:50          ', '13->50'),\n",
       " ('Causer:13->Result:6           ', '13->6'),\n",
       " ('Causer:13->Result:7           ', '13->7'),\n",
       " ('Causer:13->Result:Anaphor     ', '13->Anaphor'),\n",
       " ('Causer:13->Result:rhetorical  ', '13->rhetorical'),\n",
       " ('Causer:14                     ', '14'),\n",
       " ('Causer:14->Result:50          ', '14->50'),\n",
       " ('Causer:14->Result:6           ', '14->6'),\n",
       " ('Causer:14->Result:7           ', '14->7'),\n",
       " ('Causer:14->Result:rhetorical  ', '14->rhetorical'),\n",
       " ('Causer:2                      ', '2'),\n",
       " ('Causer:2->Result:1            ', '2->1'),\n",
       " ('Causer:2->Result:3            ', '2->3'),\n",
       " ('Causer:2->Result:50           ', '2->50'),\n",
       " ('Causer:2->Result:6            ', '2->6'),\n",
       " ('Causer:2->Result:Anaphor      ', '2->Anaphor'),\n",
       " ('Causer:3                      ', '3'),\n",
       " ('Causer:3->Result:1            ', '3->1'),\n",
       " ('Causer:3->Result:13           ', '3->13'),\n",
       " ('Causer:3->Result:14           ', '3->14'),\n",
       " ('Causer:3->Result:2            ', '3->2'),\n",
       " ('Causer:3->Result:4            ', '3->4'),\n",
       " ('Causer:3->Result:5            ', '3->5'),\n",
       " ('Causer:3->Result:50           ', '3->50'),\n",
       " ('Causer:3->Result:5b           ', '3->5b'),\n",
       " ('Causer:3->Result:6            ', '3->6'),\n",
       " ('Causer:3->Result:7            ', '3->7'),\n",
       " ('Causer:3->Result:Anaphor      ', '3->Anaphor'),\n",
       " ('Causer:3->Result:rhetorical   ', '3->rhetorical'),\n",
       " ('Causer:4                      ', '4'),\n",
       " ('Causer:4->Result:11           ', '4->11'),\n",
       " ('Causer:4->Result:13           ', '4->13'),\n",
       " ('Causer:4->Result:14           ', '4->14'),\n",
       " ('Causer:4->Result:3            ', '4->3'),\n",
       " ('Causer:4->Result:5            ', '4->5'),\n",
       " ('Causer:4->Result:50           ', '4->50'),\n",
       " ('Causer:4->Result:5b           ', '4->5b'),\n",
       " ('Causer:4->Result:6            ', '4->6'),\n",
       " ('Causer:4->Result:7            ', '4->7'),\n",
       " ('Causer:4->Result:Anaphor      ', '4->Anaphor'),\n",
       " ('Causer:4->Result:Change-factor', '4->Change-factor'),\n",
       " ('Causer:4->Result:rhetorical   ', '4->rhetorical'),\n",
       " ('Causer:5                      ', '5'),\n",
       " ('Causer:5->Result:11           ', '5->11'),\n",
       " ('Causer:5->Result:13           ', '5->13'),\n",
       " ('Causer:5->Result:14           ', '5->14'),\n",
       " ('Causer:5->Result:3            ', '5->3'),\n",
       " ('Causer:5->Result:4            ', '5->4'),\n",
       " ('Causer:5->Result:50           ', '5->50'),\n",
       " ('Causer:5->Result:5b           ', '5->5b'),\n",
       " ('Causer:5->Result:7            ', '5->7'),\n",
       " ('Causer:5->Result:Anaphor      ', '5->Anaphor'),\n",
       " ('Causer:5->Result:rhetorical   ', '5->rhetorical'),\n",
       " ('Causer:50                     ', '50'),\n",
       " ('Causer:50->Result:1           ', '50->1'),\n",
       " ('Causer:50->Result:3           ', '50->3'),\n",
       " ('Causer:50->Result:50          ', '50->50'),\n",
       " ('Causer:50->Result:7           ', '50->7'),\n",
       " ('Causer:50->Result:other       ', '50->other'),\n",
       " ('Causer:50->Result:rhetorical  ', '50->rhetorical'),\n",
       " ('Causer:5b                     ', '5b'),\n",
       " ('Causer:5b->Result:14          ', '5b->14'),\n",
       " ('Causer:5b->Result:5           ', '5b->5'),\n",
       " ('Causer:5b->Result:50          ', '5b->50'),\n",
       " ('Causer:5b->Result:7           ', '5b->7'),\n",
       " ('Causer:5b->Result:Anaphor     ', '5b->Anaphor'),\n",
       " ('Causer:5b->Result:rhetorical  ', '5b->rhetorical'),\n",
       " ('Causer:6                      ', '6'),\n",
       " ('Causer:6->Result:14           ', '6->14'),\n",
       " ('Causer:6->Result:5            ', '6->5'),\n",
       " ('Causer:6->Result:50           ', '6->50'),\n",
       " ('Causer:6->Result:5b           ', '6->5b'),\n",
       " ('Causer:6->Result:7            ', '6->7'),\n",
       " ('Causer:6->Result:Anaphor      ', '6->Anaphor'),\n",
       " ('Causer:6->Result:other        ', '6->other'),\n",
       " ('Causer:6->Result:rhetorical   ', '6->rhetorical'),\n",
       " ('Causer:7                      ', '7'),\n",
       " ('Causer:7->Result:1            ', '7->1'),\n",
       " ('Causer:7->Result:13           ', '7->13'),\n",
       " ('Causer:7->Result:14           ', '7->14'),\n",
       " ('Causer:7->Result:4            ', '7->4'),\n",
       " ('Causer:7->Result:5            ', '7->5'),\n",
       " ('Causer:7->Result:50           ', '7->50'),\n",
       " ('Causer:7->Result:5b           ', '7->5b'),\n",
       " ('Causer:7->Result:Anaphor      ', '7->Anaphor'),\n",
       " ('Causer:7->Result:rhetorical   ', '7->rhetorical'),\n",
       " ('Causer:Anaphor                ', 'Anaphor'),\n",
       " ('Causer:Anaphor->Result:11     ', 'Anaphor->11'),\n",
       " ('Causer:Anaphor->Result:12     ', 'Anaphor->12'),\n",
       " ('Causer:Anaphor->Result:13     ', 'Anaphor->13'),\n",
       " ('Causer:Anaphor->Result:14     ', 'Anaphor->14'),\n",
       " ('Causer:Anaphor->Result:2      ', 'Anaphor->2'),\n",
       " ('Causer:Anaphor->Result:3      ', 'Anaphor->3'),\n",
       " ('Causer:Anaphor->Result:4      ', 'Anaphor->4'),\n",
       " ('Causer:Anaphor->Result:5      ', 'Anaphor->5'),\n",
       " ('Causer:Anaphor->Result:50     ', 'Anaphor->50'),\n",
       " ('Causer:Anaphor->Result:5b     ', 'Anaphor->5b'),\n",
       " ('Causer:Anaphor->Result:6      ', 'Anaphor->6'),\n",
       " ('Causer:Anaphor->Result:7      ', 'Anaphor->7'),\n",
       " ('Causer:Anaphor->Result:Anaphor', 'Anaphor->Anaphor'),\n",
       " ('Causer:Anaphor->Result:other  ', 'Anaphor->other'),\n",
       " ('Causer:Anaphor->Result:rhetorical', 'Anaphor->rhetorical'),\n",
       " ('Causer:Change-factor          ', 'Change-factor'),\n",
       " ('Causer:Change-factor->Result:50', 'Change-factor->50'),\n",
       " ('Causer:other                  ', 'other'),\n",
       " ('Causer:other->Result:3        ', 'other->3'),\n",
       " ('Causer:other->Result:50       ', 'other->50'),\n",
       " ('Causer:other->Result:6        ', 'other->6'),\n",
       " ('Causer:other->Result:7        ', 'other->7'),\n",
       " ('Causer:rhetorical             ', 'rhetorical'),\n",
       " ('Causer:rhetorical->Result:5   ', 'rhetorical->5'),\n",
       " ('Causer:rhetorical->Result:50  ', 'rhetorical->50'),\n",
       " ('Causer:rhetorical->Result:5b  ', 'rhetorical->5b'),\n",
       " ('Causer:rhetorical->Result:Anaphor', 'rhetorical->Anaphor'),\n",
       " ('Change-factor                 ', 'Change-factor'),\n",
       " ('Result                        ', 'Result'),\n",
       " ('Result:1                      ', '1'),\n",
       " ('Result:11                     ', '11'),\n",
       " ('Result:12                     ', '12'),\n",
       " ('Result:13                     ', '13'),\n",
       " ('Result:14                     ', '14'),\n",
       " ('Result:2                      ', '2'),\n",
       " ('Result:3                      ', '3'),\n",
       " ('Result:4                      ', '4'),\n",
       " ('Result:5                      ', '5'),\n",
       " ('Result:50                     ', '50'),\n",
       " ('Result:5b                     ', '5b'),\n",
       " ('Result:6                      ', '6'),\n",
       " ('Result:7                      ', '7'),\n",
       " ('Result:Anaphor                ', 'Anaphor'),\n",
       " ('Result:Change-factor          ', 'Change-factor'),\n",
       " ('Result:other                  ', 'other'),\n",
       " ('Result:rhetorical             ', 'rhetorical'),\n",
       " ('explicit                      ', 'explicit'),\n",
       " ('other                         ', 'other'),\n",
       " ('rhetorical                    ', 'rhetorical')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.ljust(30),t.replace(\"Causer:\",\"\").replace(\"Result:\",\"\")) for t in sorted(tag_freq.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "START = \"<start>\"\n",
    "END   = \"<end>\"\n",
    "\n",
    "def get_training_data(tessays):\n",
    "    # outputs\n",
    "    xs = []\n",
    "    ys = []\n",
    "    seq_lens = []\n",
    "    ys_bytag_concept_sent = defaultdict(list)\n",
    "\n",
    "    # cut texts after this number of words (among top max_features most common words)\n",
    "    for essay in tessays:\n",
    "        for sentence in essay.sentences:\n",
    "            row = []\n",
    "            y_found = False\n",
    "            y_seq = []\n",
    "            unique_tags = set() # get all unique tags in sentence\n",
    "            for word, tags in [(START, set())] + sentence + [(END, set())]:\n",
    "                id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "                row.append(id)\n",
    "                \n",
    "                # Make sure to include Causer:<num> and Result:<num> tags\n",
    "                tags = set([t.replace(\"Causer:\",\"\").replace(\"Result:\",\"\") for t in tags])\n",
    "                unique_tags.update(tags)\n",
    "                \n",
    "                # remove unwanted tags, filter to concept tags\n",
    "                concept_tags = vtags.intersection(tags)\n",
    "\n",
    "                # encode ys with most common tag only\n",
    "                if len(concept_tags) > 1:\n",
    "                    # if multiple, choose concept over explicit\n",
    "                    if \"explicit\" in concept_tags:\n",
    "                        concept_tags.remove(\"explicit\")\n",
    "                    most_common = max(concept_tags, key=lambda t: tag_freq[t])\n",
    "                    concept_tags = set([most_common])\n",
    "                if len(concept_tags) == 0:\n",
    "                    concept_tags.add(EMPTY_TAG)\n",
    "\n",
    "                one_hot = []\n",
    "                for t in vtags:\n",
    "                    if t in concept_tags:\n",
    "                        one_hot.append(1)\n",
    "                    else:\n",
    "                        one_hot.append(0)\n",
    "                y_seq.append(one_hot)\n",
    "                #end for each word\n",
    "\n",
    "            # sentence level tags\n",
    "            for tag in vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_concept_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_concept_sent[tag].append(0)            \n",
    "            \n",
    "            seq_lens.append(len(row)-2)\n",
    "            ys.append(y_seq)\n",
    "            xs.append(row)\n",
    "    \n",
    "    xs = sequence.pad_sequences(xs, maxlen=maxlen)\n",
    "    ys = sequence.pad_sequences(ys, maxlen=maxlen)\n",
    "    assert xs.shape[0] == ys.shape[0], \"Sequences should have the same number of rows\"\n",
    "    assert xs.shape[1] == ys.shape[1] == maxlen, \"Sequences should have the same lengths\"\n",
    "    return xs, ys, ys_bytag_concept_sent, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        for pred_tag in pred_ys:\n",
    "            pred_ys_by_tag[pred_tag].append(1)\n",
    "            # for all other tags, a 0\n",
    "            for tag in(vtags - set([EMPTY_TAG, pred_tag])):\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results_sentence_level(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = set(pred_ys[1:-1])\n",
    "        for tag in vtags:\n",
    "            if tag == EMPTY_TAG:\n",
    "                continue\n",
    "            if tag in pred_ys:\n",
    "                pred_ys_by_tag[tag].append(1)\n",
    "            else:\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_dev_split(lst, dev_split, randomize=True):\n",
    "    # random shuffle\n",
    "    if randomize:\n",
    "        shuffle(lst)\n",
    "    num_training = int((1.0 - dev_split) * len(lst))\n",
    "    return lst[:num_training], lst[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', set()),\n",
       " ('leads', set()),\n",
       " ('to', set()),\n",
       " ('differences', set()),\n",
       " ('in', set()),\n",
       " ('the', set()),\n",
       " ('rates', set()),\n",
       " ('of', set()),\n",
       " ('coral', {'50'}),\n",
       " ('bleaching', {'50'}),\n",
       " ('.', set())]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tagged_essays[0]\n",
    "e.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.09 s, sys: 427 ms, total: 6.52 s\n",
      "Wall time: 6.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this name for a different function later\n",
    "from CrossValidation import cross_validation as cv\n",
    "\n",
    "folds = cv(tagged_essays, CV_FOLDS)\n",
    "fold2training_data = {}\n",
    "fold2dev_data = {}\n",
    "fold2test_data = {}\n",
    "\n",
    "fold2training_essays = {}\n",
    "fold2dev_essays = {}\n",
    "fold2test_essays = {}\n",
    "\n",
    "for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "    # further split into train and dev test\n",
    "    essays_train, essays_dev = train_dev_split(essays_TD, DEV_SPLIT)\n",
    "    fold2training_data[i] = get_training_data(essays_train)\n",
    "    fold2dev_data[i]      = get_training_data(essays_dev)\n",
    "    # Test Data\n",
    "    fold2test_data[i]     = get_training_data(essays_VD)\n",
    "    \n",
    "    # also store essays\n",
    "    fold2training_essays[i] = essays_train\n",
    "    fold2dev_essays[i]      = essays_dev\n",
    "    fold2test_essays[i]     = essays_VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make sure the generator is incremented on the test data too\n",
    "_,_,_,_ = get_training_data(tagged_essays)\n",
    "_,_,_,_ = get_training_data(tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(cv_folder + \"td.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_data, f)\n",
    "\n",
    "with open(cv_folder + \"td_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_essays, f)\n",
    "\n",
    "with open(cv_folder + \"devd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_data, f)\n",
    "\n",
    "with open(cv_folder + \"devd_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_essays, f)\n",
    "    \n",
    "with open(cv_folder + \"vd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_data, f)\n",
    "    \n",
    "with open(cv_folder + \"vd_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_essays, f)\n",
    "    \n",
    "with open(cv_folder + \"generator.dill\", \"wb\") as f:\n",
    "    dill.dump(generator, f)\n",
    "\n",
    "with open(cv_folder + \"vtags.dill\", \"wb\") as f:\n",
    "    dill.dump(vtags, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 'coral')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.get_id(\"coral\"), generator.get_key(generator.get_id(\"coral\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Glove 100 Dim Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# see /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/DeepLearning/WordVectors/pickle_glove_embedding.py\n",
    "# for creating pre-filtered embeddings file\n",
    "import pickle, os\n",
    "from numpy.linalg import norm\n",
    "\n",
    "embeddings_file = \"/Users/simon.hughes/data/word_embeddings/glove.6B/cb_dict_glove.6B.100d.txt\"\n",
    "# read data file\n",
    "with open(embeddings_file, \"rb+\") as f:\n",
    "    cb_emb_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 1677 2.5 %\n"
     ]
    }
   ],
   "source": [
    "missed = set()\n",
    "for wd in unique_words:\n",
    "    if wd not in cb_emb_index:\n",
    "        missed.add(wd)\n",
    "print(len(missed), len(unique_words), 100.0 * round(len(missed)/  len(unique_words),4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = list(cb_emb_index.values())[0].shape[0]\n",
    "\n",
    "def get_embedding_matrix(words, idgenerator, max_features, init='uniform', unit_length=False):\n",
    "    embedding_dim = list(cb_emb_index.values())[0].shape[0]\n",
    "    # initialize with a uniform distribution\n",
    "    if init == 'uniform':\n",
    "        # NOTE: the max norms for these is quite low relative to the embeddings\n",
    "        embedding_matrix = np.random.uniform(low=-0.05, high=0.05,size=(max_features, embedding_dim))\n",
    "    elif init =='zeros':\n",
    "        embedding_matrix = np.zeros(shape=(max_features, embedding_dim), dtype=np.float32)\n",
    "    elif init == 'normal':\n",
    "        embedding_matrix = np.random.normal(mean, sd, size=(max_features, embedding_dim))\n",
    "    else:\n",
    "        raise Exception(\"Unknown init type\")\n",
    "    for word in words:\n",
    "        i = idgenerator.get_id(word)\n",
    "        embedding_vector = cb_emb_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    if unit_length:\n",
    "        norms = np.linalg.norm(embedding_matrix, axis=1,keepdims=True)\n",
    "        # remove 0 norms to prevent divide by zero\n",
    "        norms[norms == 0.0] = 1.0\n",
    "        embedding_matrix = embedding_matrix / norms\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score_predictions(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict_classes(xs, batch_size=batch_size, verbose=0)   \n",
    "    pred_ys_by_tag = collapse_results_sentence_level(seq_len, preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pivot_predictions_to_dict(preds):\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(preds.shape[0]):\n",
    "        row = preds[i]\n",
    "        for tag_ix, pred in enumerate(row):\n",
    "            tag = ix2crtag[tag_ix]\n",
    "            pred_ys_by_tag[tag].append(pred)\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score_predictions_sent_level(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict(xs, batch_size=batch_size, verbose=0)\n",
    "    preds = np.where(preds >= 0.5, 1, 0)\n",
    "    pred_ys_by_tag = pivot_predictions_to_dict(preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2018-01-08 08:54:10.026083', '20180108_085410_026115')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from datetime import datetime\n",
    "\n",
    "def get_ts():\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "def get_file_ts():\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "\n",
    "embedding_size = EMBEDDING_DIM\n",
    "hidden_size    = 128\n",
    "out_size = len(vtags)\n",
    "batch_size = 128\n",
    "\n",
    "get_ts(), get_file_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Bi-Directional LSTM With Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_features=len(generator.get_ids())+2 #Need plus one maybe due to masking of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Models/Bi-LSTM-4-SEARN/fold_ix-0_bi_directional-True_hidden_size-128_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.h5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_signature(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    lcls = locals()\n",
    "    s = \"\"\n",
    "    for k, val in sorted(lcls.items(), key = lambda tpl: (0,tpl[0]) if tpl[0] == 'fold_ix' else (1,tpl[0])):\n",
    "        if val is not None:\n",
    "            s += \"{key}-{val}_\".format(key=k, val=str(val))\n",
    "    return s[:-1]\n",
    "\n",
    "def get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fsig = get_file_signature(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return models_folder + fsig + \".h5\"\n",
    "\n",
    "get_file_name(0, True, True, 2, \"sum\", hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_fold(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "\n",
    "    if use_pretrained_embedding:\n",
    "        embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "        embedding_layer = Embedding(max_features,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=maxlen,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    else:\n",
    "        embedding_layer = Embedding(max_features, embedding_size, input_length=maxlen, trainable=True, mask_zero=True)\n",
    "\n",
    "    if bi_directional:\n",
    "        rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "    else:\n",
    "        rnn_layer_fact = lambda : GRU(hidden_size, return_sequences=True, consume_less=\"cpu\")\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    X_train, y_train, train_ys_bytag_con_sent, seq_len_train = fold2training_data[fold_ix]\n",
    "    X_dev,   y_dev,   dev_ys_bytag_con_sent,   seq_len_dev   = fold2dev_data[fold_ix]\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "    #for i in range(10):\n",
    "        print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        epochs = 1 # epochs per training instance\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        #print(micro_metrics)\n",
    "        #print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fold2model = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = evaluate_fold(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        fname = get_file_name(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        model.save(fname)    \n",
    "        fold2model[i] = model\n",
    "    return fold2model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Params 2018-01-08 08:54:11.996557 - Embeddings=True, Bi-Direct=True Num_Rnns=2 Hidden_Size=256\n",
      "2018-01-08 08:54:12.553412: Epoch=0\n",
      "2018-01-08 08:58:56.774308: Epoch=1\n",
      "2018-01-08 09:03:05.760246: Epoch=2\n",
      "2018-01-08 09:07:14.955714: Epoch=3\n",
      "2018-01-08 09:11:23.672584: Epoch=4\n",
      "2018-01-08 09:15:32.366014: Epoch=5\n",
      "Fold[0] - Best F1 Score=0.9256080114449213\n",
      "2018-01-08 09:19:41.957503: Epoch=0\n",
      "2018-01-08 09:24:19.228762: Epoch=1\n",
      "2018-01-08 09:28:31.177535: Epoch=2\n",
      "2018-01-08 09:32:43.306652: Epoch=3\n",
      "2018-01-08 09:36:55.633983: Epoch=4\n",
      "2018-01-08 09:41:07.636672: Epoch=5\n",
      "2018-01-08 09:45:19.655473: Epoch=6\n",
      "Fold[1] - Best F1 Score=0.8991712707182321\n",
      "2018-01-08 09:49:32.416631: Epoch=0\n",
      "2018-01-08 09:54:04.759053: Epoch=1\n",
      "2018-01-08 09:58:11.473981: Epoch=2\n",
      "2018-01-08 10:02:18.153389: Epoch=3\n",
      "2018-01-08 10:06:25.069786: Epoch=4\n",
      "2018-01-08 10:10:32.319959: Epoch=5\n",
      "2018-01-08 10:14:40.267403: Epoch=6\n",
      "2018-01-08 10:18:48.070986: Epoch=7\n",
      "2018-01-08 10:22:56.153312: Epoch=8\n",
      "2018-01-08 10:27:04.359097: Epoch=9\n",
      "Fold[2] - Best F1 Score=0.9026022304832713\n",
      "2018-01-08 10:31:12.893281: Epoch=0\n",
      "2018-01-08 10:36:01.577899: Epoch=1\n",
      "2018-01-08 10:40:22.942186: Epoch=2\n",
      "2018-01-08 10:44:44.653470: Epoch=3\n",
      "2018-01-08 10:49:06.390650: Epoch=4\n",
      "2018-01-08 10:53:28.205829: Epoch=5\n",
      "2018-01-08 10:57:49.896828: Epoch=6\n",
      "2018-01-08 11:02:11.833124: Epoch=7\n",
      "2018-01-08 11:06:33.922080: Epoch=8\n",
      "Fold[3] - Best F1 Score=0.9149392423159399\n",
      "2018-01-08 11:10:57.343427: Epoch=0\n",
      "2018-01-08 11:15:46.620700: Epoch=1\n",
      "2018-01-08 11:20:09.946766: Epoch=2\n",
      "2018-01-08 11:24:33.980273: Epoch=3\n",
      "2018-01-08 11:28:57.530742: Epoch=4\n",
      "2018-01-08 11:33:21.324049: Epoch=5\n",
      "2018-01-08 11:37:44.646825: Epoch=6\n",
      "2018-01-08 11:42:07.649669: Epoch=7\n",
      "2018-01-08 11:46:30.921204: Epoch=8\n",
      "2018-01-08 11:50:54.713867: Epoch=9\n",
      "2018-01-08 11:55:18.928964: Epoch=10\n",
      "2018-01-08 11:59:42.826945: Epoch=11\n",
      "Fold[4] - Best F1 Score=0.9169960474308301\n",
      "[1] Params 2018-01-08 12:04:07.505805 - Embeddings=True, Bi-Direct=True Num_Rnns=2 Hidden_Size=256\n",
      "CPU times: user 5h 24min 37s, sys: 44min 59s, total: 6h 9min 36s\n",
      "Wall time: 3h 9min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "use_pretrained_embedding = True\n",
    "bi_directional = True\n",
    "num_rnns = 2\n",
    "merge_mode = \"sum\"\n",
    "hidden_size = 256\n",
    "\n",
    "\"\"\"\n",
    "use_pretrained_embedding = True\n",
    "bi_directional = False\n",
    "num_rnns = 1\n",
    "merge_mode = \"sum\"\n",
    "hidden_size = 32\n",
    "\"\"\"\n",
    "\n",
    "i += 1\n",
    "print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "      .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))\n",
    "fold2model = cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "#print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))\n",
    "print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "      .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1776/1776 [==============================] - 17s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "1707/1707 [==============================] - 16s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "1848/1848 [==============================] - 17s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "1469/1469 [==============================] - 14s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "1492/1492 [==============================] - 14s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "predicts_by_fold = {}\n",
    "for fold_ix in range(CV_FOLDS):\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "    model = fold2model[fold_ix]\n",
    "    probs = model.predict_classes(X_test)\n",
    "    predicts_by_fold[fold_ix] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_fname(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fsig = get_file_signature(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return predictions_folder + fsig + \".dill\"\n",
    "\n",
    "for fold, preds in predicts_by_fold.items():\n",
    "    fname = get_predictions_fname(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    with open(fname, \"wb\") as f:\n",
    "        dill.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def predictions_to_tags(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    sentence_tags = []\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        sentence_tags.append(pred_ys)\n",
    "    return sentence_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Assign Predicted Tags to Essay Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def assign_tags_to_essays(essays, preds, seq_len):\n",
    "    pred_tags = predictions_to_tags(seq_len, preds)\n",
    "    sent_ix = 0\n",
    "    for essay in essays:\n",
    "        ptagged_sentences = []\n",
    "        for sent in essay.sentences:\n",
    "            ptags = pred_tags[sent_ix]\n",
    "            assert len(ptags) == len(sent), \"Sentence and tags don't align - ntags %i , len(sentence) %i\" % ((len(ptags),len(sent)))\n",
    "            ptagged_sentences.append(ptags)\n",
    "            sent_ix += 1\n",
    "        assert len(ptagged_sentences) == len(essay.sentences), \"Lens differ\"\n",
    "        essay.pred_tagged_sentences = ptagged_sentences\n",
    "    assert sent_ix == len(pred_tags), \"Predictions don't align with sequence lens\"\n",
    "\n",
    "all_ptagged_essays = []\n",
    "for fold in fold2test_essays.keys():\n",
    "    essays = fold2test_essays[fold]\n",
    "    preds = predicts_by_fold[fold]\n",
    "    _,_,_,seq_len = fold2test_data[fold]\n",
    "    assign_tags_to_essays(essays, preds, seq_len)\n",
    "    all_ptagged_essays.extend(essays)\n",
    "\n",
    "fname = predictions_folder + \"essays_train_\" + get_file_signature(None, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size) + \".dill\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    dill.dump(all_ptagged_essays, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert len(all_ptagged_essays) == len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50', '50', 'Empty', 'Empty', 'Empty', 'Empty', 'Empty', 'Empty', 'Empty']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.pred_tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_test(num_rnns, merge_mode, hidden_size):\n",
    "    embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "    embedding_layer = Embedding(max_features,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    essays_train, essays_dev = train_dev_split(tagged_essays, DEV_SPLIT)\n",
    "    X_train, y_train,  train_ys_bytag_con_sent,  seq_len_train = get_training_data(essays_train)\n",
    "    X_dev,   y_dev,    dev_ys_bytag_con_sent,    seq_len_dev   = get_training_data(essays_dev)\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "    #for i in range(10):\n",
    "        print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        print(micro_metrics)\n",
    "        print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sum 256\n",
      "2018-01-08 12:05:34.968086: Epoch=0\n",
      "Recall: 0.8804, Precision: 0.8517, F1: 0.8658, Accuracy: 0.9783, Codes:   920\n",
      "\n",
      "2018-01-08 12:11:17.900210: Epoch=1\n",
      "Recall: 0.8935, Precision: 0.8708, F1: 0.8820, Accuracy: 0.9810, Codes:   920\n",
      "\n",
      "2018-01-08 12:16:34.179665: Epoch=2\n",
      "Recall: 0.8772, Precision: 0.9007, F1: 0.8888, Accuracy: 0.9825, Codes:   920\n",
      "\n",
      "2018-01-08 12:21:50.167164: Epoch=3\n",
      "Recall: 0.9424, Precision: 0.8635, F1: 0.9012, Accuracy: 0.9836, Codes:   920\n",
      "\n",
      "2018-01-08 12:27:06.210533: Epoch=4\n",
      "Recall: 0.9348, Precision: 0.8848, F1: 0.9091, Accuracy: 0.9851, Codes:   920\n",
      "\n",
      "2018-01-08 12:32:22.830319: Epoch=5\n",
      "Recall: 0.9163, Precision: 0.8846, F1: 0.9002, Accuracy: 0.9838, Codes:   920\n",
      "\n",
      "2018-01-08 12:37:39.622034: Epoch=6\n",
      "Recall: 0.8967, Precision: 0.9066, F1: 0.9016, Accuracy: 0.9844, Codes:   920\n",
      "\n",
      "2018-01-08 12:42:57.148289: Epoch=7\n",
      "Recall: 0.8761, Precision: 0.9159, F1: 0.8956, Accuracy: 0.9838, Codes:   920\n",
      "\n",
      "Fold[4] - Best F1 Score=0.9090909090909092\n"
     ]
    }
   ],
   "source": [
    "#test_model = evaluate_test(2, \"sum\", 256)\n",
    "print(num_rnns, merge_mode, hidden_size)\n",
    "test_model = evaluate_test(num_rnns, merge_mode, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918/1918 [==============================] - 18s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "X_test,  y_test,   test_ys_bytag_con_sent,   seq_len_test = get_training_data(tagged_essays_test)\n",
    "test_preds = test_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1918, 141), 1918)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape, len(test_ys_bytag_con_sent['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assign_tags_to_essays(tagged_essays_test, test_preds, seq_len_test)\n",
    "\n",
    "fname = predictions_folder + \"essays_test_\" + get_file_signature(None, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size) + \".dill\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    dill.dump(tagged_essays_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('well', set()), 'Empty'),\n",
       " (('based', set()), 'Empty'),\n",
       " (('on', set()), 'Empty'),\n",
       " (('what', set()), 'Empty'),\n",
       " (('i', set()), 'Empty'),\n",
       " (('read', set()), 'Empty'),\n",
       " (('the', set()), 'Empty'),\n",
       " (('corals', {'50'}), 'Empty'),\n",
       " (('are', {'50'}), 'Empty'),\n",
       " (('INFREQUENT', {'50'}), 'Empty'),\n",
       " (('their', {'50'}), 'Empty'),\n",
       " (('colors', {'50'}), '50'),\n",
       " ((',', set()), 'Empty'),\n",
       " (('coral', {'50'}), '50'),\n",
       " (('bleaching', {'50'}), '50'),\n",
       " (('are', set()), 'Empty'),\n",
       " (('a', set()), 'Empty'),\n",
       " (('serious', set()), 'Empty'),\n",
       " (('problem', set()), 'Empty'),\n",
       " (('with', set()), 'Empty'),\n",
       " (('a', set()), 'Empty'),\n",
       " (('serious', set()), 'Empty'),\n",
       " (('impact', set()), 'Empty'),\n",
       " (('on', set()), 'Empty'),\n",
       " (('the', set()), 'Empty'),\n",
       " (('worlds', set()), 'Empty'),\n",
       " (('coral', set()), 'Empty'),\n",
       " (('reefs', set()), 'Empty'),\n",
       " (('.', set()), 'Empty')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tagged_essays_test[0]\n",
    "list(zip(e.sentences[0],e.pred_tagged_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_essays_test\n",
    "\n",
    "stag_freq = defaultdict(int)\n",
    "\n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            for tag in tags:\n",
    "                stag_freq[tag] += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
