{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Any\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from Settings import Settings\n",
    "from cost_functions import *\n",
    "from crel_helper import get_cr_tags\n",
    "from function_helpers import get_function_names, get_functions_by_name\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from searn_parser import SearnModelTemplateFeatures\n",
    "from template_feature_extractor import *\n",
    "from window_based_tagger_config import get_config\n",
    "from wordtagginghelper import merge_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "len(pred_tagged_essays_train),len(pred_tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = \"Empty\"\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "def to_is_valid_crel(tags):\n",
    "    filtered = set()\n",
    "    for t in tags:\n",
    "        t_lower = t.lower()\n",
    "        if \"rhetorical\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "            continue\n",
    "        if \"->\" in t and ANAPHORA not in t:\n",
    "            filtered.add(t)\n",
    "    return filtered\n",
    "\n",
    "def get_crel_tags_by_sent(essays_a):\n",
    "    crels_by_sent = []\n",
    "    for ea in essays_a:\n",
    "        for asent in ea.sentences:\n",
    "            all_atags = set()\n",
    "            for awd, atags in asent:\n",
    "                all_atags.update(to_is_valid_crel(atags))\n",
    "            crels_by_sent.append(all_atags)\n",
    "    return crels_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:5->Result:50',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:13->Result:50',\n",
       " 'Causer:6->Result:50',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:3->Result:1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "cr_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "        collection_prefix: str,\n",
    "        folds: List[Tuple[Any, Any]],\n",
    "        extractor_fn_names_lst: List[str],\n",
    "        cost_function_name: str,\n",
    "        beta: float,\n",
    "        ngrams: int,\n",
    "        stemmed: bool,\n",
    "        max_epochs: int,\n",
    "        down_sample_rate=1.0) -> float:\n",
    "\n",
    "    if down_sample_rate < 1.0:\n",
    "        new_folds = []  # type: List[Tuple[Any, Any]]\n",
    "        for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "            essays_TD = essays_TD[:int(down_sample_rate * len(essays_TD))]\n",
    "            essays_VD = essays_VD[:int(down_sample_rate * len(essays_VD))]\n",
    "            new_folds.append((essays_TD, essays_VD))\n",
    "        folds = new_folds  # type: List[Tuple[Any, Any]]\n",
    "\n",
    "    serial_results = [\n",
    "        model_train_predict(essays_TD, essays_VD, extractor_fn_names_lst, cost_function_name, ngrams, stemmed, beta, max_epochs)\n",
    "        for essays_TD, essays_VD in folds\n",
    "    ]\n",
    "\n",
    "    cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    # record the number of features in each fold\n",
    "    number_of_feats = []\n",
    "\n",
    "    # Parallel is almost 5X faster!!!\n",
    "    cv_td_preds_by_sent = []\n",
    "    cv_vd_preds_by_sent = []\n",
    "    for (num_feats,\n",
    "         sent_td_ys_bycode, sent_vd_ys_bycode,\n",
    "         sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent) in serial_results:\n",
    "        number_of_feats.append(num_feats)\n",
    "\n",
    "        merge_dictionaries(sent_td_ys_bycode, cv_sent_td_ys_by_tag)\n",
    "        merge_dictionaries(sent_vd_ys_bycode, cv_sent_vd_ys_by_tag)\n",
    "        merge_dictionaries(sent_td_pred_ys_bycode, cv_sent_td_predictions_by_tag)\n",
    "        merge_dictionaries(sent_vd_pred_ys_bycode, cv_sent_vd_predictions_by_tag)\n",
    "        \n",
    "        cv_td_preds_by_sent.append(td_preds_by_sent)\n",
    "        cv_vd_preds_by_sent.append(vd_preds_by_sent)\n",
    "\n",
    "    # print(processor.results_to_string(sent_td_objectid, CB_SENT_TD, sent_vd_objectid, CB_SENT_VD, \"SENTENCE\"))\n",
    "    return cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_sent(tagged_essays, model):\n",
    "    predict_by_sent = []\n",
    "    for essay_ix, essay in enumerate(tagged_essays):\n",
    "        for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "            predicted_tags = essay.pred_tagged_sentences[sent_ix]\n",
    "            pred_relations = model.predict_sentence(taggged_sentence, predicted_tags)\n",
    "            # Store predictions for evaluation\n",
    "            predict_by_sent.append(pred_relations)\n",
    "    return predict_by_sent\n",
    "\n",
    "def model_train_predict(essays_TD, essays_VD, extractor_names, cost_function_name, ngrams, stemmed, beta, max_epochs):\n",
    "    extractors = get_functions_by_name(extractor_names, all_extractor_fns)\n",
    "    # get single cost function\n",
    "    cost_fn = get_functions_by_name([cost_function_name], all_cost_functions)[0]\n",
    "    assert cost_fn is not None, \"Cost function look up failed\"\n",
    "    # Ensure all extractors located\n",
    "    assert len(extractors) == len(extractor_names), \"number of extractor functions does not match the number of names\"\n",
    "\n",
    "    template_feature_extractor = NonLocalTemplateFeatureExtractor(extractors=extractors)\n",
    "    if stemmed:\n",
    "        ngram_extractor = NgramExtractorStemmed(max_ngram_len=ngrams)\n",
    "    else:\n",
    "        ngram_extractor = NgramExtractor(max_ngram_len=ngrams)\n",
    "    parse_model = SearnModelTemplateFeatures(feature_extractor=template_feature_extractor,\n",
    "                                             cost_function=cost_fn,\n",
    "                                             min_feature_freq=MIN_FEAT_FREQ,\n",
    "                                             ngram_extractor=ngram_extractor, cr_tags=cr_tags,\n",
    "                                             base_learner_fact=BASE_LEARNER_FACT,\n",
    "                                             beta=beta,\n",
    "                                             # log_fn=lambda s: print(s))\n",
    "                                             log_fn=lambda s: None)\n",
    "\n",
    "    parse_model.train(essays_TD, max_epochs=max_epochs)\n",
    "\n",
    "    num_feats = template_feature_extractor.num_features()\n",
    "\n",
    "    sent_td_ys_bycode = parse_model.get_label_data(essays_TD)\n",
    "    sent_vd_ys_bycode = parse_model.get_label_data(essays_VD)\n",
    "\n",
    "    sent_td_pred_ys_bycode = parse_model.predict(essays_TD)\n",
    "    sent_vd_pred_ys_bycode = parse_model.predict(essays_VD)\n",
    "\n",
    "    td_preds_by_sent = predict_by_sent(essays_TD, parse_model)\n",
    "    vd_preds_by_sent = predict_by_sent(essays_VD, parse_model)\n",
    "    \n",
    "    return num_feats, sent_td_ys_bycode, sent_vd_ys_bycode, sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(metrics):\n",
    "    import Rpfa\n",
    "\n",
    "    rows = []\n",
    "    for k,val in metrics.items():\n",
    "        if type(val) == Rpfa.rpfa:\n",
    "            d = dict(val.__dict__) # convert obj to dict\n",
    "        elif type(val) == dict:\n",
    "            d = dict(val)\n",
    "        else:\n",
    "            d = dict()\n",
    "        d[\"code\"] = k\n",
    "        rows.append(d)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def get_micro_metrics(df):\n",
    "    return df[df.code == \"MICRO_F1\"][[\"accuracy\", \"f1_score\", \"recall\", \"precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_WIDTH = 80\n",
    "\n",
    "# other settings\n",
    "DOWN_SAMPLE_RATE = 1.0  # For faster smoke testing the algorithm\n",
    "BASE_LEARNER_FACT = None\n",
    "COLLECTION_PREFIX = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE\"\n",
    "\n",
    "# some of the other extractors aren't functional if the system isn't able to do a basic parse\n",
    "# so the base extractors are the MVP for getting to a basic parser, then additional 'meta' parse\n",
    "# features from all_extractors can be included\n",
    "base_extractors = [\n",
    "    single_words,\n",
    "    word_pairs,\n",
    "    three_words,\n",
    "    between_word_features\n",
    "]\n",
    "\n",
    "all_extractor_fns = base_extractors + [\n",
    "    word_distance,\n",
    "    valency,\n",
    "    unigrams,\n",
    "    third_order,\n",
    "    label_set,\n",
    "    size_features\n",
    "]\n",
    "\n",
    "all_cost_functions = [\n",
    "    micro_f1_cost,\n",
    "    micro_f1_cost_squared,\n",
    "    micro_f1_cost_plusone,\n",
    "    micro_f1_cost_plusepsilon,\n",
    "    binary_cost,\n",
    "    inverse_micro_f1_cost,\n",
    "    uniform_cost\n",
    "]\n",
    "\n",
    "all_extractor_fn_names = get_function_names(all_extractor_fns)\n",
    "base_extractor_fn_names = get_function_names(base_extractors)\n",
    "all_cost_fn_names = get_function_names(all_cost_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that these are different for Skin Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 1\n",
    "stemmed = True\n",
    "cost_function_name = micro_f1_cost_plusepsilon.__name__\n",
    "dual = True\n",
    "fit_intercept = True\n",
    "beta = 0.5\n",
    "max_epochs = 2\n",
    "C = 0.5\n",
    "penalty = \"l2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these also differ for SC dataset\n",
    "BASE_LEARNER_FACT = lambda : LogisticRegression(dual=dual, C=C, penalty=penalty, fit_intercept=fit_intercept)\n",
    "best_extractor_names = ['single_words', 'between_word_features', 'label_set',\n",
    "                                    'three_words', 'third_order', 'unigrams'] # type: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for Test Set Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds     = [(pred_tagged_essays_train, pred_tagged_essays_test)]  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 242 ms, total: 29.5 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_test = evaluate_model(\n",
    "    collection_prefix=COLLECTION_PREFIX,\n",
    "    folds=test_folds,\n",
    "    extractor_fn_names_lst=best_extractor_names,\n",
    "    cost_function_name=cost_function_name,\n",
    "    ngrams=ngrams,\n",
    "    beta=beta,\n",
    "    stemmed=stemmed,\n",
    "    down_sample_rate=DOWN_SAMPLE_RATE,\n",
    "    max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Metrics (All Codes Inc. Ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>0.713494</td>\n",
       "      <td>0.772773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95  0.997865  0.741951  0.713494   0.772773"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.99776</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.677467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95   0.99776  0.701754  0.727848   0.677467"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 1918)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_crels_by_sent = cv_vd_preds_by_sent[0]\n",
    "crels_by_sent = get_crel_tags_by_sent(pred_tagged_essays_test)\n",
    "len(pred_crels_by_sent), len(crels_by_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 172 460 632 \t 181 145 \t 282\n"
     ]
    }
   ],
   "source": [
    "fp_count = 0\n",
    "fn_count = 0\n",
    "tp_count = 0\n",
    "lbl_count = 0\n",
    "pred_count = 0\n",
    "misses = 0\n",
    "fp_ixs = []\n",
    "fn_ixs = []\n",
    "tp_ixs = []\n",
    "for i, (act, pred) in enumerate(zip(crels_by_sent, pred_crels_by_sent)):\n",
    "    false_neg = act - pred\n",
    "    false_pos = pred - act\n",
    "    true_pos = act.intersection(pred)\n",
    "    \n",
    "    fp_count += len(false_pos)\n",
    "    fn_count += len(false_neg)\n",
    "    tp_count += len(true_pos)\n",
    "    lbl_count += len(act)\n",
    "    pred_count += len(pred)\n",
    "    \n",
    "    if len(true_pos) == len(act) and len(act) > 0:\n",
    "        tp_ixs.append(i)\n",
    "    if false_neg:\n",
    "        fn_ixs.append(i)\n",
    "    if false_pos:\n",
    "        fp_ixs.append(i)\n",
    "    \n",
    "    if false_neg or false_pos:\n",
    "        misses += 1\n",
    "        \n",
    "print(fp_count, fn_count, tp_count, lbl_count, \"\\t\", len(fp_ixs), len(fn_ixs), \"\\t\", misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.696969696969697, 0.7278481012658228, 0.6686046511627907)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = tp_count/lbl_count\n",
    "prec = tp_count/pred_count\n",
    "\n",
    "2*rec*prec/(rec+prec), rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if t[0].isdigit() and not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags\n",
    "\n",
    "def get_all_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use training data to get relative counts of crels and compute probabilities of each crel\n",
    "tally_crels = defaultdict(int)\n",
    "total = 0\n",
    "for crels in get_crel_tags_by_sent(pred_tagged_essays_train):\n",
    "    for cr in crels:\n",
    "        tally_crels[cr] +=1\n",
    "        total += 1\n",
    "        \n",
    "p_crels = defaultdict(float)\n",
    "for cr, cnt in tally_crels.items():\n",
    "    p_crels[cr] = cnt / total\n",
    "    \n",
    "# sorted(p_crels.items(), key = lambda tpl: -tpl[-1])\n",
    "def print_crels_probs(crels, output_probs=True):\n",
    "    cprobs = []\n",
    "    for crel in crels:\n",
    "        crel_short = crel.replace(\"Causer:\",\"\").replace(\"Result:\", \"\")\n",
    "        if not output_probs:\n",
    "            cprobs.append(crel_short)\n",
    "        else:\n",
    "            cprobs.append(\"{crel} - {prob:.3f}\".format(crel=crel_short, prob=p_crels[crel]))\n",
    "    return (\", \".join(cprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \t corals depend on clear , shallow , tropical waters , coral tissues , algae called zooxanthellae need light for the process of photosynthesis .\n",
      "ACT CREL: 5->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5->7 - 0.004\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Result:7', 'Causer:5'}\n",
      "\n",
      "14 \t corals need chemicals ( co2 ) that provide coral with the energy it needs to survive .\n",
      "ACT CREL: 4->5b\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->5b - 0.006\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:4'}\n",
      "\n",
      "33 \t i think the coral reefs are being bleached because the lack of chemicals and INFREQUENT .\n",
      "ACT CREL: 5b->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5b->50 - 0.011\n",
      "ACT  CC : {'5b', '50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '5b', 'Result:50', '50', 'Causer:5b'}\n",
      "\n",
      "39 \t the storms increase the amount of salinity .\n",
      "ACT CREL: 11->13\n",
      "TP      : \n",
      "FP      : 12->13 - 0.024, 11->12 - 0.026\n",
      "FN      : 11->13 - 0.027\n",
      "ACT  CC : {'13', '11'}\n",
      "PRED CC : {'12', '13', '11'}\n",
      "ALL ACT : {'Causer:11', 'Result:13', 'explicit', 'Result', 'Causer', '13', '11'}\n",
      "\n",
      "41 \t these reasons can lead to coral bleaching .\n",
      "ACT CREL: 4->50, 13->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019, 13->50 - 0.030, 4->50 - 0.029\n",
      "ACT  CC : {'50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'Anaphor:[13]', 'explicit', 'Result', 'Causer', 'Anaphor:[4]', 'Causer:Anaphor', 'Anaphor', 'Result:50', 'Anaphor:[11]', '50'}\n",
      "\n",
      "49 \t when people fish , or when tourists drop anchors or to walk on the reefs , they are putting stress on the coral .\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'6'}\n",
      "PRED CC : {'6'}\n",
      "ALL ACT : {'6', 'Causer:6', 'Causer'}\n",
      "\n",
      "50 \t the coral then is forced to eject a food - producing algae .\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'7'}\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'7', 'Result', 'Result:7', 'explicit'}\n",
      "\n",
      "75 \t because temperature has a big impact on the bleaching .\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3', '50'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "\n",
      "102 \t there is less co2 in the air when it is warmer water .\n",
      "ACT CREL: 3->4\n",
      "TP      : \n",
      "FP      : 4->3 - 0.001\n",
      "FN      : 3->4 - 0.043\n",
      "ACT  CC : {'3', '4'}\n",
      "PRED CC : {'3', '4'}\n",
      "ALL ACT : {'Result:4', 'explicit', 'Result', '4', '3', 'Causer', 'Causer:3'}\n",
      "\n",
      "132 \t some main causes of coral bleaching are shifting trade winds , changes in co2 ,\n",
      "ACT CREL: 4->50, 50->1\n",
      "TP      : 4->50 - 0.029\n",
      "FP      : 1->50 - 0.115, 1->4 - 0.002\n",
      "FN      : 50->1 - 0.000\n",
      "ACT  CC : {'1', '4', '50'}\n",
      "PRED CC : {'1', '4', '50'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', '4', 'Result:50', '50', '1', 'Causer:50', 'Causer:4', 'Result:1'}\n",
      "\n",
      "137 \t the way they get co2 is by water they also go throw photosynthesis just like normal land plants do , they get their food that way and so do coral plants .\n",
      "ACT CREL: 5->5b\n",
      "TP      : \n",
      "FP      : 4->5 - 0.021\n",
      "FN      : 5->5b - 0.012\n",
      "ACT  CC : set()\n",
      "PRED CC : {'4', '5'}\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:5'}\n",
      "\n",
      "161 \t the corals die because if the enviroment change , well actually there very sensitive when it comes to the weather changing and that means that there more storms and strong winds that another affect of corals dying .\n",
      "ACT CREL: 1->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 1->50 - 0.115, 11->50 - 0.019\n",
      "ACT  CC : {'50', '1', '11'}\n",
      "PRED CC : {'1', '11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Causer:1', 'Result:50', '1', '50', '11'}\n",
      "\n",
      "165 \t they live together in colonies and types of algae living in coral polyps to give their own color .\n",
      "ACT CREL: 7->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 7->50 - 0.132\n",
      "ACT  CC : set()\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:7', 'Result:50'}\n",
      "\n",
      "184 \t after looking over the documents and INFREQUENT i have come up with the INFREQUENT that more corals die when trade winds weaken and make the water temperatures rise .\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : 1->7 - 0.002, 3->7 - 0.008\n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'1', '3', '50'}\n",
      "PRED CC : {'7', '3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '50', '1', 'Result:3'}\n",
      "\n",
      "188 \t that when i INFREQUENT that in 0000 the trade winds were extremely weak and lead to temperatures rising high in the water , but also that was the time coral INFREQUENT major deaths .\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'50', '3', '1'}\n",
      "PRED CC : {'3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '1', '50', 'Result:3'}\n",
      "\n",
      "191 \t corals die when INFREQUENT to warm temperatures .\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "\n",
      "194 \t another is when co2 in water decreases .\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4'}\n",
      "PRED CC : {'4'}\n",
      "ALL ACT : {'explicit', 'Result', 'Result:Anaphor', 'Causer', '4', 'Anaphor', 'Causer:4', 'Anaphor:[50]'}\n",
      "\n",
      "254 \t if the amount of co2 INFREQUENT from the algae to the coral is lower then its supposed to be then the coral will lose the color .\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : 4->7 - 0.002\n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4', '50'}\n",
      "PRED CC : {'7', '4', '50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '4', 'Result:50', '50', 'Causer:4'}\n",
      "\n",
      "263 \t corals are very sensitive and can be damaged by storms .\n",
      "ACT CREL: 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019\n",
      "ACT  CC : {'50', '11'}\n",
      "PRED CC : {'11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Result:50', '50', '11'}\n",
      "\n",
      "289 \t which can affect the coral because if the zooxanthellae does give the coral the sun energy that it needs , the coral will lose its color , which will result in the zooxanthellae dying .\n",
      "ACT CREL: 50->7, 5b->50\n",
      "TP      : \n",
      "FP      : 7->50 - 0.132\n",
      "FN      : 50->7 - 0.002, 5b->50 - 0.011\n",
      "ACT  CC : {'7', '5b', '50'}\n",
      "PRED CC : {'7', '50'}\n",
      "ALL ACT : {'7', 'explicit', 'Result', 'Causer', '5b', 'Result:50', 'Result:7', '50', 'Causer:50', 'Causer:5b'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ixs = set(fn_ixs[:20])\n",
    "essays = pred_tagged_essays_test\n",
    "assert len(crels_by_sent) == len(pred_crels_by_sent), (len(crels_by_sent), len(pred_crels_by_sent))\n",
    "\n",
    "sent_ix = -1\n",
    "for e in essays:\n",
    "    for six, sent in enumerate(e.sentences):\n",
    "        sent_ix += 1\n",
    "        if sent_ix not in ixs:\n",
    "            continue\n",
    "        \n",
    "        act,pred = crels_by_sent[sent_ix], pred_crels_by_sent[sent_ix]\n",
    "        \n",
    "        pred_codes = set([c for c in e.pred_tagged_sentences[six] if c != EMPTY])\n",
    "        act_codes     = get_act_cc_tags(six, e)\n",
    "        all_act_codes = get_all_cc_tags(six, e)\n",
    "        \n",
    "        false_neg = act - pred\n",
    "        false_pos = pred - act\n",
    "        true_pos = act.intersection(pred)\n",
    "        words = list(zip(*sent))[0]\n",
    "        print(sent_ix, \"\\t\", \" \".join(words))\n",
    "        print(\"ACT CREL:\", print_crels_probs(act, False))\n",
    "        print(\"TP      :\", print_crels_probs(true_pos))\n",
    "        print(\"FP      :\", print_crels_probs(false_pos))\n",
    "        print(\"FN      :\", print_crels_probs(false_neg))\n",
    "#         print(act)\n",
    "#         print(pred)\n",
    "#         print(false_neg)\n",
    "        print(\"ACT  CC :\", act_codes)\n",
    "        print(\"PRED CC :\", pred_codes)\n",
    "        print(\"ALL ACT :\", all_act_codes)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes / Observations\n",
    "- A knowledge of the probability of the predicted Crel should definitely be useful to the model. Some crels that are predicted are never observed in the training data, and there are a few that are in the wrong direction (and the predicted direction is not observed or is less likely).\n",
    "- Similarly, often when the CC tagger predicts codes the causal model connects them together incorrectly. Awareness of the confidence of those predictions is probably useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
