{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Any\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from Settings import Settings\n",
    "from cost_functions import *\n",
    "from crel_helper import get_cr_tags\n",
    "from function_helpers import get_function_names, get_functions_by_name\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from searn_parser import SearnModelTemplateFeatures\n",
    "from template_feature_extractor import *\n",
    "from window_based_tagger_config import get_config\n",
    "from wordtagginghelper import merge_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "len(pred_tagged_essays_train),len(pred_tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = \"Empty\"\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "def to_is_valid_crel(tags):\n",
    "    filtered = set()\n",
    "    for t in tags:\n",
    "        t_lower = t.lower()\n",
    "        if \"rhetorical\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "            continue\n",
    "        if \"->\" in t and ANAPHORA not in t:\n",
    "            filtered.add(t)\n",
    "    return filtered\n",
    "\n",
    "def get_crel_tags_by_sent(essays_a):\n",
    "    crels_by_sent = []\n",
    "    for ea in essays_a:\n",
    "        for asent in ea.sentences:\n",
    "            all_atags = set()\n",
    "            for awd, atags in asent:\n",
    "                all_atags.update(to_is_valid_crel(atags))\n",
    "            crels_by_sent.append(all_atags)\n",
    "    return crels_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:5->Result:50',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:13->Result:50',\n",
       " 'Causer:6->Result:50',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:3->Result:1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "cr_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "        collection_prefix: str,\n",
    "        folds: List[Tuple[Any, Any]],\n",
    "        extractor_fn_names_lst: List[str],\n",
    "        cost_function_name: str,\n",
    "        beta: float,\n",
    "        ngrams: int,\n",
    "        stemmed: bool,\n",
    "        max_epochs: int,\n",
    "        down_sample_rate=1.0) -> float:\n",
    "\n",
    "    if down_sample_rate < 1.0:\n",
    "        new_folds = []  # type: List[Tuple[Any, Any]]\n",
    "        for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "            essays_TD = essays_TD[:int(down_sample_rate * len(essays_TD))]\n",
    "            essays_VD = essays_VD[:int(down_sample_rate * len(essays_VD))]\n",
    "            new_folds.append((essays_TD, essays_VD))\n",
    "        folds = new_folds  # type: List[Tuple[Any, Any]]\n",
    "\n",
    "    serial_results = [\n",
    "        model_train_predict(essays_TD, essays_VD, extractor_fn_names_lst, cost_function_name, ngrams, stemmed, beta, max_epochs)\n",
    "        for essays_TD, essays_VD in folds\n",
    "    ]\n",
    "\n",
    "    cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    # record the number of features in each fold\n",
    "    number_of_feats = []\n",
    "\n",
    "    # Parallel is almost 5X faster!!!\n",
    "    cv_td_preds_by_sent = []\n",
    "    cv_vd_preds_by_sent = []\n",
    "    for (num_feats,\n",
    "         sent_td_ys_bycode, sent_vd_ys_bycode,\n",
    "         sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent) in serial_results:\n",
    "        number_of_feats.append(num_feats)\n",
    "\n",
    "        merge_dictionaries(sent_td_ys_bycode, cv_sent_td_ys_by_tag)\n",
    "        merge_dictionaries(sent_vd_ys_bycode, cv_sent_vd_ys_by_tag)\n",
    "        merge_dictionaries(sent_td_pred_ys_bycode, cv_sent_td_predictions_by_tag)\n",
    "        merge_dictionaries(sent_vd_pred_ys_bycode, cv_sent_vd_predictions_by_tag)\n",
    "        \n",
    "        cv_td_preds_by_sent.append(td_preds_by_sent)\n",
    "        cv_vd_preds_by_sent.append(vd_preds_by_sent)\n",
    "\n",
    "    # print(processor.results_to_string(sent_td_objectid, CB_SENT_TD, sent_vd_objectid, CB_SENT_VD, \"SENTENCE\"))\n",
    "    return cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_sent(tagged_essays, model):\n",
    "    predict_by_sent = []\n",
    "    for essay_ix, essay in enumerate(tagged_essays):\n",
    "        for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "            predicted_tags = essay.pred_tagged_sentences[sent_ix]\n",
    "            pred_relations = model.predict_sentence(taggged_sentence, predicted_tags)\n",
    "            # Store predictions for evaluation\n",
    "            predict_by_sent.append(pred_relations)\n",
    "    return predict_by_sent\n",
    "\n",
    "def model_train_predict(essays_TD, essays_VD, extractor_names, cost_function_name, ngrams, stemmed, beta, max_epochs):\n",
    "    extractors = get_functions_by_name(extractor_names, all_extractor_fns)\n",
    "    # get single cost function\n",
    "    cost_fn = get_functions_by_name([cost_function_name], all_cost_functions)[0]\n",
    "    assert cost_fn is not None, \"Cost function look up failed\"\n",
    "    # Ensure all extractors located\n",
    "    assert len(extractors) == len(extractor_names), \"number of extractor functions does not match the number of names\"\n",
    "\n",
    "    template_feature_extractor = NonLocalTemplateFeatureExtractor(extractors=extractors)\n",
    "    if stemmed:\n",
    "        ngram_extractor = NgramExtractorStemmed(max_ngram_len=ngrams)\n",
    "    else:\n",
    "        ngram_extractor = NgramExtractor(max_ngram_len=ngrams)\n",
    "    parse_model = SearnModelTemplateFeatures(feature_extractor=template_feature_extractor,\n",
    "                                             cost_function=cost_fn,\n",
    "                                             min_feature_freq=MIN_FEAT_FREQ,\n",
    "                                             ngram_extractor=ngram_extractor, cr_tags=cr_tags,\n",
    "                                             base_learner_fact=BASE_LEARNER_FACT,\n",
    "                                             beta=beta,\n",
    "                                             # log_fn=lambda s: print(s))\n",
    "                                             log_fn=lambda s: None)\n",
    "\n",
    "    parse_model.train(essays_TD, max_epochs=max_epochs)\n",
    "\n",
    "    num_feats = template_feature_extractor.num_features()\n",
    "\n",
    "    sent_td_ys_bycode = parse_model.get_label_data(essays_TD)\n",
    "    sent_vd_ys_bycode = parse_model.get_label_data(essays_VD)\n",
    "\n",
    "    sent_td_pred_ys_bycode = parse_model.predict(essays_TD)\n",
    "    sent_vd_pred_ys_bycode = parse_model.predict(essays_VD)\n",
    "\n",
    "    td_preds_by_sent = predict_by_sent(essays_TD, parse_model)\n",
    "    vd_preds_by_sent = predict_by_sent(essays_VD, parse_model)\n",
    "    \n",
    "    return num_feats, sent_td_ys_bycode, sent_vd_ys_bycode, sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(metrics):\n",
    "    import Rpfa\n",
    "\n",
    "    rows = []\n",
    "    for k,val in metrics.items():\n",
    "        if type(val) == Rpfa.rpfa:\n",
    "            d = dict(val.__dict__) # convert obj to dict\n",
    "        elif type(val) == dict:\n",
    "            d = dict(val)\n",
    "        else:\n",
    "            d = dict()\n",
    "        d[\"code\"] = k\n",
    "        rows.append(d)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def get_micro_metrics(df):\n",
    "    return df[df.code == \"MICRO_F1\"][[\"accuracy\", \"f1_score\", \"recall\", \"precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_WIDTH = 80\n",
    "\n",
    "# other settings\n",
    "DOWN_SAMPLE_RATE = 1.0  # For faster smoke testing the algorithm\n",
    "BASE_LEARNER_FACT = None\n",
    "COLLECTION_PREFIX = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE\"\n",
    "\n",
    "# some of the other extractors aren't functional if the system isn't able to do a basic parse\n",
    "# so the base extractors are the MVP for getting to a basic parser, then additional 'meta' parse\n",
    "# features from all_extractors can be included\n",
    "base_extractors = [\n",
    "    single_words,\n",
    "    word_pairs,\n",
    "    three_words,\n",
    "    between_word_features\n",
    "]\n",
    "\n",
    "all_extractor_fns = base_extractors + [\n",
    "    word_distance,\n",
    "    valency,\n",
    "    unigrams,\n",
    "    third_order,\n",
    "    label_set,\n",
    "    size_features\n",
    "]\n",
    "\n",
    "all_cost_functions = [\n",
    "    micro_f1_cost,\n",
    "    micro_f1_cost_squared,\n",
    "    micro_f1_cost_plusone,\n",
    "    micro_f1_cost_plusepsilon,\n",
    "    binary_cost,\n",
    "    inverse_micro_f1_cost,\n",
    "    uniform_cost\n",
    "]\n",
    "\n",
    "all_extractor_fn_names = get_function_names(all_extractor_fns)\n",
    "base_extractor_fn_names = get_function_names(base_extractors)\n",
    "all_cost_fn_names = get_function_names(all_cost_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that these are different for Skin Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 1\n",
    "stemmed = True\n",
    "cost_function_name = micro_f1_cost_plusepsilon.__name__\n",
    "dual = True\n",
    "fit_intercept = True\n",
    "beta = 0.5\n",
    "max_epochs = 2\n",
    "C = 0.5\n",
    "penalty = \"l2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these also differ for SC dataset\n",
    "BASE_LEARNER_FACT = lambda : LogisticRegression(dual=dual, C=C, penalty=penalty, fit_intercept=fit_intercept)\n",
    "best_extractor_names = ['single_words', 'between_word_features', 'label_set',\n",
    "                                    'three_words', 'third_order', 'unigrams'] # type: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for Test Set Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds     = [(pred_tagged_essays_train, pred_tagged_essays_test)]  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 242 ms, total: 29.5 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_test = evaluate_model(\n",
    "    collection_prefix=COLLECTION_PREFIX,\n",
    "    folds=test_folds,\n",
    "    extractor_fn_names_lst=best_extractor_names,\n",
    "    cost_function_name=cost_function_name,\n",
    "    ngrams=ngrams,\n",
    "    beta=beta,\n",
    "    stemmed=stemmed,\n",
    "    down_sample_rate=DOWN_SAMPLE_RATE,\n",
    "    max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Metrics (All Codes Inc. Ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>0.713494</td>\n",
       "      <td>0.772773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95  0.997865  0.741951  0.713494   0.772773"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.99776</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.677467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95   0.99776  0.701754  0.727848   0.677467"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 1918)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_crels_by_sent = cv_vd_preds_by_sent[0]\n",
    "crels_by_sent = get_crel_tags_by_sent(pred_tagged_essays_test)\n",
    "len(pred_crels_by_sent), len(crels_by_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 172 460 632 \t 181 145 \t 282\n"
     ]
    }
   ],
   "source": [
    "fp_count = 0\n",
    "fn_count = 0\n",
    "tp_count = 0\n",
    "lbl_count = 0\n",
    "pred_count = 0\n",
    "misses = 0\n",
    "fp_ixs = []\n",
    "fn_ixs = []\n",
    "tp_ixs = []\n",
    "for i, (act, pred) in enumerate(zip(crels_by_sent, pred_crels_by_sent)):\n",
    "    false_neg = act - pred\n",
    "    false_pos = pred - act\n",
    "    true_pos = act.intersection(pred)\n",
    "    \n",
    "    fp_count += len(false_pos)\n",
    "    fn_count += len(false_neg)\n",
    "    tp_count += len(true_pos)\n",
    "    lbl_count += len(act)\n",
    "    pred_count += len(pred)\n",
    "    \n",
    "    if len(true_pos) == len(act) and len(act) > 0:\n",
    "        tp_ixs.append(i)\n",
    "    if false_neg:\n",
    "        fn_ixs.append(i)\n",
    "    if false_pos:\n",
    "        fp_ixs.append(i)\n",
    "    \n",
    "    if false_neg or false_pos:\n",
    "        misses += 1\n",
    "        \n",
    "print(fp_count, fn_count, tp_count, lbl_count, \"\\t\", len(fp_ixs), len(fn_ixs), \"\\t\", misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.696969696969697, 0.7278481012658228, 0.6686046511627907)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = tp_count/lbl_count\n",
    "prec = tp_count/pred_count\n",
    "\n",
    "2*rec*prec/(rec+prec), rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if t[0].isdigit() and not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags\n",
    "\n",
    "def get_all_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use training data to get relative counts of crels and compute probabilities of each crel\n",
    "tally_crels = defaultdict(int)\n",
    "total = 0\n",
    "for crels in get_crel_tags_by_sent(pred_tagged_essays_train):\n",
    "    for cr in crels:\n",
    "        tally_crels[cr] +=1\n",
    "        total += 1\n",
    "        \n",
    "p_crels = defaultdict(float)\n",
    "for cr, cnt in tally_crels.items():\n",
    "    p_crels[cr] = cnt / total\n",
    "    \n",
    "def to_short_tag(tag):\n",
    "    return tag.replace(\"Causer:\",\"\").replace(\"Result:\", \"\")\n",
    "    \n",
    "# sorted(p_crels.items(), key = lambda tpl: -tpl[-1])\n",
    "def print_crels_probs(crels, output_probs=True):\n",
    "    cprobs = []\n",
    "    for crel in crels:\n",
    "        crel_short = to_short_tag(crel)\n",
    "        if not output_probs:\n",
    "            cprobs.append(crel_short)\n",
    "        else:\n",
    "            cprobs.append(\"{crel} - {prob:.3f}\".format(crel=crel_short, prob=p_crels[crel]))\n",
    "    return (\", \".join(cprobs))\n",
    "\n",
    "def print_sentence_tags(words, tags):\n",
    "    sent = \"\"\n",
    "    assert len(words) == len(tags)\n",
    "    for wd, t in zip(words, tags):\n",
    "        if type(t) == str:\n",
    "            t = {t}\n",
    "        tag_str = \"\"\n",
    "        st = set([to_short_tag(tt) for tt in t])\n",
    "        for tag in st:\n",
    "            if \"->\" in tag:\n",
    "                continue\n",
    "            if tag[0].isdigit():\n",
    "                tag_str += tag + \":\"\n",
    "        sent += tag_str + wd + \" \"        \n",
    "    return sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 EBA1415_BGJD_1_CB_ES-05725.ann 3\n",
      "ACT:   corals depend on clear , shallow , tropical waters , coral tissues , 7:algae 7:called 7:zooxanthellae 5:need 5:light 5:for 5:the 5:process 5:of 5:photosynthesis .\n",
      "PRED:  corals depend on clear , shallow , tropical waters , coral tissues , algae called zooxanthellae need light for the process of photosynthesis .\n",
      "ACT CREL: 5->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5->7 - 0.004\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Result:7', 'Causer:5'}\n",
      "PREV ACT: set()\n",
      "NEXT ACT: {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:4'}\n",
      "\n",
      "14 EBA1415_BGJD_1_CB_ES-05725.ann 4\n",
      "ACT:   corals 4:need 4:chemicals ( 4:co2 ) that provide 5b:coral 5b:with 5b:the 5b:energy 5b:it 5b:needs 5b:to 5b:survive .\n",
      "PRED:  corals need chemicals ( co2 ) that provide coral with the energy it needs to survive .\n",
      "ACT CREL: 4->5b\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->5b - 0.006\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:4'}\n",
      "PREV ACT: {'explicit', 'Result', 'Causer', 'Result:7', 'Causer:5'}\n",
      "NEXT ACT: {'COMPILED'}\n",
      "\n",
      "33 EBA1415_BGJD_2_CB_ES-5746.ann 8\n",
      "ACT:   i think the 50:coral 50:reefs 50:are 50:being 50:bleached because the 5b:lack 5b:of 5b:chemicals and INFREQUENT .\n",
      "PRED:  i think the coral 50:reefs 50:are 50:being 50:bleached because the lack of chemicals and INFREQUENT .\n",
      "ACT CREL: 5b->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5b->50 - 0.011\n",
      "ACT  CC : {'5b', '50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '5b', 'Result:50', '50', 'Causer:5b'}\n",
      "PREV ACT: set()\n",
      "\n",
      "39 EBA1415_BLHT_5_CB_ES-05209.ann 5\n",
      "ACT:   the 11:storms 13:increase 13:the 13:amount 13:of 13:salinity .\n",
      "PRED:  the 11:storms 12:increase 13:the 13:amount 13:of 13:salinity .\n",
      "ACT CREL: 11->13\n",
      "TP      : \n",
      "FP      : 12->13 - 0.024, 11->12 - 0.026\n",
      "FN      : 11->13 - 0.027\n",
      "ACT  CC : {'13', '11'}\n",
      "PRED CC : {'12', '13', '11'}\n",
      "ALL ACT : {'Causer:11', 'Result:13', 'explicit', 'Result', 'Causer', '13', '11'}\n",
      "PREV ACT: {'11'}\n",
      "NEXT ACT: {'4'}\n",
      "\n",
      "41 EBA1415_BLHT_5_CB_ES-05209.ann 7\n",
      "ACT:   these reasons can lead to 50:coral 50:bleaching .\n",
      "PRED:  these reasons can lead to 50:coral 50:bleaching .\n",
      "ACT CREL: 4->50, 13->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019, 13->50 - 0.030, 4->50 - 0.029\n",
      "ACT  CC : {'50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'Anaphor:[13]', 'explicit', 'Result', 'Causer', 'Anaphor:[4]', 'Causer:Anaphor', 'Anaphor', 'Result:50', 'Anaphor:[11]', '50'}\n",
      "PREV ACT: {'4'}\n",
      "NEXT ACT: set()\n",
      "\n",
      "49 EBA1415_BLHT_5_CB_ES-05210.ann 5\n",
      "ACT:   when people fish , or when tourists drop anchors or to walk on the reefs , they are 6:putting 6:stress 6:on 6:the 6:coral .\n",
      "PRED:  when people fish , or when tourists drop anchors or to walk on the reefs , they are 6:putting 6:stress 6:on 6:the 6:coral .\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'6'}\n",
      "PRED CC : {'6'}\n",
      "ALL ACT : {'6', 'Causer:6', 'Causer'}\n",
      "PREV ACT: {'explicit', 'Result', 'Causer', 'Causer:6', '6', 'Result:50', '50'}\n",
      "NEXT ACT: {'7', 'Result', 'Result:7', 'explicit'}\n",
      "\n",
      "50 EBA1415_BLHT_5_CB_ES-05210.ann 6\n",
      "ACT:   the coral then is forced to 7:eject 7:a 7:food - 7:producing 7:algae .\n",
      "PRED:  the coral then is forced 7:to 7:eject 7:a 7:food - 7:producing 7:algae .\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'7'}\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'7', 'Result', 'Result:7', 'explicit'}\n",
      "PREV ACT: {'6', 'Causer:6', 'Causer'}\n",
      "NEXT ACT: set()\n",
      "\n",
      "75 EBA1415_BLHT_5_CB_ES-05214.ann 4\n",
      "ACT:   because 3:temperature has a big impact on the 50:bleaching .\n",
      "PRED:  because 3:temperature has a big impact on the 50:bleaching .\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3', '50'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "PREV ACT: {'explicit', 'Result', 'Causer', 'Causer:1', 'Result:50', '1', '50'}\n",
      "NEXT ACT: {'explicit', 'Result', 'rhetorical', 'Result:rhetorical', 'Causer', '4', 'Causer:4'}\n",
      "\n",
      "102 EBA1415_BLRW_3_CB_ES-05178.ann 8\n",
      "ACT:   there is 4:less 4:co2 in the air when it is 3:warmer 3:water .\n",
      "PRED:  there is 4:less 4:co2 4:in 4:the air when it is 3:warmer 3:water .\n",
      "ACT CREL: 3->4\n",
      "TP      : \n",
      "FP      : 4->3 - 0.001\n",
      "FN      : 3->4 - 0.043\n",
      "ACT  CC : {'3', '4'}\n",
      "PRED CC : {'3', '4'}\n",
      "ALL ACT : {'Result:4', 'explicit', 'Result', '4', '3', 'Causer', 'Causer:3'}\n",
      "PREV ACT: {'Anaphor:[3]', 'Anaphor'}\n",
      "NEXT ACT: set()\n",
      "\n",
      "132 EBA1415_BLRW_5_CB_ES-05190.ann 1\n",
      "ACT:   some main causes of 50:coral 50:bleaching are 1:shifting 1:trade 1:winds , 4:changes 4:in 4:co2 ,\n",
      "PRED:  some main causes of 50:coral 50:bleaching are 1:shifting 1:trade 1:winds , 4:changes 4:in 4:co2 ,\n",
      "ACT CREL: 4->50, 50->1\n",
      "TP      : 4->50 - 0.029\n",
      "FP      : 1->50 - 0.115, 1->4 - 0.002\n",
      "FN      : 50->1 - 0.000\n",
      "ACT  CC : {'1', '4', '50'}\n",
      "PRED CC : {'1', '4', '50'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', '4', 'Result:50', '50', '1', 'Causer:50', 'Causer:4', 'Result:1'}\n",
      "PREV ACT: {'50'}\n",
      "NEXT ACT: {'COMPILED'}\n",
      "\n",
      "137 EBA1415_BLRW_5_CB_ES-05196.ann 3\n",
      "ACT:   the way they get co2 is by water they also 5:go 5:throw 5:photosynthesis just like normal land plants do , 5b:they 5b:get 5b:their 5b:food 5b:that 5b:way 5b:and 5b:so 5b:do 5b:coral 5b:plants .\n",
      "PRED:  the 4:way 4:they 4:get 4:co2 4:is by 4:water they 5:also 5:go 5:throw 5:photosynthesis just like 5:normal land plants do , they get their food that way and so do coral plants .\n",
      "ACT CREL: 5->5b\n",
      "TP      : \n",
      "FP      : 4->5 - 0.021\n",
      "FN      : 5->5b - 0.012\n",
      "ACT  CC : set()\n",
      "PRED CC : {'4', '5'}\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:5'}\n",
      "PREV ACT: set()\n",
      "NEXT ACT: {'Result:5', 'explicit', 'Result', 'Causer', '3', 'Causer:3'}\n",
      "\n",
      "161 EBA1415_ERAP_1_CB_ES-05949.ann 5\n",
      "ACT:   the corals die because if the enviroment change , well actually there very sensitive when it comes to the weather changing and that means that there 11:more 11:storms and 1:strong 1:winds that another affect of 50:corals 50:dying .\n",
      "PRED:  the corals die because if the enviroment change , well actually there very sensitive when it comes to the weather 1:changing and that means that there 11:more 11:storms and 11:strong 11:winds that another affect of corals dying .\n",
      "ACT CREL: 1->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 1->50 - 0.115, 11->50 - 0.019\n",
      "ACT  CC : {'50', '1', '11'}\n",
      "PRED CC : {'1', '11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Causer:1', 'Result:50', '1', '50', '11'}\n",
      "PREV ACT: {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "NEXT ACT: {'COMPILED'}\n",
      "\n",
      "165 EBA1415_ERAP_7_CB_ES-05950.ann 2\n",
      "ACT:   they live together in colonies and types of 7:algae 7:living 7:in 7:coral 7:polyps to give 50:their 50:own 50:color .\n",
      "PRED:  they live together in colonies and types of algae living in 7:coral polyps to give their own color .\n",
      "ACT CREL: 7->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 7->50 - 0.132\n",
      "ACT  CC : set()\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:7', 'Result:50'}\n",
      "PREV ACT: set()\n",
      "NEXT ACT: {'50'}\n",
      "\n",
      "184 EBA1415_ERSK_1_CB_ES-05788.ann 0\n",
      "ACT:   after looking over the documents and INFREQUENT i have come up with the INFREQUENT that more 50:corals 50:die when 1:trade 1:winds 1:weaken and make the 3:water 3:temperatures 3:rise .\n",
      "PRED:  after looking over the documents and INFREQUENT i have come up with the INFREQUENT that more 7:corals die when 1:trade 1:winds 1:weaken and make the 3:water 3:temperatures 3:rise .\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : 1->7 - 0.002, 3->7 - 0.008\n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'1', '3', '50'}\n",
      "PRED CC : {'7', '3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '50', '1', 'Result:3'}\n",
      "NEXT ACT: set()\n",
      "\n",
      "188 EBA1415_ERSK_1_CB_ES-05788.ann 4\n",
      "ACT:   that when i INFREQUENT that in 0000 the 1:trade 1:winds 1:were 1:extremely 1:weak and lead to 3:temperatures 3:rising 3:high 3:in 3:the 3:water , but also that was the time 50:coral 50:INFREQUENT 50:major 50:deaths .\n",
      "PRED:  that when i INFREQUENT that in 0000 the 1:trade 1:winds 1:were 1:extremely 1:weak and lead to 3:temperatures 3:rising 3:high 3:in 3:the 3:water , but also that was the time coral INFREQUENT major deaths .\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'50', '3', '1'}\n",
      "PRED CC : {'3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '1', '50', 'Result:3'}\n",
      "PREV ACT: set()\n",
      "NEXT ACT: set()\n",
      "\n",
      "191 EBA1415_ERSK_1_CB_ES-05788.ann 7\n",
      "ACT:   50:corals 50:die when 3:INFREQUENT 3:to 3:warm 3:temperatures .\n",
      "PRED:  corals die when INFREQUENT to 3:warm 3:temperatures .\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "PREV ACT: set()\n",
      "NEXT ACT: {'COMPILED'}\n",
      "\n",
      "194 EBA1415_ERSK_1_CB_ES-05791.ann 1\n",
      "ACT:   another is when 4:co2 4:in 4:water 4:decreases .\n",
      "PRED:  another is when 4:co2 4:in 4:water 4:decreases .\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4'}\n",
      "PRED CC : {'4'}\n",
      "ALL ACT : {'explicit', 'Result', 'Result:Anaphor', 'Causer', '4', 'Anaphor', 'Causer:4', 'Anaphor:[50]'}\n",
      "PREV ACT: {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "NEXT ACT: {'13', '11'}\n",
      "\n",
      "254 EBA1415_HNJD_4_ES_CB-05927.ann 3\n",
      "ACT:   if the 4:amount 4:of 4:co2 4:INFREQUENT 4:from 4:the 4:algae 4:to 4:the 4:coral 4:is 4:lower then its supposed to be then the 50:coral 50:will 50:lose 50:the 50:color .\n",
      "PRED:  if the 4:amount 4:of 4:co2 4:INFREQUENT from the 7:algae 7:to the 7:coral is lower then its supposed 50:to 50:be then the 50:coral 50:will 50:lose 50:the 50:color .\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : 4->7 - 0.002\n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4', '50'}\n",
      "PRED CC : {'7', '4', '50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '4', 'Result:50', '50', 'Causer:4'}\n",
      "PREV ACT: {'3', '1'}\n",
      "\n",
      "263 EBA1415_HNJD_4_ES_CB-05954.ann 8\n",
      "ACT:   50:corals 50:are 50:very 50:sensitive 50:and 50:can 50:be 50:damaged by 11:storms .\n",
      "PRED:  corals are very sensitive and can be damaged by 11:storms .\n",
      "ACT CREL: 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019\n",
      "ACT  CC : {'50', '11'}\n",
      "PRED CC : {'11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Result:50', '50', '11'}\n",
      "PREV ACT: {'50'}\n",
      "NEXT ACT: {'COMPILED', 'Result:5', 'explicit', 'Result', 'Causer', '3', 'Causer:3'}\n",
      "\n",
      "289 EBA1415_KNKC_1_CB_ES-05410.ann 8\n",
      "ACT:   which can affect the coral because if the 5b:zooxanthellae 5b:does 5b:give 5b:the 5b:coral 5b:the 5b:sun 5b:energy 5b:that 5b:it 5b:needs , the 50:coral 50:will 50:lose 50:its 50:color , which will result in the 7:zooxanthellae 7:dying .\n",
      "PRED:  which can affect the coral because if the zooxanthellae does give the coral the sun energy that it needs , the 50:coral 50:will 50:lose 50:its 50:color , which will result in the 7:zooxanthellae 7:dying .\n",
      "ACT CREL: 50->7, 5b->50\n",
      "TP      : \n",
      "FP      : 7->50 - 0.132\n",
      "FN      : 50->7 - 0.002, 5b->50 - 0.011\n",
      "ACT  CC : {'7', '5b', '50'}\n",
      "PRED CC : {'7', '50'}\n",
      "ALL ACT : {'7', 'explicit', 'Result', 'Causer', '5b', 'Result:50', 'Result:7', '50', 'Causer:50', 'Causer:5b'}\n",
      "PREV ACT: {'5'}\n",
      "NEXT ACT: {'COMPILED', 'explicit', 'Result', 'Causer', 'Causer:1', 'Result:50', '1', '50'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ixs = set(fn_ixs[:20])\n",
    "essays = pred_tagged_essays_test\n",
    "assert len(crels_by_sent) == len(pred_crels_by_sent), (len(crels_by_sent), len(pred_crels_by_sent))\n",
    "\n",
    "sent_ix = -1\n",
    "for e in essays:\n",
    "    for six, sent in enumerate(e.sentences):\n",
    "        sent_ix += 1\n",
    "        if sent_ix not in ixs:\n",
    "            continue\n",
    "        \n",
    "        act,pred = crels_by_sent[sent_ix], pred_crels_by_sent[sent_ix]\n",
    "        \n",
    "        pred_codes = set([c for c in e.pred_tagged_sentences[six] if c != EMPTY])\n",
    "        act_codes     = get_act_cc_tags(six, e)\n",
    "        all_act_codes = get_all_cc_tags(six, e)\n",
    "        \n",
    "        false_neg = act - pred\n",
    "        false_pos = pred - act\n",
    "        true_pos = act.intersection(pred)\n",
    "        words, cc_tags = zip(*sent)\n",
    "        print(sent_ix, e.name, six)\n",
    "        print(\"ACT:  \", print_sentence_tags(words, cc_tags))\n",
    "        print(\"PRED: \", print_sentence_tags(words, e.pred_tagged_sentences[six]))\n",
    "        print(\"ACT CREL:\", print_crels_probs(act, False))\n",
    "        print(\"TP      :\", print_crels_probs(true_pos))\n",
    "        print(\"FP      :\", print_crels_probs(false_pos))\n",
    "        print(\"FN      :\", print_crels_probs(false_neg))\n",
    "#         print(act)\n",
    "#         print(pred)\n",
    "#         print(false_neg)\n",
    "        print(\"ACT  CC :\", act_codes)\n",
    "        print(\"PRED CC :\", pred_codes)\n",
    "        print(\"ALL ACT :\", all_act_codes)\n",
    "        if six > 0:            \n",
    "            print(\"PREV ACT:\", get_all_cc_tags(six-1, e))\n",
    "        if six < len(e.sentences) - 1:\n",
    "            print(\"NEXT ACT:\", get_all_cc_tags(six+1, e))\n",
    "        print()\n",
    "        \n",
    "        prev_codes.append(all_act_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes / Observations\n",
    "- A knowledge of the probability of the predicted Crel should definitely be useful to the model. Some crels that are predicted are never observed in the training data, and there are a few that are in the wrong direction (and the predicted direction is not observed or is less likely).\n",
    "- Similarly, often when the CC tagger predicts codes the causal model connects them together incorrectly. Awareness of the confidence of those predictions is probably useful.\n",
    "- Sometimes words like because appear in the sentence but not between the two codes, and so the model doesn't pick up the causality. \n",
    "- As observed before, occasionally one of the codes in the causal relation appears in the previous or subsequent sentence, but this doesn't appear to be that common. A lot of the errors are either the model not predicting a CC code, or predicting codes that aren't there.\n",
    "- Make sure there is a feature (if missing already) that encodes the order of the codes in the sentence as often that informs the order of the causality, but not always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the Max Number of Predicted Tags Per Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = pred_tagged_essays_train\n",
    "\n",
    "act_count = []\n",
    "pred_count = []\n",
    "for e in essays:\n",
    "    unique_act = set()\n",
    "    unique_pred = set()\n",
    "    for six, sent in enumerate(e.sentences):\n",
    "        pred_codes = set([c for c in e.pred_tagged_sentences[six] if c != EMPTY])\n",
    "        act_codes  = get_act_cc_tags(six, e)\n",
    "        unique_act.update(act_codes)\n",
    "        unique_pred.update(pred_codes)\n",
    "    act_count.append(len(unique_act))\n",
    "    pred_count.append(len(unique_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.128603104212861, 4.251141552511416, 11)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(act_count), np.mean([c for c in act_count if c]), np.max(act_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.452328159645233, 4.568828213879408, 12)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred_count), np.mean([c for c in pred_count if c]), np.max(pred_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
