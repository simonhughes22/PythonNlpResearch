{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Any\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from Settings import Settings\n",
    "from cost_functions import *\n",
    "from crel_helper import get_cr_tags\n",
    "from function_helpers import get_function_names, get_functions_by_name\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from searn_parser import SearnModelTemplateFeatures\n",
    "from template_feature_extractor import *\n",
    "from window_based_tagger_config import get_config\n",
    "from wordtagginghelper import merge_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "len(pred_tagged_essays_train),len(pred_tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = \"Empty\"\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "def to_is_valid_crel(tags):\n",
    "    filtered = set()\n",
    "    for t in tags:\n",
    "        t_lower = t.lower()\n",
    "        if \"rhetorical\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "            continue\n",
    "        if \"->\" in t and ANAPHORA not in t:\n",
    "            filtered.add(t)\n",
    "    return filtered\n",
    "\n",
    "def get_crel_tags_by_sent(essays_a):\n",
    "    crels_by_sent = []\n",
    "    for ea in essays_a:\n",
    "        for asent in ea.sentences:\n",
    "            all_atags = set()\n",
    "            for awd, atags in asent:\n",
    "                all_atags.update(to_is_valid_crel(atags))\n",
    "            crels_by_sent.append(all_atags)\n",
    "    return crels_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:5->Result:50',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:13->Result:50',\n",
       " 'Causer:6->Result:50',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:3->Result:1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "cr_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "        collection_prefix: str,\n",
    "        folds: List[Tuple[Any, Any]],\n",
    "        extractor_fn_names_lst: List[str],\n",
    "        cost_function_name: str,\n",
    "        beta: float,\n",
    "        ngrams: int,\n",
    "        stemmed: bool,\n",
    "        max_epochs: int,\n",
    "        down_sample_rate=1.0) -> float:\n",
    "\n",
    "    if down_sample_rate < 1.0:\n",
    "        new_folds = []  # type: List[Tuple[Any, Any]]\n",
    "        for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "            essays_TD = essays_TD[:int(down_sample_rate * len(essays_TD))]\n",
    "            essays_VD = essays_VD[:int(down_sample_rate * len(essays_VD))]\n",
    "            new_folds.append((essays_TD, essays_VD))\n",
    "        folds = new_folds  # type: List[Tuple[Any, Any]]\n",
    "\n",
    "    serial_results = [\n",
    "        model_train_predict(essays_TD, essays_VD, extractor_fn_names_lst, cost_function_name, ngrams, stemmed, beta, max_epochs)\n",
    "        for essays_TD, essays_VD in folds\n",
    "    ]\n",
    "\n",
    "    cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    # record the number of features in each fold\n",
    "    number_of_feats = []\n",
    "\n",
    "    # Parallel is almost 5X faster!!!\n",
    "    cv_td_preds_by_sent = []\n",
    "    cv_vd_preds_by_sent = []\n",
    "    for (num_feats,\n",
    "         sent_td_ys_bycode, sent_vd_ys_bycode,\n",
    "         sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent) in serial_results:\n",
    "        number_of_feats.append(num_feats)\n",
    "\n",
    "        merge_dictionaries(sent_td_ys_bycode, cv_sent_td_ys_by_tag)\n",
    "        merge_dictionaries(sent_vd_ys_bycode, cv_sent_vd_ys_by_tag)\n",
    "        merge_dictionaries(sent_td_pred_ys_bycode, cv_sent_td_predictions_by_tag)\n",
    "        merge_dictionaries(sent_vd_pred_ys_bycode, cv_sent_vd_predictions_by_tag)\n",
    "        \n",
    "        cv_td_preds_by_sent.append(td_preds_by_sent)\n",
    "        cv_vd_preds_by_sent.append(vd_preds_by_sent)\n",
    "\n",
    "    # print(processor.results_to_string(sent_td_objectid, CB_SENT_TD, sent_vd_objectid, CB_SENT_VD, \"SENTENCE\"))\n",
    "    return cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_sent(tagged_essays, model):\n",
    "    predict_by_sent = []\n",
    "    for essay_ix, essay in enumerate(tagged_essays):\n",
    "        for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "            predicted_tags = essay.pred_tagged_sentences[sent_ix]\n",
    "            pred_relations = model.predict_sentence(taggged_sentence, predicted_tags)\n",
    "            # Store predictions for evaluation\n",
    "            predict_by_sent.append(pred_relations)\n",
    "    return predict_by_sent\n",
    "\n",
    "def model_train_predict(essays_TD, essays_VD, extractor_names, cost_function_name, ngrams, stemmed, beta, max_epochs):\n",
    "    extractors = get_functions_by_name(extractor_names, all_extractor_fns)\n",
    "    # get single cost function\n",
    "    cost_fn = get_functions_by_name([cost_function_name], all_cost_functions)[0]\n",
    "    assert cost_fn is not None, \"Cost function look up failed\"\n",
    "    # Ensure all extractors located\n",
    "    assert len(extractors) == len(extractor_names), \"number of extractor functions does not match the number of names\"\n",
    "\n",
    "    template_feature_extractor = NonLocalTemplateFeatureExtractor(extractors=extractors)\n",
    "    if stemmed:\n",
    "        ngram_extractor = NgramExtractorStemmed(max_ngram_len=ngrams)\n",
    "    else:\n",
    "        ngram_extractor = NgramExtractor(max_ngram_len=ngrams)\n",
    "    parse_model = SearnModelTemplateFeatures(feature_extractor=template_feature_extractor,\n",
    "                                             cost_function=cost_fn,\n",
    "                                             min_feature_freq=MIN_FEAT_FREQ,\n",
    "                                             ngram_extractor=ngram_extractor, cr_tags=cr_tags,\n",
    "                                             base_learner_fact=BASE_LEARNER_FACT,\n",
    "                                             beta=beta,\n",
    "                                             # log_fn=lambda s: print(s))\n",
    "                                             log_fn=lambda s: None)\n",
    "\n",
    "    parse_model.train(essays_TD, max_epochs=max_epochs)\n",
    "\n",
    "    num_feats = template_feature_extractor.num_features()\n",
    "\n",
    "    sent_td_ys_bycode = parse_model.get_label_data(essays_TD)\n",
    "    sent_vd_ys_bycode = parse_model.get_label_data(essays_VD)\n",
    "\n",
    "    sent_td_pred_ys_bycode = parse_model.predict(essays_TD)\n",
    "    sent_vd_pred_ys_bycode = parse_model.predict(essays_VD)\n",
    "\n",
    "    td_preds_by_sent = predict_by_sent(essays_TD, parse_model)\n",
    "    vd_preds_by_sent = predict_by_sent(essays_VD, parse_model)\n",
    "    \n",
    "    return num_feats, sent_td_ys_bycode, sent_vd_ys_bycode, sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode, td_preds_by_sent, vd_preds_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(metrics):\n",
    "    import Rpfa\n",
    "\n",
    "    rows = []\n",
    "    for k,val in metrics.items():\n",
    "        if type(val) == Rpfa.rpfa:\n",
    "            d = dict(val.__dict__) # convert obj to dict\n",
    "        elif type(val) == dict:\n",
    "            d = dict(val)\n",
    "        else:\n",
    "            d = dict()\n",
    "        d[\"code\"] = k\n",
    "        rows.append(d)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def get_micro_metrics(df):\n",
    "    return df[df.code == \"MICRO_F1\"][[\"accuracy\", \"f1_score\", \"recall\", \"precision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_WIDTH = 80\n",
    "\n",
    "# other settings\n",
    "DOWN_SAMPLE_RATE = 1.0  # For faster smoke testing the algorithm\n",
    "BASE_LEARNER_FACT = None\n",
    "COLLECTION_PREFIX = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE\"\n",
    "\n",
    "# some of the other extractors aren't functional if the system isn't able to do a basic parse\n",
    "# so the base extractors are the MVP for getting to a basic parser, then additional 'meta' parse\n",
    "# features from all_extractors can be included\n",
    "base_extractors = [\n",
    "    single_words,\n",
    "    word_pairs,\n",
    "    three_words,\n",
    "    between_word_features\n",
    "]\n",
    "\n",
    "all_extractor_fns = base_extractors + [\n",
    "    word_distance,\n",
    "    valency,\n",
    "    unigrams,\n",
    "    third_order,\n",
    "    label_set,\n",
    "    size_features\n",
    "]\n",
    "\n",
    "all_cost_functions = [\n",
    "    micro_f1_cost,\n",
    "    micro_f1_cost_squared,\n",
    "    micro_f1_cost_plusone,\n",
    "    micro_f1_cost_plusepsilon,\n",
    "    binary_cost,\n",
    "    inverse_micro_f1_cost,\n",
    "    uniform_cost\n",
    "]\n",
    "\n",
    "all_extractor_fn_names = get_function_names(all_extractor_fns)\n",
    "base_extractor_fn_names = get_function_names(base_extractors)\n",
    "all_cost_fn_names = get_function_names(all_cost_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that these are different for Skin Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 1\n",
    "stemmed = True\n",
    "cost_function_name = micro_f1_cost_plusepsilon.__name__\n",
    "dual = True\n",
    "fit_intercept = True\n",
    "beta = 0.5\n",
    "max_epochs = 2\n",
    "C = 0.5\n",
    "penalty = \"l2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these also differ for SC dataset\n",
    "BASE_LEARNER_FACT = lambda : LogisticRegression(dual=dual, C=C, penalty=penalty, fit_intercept=fit_intercept)\n",
    "best_extractor_names = ['single_words', 'between_word_features', 'label_set',\n",
    "                                    'three_words', 'third_order', 'unigrams'] # type: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for Test Set Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds     = [(pred_tagged_essays_train, pred_tagged_essays_test)]  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 242 ms, total: 29.5 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_test = evaluate_model(\n",
    "    collection_prefix=COLLECTION_PREFIX,\n",
    "    folds=test_folds,\n",
    "    extractor_fn_names_lst=best_extractor_names,\n",
    "    cost_function_name=cost_function_name,\n",
    "    ngrams=ngrams,\n",
    "    beta=beta,\n",
    "    stemmed=stemmed,\n",
    "    down_sample_rate=DOWN_SAMPLE_RATE,\n",
    "    max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Metrics (All Codes Inc. Ana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>0.713494</td>\n",
       "      <td>0.772773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95  0.997865  0.741951  0.713494   0.772773"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.99776</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.677467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95   0.99776  0.701754  0.727848   0.677467"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, cv_vd_preds_by_sent = result_test\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 1918)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_crels_by_sent = cv_vd_preds_by_sent[0]\n",
    "crels_by_sent = get_crel_tags_by_sent(pred_tagged_essays_test)\n",
    "len(pred_crels_by_sent), len(crels_by_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 172 460 632 \t 181 145 \t 282\n"
     ]
    }
   ],
   "source": [
    "fp_count = 0\n",
    "fn_count = 0\n",
    "tp_count = 0\n",
    "lbl_count = 0\n",
    "pred_count = 0\n",
    "misses = 0\n",
    "fp_ixs = []\n",
    "fn_ixs = []\n",
    "tp_ixs = []\n",
    "for i, (act, pred) in enumerate(zip(crels_by_sent, pred_crels_by_sent)):\n",
    "    false_neg = act - pred\n",
    "    false_pos = pred - act\n",
    "    true_pos = act.intersection(pred)\n",
    "    \n",
    "    fp_count += len(false_pos)\n",
    "    fn_count += len(false_neg)\n",
    "    tp_count += len(true_pos)\n",
    "    lbl_count += len(act)\n",
    "    pred_count += len(pred)\n",
    "    \n",
    "    if len(true_pos) == len(act) and len(act) > 0:\n",
    "        tp_ixs.append(i)\n",
    "    if false_neg:\n",
    "        fn_ixs.append(i)\n",
    "    if false_pos:\n",
    "        fp_ixs.append(i)\n",
    "    \n",
    "    if false_neg or false_pos:\n",
    "        misses += 1\n",
    "        \n",
    "print(fp_count, fn_count, tp_count, lbl_count, \"\\t\", len(fp_ixs), len(fn_ixs), \"\\t\", misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.696969696969697, 0.7278481012658228, 0.6686046511627907)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec = tp_count/lbl_count\n",
    "prec = tp_count/pred_count\n",
    "\n",
    "2*rec*prec/(rec+prec), rec, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if t[0].isdigit() and not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags\n",
    "\n",
    "def get_all_cc_tags(sent_ix, essay):\n",
    "    cc_tags = set()\n",
    "    for wd, tags in essay.sentences[sent_ix]:\n",
    "        for t in tags:\n",
    "            if not \"->\" in t:\n",
    "                cc_tags.add(t)\n",
    "    return cc_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use training data to get relative counts of crels and compute probabilities of each crel\n",
    "tally_crels = defaultdict(int)\n",
    "total = 0\n",
    "for crels in get_crel_tags_by_sent(pred_tagged_essays_train):\n",
    "    for cr in crels:\n",
    "        tally_crels[cr] +=1\n",
    "        total += 1\n",
    "        \n",
    "p_crels = defaultdict(float)\n",
    "for cr, cnt in tally_crels.items():\n",
    "    p_crels[cr] = cnt / total\n",
    "    \n",
    "def to_short_tag(tag):\n",
    "    return tag.replace(\"Causer:\",\"\").replace(\"Result:\", \"\")\n",
    "    \n",
    "# sorted(p_crels.items(), key = lambda tpl: -tpl[-1])\n",
    "def print_crels_probs(crels, output_probs=True):\n",
    "    cprobs = []\n",
    "    for crel in crels:\n",
    "        crel_short = to_short_tag(crel)\n",
    "        if not output_probs:\n",
    "            cprobs.append(crel_short)\n",
    "        else:\n",
    "            cprobs.append(\"{crel} - {prob:.3f}\".format(crel=crel_short, prob=p_crels[crel]))\n",
    "    return (\", \".join(cprobs))\n",
    "\n",
    "def print_sentence_tags(words, tags):\n",
    "    sent = \"\"\n",
    "    assert len(words) == len(tags)\n",
    "    last_tag = set()\n",
    "    in_tag = False\n",
    "    for wd, t in zip(words, tags):\n",
    "        if type(t) == str:\n",
    "            t = {t}\n",
    "        tag_str = \"\"\n",
    "        st = set([to_short_tag(tt) for tt in t])\n",
    "        has_tag = False\n",
    "        for tag in st:\n",
    "            if \"->\" in tag:\n",
    "                continue\n",
    "            if tag[0].isdigit():\n",
    "                has_tag = True\n",
    "                in_tag = True\n",
    "                if st not in last_tag:\n",
    "                    tag_str = \"[\" + tag + \":\"\n",
    "        if in_tag and not has_tag:\n",
    "            tag_str = \"]\"\n",
    "            in_tag = False\n",
    "        sent += tag_str + wd + \" \"        \n",
    "        last_tag = st\n",
    "    return sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 \t corals depend on clear , shallow , tropical waters , coral tissues , [7:set()algae [7:{'Result', '5->7', '7'}called [7:{'Result', '5->7', '7'}zooxanthellae [5:{'Result', '5->7', '7'}need [5:{'Causer', '5', '5->7', 'explicit'}light [5:{'Causer', '5', '5->7'}for [5:{'Causer', '5', '5->7'}the [5:{'Causer', '5', '5->7'}process [5:{'Causer', '5', '5->7'}of [5:{'Causer', '5', '5->7'}photosynthesis ].\n",
      "ACT CREL: 5->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5->7 - 0.004\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Result:7', 'Causer:5'}\n",
      "\n",
      "14 \t corals [4:set()need [4:{'Causer', '4', '4->5b'}chemicals ]( [4:set()co2 ]) that provide [5b:{'4->5b', 'explicit'}coral [5b:{'Result', '5b', '4->5b'}with [5b:{'Result', '5b', '4->5b'}the [5b:{'Result', '5b', '4->5b'}energy [5b:{'Result', '5b', '4->5b'}it [5b:{'Result', '5b', '4->5b'}needs [5b:{'Result', '5b', '4->5b'}to [5b:{'Result', '5b', '4->5b'}survive ].\n",
      "ACT CREL: 4->5b\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->5b - 0.006\n",
      "ACT  CC : set()\n",
      "PRED CC : set()\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:4'}\n",
      "\n",
      "33 \t i think the [50:set()coral [50:{'Result', '5b->50', '50'}reefs [50:{'Result', '5b->50', '50'}are [50:{'Result', '5b->50', '50'}being [50:{'Result', '5b->50', '50'}bleached ]because the [5b:{'5b->50'}lack [5b:{'5b->50', 'Causer', '5b'}of [5b:{'5b->50', 'Causer', '5b'}chemicals ]and INFREQUENT .\n",
      "ACT CREL: 5b->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 5b->50 - 0.011\n",
      "ACT  CC : {'5b', '50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '5b', 'Result:50', '50', 'Causer:5b'}\n",
      "\n",
      "39 \t the [11:set()storms [13:{'Causer', '11->13', '11'}increase [13:{'Result', '11->13', 'explicit', '13'}the [13:{'Result', '11->13', '13'}amount [13:{'Result', '11->13', '13'}of [13:{'Result', '11->13', '13'}salinity ].\n",
      "ACT CREL: 11->13\n",
      "TP      : \n",
      "FP      : 12->13 - 0.024, 11->12 - 0.026\n",
      "FN      : 11->13 - 0.027\n",
      "ACT  CC : {'13', '11'}\n",
      "PRED CC : {'12', '13', '11'}\n",
      "ALL ACT : {'Causer:11', 'Result:13', 'explicit', 'Result', 'Causer', '13', '11'}\n",
      "\n",
      "41 \t these reasons can lead to [50:{'explicit', 'Anaphor->50', '11->50', 'Anaphor[11]->50', '4->50', 'Anaphor[13]->50', 'Anaphor[4]->50', '13->50'}coral [50:{'Result', 'Anaphor->50', '11->50', 'Anaphor[11]->50', '4->50', '50', 'Anaphor[13]->50', 'Anaphor[4]->50', '13->50'}bleaching ].\n",
      "ACT CREL: 4->50, 13->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019, 13->50 - 0.030, 4->50 - 0.029\n",
      "ACT  CC : {'50'}\n",
      "PRED CC : {'50'}\n",
      "ALL ACT : {'Anaphor:[13]', 'explicit', 'Result', 'Causer', 'Anaphor:[4]', 'Causer:Anaphor', 'Anaphor', 'Result:50', 'Anaphor:[11]', '50'}\n",
      "\n",
      "49 \t when people fish , or when tourists drop anchors or to walk on the reefs , they are [6:set()putting [6:{'6->7', '6', 'Causer'}stress [6:{'6->7', '6', 'Causer'}on [6:{'6->7', '6', 'Causer'}the [6:{'6->7', '6', 'Causer'}coral ].\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'6'}\n",
      "PRED CC : {'6'}\n",
      "ALL ACT : {'6', 'Causer:6', 'Causer'}\n",
      "\n",
      "50 \t the coral then is forced to [7:{'6->7'}eject [7:{'7', '6->7', 'Result'}a [7:{'7', '6->7', 'Result'}food ]- [7:set()producing [7:{'7', '6->7', 'Result'}algae ].\n",
      "ACT CREL: 6->7\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 6->7 - 0.043\n",
      "ACT  CC : {'7'}\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'7', 'Result', 'Result:7', 'explicit'}\n",
      "\n",
      "75 \t because [3:set()temperature ]has a big impact on the [50:{'3->50'}bleaching ].\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3', '50'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "\n",
      "102 \t there is [4:set()less [4:{'Result', '4', '3->4'}co2 ]in the air when it is [3:{'3->4'}warmer [3:{'3', 'Causer', '3->4'}water ].\n",
      "ACT CREL: 3->4\n",
      "TP      : \n",
      "FP      : 4->3 - 0.001\n",
      "FN      : 3->4 - 0.043\n",
      "ACT  CC : {'3', '4'}\n",
      "PRED CC : {'3', '4'}\n",
      "ALL ACT : {'Result:4', 'explicit', 'Result', '4', '3', 'Causer', 'Causer:3'}\n",
      "\n",
      "132 \t some main causes of [50:set()coral [50:{'Result', 'Causer', '4->50', '50', '50->1'}bleaching ]are [1:{'50->1', '4->50'}shifting [1:{'Result', '1', '50->1', '4->50'}trade [1:{'Result', '1', '50->1', '4->50'}winds ], [4:set()changes [4:{'Causer', '4', '4->50'}in [4:{'Causer', '4', '4->50'}co2 ],\n",
      "ACT CREL: 4->50, 50->1\n",
      "TP      : 4->50 - 0.029\n",
      "FP      : 1->50 - 0.115, 1->4 - 0.002\n",
      "FN      : 50->1 - 0.000\n",
      "ACT  CC : {'1', '4', '50'}\n",
      "PRED CC : {'1', '4', '50'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', '4', 'Result:50', '50', '1', 'Causer:50', 'Causer:4', 'Result:1'}\n",
      "\n",
      "137 \t the way they get co2 is by water they also [5:set()go [5:{'Causer', '5', '5->5b'}throw [5:{'Causer', '5', '5->5b'}photosynthesis ]just like normal land plants do , [5b:{'explicit'}they [5b:{'Result', '5b', '5->5b'}get [5b:{'Result', '5b', '5->5b'}their [5b:{'Result', '5b', '5->5b'}food [5b:{'Result', '5b', '5->5b'}that [5b:{'Result', '5b', '5->5b'}way [5b:{'Result', '5b', '5->5b'}and [5b:{'Result', '5b', '5->5b'}so [5b:{'Result', '5b', '5->5b'}do [5b:{'Result', '5b', '5->5b'}coral [5b:{'Result', '5b', '5->5b'}plants ].\n",
      "ACT CREL: 5->5b\n",
      "TP      : \n",
      "FP      : 4->5 - 0.021\n",
      "FN      : 5->5b - 0.012\n",
      "ACT  CC : set()\n",
      "PRED CC : {'4', '5'}\n",
      "ALL ACT : {'Result:5b', 'explicit', 'Result', 'Causer', 'Causer:5'}\n",
      "\n",
      "161 \t the corals die because if the enviroment change , well actually there very sensitive when it comes to the weather changing and that means that there [11:set()more [11:{'Causer', '11->50', '11'}storms ]and [1:{'11->50'}strong [1:{'Causer', '11->50', '1', '1->50'}winds ]that another affect of [50:{'11->50', '1->50'}corals [50:{'Result', '11->50', '50', '1->50'}dying ].\n",
      "ACT CREL: 1->50, 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 1->50 - 0.115, 11->50 - 0.019\n",
      "ACT  CC : {'50', '1', '11'}\n",
      "PRED CC : {'1', '11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Causer:1', 'Result:50', '1', '50', '11'}\n",
      "\n",
      "165 \t they live together in colonies and types of [7:set()algae [7:{'7', 'Causer', '7->50'}living [7:{'7', 'Causer', '7->50'}in [7:{'7', 'Causer', '7->50'}coral [7:{'7', 'Causer', '7->50'}polyps ]to give [50:{'7->50', 'explicit'}their [50:{'Result', '7->50', '50'}own [50:{'Result', '7->50', '50'}color ].\n",
      "ACT CREL: 7->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 7->50 - 0.132\n",
      "ACT  CC : set()\n",
      "PRED CC : {'7'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:7', 'Result:50'}\n",
      "\n",
      "184 \t after looking over the documents and INFREQUENT i have come up with the INFREQUENT that more [50:set()corals [50:{'Result', '3->50', '50'}die ]when [1:{'3->50', 'explicit'}trade [1:{'3->50', 'Causer', '1', '1->3'}winds [1:{'3->50', 'Causer', '1', '1->3'}weaken ]and make the [3:{'3->50', '1->3'}water [3:{'Result', '1->3', 'Causer', '3', '3->50'}temperatures [3:{'Result', '1->3', 'Causer', '3', '3->50'}rise ].\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : 1->7 - 0.002, 3->7 - 0.008\n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'1', '3', '50'}\n",
      "PRED CC : {'7', '3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '50', '1', 'Result:3'}\n",
      "\n",
      "188 \t that when i INFREQUENT that in 0000 the [1:set()trade [1:{'1->3', 'Causer', '1'}winds [1:{'1->3', 'Causer', '1'}were [1:{'1->3', 'Causer', '1'}extremely [1:{'1->3', 'Causer', '1'}weak ]and lead to [3:{'1->3', 'explicit'}temperatures [3:{'Result', '1->3', 'Causer', '3', '3->50'}rising [3:{'Result', '1->3', 'Causer', '3', '3->50'}high [3:{'Result', '1->3', 'Causer', '3', '3->50'}in [3:{'Result', '1->3', 'Causer', '3', '3->50'}the [3:{'Result', '1->3', 'Causer', '3', '3->50'}water ], but also that was the time [50:{'3->50'}coral [50:{'Result', '3->50', '50'}INFREQUENT [50:{'Result', '3->50', '50'}major [50:{'Result', '3->50', '50'}deaths ].\n",
      "ACT CREL: 3->50, 1->3\n",
      "TP      : 1->3 - 0.073\n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'50', '3', '1'}\n",
      "PRED CC : {'3', '1'}\n",
      "ALL ACT : {'explicit', 'Result', 'Causer', 'Causer:1', '3', 'Causer:3', 'Result:50', '1', '50', 'Result:3'}\n",
      "\n",
      "191 \t [50:set()corals [50:{'Result', '3->50', '50'}die ]when [3:{'3->50', 'explicit'}INFREQUENT [3:{'3->50', '3', 'Causer'}to [3:{'3->50', '3', 'Causer'}warm [3:{'3->50', '3', 'Causer'}temperatures ].\n",
      "ACT CREL: 3->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 3->50 - 0.106\n",
      "ACT  CC : {'3', '50'}\n",
      "PRED CC : {'3'}\n",
      "ALL ACT : {'explicit', 'Result', '3', 'Causer', 'Causer:3', 'Result:50', '50'}\n",
      "\n",
      "194 \t another is when [4:{'4->Anaphor', '4->Anaphor[50]', 'explicit', '4->50'}co2 [4:{'4->Anaphor[50]', 'Causer', '4', '4->50', '4->Anaphor'}in [4:{'4->Anaphor[50]', 'Causer', '4', '4->50', '4->Anaphor'}water [4:{'4->Anaphor[50]', 'Causer', '4', '4->50', '4->Anaphor'}decreases ].\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4'}\n",
      "PRED CC : {'4'}\n",
      "ALL ACT : {'explicit', 'Result', 'Result:Anaphor', 'Causer', '4', 'Anaphor', 'Causer:4', 'Anaphor:[50]'}\n",
      "\n",
      "254 \t if the [4:set()amount [4:{'Causer', '4', '4->50'}of [4:{'Causer', '4', '4->50'}co2 [4:{'Causer', '4', '4->50'}INFREQUENT [4:{'Causer', '4', '4->50'}from [4:{'Causer', '4', '4->50'}the [4:{'Causer', '4', '4->50'}algae [4:{'Causer', '4', '4->50'}to [4:{'Causer', '4', '4->50'}the [4:{'Causer', '4', '4->50'}coral [4:{'Causer', '4', '4->50'}is [4:{'Causer', '4', '4->50'}lower ]then its supposed to be then the [50:{'4->50'}coral [50:{'Result', '50', '4->50'}will [50:{'Result', '50', '4->50'}lose [50:{'Result', '50', '4->50'}the [50:{'Result', '50', '4->50'}color ].\n",
      "ACT CREL: 4->50\n",
      "TP      : \n",
      "FP      : 4->7 - 0.002\n",
      "FN      : 4->50 - 0.029\n",
      "ACT  CC : {'4', '50'}\n",
      "PRED CC : {'7', '4', '50'}\n",
      "ALL ACT : {'COMPILED', 'explicit', 'Result', 'Causer', '4', 'Result:50', '50', 'Causer:4'}\n",
      "\n",
      "263 \t [50:set()corals [50:{'Result', '11->50', '50'}are [50:{'Result', '11->50', '50'}very [50:{'Result', '11->50', '50'}sensitive [50:{'Result', '11->50', '50'}and [50:{'Result', '11->50', '50'}can [50:{'Result', '11->50', '50'}be [50:{'Result', '11->50', '50'}damaged ]by [11:{'11->50', 'explicit'}storms ].\n",
      "ACT CREL: 11->50\n",
      "TP      : \n",
      "FP      : \n",
      "FN      : 11->50 - 0.019\n",
      "ACT  CC : {'50', '11'}\n",
      "PRED CC : {'11'}\n",
      "ALL ACT : {'Causer:11', 'explicit', 'Result', 'Causer', 'Result:50', '50', '11'}\n",
      "\n",
      "289 \t which can affect the coral because if the [5b:set()zooxanthellae [5b:{'5b->50', 'Causer', '5b'}does [5b:{'5b->50', 'Causer', '5b'}give [5b:{'5b->50', 'Causer', '5b'}the [5b:{'5b->50', 'Causer', '5b'}coral [5b:{'5b->50', 'Causer', '5b'}the [5b:{'5b->50', 'Causer', '5b'}sun [5b:{'5b->50', 'Causer', '5b'}energy [5b:{'5b->50', 'Causer', '5b'}that [5b:{'5b->50', 'Causer', '5b'}it [5b:{'5b->50', 'Causer', '5b'}needs ], the [50:{'5b->50'}coral [50:{'Result', '5b->50', 'Causer', '50', '50->7'}will [50:{'Result', '5b->50', 'Causer', '50', '50->7'}lose [50:{'Result', '5b->50', 'Causer', '50', '50->7'}its [50:{'Result', '5b->50', 'Causer', '50', '50->7'}color ], which will result in the [7:{'50->7'}zooxanthellae [7:{'7', 'Result', '50->7'}dying ].\n",
      "ACT CREL: 50->7, 5b->50\n",
      "TP      : \n",
      "FP      : 7->50 - 0.132\n",
      "FN      : 50->7 - 0.002, 5b->50 - 0.011\n",
      "ACT  CC : {'7', '5b', '50'}\n",
      "PRED CC : {'7', '50'}\n",
      "ALL ACT : {'7', 'explicit', 'Result', 'Causer', '5b', 'Result:50', 'Result:7', '50', 'Causer:50', 'Causer:5b'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ixs = set(fn_ixs[:20])\n",
    "essays = pred_tagged_essays_test\n",
    "assert len(crels_by_sent) == len(pred_crels_by_sent), (len(crels_by_sent), len(pred_crels_by_sent))\n",
    "\n",
    "sent_ix = -1\n",
    "for e in essays:\n",
    "    for six, sent in enumerate(e.sentences):\n",
    "        sent_ix += 1\n",
    "        if sent_ix not in ixs:\n",
    "            continue\n",
    "        \n",
    "        act,pred = crels_by_sent[sent_ix], pred_crels_by_sent[sent_ix]\n",
    "        \n",
    "        pred_codes = set([c for c in e.pred_tagged_sentences[six] if c != EMPTY])\n",
    "        act_codes     = get_act_cc_tags(six, e)\n",
    "        all_act_codes = get_all_cc_tags(six, e)\n",
    "        \n",
    "        false_neg = act - pred\n",
    "        false_pos = pred - act\n",
    "        true_pos = act.intersection(pred)\n",
    "        words, cc_tags = zip(*sent)\n",
    "        print(sent_ix, \"\\t\", print_sentence_tags(words, cc_tags))\n",
    "        print(\"ACT CREL:\", print_crels_probs(act, False))\n",
    "        print(\"TP      :\", print_crels_probs(true_pos))\n",
    "        print(\"FP      :\", print_crels_probs(false_pos))\n",
    "        print(\"FN      :\", print_crels_probs(false_neg))\n",
    "#         print(act)\n",
    "#         print(pred)\n",
    "#         print(false_neg)\n",
    "        print(\"ACT  CC :\", act_codes)\n",
    "        print(\"PRED CC :\", pred_codes)\n",
    "        print(\"ALL ACT :\", all_act_codes)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes / Observations\n",
    "- A knowledge of the probability of the predicted Crel should definitely be useful to the model. Some crels that are predicted are never observed in the training data, and there are a few that are in the wrong direction (and the predicted direction is not observed or is less likely).\n",
    "- Similarly, often when the CC tagger predicts codes the causal model connects them together incorrectly. Awareness of the confidence of those predictions is probably useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
