{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "models_folder = os.path.join(cm_folder, \"BEAM Parser - Essay Level/models/\")\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model_parallel_logged, train_model_parallel, train_model, train_cost_sensitive_instance\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_essay_level\n",
    "from results_procesor import ResultsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.CORAL_BLEACHING\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "crels_folder = \"./crels/CB\"\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "MONGO_COLLECTION = \"CB_ESSAY_PARSER_RE-RANKER_FEATURE_SEL_TD\"\n",
    "# first and second were with initial_weight set to 1.0\n",
    "# thrid is with set to 0.001\n",
    "\n",
    "config = get_config(training_folder)\n",
    "results_processor = ResultsProcessor(dbname=\"metrics_causal_model\")\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:5b->Result:7',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:2->Result:4',\n",
       " 'Causer:13->Result:7',\n",
       " 'Causer:12->Result:7',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:13->Result:11',\n",
       " 'Causer:3->Result:7',\n",
       " 'Causer:4->Result:7',\n",
       " 'Causer:14->Result:7']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Re-Ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Parses from Essay Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_top_n = 2\n",
    "min_feat_freq = 1\n",
    "best_max_upd = 2 \n",
    "best_max_parses = 300\n",
    "best_min_prob = 0.0  # min prob of 0 seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM_SIZE = 100\n",
    "best_C, best_max_upd = 0.01, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/BEAM Parser - Essay Level/models/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "rr_fname = \"xs_rerank_\" + str(BEAM_SIZE) + \".dill\"\n",
    "with open(os.path.join(models_folder, rr_fname), \"rb\") as f:\n",
    "    xs_rerank = dill.load(f)\n",
    "    \n",
    "rr_fname = \"xs_rerank_test_\" + str(BEAM_SIZE) + \".dill\"\n",
    "with open(os.path.join(models_folder, rr_fname), \"rb\") as f:\n",
    "    xs_test_rerank = dill.load(f)\n",
    "\n",
    "len(xs_rerank), len(xs_test_rerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 s, sys: 550 ms, total: 40.1 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs = get_features_essay_level(xs_rerank, name2crels, causal_model_type=CAUSAL_MODEL_TYPE, min_feat_freq=1)\n",
    "\n",
    "cv_folds_rerank = cross_validation(xs, 5)\n",
    "cv_folds_mm = [min_max_normalize_feats(train, test) for (train, test) in cv_folds_rerank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 422 ms, total: 3.23 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs_test = get_features_essay_level(xs_test_rerank, name2crels, causal_model_type=CAUSAL_MODEL_TYPE, min_feat_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset \n",
    "  # training data comes from the test fold predictions from CV on the full training dataset\n",
    "xs_train = []\n",
    "for train, test in cv_folds_rerank:\n",
    "    xs_train.extend(test)\n",
    "\n",
    "# Normalize both using training data\n",
    "xs_train_mm, xs_test_mm = min_max_normalize_feats(xs_train,xs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 0.0025       # 0.0025\n",
    "C = best_C            # This needs to be a lot lower\n",
    "pa_type = 1\n",
    "loss_type= \"ml\"\n",
    "max_update_items = 2  # best_max_upd - 2\n",
    "initial_weight = 0.01  # was 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# f1 = train_model_parallel(\n",
    "#     cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "#     set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "# print(f1)  # 0.7421167703055035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm))\n",
    "tmp_train_copy = list(xs_train_mm)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7349 Test Accuracy: 0.7484\n",
      "Epoch: 1 Train Accuracy: 0.7391 Test Accuracy: 0.7482\n",
      "Epoch: 2 Train Accuracy: 0.7403 Test Accuracy: 0.7490\n",
      "Epoch: 3 Train Accuracy: 0.7409 Test Accuracy: 0.7518\n",
      "Epoch: 4 Train Accuracy: 0.7420 Test Accuracy: 0.7510\n",
      "Epoch: 5 Train Accuracy: 0.7428 Test Accuracy: 0.7510\n",
      "Epoch: 6 Train Accuracy: 0.7429 Test Accuracy: 0.7537\n",
      "Epoch: 7 Train Accuracy: 0.7436 Test Accuracy: 0.7550\n",
      "Epoch: 8 Train Accuracy: 0.7445 Test Accuracy: 0.7537\n",
      "Epoch: 9 Train Accuracy: 0.7445 Test Accuracy: 0.7537\n",
      "Epoch: 10 Train Accuracy: 0.7447 Test Accuracy: 0.7510\n",
      "Epoch: 11 Train Accuracy: 0.7444 Test Accuracy: 0.7510\n",
      "Epoch: 12 Train Accuracy: 0.7443 Test Accuracy: 0.7510\n",
      "Best Test Acc: 0.7550\n",
      "Best iterations: 8\n",
      "CPU times: user 2min 14s, sys: 1.13 s, total: 2min 15s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use training data to determine number of iterations\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=5, \n",
    "     train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=True)\n",
    "print(\"Best iterations:\", best_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Test on test data\n",
    "# mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "#                         max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "# best_mdl, test_acc_df_ml,_ = train_model(mdl,  xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "#                                        name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "#      max_epochs=best_iterations, early_stop_iters=best_iterations, train_instance_fn = train_cost_sensitive_instance, verbose=True)\n",
    "# # Best Test Acc: 0.7406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_features import filter_feats\n",
    "\n",
    "prefixes = [\n",
    "    \"Prob-\",\n",
    "    \"CREL_Pair-\",\n",
    "    \"Inv-\",\n",
    "    \"num_crels\",\n",
    "    \"Tally-\",\n",
    "    \"CChain-\",\n",
    "    \"CChainStats-\",\n",
    "    \"Above-\",\n",
    "    \"CREL_\",\n",
    "    \"Propn_\",\n",
    "    \"Diff_\"\n",
    "]\n",
    "# xs_fltr_train, xs_fltr_test = filter_feats(xs_train_mm, xs_test_mm, prefixes)\n",
    "assert len(prefixes) == len(set(prefixes)), \"Duplicate prefixes found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = -1\n",
    "current_best = []\n",
    "remaining = list(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CB_ESSAY_PARSER_RE-RANKER_FEATURE_SEL_TD', 8, 0.01)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONGO_COLLECTION, best_iterations, initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "\t1 feats F1: 0.7122 Prefixes: ['Prob-']\n",
      "\t1 feats F1: 0.7255 Prefixes: ['CREL_Pair-']\n",
      "\t1 feats F1: 0.7413 Prefixes: ['Inv-']\n",
      "\t1 feats F1: 0.6812 Prefixes: ['num_crels']\n",
      "\t1 feats F1: 0.6820 Prefixes: ['Tally-']\n",
      "\t1 feats F1: 0.7257 Prefixes: ['CChain-']\n",
      "\t1 feats F1: 0.7074 Prefixes: ['CChainStats-']\n",
      "\t1 feats F1: 0.7334 Prefixes: ['Above-']\n",
      "\t1 feats F1: 0.7317 Prefixes: ['CREL_']\n",
      "\t1 feats F1: 0.7103 Prefixes: ['Propn_']\n",
      "\t1 feats F1: 0.6871 Prefixes: ['Diff_']\n",
      "1 feats, new Best F1: 0.7413 Prefixes: ['Inv-']\n",
      "\t2 feats F1: 0.7228 Prefixes: ['Inv-', 'Prob-']\n",
      "\t2 feats F1: 0.7205 Prefixes: ['Inv-', 'CREL_Pair-']\n",
      "\t2 feats F1: 0.6821 Prefixes: ['Inv-', 'num_crels']\n",
      "\t2 feats F1: 0.6816 Prefixes: ['Inv-', 'Tally-']\n",
      "\t2 feats F1: 0.7239 Prefixes: ['Inv-', 'CChain-']\n",
      "\t2 feats F1: 0.7139 Prefixes: ['Inv-', 'CChainStats-']\n",
      "\t2 feats F1: 0.7344 Prefixes: ['Inv-', 'Above-']\n",
      "\t2 feats F1: 0.7300 Prefixes: ['Inv-', 'CREL_']\n",
      "\t2 feats F1: 0.7102 Prefixes: ['Inv-', 'Propn_']\n",
      "\t2 feats F1: 0.7206 Prefixes: ['Inv-', 'Diff_']\n",
      "No further improvement, stopping\n",
      "CPU times: user 20min 43s, sys: 36.9 s, total: 21min 19s\n",
      "Wall time: 21min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"best_top_n\": best_top_n,\n",
    "    \"best_max_upd\": best_max_upd,\n",
    "    \"best_max_parses\": best_max_parses,\n",
    "    \"best_min_prob\": best_min_prob,\n",
    "    \"min_feat_freq\": min_feat_freq\n",
    "}\n",
    "\n",
    "print(\"Starting...\")\n",
    "while True:\n",
    "    if len(remaining) == 0:\n",
    "        break\n",
    "    \n",
    "    f1_by_prefix = dict()\n",
    "    for prefix in remaining:\n",
    "        new_prefixes = current_best + [prefix]\n",
    "        \n",
    "        cv_filtered = []\n",
    "        for tr, test in cv_folds_mm:\n",
    "            x_tr,x_test = filter_feats(tr, test, new_prefixes)\n",
    "            cv_filtered.append((x_tr,x_test))\n",
    "        \n",
    "        f1_by_prefix[prefix] = train_model_parallel(\n",
    "            #training_collection_name=MONGO_COLLECTION, results_processor=results_processor,\n",
    "            #feat_extractors=new_prefixes, params=params,            \n",
    "            cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "            pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "            set_cr_tags=set_cr_tags, initial_weight=initial_weight,\n",
    "            # use best iterations from above\n",
    "            max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        print(\"\\t{length} feats F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(new_prefixes), f1=f1_by_prefix[prefix], prefixes=str(new_prefixes)))\n",
    "    \n",
    "    best_prefix, new_best_f1 = sorted(f1_by_prefix.items(), key = lambda tpl: -tpl[1])[0]\n",
    "    if new_best_f1 > best_f1:\n",
    "        best_f1 = new_best_f1\n",
    "        current_best.append(best_prefix)\n",
    "        remaining.remove(best_prefix)\n",
    "        print(\"{length} feats, new Best F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(current_best), f1=best_f1, prefixes=str(current_best)))\n",
    "    else:\n",
    "        print(\"No further improvement, stopping\")\n",
    "        break\n",
    "        \n",
    "# 1 feats, new Best F1: 0.7389 Prefixes: ['CREL_']\n",
    "# 2 feats, new Best F1: 0.7426 Prefixes: ['CREL_', 'Above-']\n",
    "\n",
    "# with num_crels fixed:\n",
    "# 1 feats, new Best F1: 0.7481 Prefixes: ['CREL_']\n",
    "# 2 feats, new Best F1: 0.7482 Prefixes: ['CREL_', 'num_crels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Inv-'], 0.7412673891359148)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_best, best_f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run it against the full set of features for comparison\n",
    "# cv_filtered = []\n",
    "# for tr, test in cv_folds_mm:\n",
    "#     x_tr,x_test = filter_feats(tr, test, prefixes)\n",
    "#     cv_filtered.append((x_tr,x_test))\n",
    "\n",
    "# f1 = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "#                           pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "#                           set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "# f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train_mm_fltr, xs_test_mm_fltr = filter_feats(xs_train_mm, xs_test_mm, current_best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm_fltr))\n",
    "tmp_train_copy = list(xs_train_mm_fltr)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the Optimal Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7454 Test Accuracy: 0.7226\n",
      "Epoch: 1 Train Accuracy: 0.7454 Test Accuracy: 0.7226\n",
      "Epoch: 2 Train Accuracy: 0.7454 Test Accuracy: 0.7226\n",
      "Epoch: 3 Train Accuracy: 0.7454 Test Accuracy: 0.7226\n",
      "Best Test Acc: 0.7226\n",
      "CPU times: user 872 ms, sys: 42.4 ms, total: 914 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=3, train_instance_fn = train_cost_sensitive_instance,\n",
    "                                                        verbose=True,  early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for X Iterations on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Best Test Acc: 0.7364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7364\n",
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Best Test Acc: 0.7364\n"
     ]
    }
   ],
   "source": [
    "# try initial weight of 0\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 1 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 2 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 3 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 4 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 5 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 6 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 7 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 8 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 9 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 10 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 11 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 12 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 13 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 14 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 15 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 16 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 17 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 18 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Epoch: 19 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
      "Best Test Acc: 0.7364\n"
     ]
    }
   ],
   "source": [
    "# try initial weight of 0, more training iterations\n",
    "ITERATIONS = 20\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=ITERATIONS, early_stop_iters=ITERATIONS,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Epoch: 19 Train Accuracy: 0.7411 Test Accuracy: 0.7364\n",
    "# Best Test Acc: 0.7364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7303 Test Accuracy: 0.7308\n",
      "Best Test Acc: 0.7308\n"
     ]
    }
   ],
   "source": [
    "# try an initial weight of 1\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Epoch: 0 Train Accuracy: 0.7303 Test Accuracy: 0.7308\n",
    "# Best Test Acc: 0.7308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.6864 Test Accuracy: 0.6814\n",
      "Best Test Acc: 0.6814\n"
     ]
    }
   ],
   "source": [
    "# initial weight of 1, all feats\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Epoch: 0 Train Accuracy: 0.6864 Test Accuracy: 0.6814\n",
    "# Best Test Acc: 0.6814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814024390243902"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Inv-not_inverted', 2.264999999999973),\n",
       " ('Above-All-Above-0.3', 2.0449999999999777),\n",
       " ('Above-All-Above-0.2', 2.0424999999999778),\n",
       " ('Above-All-Above-0.5', 1.8549999999999818),\n",
       " ('Prob-geo-mean', 1.7235842806917),\n",
       " ('Prob-min-prob', 1.6958928931766082),\n",
       " ('Prob-5%-prob', 1.6892733888996858),\n",
       " ('Prob-10%-prob', 1.6801976472883926),\n",
       " ('Prob-25%-prob', 1.5555806086790627),\n",
       " ('num_crels<=5', 1.517499999999989),\n",
       " ('Prob-prod-prob', 1.5041516926477634),\n",
       " ('Above-All-Above-0.7', 1.4599999999999902),\n",
       " ('num_crels<=6', 1.4574999999999902),\n",
       " ('num_crels<=4', 1.4349999999999907),\n",
       " ('num_crels<=7', 1.372499999999992),\n",
       " ('CChainStats-num_distinct_chains <=1', 1.3574999999999924),\n",
       " ('num_crels=0', 1.3574999999999924),\n",
       " ('CChainStats-num_distinct_chains <=2', 1.332499999999993),\n",
       " ('num_crels<=8', 1.3049999999999935),\n",
       " ('num_crels<=3', 1.3049999999999935),\n",
       " ('CChainStats-MaxChain_Len=3', 1.2949999999999937),\n",
       " ('Above-All-Above-0.8', 1.277499999999994),\n",
       " ('Above-%-0.5', 1.2748797279109814),\n",
       " ('Above-%-0.3', 1.2651302378177396),\n",
       " ('Above-%-0.8', 1.2641372273559814),\n",
       " ('Above-%-0.7', 1.262140505328009),\n",
       " ('Above-%-0.9', 1.2587461913086955),\n",
       " ('Above-%-0.2', 1.253745823620825),\n",
       " ('CChainStats-num_distinct_chains <=3', 1.2524999999999946),\n",
       " ('Prob-avg-prob', 1.2470314559455233),\n",
       " ('num_crels<=9', 1.2449999999999948),\n",
       " ('num_crels<=2', 1.2449999999999948),\n",
       " ('num_crels<=1', 1.2149999999999954),\n",
       " ('CChainStats-MaxChain_Len=0', 1.2099999999999955),\n",
       " ('CChainStats-num_distinct_chains=0', 1.2099999999999955),\n",
       " ('CChainStats-num_distinct_chains <=0', 1.2099999999999955),\n",
       " ('Above-%-0.95', 1.2022766504329037),\n",
       " ('Prob-med-prob', 1.18943557968473),\n",
       " ('CChainStats-num_distinct_chains <=4', 1.187499999999996),\n",
       " ('num_crels<=10', 1.1599999999999966),\n",
       " ('Above-All-Above-0.9', 1.1499999999999968),\n",
       " ('CChainStats-num_distinct_chains=1', 1.1474999999999969),\n",
       " ('CChainStats-num_distinct_chains <=5', 1.1324999999999972),\n",
       " ('num_crels=4', 1.1299999999999972),\n",
       " ('Propn_fwd', 1.111329018204022),\n",
       " ('num_crels=5', 1.0824999999999982),\n",
       " ('Above-All-Above-0.95', 1.0774999999999983),\n",
       " ('num_crels=3', 1.0599999999999987),\n",
       " ('Diff_adjacent_codes', 1.0485013181263199),\n",
       " ('Propn_unique_codes', 1.0462397862554205)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_mdl.weights.items(), key = lambda tpl: -abs(tpl[1]))[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "### Ideas\n",
    "- ~~num-crels - add back in the logic to threshold these? But only if needed to improve results here (seemed to help essay parser)~~\n",
    "- ~~Re-run with more realistic initial hyper params~~\n",
    "- ~~Add in logic to store results to mongo~~\n",
    "- ~~Switch back to using an initial_weight of 1~~\n",
    "- Approach seems very sensitive to the initial configuration of the algorithm. However, it also seems correlated to the training data performance on the first epoch. Run the algorithm multiple times, take the model with the best training performance and use that as the final selected model to train futher.\n",
    "- We need to add hyper parameter tuning\n",
    "- Do we want to just remove the BEAM search from this? It makes the explanation a lot more complex. But then again, it's the only way we can really add more crels that the model wouldn't otherwise parse\n",
    "- Do we use the BEAM search with some de-duping? Although we already de-dupe to some extent anyways\n",
    "\n",
    "### Needed to Finish\n",
    "- Record run on test data - needs optimal hyper parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
