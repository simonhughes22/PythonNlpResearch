{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Any\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from Settings import Settings\n",
    "from cost_functions import *\n",
    "from crel_helper import get_cr_tags\n",
    "from function_helpers import get_function_names, get_functions_by_name\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from searn_parser import SearnModelTemplateFeatures\n",
    "from template_feature_extractor import *\n",
    "from window_based_tagger_config import get_config\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "from searn_parser_breadth_first import ParseActionResult, SearnModelBreadthFirst\n",
    "from MIRA import MIRA, CostSensitiveMIRA\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "len(pred_tagged_essays_train),len(pred_tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY = \"Empty\"\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "def to_is_valid_crel(tags):\n",
    "    filtered = set()\n",
    "    for t in tags:\n",
    "        t_lower = t.lower()\n",
    "        if \"rhetorical\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "            continue\n",
    "        if \"->\" in t and ANAPHORA not in t:\n",
    "            filtered.add(t)\n",
    "    return filtered\n",
    "\n",
    "def get_crel_tags_by_sent(essays_a):\n",
    "    crels_by_sent = []\n",
    "    for ea in essays_a:\n",
    "        for asent in ea.sentences:\n",
    "            all_atags = set()\n",
    "            for awd, atags in asent:\n",
    "                all_atags.update(to_is_valid_crel(atags))\n",
    "            crels_by_sent.append(all_atags)\n",
    "    return crels_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:5->Result:50',\n",
       " 'Causer:7->Result:50',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:13->Result:50',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:6->Result:50',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:3->Result:1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "cr_tags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_cr_tags = set(cr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_essay_level(\n",
    "        folds: List[Tuple[Any, Any]],\n",
    "        extractor_fn_names_lst: List[str],\n",
    "        cost_function_name: str,\n",
    "        beta: float,\n",
    "        ngrams: int,\n",
    "        stemmed: bool,\n",
    "        max_epochs: int,\n",
    "        down_sample_rate=1.0) -> float:\n",
    "\n",
    "    if down_sample_rate < 1.0:\n",
    "        new_folds = []  # type: List[Tuple[Any, Any]]\n",
    "        for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "            essays_TD = essays_TD[:int(down_sample_rate * len(essays_TD))]\n",
    "            essays_VD = essays_VD[:int(down_sample_rate * len(essays_VD))]\n",
    "            new_folds.append((essays_TD, essays_VD))\n",
    "        folds = new_folds  # type: List[Tuple[Any, Any]]\n",
    "\n",
    "    serial_results = [\n",
    "        train_sr_parser(essays_TD, essays_VD, extractor_fn_names_lst, cost_function_name, ngrams, stemmed, beta, max_epochs)\n",
    "        for essays_TD, essays_VD in folds\n",
    "    ]\n",
    "\n",
    "    cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    # record the number of features in each fold\n",
    "    number_of_feats = []\n",
    "\n",
    "    # Parallel is almost 5X faster!!!\n",
    "    parser_models = []\n",
    "    for (model, num_feats,\n",
    "         sent_td_ys_bycode, sent_vd_ys_bycode,\n",
    "         sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode) in serial_results:\n",
    "        number_of_feats.append(num_feats)\n",
    "\n",
    "        parser_models.append(model)\n",
    "        merge_dictionaries(sent_td_ys_bycode, cv_sent_td_ys_by_tag)\n",
    "        merge_dictionaries(sent_vd_ys_bycode, cv_sent_vd_ys_by_tag)\n",
    "        merge_dictionaries(sent_td_pred_ys_bycode, cv_sent_td_predictions_by_tag)\n",
    "        merge_dictionaries(sent_vd_pred_ys_bycode, cv_sent_vd_predictions_by_tag)\n",
    "\n",
    "    # print(processor.results_to_string(sent_td_objectid, CB_SENT_TD, sent_vd_objectid, CB_SENT_VD, \"SENTENCE\"))\n",
    "    return parser_models, cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(observed_tags, ys_bytag_sent):\n",
    "    global set_cr_tags\n",
    "    for tag in set_cr_tags:\n",
    "        if tag in observed_tags:\n",
    "            ys_bytag_sent[tag].append(1)\n",
    "        else:\n",
    "            ys_bytag_sent[tag].append(0)\n",
    "            \n",
    "def get_label_data_essay_level(tagged_essays):\n",
    "    global set_cr_tags\n",
    "    # outputs\n",
    "    ys_bytag_essay = defaultdict(list)\n",
    "\n",
    "    for essay in tagged_essays:\n",
    "        unique_cr_tags = set()\n",
    "        for sentence in essay.sentences:\n",
    "            for word, tags in sentence:\n",
    "                unique_cr_tags.update(set_cr_tags.intersection(tags))\n",
    "        add_labels(unique_cr_tags, ys_bytag_essay)\n",
    "    return dict(ys_bytag_essay) # convert to dict so no issue when iterating over if additional keys are present\n",
    "\n",
    "def essay_to_crels(tagged_essays):\n",
    "    global set_cr_tags\n",
    "    # outputs\n",
    "    name2crels = defaultdict(set)\n",
    "    for essay in tagged_essays:\n",
    "        unique_cr_tags = set()\n",
    "        for sentence in essay.sentences:\n",
    "            for word, tags in sentence:\n",
    "                unique_cr_tags.update(set_cr_tags.intersection(tags))\n",
    "        name2crels[essay.name] = unique_cr_tags\n",
    "    return dict(name2crels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(metrics):\n",
    "    import Rpfa\n",
    "\n",
    "    rows = []\n",
    "    for k,val in metrics.items():\n",
    "        if type(val) == Rpfa.rpfa:\n",
    "            d = dict(val.__dict__) # convert obj to dict\n",
    "        elif type(val) == dict:\n",
    "            d = dict(val)\n",
    "        else:\n",
    "            d = dict()\n",
    "        d[\"code\"] = k\n",
    "        rows.append(d)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def get_micro_metrics(df):\n",
    "    return df[df.code == \"MICRO_F1\"][[\"accuracy\", \"f1_score\", \"recall\", \"precision\"]]\n",
    "\n",
    "def predict_essay_level(parser, essays):\n",
    "    pred_ys_by_sent = defaultdict(list)\n",
    "    for essay_ix, essay in enumerate(essays):\n",
    "        unq_pre_relations = set()\n",
    "        for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "            predicted_tags = essay.pred_tagged_sentences[sent_ix]\n",
    "            pred_relations = parser.predict_sentence(taggged_sentence, predicted_tags)\n",
    "            unq_pre_relations.update(pred_relations)\n",
    "        # Store predictions for evaluation\n",
    "        add_labels(unq_pre_relations, pred_ys_by_sent)\n",
    "    return pred_ys_by_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE_WIDTH = 80\n",
    "\n",
    "# other settings\n",
    "DOWN_SAMPLE_RATE = 1.0  # For faster smoke testing the algorithm\n",
    "BASE_LEARNER_FACT = None\n",
    "COLLECTION_PREFIX = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE\"\n",
    "\n",
    "# some of the other extractors aren't functional if the system isn't able to do a basic parse\n",
    "# so the base extractors are the MVP for getting to a basic parser, then additional 'meta' parse\n",
    "# features from all_extractors can be included\n",
    "base_extractors = [\n",
    "    single_words,\n",
    "    word_pairs,\n",
    "    three_words,\n",
    "    between_word_features\n",
    "]\n",
    "\n",
    "all_extractor_fns = base_extractors + [\n",
    "    word_distance,\n",
    "    valency,\n",
    "    unigrams,\n",
    "    third_order,\n",
    "    label_set,\n",
    "    size_features\n",
    "]\n",
    "\n",
    "all_cost_functions = [\n",
    "    micro_f1_cost,\n",
    "    micro_f1_cost_squared,\n",
    "    micro_f1_cost_plusone,\n",
    "    micro_f1_cost_plusepsilon,\n",
    "    binary_cost,\n",
    "    inverse_micro_f1_cost,\n",
    "    uniform_cost\n",
    "]\n",
    "\n",
    "all_extractor_fn_names = get_function_names(all_extractor_fns)\n",
    "base_extractor_fn_names = get_function_names(base_extractors)\n",
    "all_cost_fn_names = get_function_names(all_cost_functions)\n",
    "\n",
    "ngrams = 1\n",
    "stemmed = True\n",
    "cost_function_name = micro_f1_cost_plusepsilon.__name__\n",
    "dual = True\n",
    "fit_intercept = True\n",
    "beta = 0.5\n",
    "max_epochs = 2\n",
    "C = 0.5\n",
    "penalty = \"l2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note these also differ for SC dataset\n",
    "BASE_LEARNER_FACT = lambda : LogisticRegression(dual=dual, C=C, penalty=penalty, fit_intercept=fit_intercept)\n",
    "best_extractor_names = ['single_words', 'between_word_features', 'label_set',\n",
    "                                    'three_words', 'third_order', 'unigrams'] # type: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sr_parser(essays_TD, essays_VD, extractor_names, cost_function_name, ngrams, stemmed, beta, max_epochs):\n",
    "    extractors = get_functions_by_name(extractor_names, all_extractor_fns)\n",
    "    # get single cost function\n",
    "    cost_fn = get_functions_by_name([cost_function_name], all_cost_functions)[0]\n",
    "    assert cost_fn is not None, \"Cost function look up failed\"\n",
    "    # Ensure all extractors located\n",
    "    assert len(extractors) == len(extractor_names), \"number of extractor functions does not match the number of names\"\n",
    "\n",
    "    template_feature_extractor = NonLocalTemplateFeatureExtractor(extractors=extractors)\n",
    "    if stemmed:\n",
    "        ngram_extractor = NgramExtractorStemmed(max_ngram_len=ngrams)\n",
    "    else:\n",
    "        ngram_extractor = NgramExtractor(max_ngram_len=ngrams)\n",
    "    parse_model = SearnModelBreadthFirst(feature_extractor=template_feature_extractor,\n",
    "                                             cost_function=cost_fn,\n",
    "                                             min_feature_freq=MIN_FEAT_FREQ,\n",
    "                                             ngram_extractor=ngram_extractor, cr_tags=cr_tags,\n",
    "                                             base_learner_fact=BASE_LEARNER_FACT,\n",
    "                                             beta=beta,\n",
    "                                             # log_fn=lambda s: print(s))\n",
    "                                             log_fn=lambda s: None)\n",
    "\n",
    "    parse_model.train(essays_TD, max_epochs=max_epochs)\n",
    "\n",
    "    num_feats = template_feature_extractor.num_features()\n",
    "\n",
    "    sent_td_ys_bycode = get_label_data_essay_level(essays_TD)\n",
    "    sent_vd_ys_bycode = get_label_data_essay_level(essays_VD)\n",
    "\n",
    "    sent_td_pred_ys_bycode = predict_essay_level(parse_model, essays_TD)\n",
    "    sent_vd_pred_ys_bycode = predict_essay_level(parse_model, essays_VD)\n",
    "\n",
    "    return parse_model, num_feats, sent_td_ys_bycode, sent_vd_ys_bycode, sent_td_pred_ys_bycode, sent_vd_pred_ys_bycode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds     = [(pred_tagged_essays_train, pred_tagged_essays_test)]  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = cross_validation(pred_tagged_essays_train, CV_FOLDS)  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay Level Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_essay_level = evaluate_model_essay_level(\n",
    "    folds=cv_folds,\n",
    "    extractor_fn_names_lst=best_extractor_names,\n",
    "    cost_function_name=cost_function_name,\n",
    "    ngrams=ngrams,\n",
    "    beta=beta,\n",
    "    stemmed=stemmed,\n",
    "    down_sample_rate=DOWN_SAMPLE_RATE,\n",
    "    max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.98588</td>\n",
       "      <td>0.782102</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.806514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95   0.98588  0.782102  0.759124   0.806514"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, cv_td_preds_by_sent, \\\n",
    "    cv_sent_vd_ys_by_tag = result_test_essay_level\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.983102</td>\n",
       "      <td>0.742337</td>\n",
       "      <td>0.729197</td>\n",
       "      <td>0.755959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score    recall  precision\n",
       "95  0.983102  0.742337  0.729197   0.755959"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models, cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, \\\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = result_test_essay_level\n",
    "    \n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag)\n",
    "get_micro_metrics(metrics_to_df(mean_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Re-Ranker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_possible_crels(predicted_tags):\n",
    "    if len(predicted_tags) < 2:\n",
    "        return set()\n",
    "    predicted_tags = sorted(predicted_tags)\n",
    "    pred_crels = set()\n",
    "    for a,b in combinations(predicted_tags, 2):\n",
    "        pred_crels.add(\"Causer:{a}->Result:{b}\".format(a=a, b=b))\n",
    "        pred_crels.add(\"Causer:{b}->Result:{a}\".format(a=a, b=b))\n",
    "    return pred_crels\n",
    "\n",
    "def to_canonical_parse(crels):\n",
    "    return tuple(sorted(crels))\n",
    "\n",
    "def get_crels(parse):\n",
    "    crels = set()\n",
    "    p = parse\n",
    "    while p:\n",
    "        if p.relations:\n",
    "            crels.update(p.relations)\n",
    "        p = p.parent_action\n",
    "    return crels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searn_parser_breadth_first import geo_mean\n",
    "\n",
    "def collapse_sent_parse(pred_parses):\n",
    "    crel2prob = defaultdict(list)\n",
    "    for pact in pred_parses:\n",
    "        act_seq = pact.get_action_sequence()\n",
    "        for act in act_seq:\n",
    "            if not act.relations:\n",
    "                continue\n",
    "\n",
    "            assert act.lr_action_prob >= 0\n",
    "            prob = geo_mean([act.action_prob * act.lr_action_prob])\n",
    "            for r in act.relations:\n",
    "                crel2prob[r].append(prob)\n",
    "    return crel2prob\n",
    "\n",
    "def merge_crel_probs(a, b):    \n",
    "    for k,v in b.items():\n",
    "        a[k].extend(v)\n",
    "    return a\n",
    "\n",
    "def get_max_probs(crel2probs):\n",
    "    crel2max_prob = dict()\n",
    "    for crel, probs in crel2probs.items():\n",
    "        crel2max_prob[crel] = max(probs)\n",
    "    return crel2max_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "()\n",
      "(1,)\n",
      "(2,)\n",
      "(3,)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def get_all_combos(items):\n",
    "    # enforces a consistent ordering for the resulting tuples\n",
    "    items = sorted(items) \n",
    "    cbos = [()] # seed with the empty combo\n",
    "    for i in range(1, len(items)+1):\n",
    "        cbos.extend(combinations(items,i))\n",
    "    return cbos\n",
    "\n",
    "cbos = get_all_combos([3,2,1])\n",
    "print(len(cbos)) # 2**len(items)-1\n",
    "if len(cbos) < 1000:\n",
    "    for cbo in sorted(cbos, key = lambda l: (len(l), l)):\n",
    "        print(cbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(), ('1->2', '10->12', '12->50')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_parse(lst):\n",
    "    return tuple(sorted(lst))\n",
    "\n",
    "def sample_top_parses(crel2maxprobs, top_n):\n",
    "\n",
    "    max_parses = 2**len(crel2maxprobs) # maximum parse combinations\n",
    "    assert max_parses > top_n, (max_parses, top_n) # otherwise brute force it\n",
    "\n",
    "    top_parses = set([()]) # always seed with the empty parse\n",
    "    probs = []\n",
    "    while len(top_parses) < top_n:\n",
    "        new_parse = []\n",
    "        for crel, prob in crel2maxprobs.items():\n",
    "            rand_val = np.random.random() # random number >= 0 and < 1\n",
    "            if rand_val < prob:\n",
    "                new_parse.append(crel)\n",
    "        # make hashable and enforce consistent order\n",
    "        top_parses.add(to_parse(new_parse))\n",
    "    \n",
    "    return list(top_parses)\n",
    "\n",
    "def get_top_parses(crel2maxprobs, threshold=0.5):\n",
    "    top_parse = [crel for crel, prob in crel2maxprobs.items() if prob >= threshold]\n",
    "    if top_parse:\n",
    "        return [to_parse(top_parse)]\n",
    "    else:\n",
    "        return [()]\n",
    "    \n",
    "def get_top_n_parses(crel2maxprobs, top_n):\n",
    "    top_parses = [()]\n",
    "    by_prob = sorted(crel2maxprobs.keys(), key = lambda k: -crel2maxprobs[k])\n",
    "    for i in range(1, min(top_n, len(crel2maxprobs))+1):\n",
    "        parse = by_prob[:i]\n",
    "        top_parses.append(to_parse(parse))\n",
    "    return top_parses\n",
    "\n",
    "def get_top_n_parses2(crel2maxprobs, top_n):\n",
    "    top_parses = [()]\n",
    "    by_prob = sorted(crel2maxprobs.keys(), key = lambda k: -crel2maxprobs[k])\n",
    "    num_predicted = len([crel for crel in by_prob if crel2maxprobs[crel] >= 0.5])\n",
    "    for i in range(num_predicted-1, len(by_prob)+1):\n",
    "        parse = by_prob[:i]\n",
    "        top_parses.append(to_parse(parse))\n",
    "        if len(top_parses) > top_n:\n",
    "            break\n",
    "    return top_parses\n",
    "\n",
    "crel_probs = {\n",
    "    \"1->2\":   0.8,\n",
    "    \"2->3\":   0.01,\n",
    "    \"5->8\":   0.25,\n",
    "    \"10->12\": 0.75,\n",
    "    \"12->50\": 0.99,\n",
    "    \"3->4\":   0.50,\n",
    "}\n",
    "\n",
    "# important - should see a lot more of the more probable codes\n",
    "# sample_top_parses(crel_probs, 8)\n",
    "get_top_n_parses2(crel_probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NgramGenerator import compute_ngrams\n",
    "\n",
    "def to_short_tag(tag):\n",
    "    return tag.replace(\"Causer:\",\"\").replace(\"Result:\", \"\")\n",
    "\n",
    "def build_chains_inner(tree, l, visited, depth=0):\n",
    "    chains = []\n",
    "    if l not in tree:\n",
    "        return chains\n",
    "    for r in tree[l]:\n",
    "        if r in visited:\n",
    "            continue\n",
    "        visited.add(r) # needed to prevent cycles, which cause infinite recursion\n",
    "        extensions = build_chains_inner(tree, r, visited, depth+1)\n",
    "        visited.remove(r)\n",
    "        for ch in extensions:\n",
    "            chains.append([r] + ch)\n",
    "        if not extensions:\n",
    "            chains.append([r])\n",
    "    return chains\n",
    "\n",
    "def build_chains(tree):    \n",
    "    lhs_items = set(tree.keys())\n",
    "    rhs_items = set()\n",
    "    for l,rhs in tree.items():        \n",
    "        rhs_items.update(rhs)\n",
    "    \n",
    "    chains = []\n",
    "    # starting positions of each chain are those appearing on the lhs but not the rhs\n",
    "    start_codes = lhs_items - rhs_items    \n",
    "    for l in start_codes:\n",
    "        rhs = tree[l]\n",
    "        for r in rhs:\n",
    "            for ch in build_chains_inner(tree, r, {l,r}, 0):\n",
    "                chains.append([l,r] + ch)\n",
    "    return chains\n",
    "\n",
    "def extend_chains(chains):\n",
    "    ext_chains = set()\n",
    "    for tokens in chains:\n",
    "        ext_chains.add(\",\".join(tokens))\n",
    "        ngrams = compute_ngrams(tokens,max_len=None, min_len=3)\n",
    "        for t in ngrams:\n",
    "            ext_chains.add(\",\".join(t))\n",
    "    return ext_chains\n",
    "\n",
    "def extract_features_from_parse(parse, crel2probs):\n",
    "    \n",
    "    feats = defaultdict(float)\n",
    "    tree = defaultdict(set) # maps causers to effects for building chains\n",
    "    max_probs = []    \n",
    "    code_tally = defaultdict(float)\n",
    "    \n",
    "    pairs = set()\n",
    "    inverted_count = 0\n",
    "    for crel in parse:\n",
    "        probs = crel2probs[crel]\n",
    "        max_p = max(probs)\n",
    "        max_probs.append(max_p)\n",
    "        feats[\"{crel}-MAX(prob)\".format(crel=crel)] = max_p\n",
    "        feats[\"{crel}-MIN(prob)\".format(crel=crel)] = min(probs)\n",
    "        feats[\"{crel}-pred-count\".format(crel=crel)] = len(probs)\n",
    "        feats[\"{crel}-pred-count={count}\".format(crel=crel, count=len(probs))] = 1\n",
    "        \n",
    "        # with type\n",
    "        l,r = crel.split(\"->\")\n",
    "        code_tally[l] +=1\n",
    "        code_tally[r] +=1\n",
    "        \n",
    "        # without type\n",
    "        l_short, r_short = to_short_tag(l), to_short_tag(r)\n",
    "        code_tally[l_short] +=1\n",
    "        code_tally[r_short] +=1\n",
    "        # ordering of the codes, ignoring the causal direction\n",
    "        feats[l_short + \":\" + r_short] = 1\n",
    "        \n",
    "        # build tree structure so we can retrieve the chains\n",
    "        tree[l_short].add(r_short)\n",
    "        \n",
    "        # track whether the rule exists in the opposite direction\n",
    "        pairs.add((l_short,r_short))\n",
    "        if (r_short,l_short) in pairs:\n",
    "            inverted_count += 1\n",
    "            \n",
    "    if inverted_count:\n",
    "        feats[\"inverted\"] = 1\n",
    "        feats[\"num_inverted\"] = inverted_count\n",
    "    else:\n",
    "        feats[\"not_inverted\"] = 1\n",
    "    \n",
    "    # counts\n",
    "    feats.update(code_tally)\n",
    "    num_crels = len(parse)\n",
    "    feats[\"num_crels\"] = num_crels\n",
    "    feats[\"num_crels=\"+str(len(parse))] = 1 # includes a tag for the empty parse\n",
    "    for i in range(1,11):\n",
    "        if num_crels <= i:\n",
    "            feats[\"num_crels<={i}\".format(i=i)] = 1\n",
    "        else:\n",
    "            feats[\"num_crels>{i}\".format(i=i)] = 1\n",
    "        \n",
    "    # combination of crels\n",
    "    # need to sort so that order of a and b is consistent across parses\n",
    "    pairs = combinations(sorted(parse), r=2)\n",
    "    for a, b in pairs:\n",
    "        feats[\"{a}|{b}\".format(a=a, b=b)] = 1\n",
    "        \n",
    "    #chains\n",
    "    causer_chains = extend_chains(build_chains(tree))\n",
    "    for ch in causer_chains:\n",
    "        feats[\"CChain:\" + ch] = 1\n",
    "    \n",
    "    if max_probs: # might be an empty parse\n",
    "        for cutoff in [0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95]:\n",
    "            above =  len([p for p in max_probs if p >=cutoff])\n",
    "            feats[\"Above-{cutoff}\".format(cutoff=cutoff)] = above\n",
    "            feats[\"%-Above-{cutoff}\".format(cutoff=cutoff)] = above/len(max_probs)\n",
    "            if above == len(max_probs):\n",
    "                feats[\"All-Above-{cutoff}\".format(cutoff=cutoff)] = 1\n",
    "        \n",
    "        feats[\"avg-prob\"] = np.mean(max_probs)\n",
    "        feats[\"med-prob\"] = np.median(max_probs)\n",
    "        feats[\"prod-prob\"]= np.product(max_probs)\n",
    "        feats[\"min-prob\"] = np.min(max_probs)\n",
    "        feats[\"max-prob\"] = np.max(max_probs)\n",
    "        for p in [5, 10, 25, 75, 90, 95]:\n",
    "            feats[\"{p}%-prob\".format(p=p)] = np.percentile(max_probs, p)\n",
    "        # geometric mean\n",
    "        feats[\"geo-mean\"] = np.prod(max_probs)**(1/len(max_probs))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "    \n",
    "name2crels = essay_to_crels(all_essays)\n",
    "\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_costs(parser_input):\n",
    "    opt_parse = parser_input.opt_parse\n",
    "    other_parses = parser_input.other_parses\n",
    "\n",
    "    other_costs = []\n",
    "    op = set(opt_parse)\n",
    "    for p in other_parses:\n",
    "        p = set(p)\n",
    "        fp = p - op\n",
    "        fn = op - p\n",
    "        cost = len(fp) + len(fn)\n",
    "        other_costs.append(cost)\n",
    "    return other_costs\n",
    "\n",
    "def copy_dflt_dict(d):\n",
    "    copy = defaultdict(d.default_factory)\n",
    "    copy.update(d)\n",
    "    return copy\n",
    "\n",
    "class ParserInputs(object):\n",
    "    def __init__(self, essay_name, opt_parse, all_parses, crel2probs, compute_feats=True):\n",
    "        self.essay_name = essay_name\n",
    "        self.opt_parse = opt_parse\n",
    "        self.crel2probs = crel2probs\n",
    "        \n",
    "        if compute_feats:\n",
    "            self.opt_features = extract_features_from_parse(opt_parse, crel2probs)\n",
    "            \n",
    "            other_parses = []\n",
    "            other_feats_array = []\n",
    "            all_feats_array = []\n",
    "            for p in all_parses:\n",
    "                feats = extract_features_from_parse(p, crel2probs)\n",
    "                all_feats_array.append(feats)\n",
    "                if p != opt_parse:\n",
    "                    other_parses.append(p)\n",
    "                    other_feats_array.append(feats)\n",
    "\n",
    "            self.all_feats_array = all_feats_array\n",
    "            self.other_parses = other_parses\n",
    "            self.other_features_array = other_feats_array\n",
    "            self.other_costs_array = compute_costs(self)\n",
    "                    \n",
    "        self.all_parses = all_parses\n",
    "        \n",
    "    def clone_without_feats(self):\n",
    "        c = ParserInputs(essay_name=self.essay_name, opt_parse=self.opt_parse, \n",
    "                         all_parses=self.all_parses, crel2probs=self.crel2probs, compute_feats=False)\n",
    "        \n",
    "        c.other_parses = self.other_parses\n",
    "        c.other_costs_array = self.other_costs_array\n",
    "        return c\n",
    "\n",
    "    def clone(self):\n",
    "        c = ParserInputs(essay_name=self.essay_name, opt_parse=self.opt_parse, \n",
    "                         all_parses=self.all_parses, crel2probs=self.crel2probs, compute_feats=False)\n",
    "        \n",
    "        c.all_feats_array = [copy_dflt_dict(f) for f in self.all_feats_array]\n",
    "        c.opt_features = copy_dflt_dict(self.opt_features)\n",
    "        c.other_parses = self.other_parses\n",
    "        c.other_features_array = [copy_dflt_dict(f) for f in self.other_features_array]\n",
    "        c.other_costs_array = self.other_costs_array\n",
    "        return c\n",
    "\n",
    "def to_freq_feats(feats, freq_feats):\n",
    "    new_feats = defaultdict(float)\n",
    "    for f, v in feats.items():\n",
    "        if f in freq_feats:\n",
    "            new_feats[f] = v\n",
    "    return new_feats\n",
    "\n",
    "def filter_by_min_freq(xs, feat_freq, min_freq):\n",
    "    if min_freq <= 1:\n",
    "        return xs\n",
    "    freq_feats = set((f for f, cnt in feat_freq.items() if cnt >= min_freq))\n",
    "    for parser_input in xs:\n",
    "        parser_input.opt_features = to_freq_feats(parser_input.opt_features, freq_feats)\n",
    "        parser_input.other_features_array = [to_freq_feats(x, freq_feats)\n",
    "                                             for x in parser_input.other_features_array]\n",
    "    return xs\n",
    "\n",
    "def accumulate_feat_vals(xs_train):\n",
    "    def merge_feats(feats):\n",
    "        for ft,val in feats.items():\n",
    "            fts_vals[ft].append(val)\n",
    "    \n",
    "    fts_vals = defaultdict(list)\n",
    "    cnt = 0\n",
    "    for parser_input in xs_train:\n",
    "        cnt+=1\n",
    "        merge_feats(parser_input.opt_features)\n",
    "        for x in parser_input.other_features_array:\n",
    "            cnt+=1\n",
    "            merge_feats(x)\n",
    "    return fts_vals, cnt\n",
    "\n",
    "def z_score_normalize_feats(xs_train, xs_test):\n",
    "    fts_vals, cnt = accumulate_feat_vals(xs_train)\n",
    "    \n",
    "    fts_mean, fts_std = dict(), dict()\n",
    "    for ft, vals in fts_vals.items():\n",
    "        v_with_zeros = vals + ([0] * (cnt-len(vals)))\n",
    "        std = np.std(v_with_zeros)\n",
    "        if std == 0.0:\n",
    "            fts_mean[ft] = 0\n",
    "            fts_std[ft] = vals[0]\n",
    "        else:\n",
    "            fts_mean[ft] = np.mean(v_with_zeros)\n",
    "            fts_std[ft] =  np.std(v_with_zeros)\n",
    "    \n",
    "    def to_z_score(fts):\n",
    "        new_fts = defaultdict(fts.default_factory)\n",
    "        for ft, val in fts.items():\n",
    "            if ft in fts_mean:\n",
    "                new_val = (val - fts_mean[ft])/fts_std[ft]\n",
    "                if new_val:\n",
    "                    new_fts[ft] = new_val\n",
    "        return new_fts\n",
    "    \n",
    "    def z_score_normalize(parser_input):\n",
    "        clone = parser_input.clone_without_feats()\n",
    "        clone.opt_features = to_z_score(parser_input.opt_features)\n",
    "        clone.all_feats_array = [to_z_score(x) for x in parser_input.all_feats_array]\n",
    "        clone.other_features_array = [to_z_score(x) for x in parser_input.other_features_array]\n",
    "        return clone\n",
    "    \n",
    "    new_xs_train = [z_score_normalize(x) for x in xs_train]\n",
    "    new_xs_test  = [z_score_normalize(x) for x in xs_test]\n",
    "    return new_xs_train, new_xs_test\n",
    "\n",
    "def min_max_normalize_feats(xs_train, xs_test):\n",
    "    fts_vals, cnt = accumulate_feat_vals(xs_train)\n",
    "    \n",
    "    fts_min, fts_range = dict(), dict()\n",
    "    for ft, vals in fts_vals.items():\n",
    "        v_with_zeros = vals + ([0] * (cnt-len(vals)))   \n",
    "        min_val = np.min(v_with_zeros)\n",
    "        range_val = np.max(v_with_zeros) - min_val\n",
    "        fts_min[ft] = min_val\n",
    "        fts_range[ft] = range_val\n",
    "    \n",
    "    def to_min_max_score(fts):\n",
    "        new_fts = defaultdict(fts.default_factory)\n",
    "        for ft, val in fts.items():\n",
    "            if ft in fts_min and fts_range[ft] != 0:\n",
    "                new_val = (val - fts_min[ft])/fts_range[ft]\n",
    "                if new_val:\n",
    "                    new_fts[ft] = new_val\n",
    "        return new_fts\n",
    "    \n",
    "    def min_max_normalize(parser_input):\n",
    "        clone = parser_input.clone_without_feats()\n",
    "        clone.opt_features = to_min_max_score(parser_input.opt_features)\n",
    "        clone.all_feats_array = [to_min_max_score(x) for x in parser_input.all_feats_array]\n",
    "        clone.other_features_array = [to_min_max_score(x) for x in parser_input.other_features_array]\n",
    "        return clone\n",
    "    \n",
    "    new_xs_train = [min_max_normalize(x) for x in xs_train]\n",
    "    new_xs_test  = [min_max_normalize(x) for x in xs_test]\n",
    "    return new_xs_train, new_xs_test\n",
    "\n",
    "def get_crels_above(crel2maxprob, threshold):\n",
    "    return [k for k, p in crel2maxprob.items() if p >= threshold]\n",
    "\n",
    "def get_features_from_probabilities(essay2probs, top_n, min_feat_freq=1, min_prob=0.0):\n",
    "    xs = []\n",
    "    feat_freq = defaultdict(int)\n",
    "    \n",
    "    for ename, crel2probs in essay2probs.items():\n",
    "\n",
    "        act_crels = name2crels[ename]\n",
    "        crel2maxprob = get_max_probs(crel2probs)        \n",
    "        crel2probs = dict(crel2probs)\n",
    "        \n",
    "        keys = list(crel2probs.keys())\n",
    "        n_parses = 2 ** len(keys)\n",
    "        \n",
    "        increment = 0.05\n",
    "        threshold = min_prob - increment\n",
    "        while n_parses > 2 * top_n and threshold < 1.0:\n",
    "            threshold += increment\n",
    "            keys = get_crels_above(crel2maxprob, threshold)\n",
    "            n_parses = 2 ** len(keys)\n",
    "\n",
    "        if n_parses >  2 * top_n:\n",
    "            print(\"n_parses={n_parses} still exceeded max={max_p} at p={p:.4f}\".format(\n",
    "                p=threshold, n_parses=n_parses, max_p=top_n))\n",
    "            parses = get_top_parses(crel2maxprob)\n",
    "        else:\n",
    "            parses = get_all_combos(keys)\n",
    "\n",
    "        # constrain optimal parse to only those crels that are predicted\n",
    "        opt_parse = tuple(sorted(act_crels.intersection(crel2probs.keys())))\n",
    "        x = ParserInputs(essay_name=ename, opt_parse=opt_parse, all_parses=parses, crel2probs=crel2probs)\n",
    "        xs.append(x)\n",
    "\n",
    "        # Get unique features for essay\n",
    "        all_feats = set()\n",
    "        for fts in x.all_feats_array:\n",
    "            all_feats.update(fts.keys())\n",
    "\n",
    "        for ft in all_feats:\n",
    "            feat_freq[ft] += 1\n",
    "\n",
    "    assert len(xs) == len(essay2probs), \"Parses for all essays should be generated\"\n",
    "    return filter_by_min_freq(xs, feat_freq, min_feat_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cr_labels(observed_tags, ys_bytag_sent):\n",
    "    global set_cr_tags\n",
    "    for tag in set_cr_tags:\n",
    "        if tag in observed_tags:\n",
    "            ys_bytag_sent[tag].append(1)\n",
    "        else:\n",
    "            ys_bytag_sent[tag].append(0)\n",
    "            \n",
    "def evaluate_ranker(model, xs, essay2crels, ys_bytag):\n",
    "    clone = model.clone()\n",
    "    if hasattr(model, \"average_weights\"):\n",
    "        clone.average_weights()\n",
    "    rank_acc = []\n",
    "    pred_ys_bytag = defaultdict(list)\n",
    "    ename2inps = dict()\n",
    "    for parser_input in xs:\n",
    "        ename2inps[parser_input.essay_name] = parser_input\n",
    "    \n",
    "    for ename, act_crels in essay2crels.items():        \n",
    "        if ename not in ename2inps:\n",
    "            # no predicted crels for this essay\n",
    "            highest_ranked = set()\n",
    "        else:\n",
    "            parser_input = ename2inps[ename]\n",
    "            ixs = clone.rank(parser_input.all_feats_array)\n",
    "            highest_ranked = parser_input.all_parses[ixs[0]] # type: Tuple[str]        \n",
    "            rank_acc.append(1 if highest_ranked == parser_input.opt_parse else 0)\n",
    "            \n",
    "        add_cr_labels(set(highest_ranked), pred_ys_bytag)\n",
    "\n",
    "    mean_metrics = ResultsProcessor.compute_mean_metrics(ys_bytag, pred_ys_bytag)\n",
    "    df = get_micro_metrics(metrics_to_df(mean_metrics))\n",
    "    df[\"rank_acc\"] = np.mean(rank_acc)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "\n",
    "def train_instance(parser_input, model):\n",
    "    model.train(best_feats=parser_input.opt_features, other_feats_array=parser_input.other_features_array)\n",
    "\n",
    "def train_cost_sensitive_instance(parser_input, model):\n",
    "    model.train(best_feats=parser_input.opt_features, \n",
    "                other_feats_array=parser_input.other_features_array, other_costs_array=parser_input.other_costs_array)\n",
    "    \n",
    "def get_essays_for_data(xs):\n",
    "    return [name2essay[x.essay_name] for x in xs]\n",
    "    \n",
    "def train_model(model, xs_train, xs_test, max_epochs=30, early_stop_iters=8, train_instance_fn=train_instance, verbose=True):\n",
    "    test_accs = [-1]\n",
    "    best_model = None\n",
    "    best_test_accuracy = None\n",
    "    num_declining_acc = 0\n",
    "\n",
    "    train_essays = get_essays_for_data(xs_train)\n",
    "    test_essays  = get_essays_for_data(xs_test)\n",
    "\n",
    "    ys_by_tag_train = get_label_data_essay_level(train_essays)\n",
    "    ys_by_tag_test  = get_label_data_essay_level(test_essays)\n",
    "\n",
    "    essay2crels_train = essay_to_crels(train_essays)\n",
    "    essay2crels_test  = essay_to_crels(test_essays)\n",
    "    \n",
    "    xs_train_copy = list(xs_train)    \n",
    "    for i in range(max_epochs):\n",
    "        shuffle(xs_train_copy)\n",
    "        for parser_input in xs_train_copy:\n",
    "            if len(parser_input.other_parses) > 0:\n",
    "                train_instance_fn(parser_input, model)\n",
    "\n",
    "        train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n",
    "        test_accuracy_df  = evaluate_ranker(model, xs_test,  essay2crels_test,  ys_by_tag_test)\n",
    "        train_accuracy = train_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n",
    "        test_accuracy  = test_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n",
    "        if verbose:\n",
    "            print(\"Epoch: {epoch} Train Accuracy: {train_acc:.4f} Test Accuracy: {test_acc:.4f}\".format(\n",
    "            epoch=i,  train_acc=train_accuracy, test_acc=test_accuracy))\n",
    "        if test_accuracy > max(test_accs):\n",
    "            best_model = model.clone()\n",
    "            best_test_accuracy = test_accuracy_df\n",
    "            num_declining_acc = 0\n",
    "        else:\n",
    "            num_declining_acc += 1\n",
    "            if num_declining_acc >= early_stop_iters:\n",
    "                break\n",
    "        test_accs.append(test_accuracy)\n",
    "    if verbose:\n",
    "        print(\"Best Test Acc: {acc:.4f}\".format(acc=max(test_accs)))\n",
    "    return best_model, best_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_essay2crelprobs(a,b):\n",
    "    for ename, dct in b.items():\n",
    "        a[ename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essays2crels(essays, sr_model, top_n):\n",
    "    trainessay2probs = defaultdict(list)\n",
    "    for eix, essay in enumerate(essays):\n",
    "        crel2probs = defaultdict(list)        \n",
    "        for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "            predicted_tags = essay.pred_tagged_sentences[sent_ix]\n",
    "            unq_ptags = set([t for t in predicted_tags if t != EMPTY])            \n",
    "            if len(unq_ptags) >= 2:\n",
    "                pred_parses = sr_model.generate_all_potential_parses_for_sentence(\n",
    "                    tagged_sentence=taggged_sentence, predicted_tags=predicted_tags, top_n=top_n)\n",
    "                cr2p = collapse_sent_parse(pred_parses)\n",
    "                merge_crel_probs(crel2probs, cr2p)\n",
    "    \n",
    "        if len(crel2probs) > 0:\n",
    "            trainessay2probs[essay.name] = dict(crel2probs)\n",
    "        else:\n",
    "            trainessay2probs[essay.name] = dict()\n",
    "    return trainessay2probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essay_to_crels_cv(cv_volds, models, top_n):\n",
    "    essay2crelprobs = defaultdict(list)\n",
    "    assert len(cv_folds) == len(models)\n",
    "    for (train, test), mdl in zip(cv_folds, models):\n",
    "        test2probs = get_essays2crels(test, mdl, top_n)\n",
    "        for k,v in test2probs.items():\n",
    "            assert k not in essay2crelprobs\n",
    "            essay2crelprobs[k] = v\n",
    "    return essay2crelprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split_dict(dct, train_pct):\n",
    "    items = list(dct.items())\n",
    "    np.random.shuffle(items)\n",
    "    num_train = int(len(items) * train_pct)\n",
    "    train_items, test_items = items[:num_train], items[num_train:]\n",
    "    return dict(train_items), dict(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# TOP_N = 10 # 10 is better\n",
    "# xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=TOP_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2predcrels, test2predcrels = shuffle_split_dict(xs_rerank, 0.8)\n",
    "# len(train2predcrels), len(test2predcrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = []\n",
    "# for ename, crel2probs in train2predcrels.items():\n",
    "#     lens.append(len(crel2probs))\n",
    "# min(lens), max(lens), np.mean(lens), np.median(lens), len([l for l in lens if l > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# MAX_PARSES = 500\n",
    "# xs_train = get_features_from_probabilities(train2predcrels, MAX_PARSES, min_feat_freq=1)\n",
    "# xs_test  = get_features_from_probabilities(test2predcrels,  MAX_PARSES, min_feat_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(xs_train), len(xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new record accuracy - ML, C=0.05, PA = I, with min max feats\n",
    "# model_ml = CostSensitiveMIRA(C=0.05, pa_type=1, loss_type=\"ml\", max_update_items=1, initial_weight=1)\n",
    "# best_model_ml, test_acc_df_ml = train_model(model_ml, xs_train=xs_train, xs_test=xs_test,         \n",
    "#         max_epochs=50, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# xs_train_mm_norm, xs_test_mm_norm = min_max_normalize_feats(xs_train, xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new record accuracy - ML, C=0.05, PA = I, with min max feats\n",
    "# model_ml = CostSensitiveMIRA(C=0.05, pa_type=1, loss_type=\"ml\", max_update_items=1, initial_weight=1)\n",
    "# best_model_ml, test_acc_df_ml = train_model(model_ml, xs_train=xs_train_mm_norm, xs_test=xs_test_mm_norm,          \n",
    "#         max_epochs=50, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_fold(xs_train, xs_test, C, pa_type, loss_type, max_update_items):\n",
    "    \n",
    "    mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, max_update_items=max_update_items, initial_weight=1)\n",
    "    best_mdl, test_acc_df_ml = train_model(mdl, xs_train=xs_train, xs_test=xs_test, \n",
    "        max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n",
    "    f1 = test_acc_df_ml[\"f1_score\"].values[0]\n",
    "    return f1\n",
    "\n",
    "def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n",
    "    \n",
    "    try:\n",
    "        f1s = Parallel(n_jobs=len(cv_folds))(delayed(train_model_fold)(train,test, C, pa_type, loss_type, max_update_items) \n",
    "                                         for (train,test) in cv_folds)\n",
    "        return np.mean(f1s)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Process stopped by user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for Beam Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial settings for other params\n",
    "best_max_parses = 300\n",
    "best_C = 0.005\n",
    "best_max_upd=5\n",
    "best_min_prob = 0.05\n",
    "best_top_n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_n: 2\n",
      "F1: 0.7414\n",
      "********************************************************************************\n",
      "New Max F1: 0.7414 \tTop N: 2\n",
      "\n",
      "top_n: 3\n",
      "F1: 0.7343\n",
      "\n",
      "top_n: 5\n",
      "F1: 0.7301\n",
      "\n",
      "top_n: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-41:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-52d6dfd34d4c>\u001b[0m in \u001b[0;36mtrain_model_parallel\u001b[0;34m(cv_folds, C, pa_type, loss_type, max_update_items, train_instance_fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     f1s = Parallel(n_jobs=len(cv_folds))(delayed(train_model_fold)(train,test, C, pa_type, loss_type, max_update_items) \n\u001b[0;32m---> 12\u001b[0;31m                                          for (train,test) in cv_folds)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# the results as we will raise the exception we got back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;31m# to the caller instead of returning any result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                     \u001b[0;31m# In case we had to terminate a managed pool, let\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# terminate does a join()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multiprocessing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \u001b[0;31m# worker has not yet exited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cleaning up worker %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAX_PARSES = 500\n",
    "\n",
    "max_f1 = -1\n",
    "topn2metrics = defaultdict(list)\n",
    "best_top_n = -1\n",
    "\n",
    "for top_n in [2,3,5,10,20,50,100]:    \n",
    "    print(\"top_n: {top_n}\".format(top_n=top_n))\n",
    "    \n",
    "    xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=top_n)\n",
    "    xs = get_features_from_probabilities(xs_rerank, best_max_parses, min_feat_freq=1, min_prob=best_min_prob)\n",
    "    \n",
    "    cv_folds_rerank = cross_validation(xs, 3)\n",
    "# Parallelizing this takes longer as it uses a lot of RAM\n",
    "#     cf_folds_mm = Parallel(n_jobs=len(cv_folds_rerank))(delayed(min_max_normalize_feats)(train,test) for (train,test) in cv_folds_rerank)\n",
    "#     cv_folds_mm = [min_max_normalize_feats(train,test) for (train,test) in cv_folds_rerank]\n",
    "    \n",
    "    f1 = train_model_parallel(cv_folds=cv_folds_rerank, C=best_C, pa_type=1, loss_type=\"ml\", \n",
    "                              max_update_items=best_max_upd)             \n",
    "    topn2metrics[top_n].append(f1)\n",
    "    print(\"F1: {f1:.4f}\".format(f1=f1))\n",
    "    if f1 > max_f1:\n",
    "        print(\"*\" * 80)\n",
    "        max_f1 = f1\n",
    "        best_top_n = top_n\n",
    "        print(\"New Max F1: {f1:.4f} \\tTop N: {top_n}\".format(f1=max_f1, top_n=top_n))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for C and Max Upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MAX_PARSES = 500\n",
    "TOP_N = best_top_n\n",
    "max_f1 = -1\n",
    "\n",
    "xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=top_n)\n",
    "xs = get_features_from_probabilities(xs_rerank, best_max_parses, min_feat_freq=1, min_prob=best_min_prob)\n",
    "    \n",
    "cv_folds_rerank = cross_validation(xs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1.0 Max_Upd:1\n"
     ]
    }
   ],
   "source": [
    "best_C = -1\n",
    "best_max_upd = -1\n",
    "c2metrics = defaultdict(list)\n",
    "for C in [0.0025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.5, 1.0][::-1]:\n",
    "    \n",
    "    for max_upd in [1, 2, 3, 5, 7, 10, 15, 20]:\n",
    "        print(\"C: {c} Max_Upd:{max_upd}\".format(c=C, max_upd=max_upd))\n",
    "\n",
    "        f1 = train_model_parallel(cv_folds=cv_folds_rerank, C=C, pa_type=1, loss_type=\"ml\", \n",
    "                              max_update_items=max_upd)\n",
    "\n",
    "        c2metrics[(C,max_upd)].append(f1)\n",
    "        print(\"F1: {f1:.4f}\".format(f1=f1))\n",
    "        if f1 > max_f1:\n",
    "            print(\"*\" * 80)\n",
    "            max_f1 = f1\n",
    "            best_C=C\n",
    "            best_max_upd = max_upd\n",
    "            print(\"New Max F1: {f1:.4f} \\tC: {C} \\tMax_Upd: {max_upd}\".format(f1=max_f1, C=C, max_upd=max_upd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize for MAX Parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_parses: 50\n"
     ]
    },
    {
     "ename": "JoblibZeroDivisionError",
     "evalue": "JoblibZeroDivisionError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10a482660, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/simon.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10a482660, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/simon.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method PollIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    827                         self._timeouts = [x for x in self._timeouts\n    828                                           if x.callback is not None]\n    829                         heapq.heapify(self._timeouts)\n    830 \n    831                 for i in range(ncallbacks):\n--> 832                     self._run_callback(self._callbacks.popleft())\n        self._run_callback = <bound method IOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        self._callbacks.popleft = <built-in method popleft of collections.deque object>\n    833                 for timeout in due_timeouts:\n    834                     if timeout.callback is not None:\n    835                         self._run_callback(timeout.callback)\n    836                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x1a3bf23048>))\n    600         \"\"\"Runs a callback with error handling.\n    601 \n    602         For use in subclasses.\n    603         \"\"\"\n    604         try:\n--> 605             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1a3bf23048>)\n    606             if ret is not None:\n    607                 from tornado import gen\n    608                 # Functions that return Futures typically swallow all\n    609                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'11bc89fb088bc560fec8b97fc828d2c9']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'11bc89fb088bc560fec8b97fc828d2c9'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-54-05015c66bd34>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>\n        result = <ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>, result=<ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>\n        self.user_global_ns = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n        self.user_ns = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-54-05015c66bd34> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic('time', '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nbest_max_parses = -1\\nfor max_parses in [50, 75, 100, 150, 200, 300]:\\n    \\n    print(\"max_parses: {max_parses}\".format(max_parses=max_parses))\\n    \\n    xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=best_top_n)\\n    xs = get_features_from_probabilities(xs_rerank, max_parses, min_feat_freq=1, min_prob=best_min_prob)    \\n    cv_folds_rerank = cross_validation(xs, 3)\\n    \\n    f1 = train_model_parallel(cv_folds=cv_folds_rerank, C=best_C, pa_type=1, loss_type=\"ml\", \\n                              max_update_items=best_max_upd)             \\n    print(\"F1: {f1:.4f}\".format(f1=f1))\\n    topn2metrics2[max_parses].append(f1)\\n    if f1 > max_f1:\\n        print(\"*\" * 80)\\n        max_f1 = f1\\n        best_max_parses = max_parses\\n        print(\"New Max F1: {f1:.4f} \\\\tMax Parses: {max_parses}\".format(f1=max_f1, top_n=max_parses))')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))')\n   2126             # This will need to be updated if the internal calling logic gets\n   2127             # refactored, or else we'll be expanding the wrong variables.\n   2128             stack_depth = 2\n   2129             magic_arg_s = self.var_expand(line, stack_depth)\n   2130             with self.builtin_trap:\n-> 2131                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))'\n   2132             return result\n   2133 \n   2134     def find_line_magic(self, magic_name):\n   2135         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', local_ns=None)\n   1233                 return\n   1234             end = clock2()\n   1235         else:\n   1236             st = clock2()\n   1237             try:\n-> 1238                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x1a497e6ae0, file \"<timed exec>\", line 2>\n        glob = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n        local_ns = None\n   1239             except:\n   1240                 self.shell.showtraceback()\n   1241                 return\n   1242             end = clock2()\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<timed exec> in <module>()\n      9 \n     10 \n     11 \n     12 \n     13 \n---> 14 \n     15 \n     16 \n     17 \n     18 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_parallel(cv_folds=[([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...]), ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...]), ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...])], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      8 \n      9 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     10     \n     11     try:\n     12         f1s = Parallel(n_jobs=len(cv_folds))(delayed(train_model_fold)(train,test, C, pa_type, loss_type, max_update_items) \n---> 13                                          for (train,test) in cv_folds)\n     14         return np.mean(f1s)\n     15     except KeyboardInterrupt:\n     16         print(\"Process stopped by user\")\n     17 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object train_model_parallel.<locals>.<genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nZeroDivisionError                                  Wed Feb  6 18:30:17 2019\nPID: 95085Python 3.6.4: /Users/simon.hughes/anaconda3/envs/phd_py36/bin/python\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function train_model_fold>, ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function train_model_fold>\n        args = ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1)\n        kwargs = {}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_fold(xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      1 \n      2 def train_model_fold(xs_train, xs_test, C, pa_type, loss_type, max_update_items):\n      3     \n      4     mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, max_update_items=max_update_items, initial_weight=1)\n----> 5     best_mdl, test_acc_df_ml = train_model(mdl, xs_train=xs_train, xs_test=xs_test, \n      6         max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n      7     f1 = test_acc_df_ml[\"f1_score\"].values[0]\n      8     return f1\n      9 \n     10 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     11     \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-27-6d12fdd5755e> in train_model(model=<MIRA.CostSensitiveMIRA object>, xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], max_epochs=25, early_stop_iters=10, train_instance_fn=<function train_cost_sensitive_instance>, verbose=False)\n     30         shuffle(xs_train_copy)\n     31         for parser_input in xs_train_copy:\n     32             if len(parser_input.other_parses) > 0:\n     33                 train_instance_fn(parser_input, model)\n     34 \n---> 35         train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n     36         test_accuracy_df  = evaluate_ranker(model, xs_test,  essay2crels_test,  ys_by_tag_test)\n     37         train_accuracy = train_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     38         test_accuracy  = test_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     39         if verbose:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-26-da0c283e4cbd> in evaluate_ranker(model=<MIRA.CostSensitiveMIRA object>, xs=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], essay2crels={'EBA1415_RDCS_2_CB_ES-06243.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04694.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04697.ann': {'Causer:1->Result:3', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04699.ann': {'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04700.ann': {'Causer:3->Result:4', 'Causer:4->Result:5', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04701.ann': {'Causer:11->Result:13', 'Causer:13->Result:14', 'Causer:13->Result:50', 'Causer:3->Result:4', 'Causer:3->Result:5', 'Causer:3->Result:50', ...}, 'EBA1415_RDCSa_1_CB_ES-04703.ann': {'Causer:11->Result:13', 'Causer:14->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-05450.ann': set(), 'EBA1415_RDJK_5_CB-04718.ann': {'Causer:7->Result:50'}, 'EBA1415_RDJK_5_CB-04719.ann': set(), ...}, ys_bytag={'Causer:1->Result:11': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:13': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:14': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:2': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...], 'Causer:1->Result:3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...], 'Causer:1->Result:4': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:5': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:50': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...], 'Causer:1->Result:6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:7': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], ...})\n      7             ys_bytag_sent[tag].append(0)\n      8             \n      9 def evaluate_ranker(model, xs, essay2crels, ys_bytag):\n     10     clone = model.clone()\n     11     if hasattr(model, \"average_weights\"):\n---> 12         clone.average_weights()\n     13     rank_acc = []\n     14     pred_ys_bytag = defaultdict(list)\n     15     ename2inps = dict()\n     16     for parser_input in xs:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Classifiers/Online/structured_perceptron.py in average_weights(self=<MIRA.CostSensitiveMIRA object>)\n     93         '''Average weights from all iterations.'''\n     94         new_feat_weights = defaultdict(float)\n     95         for feat, weight in self.weights.items():\n     96             total = self._totals[feat]\n     97             total += (self.i - self._tstamps[feat]) * weight\n---> 98             averaged = round(total / float(self.i), 5)\n        averaged = undefined\n        total = 0\n        self.i = 0\n     99             if averaged != 0.0:\n    100                 new_feat_weights[feat] = averaged\n    101         self.weights = new_feat_weights\n    102         return None\n\nZeroDivisionError: float division by zero\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 130, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 72, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 72, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"<ipython-input-51-6bf0e9889fa3>\", line 5, in train_model_fold\n    max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n  File \"<ipython-input-27-6d12fdd5755e>\", line 35, in train_model\n    train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n  File \"<ipython-input-26-da0c283e4cbd>\", line 12, in evaluate_ranker\n    clone.average_weights()\n  File \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Classifiers/Online/structured_perceptron.py\", line 98, in average_weights\n    averaged = round(total / float(self.i), 5)\nZeroDivisionError: float division by zero\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\", line 140, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nZeroDivisionError                                  Wed Feb  6 18:30:17 2019\nPID: 95085Python 3.6.4: /Users/simon.hughes/anaconda3/envs/phd_py36/bin/python\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function train_model_fold>, ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function train_model_fold>\n        args = ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1)\n        kwargs = {}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_fold(xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      1 \n      2 def train_model_fold(xs_train, xs_test, C, pa_type, loss_type, max_update_items):\n      3     \n      4     mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, max_update_items=max_update_items, initial_weight=1)\n----> 5     best_mdl, test_acc_df_ml = train_model(mdl, xs_train=xs_train, xs_test=xs_test, \n      6         max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n      7     f1 = test_acc_df_ml[\"f1_score\"].values[0]\n      8     return f1\n      9 \n     10 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     11     \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-27-6d12fdd5755e> in train_model(model=<MIRA.CostSensitiveMIRA object>, xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], max_epochs=25, early_stop_iters=10, train_instance_fn=<function train_cost_sensitive_instance>, verbose=False)\n     30         shuffle(xs_train_copy)\n     31         for parser_input in xs_train_copy:\n     32             if len(parser_input.other_parses) > 0:\n     33                 train_instance_fn(parser_input, model)\n     34 \n---> 35         train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n     36         test_accuracy_df  = evaluate_ranker(model, xs_test,  essay2crels_test,  ys_by_tag_test)\n     37         train_accuracy = train_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     38         test_accuracy  = test_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     39         if verbose:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-26-da0c283e4cbd> in evaluate_ranker(model=<MIRA.CostSensitiveMIRA object>, xs=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], essay2crels={'EBA1415_RDCS_2_CB_ES-06243.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04694.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04697.ann': {'Causer:1->Result:3', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04699.ann': {'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04700.ann': {'Causer:3->Result:4', 'Causer:4->Result:5', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04701.ann': {'Causer:11->Result:13', 'Causer:13->Result:14', 'Causer:13->Result:50', 'Causer:3->Result:4', 'Causer:3->Result:5', 'Causer:3->Result:50', ...}, 'EBA1415_RDCSa_1_CB_ES-04703.ann': {'Causer:11->Result:13', 'Causer:14->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-05450.ann': set(), 'EBA1415_RDJK_5_CB-04718.ann': {'Causer:7->Result:50'}, 'EBA1415_RDJK_5_CB-04719.ann': set(), ...}, ys_bytag={'Causer:1->Result:11': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:13': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:14': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:2': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...], 'Causer:1->Result:3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...], 'Causer:1->Result:4': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:5': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:50': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...], 'Causer:1->Result:6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:7': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], ...})\n      7             ys_bytag_sent[tag].append(0)\n      8             \n      9 def evaluate_ranker(model, xs, essay2crels, ys_bytag):\n     10     clone = model.clone()\n     11     if hasattr(model, \"average_weights\"):\n---> 12         clone.average_weights()\n     13     rank_acc = []\n     14     pred_ys_bytag = defaultdict(list)\n     15     ename2inps = dict()\n     16     for parser_input in xs:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Classifiers/Online/structured_perceptron.py in average_weights(self=<MIRA.CostSensitiveMIRA object>)\n     93         '''Average weights from all iterations.'''\n     94         new_feat_weights = defaultdict(float)\n     95         for feat, weight in self.weights.items():\n     96             total = self._totals[feat]\n     97             total += (self.i - self._tstamps[feat]) * weight\n---> 98             averaged = round(total / float(self.i), 5)\n        averaged = undefined\n        total = 0\n        self.i = 0\n     99             if averaged != 0.0:\n    100                 new_feat_weights[feat] = averaged\n    101         self.weights = new_feat_weights\n    102         return None\n\nZeroDivisionError: float division by zero\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nZeroDivisionError                                  Wed Feb  6 18:30:17 2019\nPID: 95085Python 3.6.4: /Users/simon.hughes/anaconda3/envs/phd_py36/bin/python\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function train_model_fold>, ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function train_model_fold>\n        args = ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1)\n        kwargs = {}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_fold(xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      1 \n      2 def train_model_fold(xs_train, xs_test, C, pa_type, loss_type, max_update_items):\n      3     \n      4     mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, max_update_items=max_update_items, initial_weight=1)\n----> 5     best_mdl, test_acc_df_ml = train_model(mdl, xs_train=xs_train, xs_test=xs_test, \n      6         max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n      7     f1 = test_acc_df_ml[\"f1_score\"].values[0]\n      8     return f1\n      9 \n     10 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     11     \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-27-6d12fdd5755e> in train_model(model=<MIRA.CostSensitiveMIRA object>, xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], max_epochs=25, early_stop_iters=10, train_instance_fn=<function train_cost_sensitive_instance>, verbose=False)\n     30         shuffle(xs_train_copy)\n     31         for parser_input in xs_train_copy:\n     32             if len(parser_input.other_parses) > 0:\n     33                 train_instance_fn(parser_input, model)\n     34 \n---> 35         train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n     36         test_accuracy_df  = evaluate_ranker(model, xs_test,  essay2crels_test,  ys_by_tag_test)\n     37         train_accuracy = train_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     38         test_accuracy  = test_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     39         if verbose:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-26-da0c283e4cbd> in evaluate_ranker(model=<MIRA.CostSensitiveMIRA object>, xs=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], essay2crels={'EBA1415_RDCS_2_CB_ES-06243.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04694.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04697.ann': {'Causer:1->Result:3', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04699.ann': {'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04700.ann': {'Causer:3->Result:4', 'Causer:4->Result:5', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04701.ann': {'Causer:11->Result:13', 'Causer:13->Result:14', 'Causer:13->Result:50', 'Causer:3->Result:4', 'Causer:3->Result:5', 'Causer:3->Result:50', ...}, 'EBA1415_RDCSa_1_CB_ES-04703.ann': {'Causer:11->Result:13', 'Causer:14->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-05450.ann': set(), 'EBA1415_RDJK_5_CB-04718.ann': {'Causer:7->Result:50'}, 'EBA1415_RDJK_5_CB-04719.ann': set(), ...}, ys_bytag={'Causer:1->Result:11': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:13': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:14': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:2': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...], 'Causer:1->Result:3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...], 'Causer:1->Result:4': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:5': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:50': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...], 'Causer:1->Result:6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:7': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], ...})\n      7             ys_bytag_sent[tag].append(0)\n      8             \n      9 def evaluate_ranker(model, xs, essay2crels, ys_bytag):\n     10     clone = model.clone()\n     11     if hasattr(model, \"average_weights\"):\n---> 12         clone.average_weights()\n     13     rank_acc = []\n     14     pred_ys_bytag = defaultdict(list)\n     15     ename2inps = dict()\n     16     for parser_input in xs:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Classifiers/Online/structured_perceptron.py in average_weights(self=<MIRA.CostSensitiveMIRA object>)\n     93         '''Average weights from all iterations.'''\n     94         new_feat_weights = defaultdict(float)\n     95         for feat, weight in self.weights.items():\n     96             total = self._totals[feat]\n     97             total += (self.i - self._tstamps[feat]) * weight\n---> 98             averaged = round(total / float(self.i), 5)\n        averaged = undefined\n        total = 0\n        self.i = 0\n     99             if averaged != 0.0:\n    100                 new_feat_weights[feat] = averaged\n    101         self.weights = new_feat_weights\n    102         return None\n\nZeroDivisionError: float division by zero\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibZeroDivisionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-6bf0e9889fa3>\u001b[0m in \u001b[0;36mtrain_model_parallel\u001b[0;34m(cv_folds, C, pa_type, loss_type, max_update_items)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         f1s = Parallel(n_jobs=len(cv_folds))(delayed(train_model_fold)(train,test, C, pa_type, loss_type, max_update_items) \n\u001b[0;32m---> 13\u001b[0;31m                                          for (train,test) in cv_folds)\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibZeroDivisionError\u001b[0m: JoblibZeroDivisionError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10a482660, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/simon.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10a482660, file \"/Use...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/...ges/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/simon.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method PollIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    827                         self._timeouts = [x for x in self._timeouts\n    828                                           if x.callback is not None]\n    829                         heapq.heapify(self._timeouts)\n    830 \n    831                 for i in range(ncallbacks):\n--> 832                     self._run_callback(self._callbacks.popleft())\n        self._run_callback = <bound method IOLoop._run_callback of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n        self._callbacks.popleft = <built-in method popleft of collections.deque object>\n    833                 for timeout in due_timeouts:\n    834                     if timeout.callback is not None:\n    835                         self._run_callback(timeout.callback)\n    836                 # Closures may be holding on to a lot of memory, so allow\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<zmq.eventloop.ioloop.ZMQIOLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x1a3bf23048>))\n    600         \"\"\"Runs a callback with error handling.\n    601 \n    602         For use in subclasses.\n    603         \"\"\"\n    604         try:\n--> 605             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x1a3bf23048>)\n    606             if ret is not None:\n    607                 from tornado import gen\n    608                 # Functions that return Futures typically swallow all\n    609                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'11bc89fb088bc560fec8b97fc828d2c9']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'11bc89fb088bc560fec8b97fc828d2c9'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 2, 7, 0, 10, 42, 44037, tzinfo=tzutc()), 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'session': '11bc89fb088bc560fec8b97fc828d2c9', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2fa1b95eed7aa025409cc7149f974fba', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='%%time\\n\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(...max_parses}\".format(f1=max_f1, top_n=max_parses))', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-54-05015c66bd34>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>\n        result = <ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>, result=<ExecutionResult object at 1a151c6160, execution..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a497e6540, file \"<ipython-input-54-05015c66bd34>\", line 1>\n        self.user_global_ns = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n        self.user_ns = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-54-05015c66bd34> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic('time', '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nbest_max_parses = -1\\nfor max_parses in [50, 75, 100, 150, 200, 300]:\\n    \\n    print(\"max_parses: {max_parses}\".format(max_parses=max_parses))\\n    \\n    xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=best_top_n)\\n    xs = get_features_from_probabilities(xs_rerank, max_parses, min_feat_freq=1, min_prob=best_min_prob)    \\n    cv_folds_rerank = cross_validation(xs, 3)\\n    \\n    f1 = train_model_parallel(cv_folds=cv_folds_rerank, C=best_C, pa_type=1, loss_type=\"ml\", \\n                              max_update_items=best_max_upd)             \\n    print(\"F1: {f1:.4f}\".format(f1=f1))\\n    topn2metrics2[max_parses].append(f1)\\n    if f1 > max_f1:\\n        print(\"*\" * 80)\\n        max_f1 = f1\\n        best_max_parses = max_parses\\n        print(\"New Max F1: {f1:.4f} \\\\tMax Parses: {max_parses}\".format(f1=max_f1, top_n=max_parses))')\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))')\n   2126             # This will need to be updated if the internal calling logic gets\n   2127             # refactored, or else we'll be expanding the wrong variables.\n   2128             stack_depth = 2\n   2129             magic_arg_s = self.var_expand(line, stack_depth)\n   2130             with self.builtin_trap:\n-> 2131                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = ''\n        cell = '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))'\n   2132             return result\n   2133 \n   2134     def find_line_magic(self, magic_name):\n   2135         \"\"\"Find and return a line magic by name.\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<decorator-gen-62> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', None), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, '', '\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', None)\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/IPython/core/magics/execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='', cell='\\nmax_f1 = -1\\ntopn2metrics2 = defaultdict(list)\\nb...max_parses}\".format(f1=max_f1, top_n=max_parses))', local_ns=None)\n   1233                 return\n   1234             end = clock2()\n   1235         else:\n   1236             st = clock2()\n   1237             try:\n-> 1238                 exec(code, glob, local_ns)\n        code = <code object <module> at 0x1a497e6ae0, file \"<timed exec>\", line 2>\n        glob = {'ANAPHORA': 'Anaphor', 'Any': typing.Any, 'BASE_LEARNER_FACT': <function <lambda>>, 'C': 0.0025, 'COLLECTION_PREFIX': 'CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_MOST_RECENT_CODE', 'CV_FOLDS': 5, 'CostSensitiveMIRA': <class 'MIRA.CostSensitiveMIRA'>, 'DOWN_SAMPLE_RATE': 1.0, 'Dict': typing.Dict, 'EMPTY': 'Empty', ...}\n        local_ns = None\n   1239             except:\n   1240                 self.shell.showtraceback()\n   1241                 return\n   1242             end = clock2()\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<timed exec> in <module>()\n      9 \n     10 \n     11 \n     12 \n     13 \n---> 14 \n     15 \n     16 \n     17 \n     18 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_parallel(cv_folds=[([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...]), ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...]), ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...])], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      8 \n      9 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     10     \n     11     try:\n     12         f1s = Parallel(n_jobs=len(cv_folds))(delayed(train_model_fold)(train,test, C, pa_type, loss_type, max_update_items) \n---> 13                                          for (train,test) in cv_folds)\n     14         return np.mean(f1s)\n     15     except KeyboardInterrupt:\n     16         print(\"Process stopped by user\")\n     17 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object train_model_parallel.<locals>.<genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nZeroDivisionError                                  Wed Feb  6 18:30:17 2019\nPID: 95085Python 3.6.4: /Users/simon.hughes/anaconda3/envs/phd_py36/bin/python\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function train_model_fold>, ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/anaconda3/envs/phd_py36/lib/python3.6/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function train_model_fold>\n        args = ([<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], [<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], -1, 1, 'ml', -1)\n        kwargs = {}\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-51-6bf0e9889fa3> in train_model_fold(xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], C=-1, pa_type=1, loss_type='ml', max_update_items=-1)\n      1 \n      2 def train_model_fold(xs_train, xs_test, C, pa_type, loss_type, max_update_items):\n      3     \n      4     mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, max_update_items=max_update_items, initial_weight=1)\n----> 5     best_mdl, test_acc_df_ml = train_model(mdl, xs_train=xs_train, xs_test=xs_test, \n      6         max_epochs=25, early_stop_iters=10, train_instance_fn = train_cost_sensitive_instance, verbose=False)\n      7     f1 = test_acc_df_ml[\"f1_score\"].values[0]\n      8     return f1\n      9 \n     10 def train_model_parallel(cv_folds, C, pa_type, loss_type, max_update_items):\n     11     \n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-27-6d12fdd5755e> in train_model(model=<MIRA.CostSensitiveMIRA object>, xs_train=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], xs_test=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], max_epochs=25, early_stop_iters=10, train_instance_fn=<function train_cost_sensitive_instance>, verbose=False)\n     30         shuffle(xs_train_copy)\n     31         for parser_input in xs_train_copy:\n     32             if len(parser_input.other_parses) > 0:\n     33                 train_instance_fn(parser_input, model)\n     34 \n---> 35         train_accuracy_df = evaluate_ranker(model, xs_train, essay2crels_train, ys_by_tag_train)\n     36         test_accuracy_df  = evaluate_ranker(model, xs_test,  essay2crels_test,  ys_by_tag_test)\n     37         train_accuracy = train_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     38         test_accuracy  = test_accuracy_df.iloc[0].to_dict()[\"f1_score\"]\n     39         if verbose:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/<ipython-input-26-da0c283e4cbd> in evaluate_ranker(model=<MIRA.CostSensitiveMIRA object>, xs=[<__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, <__main__.ParserInputs object>, ...], essay2crels={'EBA1415_RDCS_2_CB_ES-06243.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04694.ann': set(), 'EBA1415_RDCSa_1_CB_ES-04697.ann': {'Causer:1->Result:3', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04699.ann': {'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04700.ann': {'Causer:3->Result:4', 'Causer:4->Result:5', 'Causer:7->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-04701.ann': {'Causer:11->Result:13', 'Causer:13->Result:14', 'Causer:13->Result:50', 'Causer:3->Result:4', 'Causer:3->Result:5', 'Causer:3->Result:50', ...}, 'EBA1415_RDCSa_1_CB_ES-04703.ann': {'Causer:11->Result:13', 'Causer:14->Result:50'}, 'EBA1415_RDCSa_1_CB_ES-05450.ann': set(), 'EBA1415_RDJK_5_CB-04718.ann': {'Causer:7->Result:50'}, 'EBA1415_RDJK_5_CB-04719.ann': set(), ...}, ys_bytag={'Causer:1->Result:11': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:13': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:14': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:2': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...], 'Causer:1->Result:3': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, ...], 'Causer:1->Result:4': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:5': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:50': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...], 'Causer:1->Result:6': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], 'Causer:1->Result:7': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...], ...})\n      7             ys_bytag_sent[tag].append(0)\n      8             \n      9 def evaluate_ranker(model, xs, essay2crels, ys_bytag):\n     10     clone = model.clone()\n     11     if hasattr(model, \"average_weights\"):\n---> 12         clone.average_weights()\n     13     rank_acc = []\n     14     pred_ys_bytag = defaultdict(list)\n     15     ename2inps = dict()\n     16     for parser_input in xs:\n\n...........................................................................\n/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/Classifiers/Online/structured_perceptron.py in average_weights(self=<MIRA.CostSensitiveMIRA object>)\n     93         '''Average weights from all iterations.'''\n     94         new_feat_weights = defaultdict(float)\n     95         for feat, weight in self.weights.items():\n     96             total = self._totals[feat]\n     97             total += (self.i - self._tstamps[feat]) * weight\n---> 98             averaged = round(total / float(self.i), 5)\n        averaged = undefined\n        total = 0\n        self.i = 0\n     99             if averaged != 0.0:\n    100                 new_feat_weights[feat] = averaged\n    101         self.weights = new_feat_weights\n    102         return None\n\nZeroDivisionError: float division by zero\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_f1 = -1\n",
    "topn2metrics2 = defaultdict(list)\n",
    "best_max_parses = -1\n",
    "for max_parses in [50, 75, 100, 150, 200, 300]:\n",
    "    \n",
    "    print(\"max_parses: {max_parses}\".format(max_parses=max_parses))\n",
    "    \n",
    "    xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=best_top_n)\n",
    "    xs = get_features_from_probabilities(xs_rerank, max_parses, min_feat_freq=1, min_prob=best_min_prob)    \n",
    "    cv_folds_rerank = cross_validation(xs, 3)\n",
    "    \n",
    "    f1 = train_model_parallel(cv_folds=cv_folds_rerank, C=best_C, pa_type=1, loss_type=\"ml\", \n",
    "                              max_update_items=best_max_upd)             \n",
    "    print(\"F1: {f1:.4f}\".format(f1=f1))\n",
    "    topn2metrics2[max_parses].append(f1)\n",
    "    if f1 > max_f1:\n",
    "        print(\"*\" * 80)\n",
    "        max_f1 = f1\n",
    "        best_max_parses = max_parses\n",
    "        print(\"New Max F1: {f1:.4f} \\tMax Parses: {max_parses}\".format(f1=max_f1, top_n=max_parses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Probability Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_prob: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-cbc4ed7c9f67>\u001b[0m in \u001b[0;36mget_essays2crels\u001b[0;34m(essays, sr_model, top_n)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munq_ptags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 pred_parses = sr_model.generate_all_potential_parses_for_sentence(\n\u001b[0;32m---> 10\u001b[0;31m                     tagged_sentence=taggged_sentence, predicted_tags=predicted_tags, top_n=top_n)\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mcr2p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollapse_sent_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_parses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mmerge_crel_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrel2probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcr2p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/NlpResearch/PythonNlpResearch/Classifiers/StructuredLearning/SEARN/searn_parser_breadth_first.py\u001b[0m in \u001b[0;36mgenerate_all_potential_parses_for_sentence\u001b[0;34m(self, tagged_sentence, predicted_tags, top_n, search_mode_max_prob)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mterminal_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                 \u001b[0mactions_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions_queue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/NlpResearch/PythonNlpResearch/Classifiers/StructuredLearning/SEARN/searn_parser_breadth_first.py\u001b[0m in \u001b[0;36mget_next_actions\u001b[0;34m(self, parse_action, ctx)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnext_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parse_action_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause2effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffect2causers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone_cause2effect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/NlpResearch/PythonNlpResearch/Classifiers/StructuredLearning/SEARN/searn_parser_breadth_first.py\u001b[0m in \u001b[0;36mget_parse_action_results\u001b[0;34m(self, cause2effects, effect2causers, oracle, tag_ix, ctx, parent_action)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                            \u001b[0mtos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtos_tag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                                            \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                                            vectorizer=self.parser_feature_vectorizers[-1])\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mparse_action_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/NlpResearch/PythonNlpResearch/Classifiers/StructuredLearning/SEARN/searn_parser_breadth_first.py\u001b[0m in \u001b[0;36mpredict_parse_action_probabilities\u001b[0;34m(self, feats, tos, models, vectorizer)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mprob_by_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob_by_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0mcalculate_ovr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcalculate_ovr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 380\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    266\u001b[0m                           % spmatrix.format)\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m\"\"\"Like assert_all_finite, but only for ndarray.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# First try an O(n) time, O(1) space solution for the common case that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m     \"\"\"Convert the input to an ndarray, but pass ndarray subclasses through.\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_f1 = -1\n",
    "topprob2metrics = defaultdict(list)\n",
    "\n",
    "max_parses = best_max_parses\n",
    "best_min_prob = -1\n",
    "for min_prob in [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    \n",
    "    print(\"min_prob: {min_prob}\".format(min_prob=min_prob))\n",
    "    \n",
    "    xs_rerank = essay_to_crels_cv(cv_folds, models, top_n=best_top_n)\n",
    "    xs = get_features_from_probabilities(xs_rerank, max_parses, min_feat_freq=1, min_prob=min_prob)\n",
    "    \n",
    "    cv_folds_rerank = cross_validation(xs, 5)\n",
    "    cf_folds_mm = Parallel(n_jobs=len(cv_folds_rerank)(delayed(min_max_normalize_feats)(train,test) for (train,test) in cv_folds_rerank)\n",
    "    \n",
    "    f1 = train_model_parallel(cv_folds=cf_folds_mm, C=best_C, pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, train_instance_fn=train_cost_sensitive_instance)             \n",
    "    topprob2metrics[min_prob].append(f1)\n",
    "    if f1 > max_f1:\n",
    "        print(\"*\" * 80)\n",
    "        max_f1 = f1\n",
    "        best_min_prob = min_prob\n",
    "        print(\"New Max F1: {f1:.4f} \\tMin P: {min_prob}\".format(f1=max_f1, min_prob=min_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Try Sampling from the Predicted Parses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
