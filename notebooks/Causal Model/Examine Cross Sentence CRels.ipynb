{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from typing import Any\n",
    "from collections import defaultdict\n",
    "import dill\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from window_based_tagger_config import get_config\n",
    "from shift_reduce_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Global settings\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:1->Result:4',\n",
       " 'Causer:14->Result:6',\n",
       " 'Causer:2->Result:3',\n",
       " 'Causer:5->Result:5b',\n",
       " 'Causer:12->Result:50',\n",
       " 'Causer:4->Result:5b',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:11->Result:14',\n",
       " 'Causer:13->Result:7',\n",
       " 'Causer:7->Result:1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT = \"<SENT>\"\n",
    "\n",
    "def get_reg_tags(tags):\n",
    "    return [t for t in tags if \"->\" not in t and \":\" not in t and t[0].isdigit()]\n",
    "\n",
    "def flatten_essay(essay):\n",
    "    flat_tagged_sent = []\n",
    "    flat_pred_tags = []\n",
    "    for sent_ix, taggged_sentence in enumerate(essay.sentences):\n",
    "        flat_tagged_sent.extend(taggged_sentence)\n",
    "        flat_tagged_sent.append((SENT, set()))\n",
    "\n",
    "        flat_pred_tags.extend(essay.pred_tagged_sentences[sent_ix])\n",
    "        flat_pred_tags.append(SENT)\n",
    "    assert len(flat_tagged_sent) == len(flat_pred_tags), \"Tagged essay should be the same length as the predicted tags\"\n",
    "    return flat_tagged_sent, flat_pred_tags\n",
    "\n",
    "def get_tags_relations_for(tagged_sentence, predicted_tags, cr_tags):\n",
    "\n",
    "    sent_reg_predicted_tags = set()\n",
    "    sent_act_cr_tags = set()\n",
    "    tag2ixs = defaultdict(list)\n",
    "\n",
    "    tag_seq = [None]  # seed with None\n",
    "    crel_set_seq = [set()]\n",
    "\n",
    "    pos_tag_seq = []\n",
    "    latest_tag_posns = {}\n",
    "    crel_child_tags = defaultdict(set)\n",
    "    for i, (wd, tags) in enumerate(tagged_sentence):\n",
    "        if wd in string.punctuation:\n",
    "            continue\n",
    "        if wd == SENT:\n",
    "            continue\n",
    "\n",
    "        active_tag = None\n",
    "        rtag = predicted_tags[i]\n",
    "        if rtag != EMPTY_TAG:\n",
    "            active_tag = rtag\n",
    "            sent_reg_predicted_tags.add(active_tag)\n",
    "            # if no prev tag and the current matches -2 (a gap of one), skip over\n",
    "            if active_tag != tag_seq[-1] and \\\n",
    "                    not (tag_seq[-1] is None and (len(tag_seq) > 2) and active_tag == tag_seq[-2]):\n",
    "                latest_tag_posns[active_tag] = (active_tag, i)\n",
    "                pos_tag_seq.append((active_tag, i))\n",
    "            # need to be after we update the latest tag position\n",
    "            tag2ixs[latest_tag_posns[active_tag]].append(i)\n",
    "        tag_seq.append(active_tag)\n",
    "\n",
    "        active_crels = tags.intersection(cr_tags)\n",
    "        for cr in sorted(active_crels):\n",
    "            sent_act_cr_tags.add(cr)\n",
    "            if cr not in crel_set_seq[-1] \\\n",
    "                    and not (cr not in crel_set_seq[-1] and (len(crel_set_seq) > 2) and cr in crel_set_seq[-2]):\n",
    "                latest_tag_posns[cr] = (cr, i)\n",
    "        crel_set_seq.append(active_crels)\n",
    "\n",
    "        # to have child tags, need a tag sequence and a current valid regular tag\n",
    "        if not active_tag or len(active_crels) == 0:\n",
    "            continue\n",
    "\n",
    "        for crel in active_crels:\n",
    "            l, r = normalize_cr(crel)\n",
    "            if active_tag in (l, r):\n",
    "                crel_child_tags[latest_tag_posns[crel]].add(latest_tag_posns[active_tag])\n",
    "\n",
    "    pos_crels = []\n",
    "    for (crelation, crix), tag_pairs in crel_child_tags.items():\n",
    "        l, r = normalize_cr(crelation)\n",
    "        # unsupported relation\n",
    "        if l not in sent_reg_predicted_tags or r not in sent_reg_predicted_tags:\n",
    "            continue\n",
    "        tag2pair = defaultdict(list)\n",
    "        for taga, ixa in tag_pairs:\n",
    "            tag2pair[taga].append((taga, ixa))\n",
    "        # un-supported relation\n",
    "        if l not in tag2pair or r not in tag2pair:\n",
    "            continue\n",
    "\n",
    "        l_pairs = tag2pair[l]\n",
    "        r_pairs = tag2pair[r]\n",
    "        for pairsa in l_pairs:\n",
    "            for pairsb in r_pairs:\n",
    "                if pairsa != pairsb:\n",
    "                    pos_crels.append((pairsa, pairsb))\n",
    "\n",
    "    tag2span = dict()\n",
    "    for tagpos, ixs in tag2ixs.items():\n",
    "        tag2span[tagpos] = (min(ixs), max(ixs))\n",
    "\n",
    "    return pos_tag_seq, pos_crels, tag2span, sent_reg_predicted_tags, sent_act_cr_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay2collapsed = dict()\n",
    "for essay_ix, essay in enumerate(pred_tagged_essays_train):\n",
    "    essay2collapsed[essay.name] = flatten_essay(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sent_crels(sent):\n",
    "    crels = set()\n",
    "    for wd, tags in sent:\n",
    "        cr = set_cr_tags.intersection(tags)\n",
    "        if cr:\n",
    "            crels.update(cr)\n",
    "    return crels\n",
    "\n",
    "cross_sent_crels = dict()\n",
    "for essay in pred_tagged_essays_train:\n",
    "    for ix, sent in enumerate(essay.sentences):\n",
    "        if ix == 0:\n",
    "            continue\n",
    "        sent_crels = get_sent_crels(sent)\n",
    "        if len(sent_crels) == 0:\n",
    "            continue\n",
    "        prev_sent = essay.sentences[ix-1]\n",
    "        prev_crels = get_sent_crels(prev_sent)\n",
    "        crel_crossing =  prev_crels.intersection(sent_crels)\n",
    "        if crel_crossing:\n",
    "            cross_sent_crels[(essay.name, ix)] = (crel_crossing, prev_sent, sent)\n",
    "len(cross_sent_crels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_BGJD_1_CB_ES-05975.ann 8\n",
      "{'Causer:7->Result:50'}\n",
      "********************************************************************************\n",
      "during                         set() []\n",
      "bleaching                      set() []\n",
      ";                              set() []\n",
      "corals                         {'Causer:7->Result:50'} ['50']\n",
      "turn                           {'Causer:7->Result:50'} ['50']\n",
      "white                          {'Causer:7->Result:50'} ['50']\n",
      "due                            {'Causer:7->Result:50'} []\n",
      "to                             {'Causer:7->Result:50'} []\n",
      "the                            {'Causer:7->Result:50'} []\n",
      "ejection                       {'Causer:7->Result:50'} ['7']\n",
      "or                             {'Causer:7->Result:50'} ['7']\n",
      "death                          {'Causer:7->Result:50'} ['7']\n",
      "of                             {'Causer:7->Result:50'} ['7']\n",
      "the                            {'Causer:7->Result:50'} ['7']\n",
      "zooxanthellae                  {'Causer:7->Result:50'} ['7']\n",
      ".                              set() []\n",
      "********************************************************************************\n",
      "this                           {'Causer:7->Result:50'} []\n",
      "results                        {'Causer:7->Result:50'} []\n",
      "in                             {'Causer:7->Result:50'} []\n",
      "a                              {'Causer:7->Result:50'} []\n",
      "bleaching                      {'Causer:7->Result:50'} ['50']\n",
      "event                          {'Causer:7->Result:50'} ['50']\n",
      "that                           set() []\n",
      "makes                          set() []\n",
      "corals                         set() []\n",
      "vulnerable                     set() []\n",
      "to                             set() []\n",
      "disease                        set() []\n",
      "and                            set() []\n",
      "starvation                     set() []\n",
      ".                              set() []\n"
     ]
    }
   ],
   "source": [
    "essay_name, sent_ix = list(cross_sent_crels.keys())[0] #0,5\n",
    "crel_crossing, prev_sent, sent = cross_sent_crels[(essay_name, sent_ix)]\n",
    "\n",
    "print(essay_name, sent_ix)\n",
    "print(crel_crossing)\n",
    "print(\"*\" * 80)\n",
    "for wd, tags in prev_sent:\n",
    "    reg_tags = get_reg_tags(tags)\n",
    "    print(wd.ljust(30), set_cr_tags.intersection(tags), reg_tags)\n",
    "print(\"*\" * 80)\n",
    "for wd, tags in sent:\n",
    "    reg_tags = get_reg_tags(tags)\n",
    "    print(wd.ljust(30), set_cr_tags.intersection(tags), reg_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for essay_name, (flat_tagged_sent, flat_pred_tags) in essay2collapsed.items():    \n",
    "    pos_tag_seq, pos_crels, tag2span, sent_reg_predicted_tags, sent_act_cr_tags = \\\n",
    "        get_tags_relations_for(flat_tagged_sent, flat_pred_tags, cr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essay_name = \"EBA1415_BLHT_5_CB_ES-05205.ann\"\n",
    "flat_tagged_sent, flat_pred_tags = essay2collapsed[essay_name]\n",
    "\n",
    "pos_tag_seq, pos_crels, tag2span, sent_reg_predicted_tags, sent_act_cr_tags = \\\n",
    "        get_tags_relations_for(flat_tagged_sent, flat_pred_tags, cr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113   <SENT>                               set()\n",
      "114   during                               set()\n",
      "115   bleaching                            set()\n",
      "116   ;                                    set()\n",
      "117   corals                         50    {'Causer:7->Result:50'}\n",
      "118   turn                           50    {'Causer:7->Result:50'}\n",
      "119   white                          50    {'Causer:7->Result:50'}\n",
      "120   due                                  {'Causer:7->Result:50'}\n",
      "121   to                                   {'Causer:7->Result:50'}\n",
      "122   the                                  {'Causer:7->Result:50'}\n",
      "123   ejection                       7     {'Causer:7->Result:50'}\n",
      "124   or                             7     {'Causer:7->Result:50'}\n",
      "125   death                          7     {'Causer:7->Result:50'}\n",
      "126   of                             7     {'Causer:7->Result:50'}\n",
      "127   the                            7     {'Causer:7->Result:50'}\n",
      "128   zooxanthellae                  7     {'Causer:7->Result:50'}\n",
      "129   .                                    set()\n",
      "130   <SENT>                               set()\n",
      "131   this                                 {'Causer:7->Result:50'}\n",
      "132   results                              {'Causer:7->Result:50'}\n",
      "133   in                                   {'Causer:7->Result:50'}\n",
      "134   a                                    {'Causer:7->Result:50'}\n",
      "135   bleaching                      50    {'Causer:7->Result:50'}\n",
      "136   event                          50    {'Causer:7->Result:50'}\n",
      "137   that                                 set()\n",
      "138   makes                                set()\n",
      "139   corals                               set()\n",
      "140   vulnerable                           set()\n",
      "141   to                                   set()\n",
      "142   disease                              set()\n",
      "143   and                                  set()\n",
      "144   starvation                           set()\n",
      "145   .                                    set()\n"
     ]
    }
   ],
   "source": [
    "# pos_tag_seq\n",
    "sent_cnt = 0\n",
    "for ix, (wd, tags) in enumerate(flat_tagged_sent):    \n",
    "    if wd == SENT:\n",
    "        sent_cnt += 1\n",
    "    if sent_cnt in  (sent_ix,sent_ix-1):\n",
    "        print(str(ix).ljust(5), wd.ljust(30), \",\".join(get_reg_tags(tags)).ljust(5), tags.intersection(set_cr_tags))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('7', 17), ('50', 25)), (('7', 123), ('50', 115)), (('7', 123), ('50', 135))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_crels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7', 17),\n",
       " ('50', 25),\n",
       " ('50', 95),\n",
       " ('6', 99),\n",
       " ('14', 102),\n",
       " ('50', 115),\n",
       " ('7', 123),\n",
       " ('50', 135),\n",
       " ('50', 165)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 128)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2span[('7',123)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 136)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2span[('50',135)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
