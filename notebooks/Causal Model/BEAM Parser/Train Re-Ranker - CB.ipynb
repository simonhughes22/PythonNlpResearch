{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/BEAM Parser\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# cwd = os.getcwd()\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "models_folder = os.path.join(cm_folder, \"BEAM Parser/models/\")\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model_parallel, train_model, train_cost_sensitive_instance\n",
    "from window_based_tagger_config import get_config\n",
    "from feature_extraction import get_features_essay_level\n",
    "from causal_model_features import CausalModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.CORAL_BLEACHING\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:3->Result:5',\n",
       " 'Causer:13->Result:5',\n",
       " 'Causer:2->Result:7',\n",
       " 'Causer:1->Result:2',\n",
       " 'Causer:7->Result:5',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:11->Result:14',\n",
       " 'Causer:12->Result:50',\n",
       " 'Causer:4->Result:5b',\n",
       " 'Causer:1->Result:3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searn_essay_parser_breadth_first import SearnModelEssayParserBreadthFirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds = [(pred_tagged_essays_train, pred_tagged_essays_test)]  # type: List[Tuple[Any,Any]]\n",
    "cv_folds = cross_validation(pred_tagged_essays_train, CV_FOLDS)  # type: List[Tuple[Any,Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_tagged_essays_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Expected Crels Per Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Re-Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "rr_fname = \"xs_rerank_\" + str(BEAM_SIZE) + \".dill\"\n",
    "with open(os.path.join(models_folder, rr_fname), \"rb\") as f:\n",
    "    xs_rr = dill.load(f)\n",
    "len(xs_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(xs_rr) == len(pred_tagged_essays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 902)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs_rr), len(pred_tagged_essays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAUSAL_MODEL_TYPE == CausalModelType.CORAL_BLEACHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 342 ms, total: 27.6 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs = get_features_essay_level(xs_rr, name2crels, causal_model_type=CAUSAL_MODEL_TYPE, min_feat_freq=1)\n",
    "\n",
    "cv_folds_rerank = cross_validation(xs, 5)\n",
    "cv_folds_mm = [min_max_normalize_feats(train, test) for (train, test) in cv_folds_rerank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C, best_max_upd = 0.01, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7316674196020332\n",
      "CPU times: user 24.1 s, sys: 1.86 s, total: 26 s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1 = train_model_parallel(cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", \\\n",
    "                          max_update_items=best_max_upd, set_cr_tags=set_cr_tags)\n",
    "print(f1) # 0.733426894314066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7316674196020332\n",
      "CPU times: user 21.4 s, sys: 1.48 s, total: 22.9 s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1 = train_model_parallel(cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", \\\n",
    "                          max_update_items=best_max_upd, set_cr_tags=set_cr_tags)\n",
    "print(f1) # 0.7336580926726814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317485002668207\n",
      "CPU times: user 22.7 s, sys: 1.61 s, total: 24.3 s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1 = train_model_parallel(cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", \\\n",
    "                          max_update_items=best_max_upd, set_cr_tags=set_cr_tags)\n",
    "print(f1) # 0.7338333044191401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BEAM_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_fname = \"xs_rerank_test_\" + str(BEAM_SIZE) + \".dill\"\n",
    "with open(os.path.join(models_folder, rr_fname), \"rb+\") as f:\n",
    "    xs_test_rerank = dill.load(f)\n",
    "len(xs_test_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test = get_features_essay_level(xs_test_rerank, name2crels, causal_model_type=CAUSAL_MODEL_TYPE, min_feat_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data comes from the test fold predictions from CV on the full training dataset\n",
    "xs_train = []\n",
    "for train, test in cv_folds_rerank:\n",
    "    xs_train.extend(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize both using training data\n",
    "xs_train_mm, xs_test_mm = min_max_normalize_feats(xs_train,xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm))\n",
    "tmp_train_copy = list(xs_train_mm)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7414 Test Accuracy: 0.7435\n",
      "Epoch: 1 Train Accuracy: 0.7395 Test Accuracy: 0.7433\n",
      "Epoch: 2 Train Accuracy: 0.7406 Test Accuracy: 0.7451\n",
      "Epoch: 3 Train Accuracy: 0.7424 Test Accuracy: 0.7439\n",
      "Epoch: 4 Train Accuracy: 0.7418 Test Accuracy: 0.7428\n",
      "Epoch: 5 Train Accuracy: 0.7438 Test Accuracy: 0.7439\n",
      "Epoch: 6 Train Accuracy: 0.7440 Test Accuracy: 0.7439\n",
      "Epoch: 7 Train Accuracy: 0.7440 Test Accuracy: 0.7439\n",
      "Best Test Acc: 0.7451\n",
      "CPU times: user 50.8 s, sys: 257 ms, total: 51.1 s\n",
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C = best_C\n",
    "pa_type = 1\n",
    "loss_type= \"ml\"\n",
    "max_update_items = best_max_upd\n",
    "\n",
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=5, train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7425 Test Accuracy: 0.7306\n",
      "Epoch: 1 Train Accuracy: 0.7441 Test Accuracy: 0.7322\n",
      "Epoch: 2 Train Accuracy: 0.7437 Test Accuracy: 0.7301\n",
      "Best Test Acc: 0.7322\n"
     ]
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "                                       name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=best_iterations, early_stop_iters=best_iterations, train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_features import filter_feats\n",
    "\n",
    "prefixes = [\n",
    "    \"Prob-\",\n",
    "    \"CREL_Pair-\",\n",
    "    \"Inv-\",\n",
    "    \"num_crels\",\n",
    "    \"Tally-\",\n",
    "    \"CChain-\",\n",
    "    \"CChainStats-\",\n",
    "    \"Above-\",\n",
    "    \"CREL_\",\n",
    "    \"Propn_\",\n",
    "    \"Diff_\"\n",
    "]\n",
    "# xs_fltr_train, xs_fltr_test = filter_feats(xs_train_mm, xs_test_mm, prefixes)\n",
    "assert len(prefixes) == len(set(prefixes)), \"Duplicate prefixes found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feats, new Best F1: 0.7356 Prefixes: ['Above-']\n",
      "2 feats, new Best F1: 0.7387 Prefixes: ['Above-', 'num_crels']\n",
      "3 feats, new Best F1: 0.7397 Prefixes: ['Above-', 'num_crels', 'Diff_']\n",
      "4 feats, new Best F1: 0.7402 Prefixes: ['Above-', 'num_crels', 'Diff_', 'CChainStats-']\n",
      "5 feats, new Best F1: 0.7402 Prefixes: ['Above-', 'num_crels', 'Diff_', 'CChainStats-', 'Inv-']\n",
      "No further improvement, stopping\n"
     ]
    }
   ],
   "source": [
    "best_f1 = -1\n",
    "current_best = []\n",
    "remaining = list(prefixes)\n",
    "\n",
    "while True:\n",
    "    if len(remaining) == 0:\n",
    "        break\n",
    "    \n",
    "    f1_by_prefix = dict()\n",
    "    for prefix in remaining:\n",
    "        new_prefixes = current_best + [prefix]\n",
    "        \n",
    "        cv_filtered = []\n",
    "        for tr, test in cv_folds_mm:\n",
    "            x_tr,x_test = filter_feats(tr, test, new_prefixes)\n",
    "            cv_filtered.append((x_tr,x_test))\n",
    "        \n",
    "        f1_by_prefix[prefix] = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "                                  pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "                                  set_cr_tags=set_cr_tags)\n",
    "    \n",
    "    best_prefix, new_best_f1 = sorted(f1_by_prefix.items(), key = lambda tpl: -tpl[1])[0]\n",
    "    if new_best_f1 > best_f1:\n",
    "        best_f1 = new_best_f1\n",
    "        current_best.append(best_prefix)\n",
    "        remaining.remove(best_prefix)\n",
    "        print(\"{length} feats, new Best F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(current_best), f1=best_f1, prefixes=str(current_best)))\n",
    "    else:\n",
    "        print(\"No further improvement, stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7399266076852923\n",
      "CPU times: user 14.1 s, sys: 959 ms, total: 15 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run it against the full set for comparison\n",
    "cv_filtered = []\n",
    "for tr, test in cv_folds_mm:\n",
    "    x_tr,x_test = filter_feats(tr, test, prefixes)\n",
    "#     x_tr,x_test = filter_feats(tr, test, current_best)\n",
    "    cv_filtered.append((x_tr,x_test))\n",
    "\n",
    "f1 = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "                          pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "                          set_cr_tags=set_cr_tags)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Above-', 'num_crels', 'Diff_', 'CChainStats-', 'Inv-']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train_mm_fltr, xs_test_mm_fltr = filter_feats(xs_train_mm, xs_test_mm, current_best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use training data to determine the best number of traininng iterations\n",
    "num_train = int(0.8 * len(xs_train_mm_fltr))\n",
    "tmp_train_copy = list(xs_train_mm_fltr)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7363 Test Accuracy: 0.7305\n",
      "Epoch: 1 Train Accuracy: 0.7394 Test Accuracy: 0.7300\n",
      "Epoch: 2 Train Accuracy: 0.7397 Test Accuracy: 0.7268\n",
      "Epoch: 3 Train Accuracy: 0.7404 Test Accuracy: 0.7291\n",
      "Best Test Acc: 0.7305\n",
      "CPU times: user 3.95 s, sys: 31.9 ms, total: 3.99 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C = best_C\n",
    "pa_type = 1\n",
    "loss_type= \"ml\"\n",
    "max_update_items = best_max_upd\n",
    "\n",
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=3, train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7329 Test Accuracy: 0.7322\n",
      "Best Test Acc: 0.7322\n"
     ]
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations, \n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7328 Test Accuracy: 0.7382\n",
      "Epoch: 1 Train Accuracy: 0.7371 Test Accuracy: 0.7356\n",
      "Epoch: 2 Train Accuracy: 0.7379 Test Accuracy: 0.7349\n",
      "Epoch: 3 Train Accuracy: 0.7382 Test Accuracy: 0.7327\n",
      "Epoch: 4 Train Accuracy: 0.7382 Test Accuracy: 0.7298\n",
      "Epoch: 5 Train Accuracy: 0.7385 Test Accuracy: 0.7292\n",
      "Epoch: 6 Train Accuracy: 0.7398 Test Accuracy: 0.7285\n",
      "Epoch: 7 Train Accuracy: 0.7401 Test Accuracy: 0.7279\n",
      "Epoch: 8 Train Accuracy: 0.7407 Test Accuracy: 0.7273\n",
      "Epoch: 9 Train Accuracy: 0.7405 Test Accuracy: 0.7273\n",
      "Epoch: 10 Train Accuracy: 0.7403 Test Accuracy: 0.7273\n",
      "Epoch: 11 Train Accuracy: 0.7401 Test Accuracy: 0.7266\n",
      "Epoch: 12 Train Accuracy: 0.7403 Test Accuracy: 0.7266\n",
      "Epoch: 13 Train Accuracy: 0.7398 Test Accuracy: 0.7277\n",
      "Epoch: 14 Train Accuracy: 0.7397 Test Accuracy: 0.7277\n",
      "Epoch: 15 Train Accuracy: 0.7399 Test Accuracy: 0.7277\n",
      "Epoch: 16 Train Accuracy: 0.7401 Test Accuracy: 0.7277\n",
      "Epoch: 17 Train Accuracy: 0.7401 Test Accuracy: 0.7277\n",
      "Epoch: 18 Train Accuracy: 0.7400 Test Accuracy: 0.7289\n",
      "Epoch: 19 Train Accuracy: 0.7401 Test Accuracy: 0.7289\n",
      "Epoch: 20 Train Accuracy: 0.7403 Test Accuracy: 0.7289\n",
      "Epoch: 21 Train Accuracy: 0.7403 Test Accuracy: 0.7289\n",
      "Epoch: 22 Train Accuracy: 0.7401 Test Accuracy: 0.7277\n",
      "Epoch: 23 Train Accuracy: 0.7401 Test Accuracy: 0.7277\n",
      "Epoch: 24 Train Accuracy: 0.7401 Test Accuracy: 0.7277\n",
      "Epoch: 25 Train Accuracy: 0.7404 Test Accuracy: 0.7284\n",
      "Epoch: 26 Train Accuracy: 0.7404 Test Accuracy: 0.7284\n",
      "Epoch: 27 Train Accuracy: 0.7406 Test Accuracy: 0.7284\n",
      "Epoch: 28 Train Accuracy: 0.7406 Test Accuracy: 0.7284\n",
      "Epoch: 29 Train Accuracy: 0.7405 Test Accuracy: 0.7290\n",
      "Best Test Acc: 0.7382\n"
     ]
    }
   ],
   "source": [
    "# Set higher max iterations\n",
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=30, early_stop_iters=30, \n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7417 Test Accuracy: 0.7386\n",
      "Epoch: 1 Train Accuracy: 0.7423 Test Accuracy: 0.7326\n",
      "Epoch: 2 Train Accuracy: 0.7433 Test Accuracy: 0.7306\n",
      "Epoch: 3 Train Accuracy: 0.7437 Test Accuracy: 0.7277\n",
      "Epoch: 4 Train Accuracy: 0.7451 Test Accuracy: 0.7255\n",
      "Epoch: 5 Train Accuracy: 0.7456 Test Accuracy: 0.7255\n",
      "Epoch: 6 Train Accuracy: 0.7464 Test Accuracy: 0.7262\n",
      "Epoch: 7 Train Accuracy: 0.7467 Test Accuracy: 0.7262\n",
      "Epoch: 8 Train Accuracy: 0.7473 Test Accuracy: 0.7262\n",
      "Epoch: 9 Train Accuracy: 0.7477 Test Accuracy: 0.7250\n",
      "Epoch: 10 Train Accuracy: 0.7481 Test Accuracy: 0.7262\n",
      "Epoch: 11 Train Accuracy: 0.7483 Test Accuracy: 0.7266\n",
      "Epoch: 12 Train Accuracy: 0.7485 Test Accuracy: 0.7262\n",
      "Epoch: 13 Train Accuracy: 0.7485 Test Accuracy: 0.7268\n",
      "Epoch: 14 Train Accuracy: 0.7489 Test Accuracy: 0.7268\n",
      "Epoch: 15 Train Accuracy: 0.7490 Test Accuracy: 0.7262\n",
      "Epoch: 16 Train Accuracy: 0.7497 Test Accuracy: 0.7262\n",
      "Epoch: 17 Train Accuracy: 0.7501 Test Accuracy: 0.7262\n",
      "Epoch: 18 Train Accuracy: 0.7502 Test Accuracy: 0.7262\n",
      "Epoch: 19 Train Accuracy: 0.7505 Test Accuracy: 0.7255\n",
      "Epoch: 20 Train Accuracy: 0.7505 Test Accuracy: 0.7249\n",
      "Epoch: 21 Train Accuracy: 0.7507 Test Accuracy: 0.7249\n",
      "Epoch: 22 Train Accuracy: 0.7511 Test Accuracy: 0.7249\n",
      "Epoch: 23 Train Accuracy: 0.7514 Test Accuracy: 0.7249\n",
      "Epoch: 24 Train Accuracy: 0.7521 Test Accuracy: 0.7249\n",
      "Epoch: 25 Train Accuracy: 0.7526 Test Accuracy: 0.7249\n",
      "Epoch: 26 Train Accuracy: 0.7529 Test Accuracy: 0.7238\n",
      "Epoch: 27 Train Accuracy: 0.7532 Test Accuracy: 0.7231\n",
      "Epoch: 28 Train Accuracy: 0.7536 Test Accuracy: 0.7231\n",
      "Epoch: 29 Train Accuracy: 0.7537 Test Accuracy: 0.7231\n",
      "Best Test Acc: 0.7386\n"
     ]
    }
   ],
   "source": [
    "# Try no filters\n",
    "mdl = CostSensitiveMIRA(C=C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0.01)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=30, early_stop_iters=30, \n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('num_crels=0', 0.3285077040959117),\n",
       " ('Inv-not_inverted', 0.29336942671062827),\n",
       " ('Above-%-0.9', 0.2924967375197842),\n",
       " ('Above-All-Above-0.7', 0.24747217742060995),\n",
       " ('Above-%-0.95', 0.240299419164543),\n",
       " ('Above-All-Above-0.5', 0.2274721774206099),\n",
       " ('CREL_Causer:7->Result:50-MIN(prob)', 0.2216978786685111),\n",
       " ('CREL_7:50', 0.20997943357559656),\n",
       " ('CREL_Causer:7->Result:50-MAX(prob)', 0.20557895248912006),\n",
       " ('Above-All-Above-0.9', 0.2016405596489272),\n",
       " ('Prob-min-prob', 0.18950247771053025),\n",
       " ('Prob-5%-prob', 0.18797979400407147),\n",
       " ('Above-%-0.8', 0.18602666699265427),\n",
       " ('Above-All-Above-0.8', 0.18517063817849072),\n",
       " ('Prob-10%-prob', 0.18363771392475062),\n",
       " ('Above-All-Above-0.3', 0.1823015392421192),\n",
       " ('Prob-prod-prob', 0.17677218277061454),\n",
       " ('Prob-geo-mean', 0.16311881496828176),\n",
       " ('Above-All-Above-0.2', 0.15716326185683582),\n",
       " ('CREL_Causer:6->Result:7-MAX(prob)', 0.15418552921399484)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_mdl.weights.items(), key = lambda tpl: -tpl[1])[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Remaining Code Changes\n",
    "- The Beam search approach outputs a list of Dict[str, List[float]], instead of just one Dict[str, List[float]]\n",
    "- However, we don't need to sample from the crels, we will just use the already generated parses, after de-duping\n",
    "- ParserInputs needs modifying so that it takes a list of crel2probs instead of on dict for all parses\n",
    "- Need to figure out what the optimal parse is based on amount of overlap with the actual crels, minus the false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "- include the cum prob from the parse action result as a feature? - or simply compute the geometric mean of the probs?\n",
    "- To speed up MIRA, de-dupe the generated parses prior to feature extraction. Where there are dupes, take the one with the highest cum prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
