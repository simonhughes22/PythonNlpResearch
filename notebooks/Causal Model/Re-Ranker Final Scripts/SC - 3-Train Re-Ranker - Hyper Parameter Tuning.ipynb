{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model_parallel_logged, train_model_parallel, train_model, train_cost_sensitive_instance\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from results_procesor import ResultsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "870 218\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.SKIN_CANCER\n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "crels_folder = \"./crels/SC\"\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "MONGO_COLLECTION = \"SC_RE-RANKER_HYPER_PARAM_TD\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "results_processor = ResultsProcessor(dbname=\"metrics_causal_model_reranker\")\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:12->Result:5',\n",
       " 'Causer:12->Result:2',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:5->Result:11',\n",
       " 'Causer:4->Result:12',\n",
       " 'Causer:2->Result:2',\n",
       " 'Causer:6->Result:3',\n",
       " 'Causer:50->Result:2',\n",
       " 'Causer:50->Result:3',\n",
       " 'Causer:2->Result:5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Re-Ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Parses from Sentence Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_top_n = 2\n",
    "min_feat_freq = 1\n",
    "best_max_upd = 2 \n",
    "best_max_parses = 300\n",
    "best_min_prob = 0.0  # min prob of 0 seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rerank(top_n):\n",
    "    rr_fname = \"xs_rerank_\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_rerank = dill.load(f)\n",
    "\n",
    "    rr_fname = \"xs_rerank_test\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_test_rerank = dill.load(f)\n",
    "    return xs_rerank, xs_test_rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_features import filter_feats\n",
    "\n",
    "prefixes = [\n",
    "    \"Prob-\",\n",
    "#     \"CREL_Pair-\",\n",
    "    \"Inv-\",\n",
    "    \"num_crels\",\n",
    "    \"Tally-\",\n",
    "    \"CChain-\",\n",
    "    \"CChainStats-\",\n",
    "    \"Above-\",\n",
    "    \"CREL_\",\n",
    "    \"Propn_\",\n",
    "    \"Diff_\"\n",
    "]\n",
    "\n",
    "# Results for SC\n",
    "current_best = ['CREL_', 'CChain-', 'Prob-']\n",
    "best_iterations = 1\n",
    "\n",
    "# default params (not all of these are optimized)\n",
    "params = {\n",
    "    \"best_top_n\": best_top_n,\n",
    "    \"best_max_upd\": best_max_upd,\n",
    "    \"best_max_parses\": best_max_parses,\n",
    "    \"best_min_prob\": best_min_prob,\n",
    "    \"min_feat_freq\": min_feat_freq\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SC_RE-RANKER_HYPER_PARAM_TD', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONGO_COLLECTION, best_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Param Hash (avoid re-running same experiment multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = (\"C\", \"best_max_parses\", \n",
    "        #\"best_max_upd\", \n",
    "        \"max_update_items\", \n",
    "        \"best_min_prob\", \"best_top_n\", \"extractors\", \"initial_weight\", \"loss_type\",\\\n",
    "        \"min_feat_freq\", \"pa_type\")\n",
    "\n",
    "def hash_params(params):\n",
    "    p = dict()\n",
    "    # only copy over white list vals\n",
    "    for v in vals:\n",
    "        p[v] = params[v]\n",
    "    return str(sorted(p.items())).replace(\" \",\"\")\n",
    "\n",
    "def load_param_hash(db, collection):\n",
    "    project = {\n",
    "        \"params\": \"$parameters\",\n",
    "#         \"asof\":   \"$asof\",\n",
    "        \"_id\": 1\n",
    "    }\n",
    "    feats_pipeline = [{ \"$project\": project }]\n",
    "    rows = [row for row in db[collection].aggregate(feats_pipeline)]\n",
    "    print(\"len(rows)\", len(rows))\n",
    "    param_hash = set()\n",
    "    for r in rows:\n",
    "        param_hash.add(hash_params(r[\"params\"]))\n",
    "    return param_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rows) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 'SC_RE-RANKER_HYPER_PARAM_TD')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(serverSelectionTimeoutMS=100, host=\"127.0.0.1\")\n",
    "param_hash = load_param_hash(client.metrics_causal_model_reranker, MONGO_COLLECTION)\n",
    "len(param_hash), MONGO_COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 6, 18, 7, 40, 23, 956777)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = -1\n",
    "# best_f1 = 0.7457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a closure to simplify loop\n",
    "def trn_mdl(top_n, prms, cv_filtrd):\n",
    "    \n",
    "    global best_f1, best_C, pa_type, best_max_upd, initial_weight, loss_type\n",
    "    \n",
    "    n_jobs = None\n",
    "    # Uses too much RAM, drop to single threaded\n",
    "    if top_n > 3:        \n",
    "        n_jobs = 1\n",
    "    \n",
    "    f1 = train_model_parallel_logged(\n",
    "        training_collection_name=MONGO_COLLECTION, results_processor=results_processor,\n",
    "        feat_extractors=current_best, params=prms,\n",
    "\n",
    "        cv_folds=cv_filtrd, name2essay=name2essay, \n",
    "        C=best_C, pa_type=pa_type, loss_type=loss_type, max_update_items=best_max_upd, initial_weight=initial_weight,\n",
    "        set_cr_tags=set_cr_tags,\n",
    "        # use best iterations from above\n",
    "        max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        print(\"New Best F1: {f1:.6f}:\\t{params}\".format(f1=f1, params=\\\n",
    "                                                       str((top_n, best_C, pa_type, best_max_upd, initial_weight, loss_type))))\n",
    "    else:\n",
    "        print(\"         F1: {f1:.6f}:\\t{params}\".format(f1=f1, params=\\\n",
    "                                                       str((top_n, best_C, pa_type, best_max_upd, initial_weight, loss_type))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rows) 0\n",
      "top_n 1\n",
      "New Best F1: 0.805714:\t(1, 0.0005, 1, 1, 0.01, 'pb')\n",
      "New Best F1: 0.806522:\t(1, 0.0005, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.804152:\t(1, 0.0005, 2, 1, 0.01, 'pb')\n",
      "New Best F1: 0.806736:\t(1, 0.0005, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.799449:\t(1, 0.0025, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.806688:\t(1, 0.0025, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.798843:\t(1, 0.0025, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.806254:\t(1, 0.0025, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.800441:\t(1, 0.01, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.805336:\t(1, 0.01, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.800331:\t(1, 0.01, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.804265:\t(1, 0.01, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.799559:\t(1, 0.1, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.804107:\t(1, 0.1, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.798560:\t(1, 0.1, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.796955:\t(1, 0.1, 2, 1, 0.01, 'ml')\n",
      "top_n 2\n",
      "         F1: 0.805982:\t(2, 0.0005, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.806574:\t(2, 0.0005, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.802243:\t(2, 0.0005, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.806627:\t(2, 0.0005, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.798564:\t(2, 0.0025, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.806360:\t(2, 0.0025, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.799174:\t(2, 0.0025, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.806254:\t(2, 0.0025, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.801267:\t(2, 0.01, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.806145:\t(2, 0.01, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.798898:\t(2, 0.01, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.805840:\t(2, 0.01, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.801977:\t(2, 0.1, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.803833:\t(2, 0.1, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.797454:\t(2, 0.1, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.793439:\t(2, 0.1, 2, 1, 0.01, 'ml')\n",
      "top_n 3\n",
      "         F1: 0.800053:\t(3, 0.0005, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.803837:\t(3, 0.0005, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.792381:\t(3, 0.0005, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.805202:\t(3, 0.0005, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.796508:\t(3, 0.0025, 1, 1, 0.01, 'pb')\n",
      "New Best F1: 0.806882:\t(3, 0.0025, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.797604:\t(3, 0.0025, 2, 1, 0.01, 'pb')\n",
      "New Best F1: 0.807661:\t(3, 0.0025, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.800922:\t(3, 0.01, 1, 1, 0.01, 'pb')\n",
      "New Best F1: 0.808089:\t(3, 0.01, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.802069:\t(3, 0.01, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.805619:\t(3, 0.01, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.803256:\t(3, 0.1, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.806131:\t(3, 0.1, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.798148:\t(3, 0.1, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.797441:\t(3, 0.1, 2, 1, 0.01, 'ml')\n",
      "top_n 5\n",
      "         F1: 0.782937:\t(5, 0.0005, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.803294:\t(5, 0.0005, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.789123:\t(5, 0.0005, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.805451:\t(5, 0.0005, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.794408:\t(5, 0.0025, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.805954:\t(5, 0.0025, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.794903:\t(5, 0.0025, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.804582:\t(5, 0.0025, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.799288:\t(5, 0.01, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.807500:\t(5, 0.01, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.802551:\t(5, 0.01, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.806079:\t(5, 0.01, 2, 1, 0.01, 'ml')\n",
      "         F1: 0.805360:\t(5, 0.1, 1, 1, 0.01, 'pb')\n",
      "         F1: 0.805496:\t(5, 0.1, 1, 1, 0.01, 'ml')\n",
      "         F1: 0.797984:\t(5, 0.1, 2, 1, 0.01, 'pb')\n",
      "         F1: 0.796624:\t(5, 0.1, 2, 1, 0.01, 'ml')\n"
     ]
    }
   ],
   "source": [
    "param_hash = load_param_hash(client.metrics_causal_model_reranker, MONGO_COLLECTION)\n",
    "\n",
    "for top_n in [1,2,3,5]: # [1,2,3,5] - for SC\n",
    "    \n",
    "    print(\"top_n\", top_n)\n",
    "    xs_rr, _ = load_rerank(top_n)\n",
    "    xs_temp = get_features_from_probabilities(xs_rr, name2crels, best_max_parses, \n",
    "                                     causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                     min_feat_freq=min_feat_freq, min_prob=best_min_prob)\n",
    "    \n",
    "    cv_flds_rr = cross_validation(xs_temp, 5)\n",
    "    cv_flds_mm = [min_max_normalize_feats(train, test) for (train, test) in cv_flds_rr]\n",
    "    \n",
    "    # Filter feats\n",
    "    cv_filtered = []\n",
    "    for tr, test in cv_flds_mm:\n",
    "        x_tr,x_test = filter_feats(tr, test, current_best)\n",
    "        cv_filtered.append((x_tr,x_test))\n",
    "    \n",
    "    skipped = False\n",
    "    for best_C in [0.0005, 0.0025, 0.0100, 0.1]:\n",
    "        for pa_type in [1,2]: # [0]\n",
    "            for best_max_upd in [1]:\n",
    "                for initial_weight in [0.01]:\n",
    "                    for loss_type in [\"pb\", \"ml\"]:\n",
    "                        \n",
    "                        p = {'C': best_C,\n",
    "                             'best_max_parses': best_max_parses,\n",
    "                             'best_min_prob': best_min_prob,\n",
    "                             'best_top_n': top_n,\n",
    "                             'extractors': list(current_best),\n",
    "                             'initial_weight': initial_weight,\n",
    "                             'loss_type': loss_type,\n",
    "                             'max_update_items': best_max_upd,\n",
    "                             'min_feat_freq': min_feat_freq,\n",
    "                             'pa_type': pa_type\n",
    "                        }\n",
    "                        hash_p = hash_params(p)\n",
    "                        if hash_p in param_hash:\n",
    "                            print(\".\", end = '')\n",
    "                            skipped = True\n",
    "                            continue\n",
    "                        if skipped:\n",
    "                            print()\n",
    "                        trn_mdl(top_n, p, cv_filtered)\n",
    "                        skipped = False\n",
    "\n",
    "# top_n, best_C, pa_type, best_max_upd, initial_weight, loss_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_feat_freq, best_min_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score\tprecision\trecall\t    best_top_n\tC\t    best_max_parses\t  max_update_items\tinitial_weight\tloss_type\tpa_type\n",
    "# 0.808089\t0.856129\t0.765153\t3\t        0.01\t300\t              1\t                0.01\t        ml\t        1\n",
    "# # current best settings\n",
    "# C=best_C, pa_type=pa_type, loss_type=loss_type, max_update_items=best_max_upd, initial_weight=initial_weight,\n",
    "\n",
    "top_n = 3\n",
    "best_C = 0.01\n",
    "best_max_upd = 1\n",
    "max_update_items = 1\n",
    "initial_weight = 0.01\n",
    "loss_type = \"ml\"\n",
    "pa_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_rr, xs_tst_rr = load_rerank(top_n)\n",
    "xs_temp = get_features_from_probabilities(xs_rr, name2crels, best_max_parses, \n",
    "                                 causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                 min_feat_freq=min_feat_freq, min_prob=best_min_prob)\n",
    "\n",
    "# Don't need CV here, but leave it in anyways\n",
    "cv_flds_rr = cross_validation(xs_temp, 5)    \n",
    "xs_test = get_features_from_probabilities(xs_tst_rr, name2crels, best_max_parses, \n",
    "                                      causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                      min_feat_freq=min_feat_freq, min_prob=best_min_prob)\n",
    "xs_train_tmp = []\n",
    "for train, test in cv_flds_rr:\n",
    "    xs_train_tmp.extend(test)\n",
    "\n",
    "xs_train_mm, xs_test_mm = min_max_normalize_feats(xs_train_tmp, xs_test)\n",
    "# Filter at the end\n",
    "xs_train_mm_fltr, xs_test_mm_fltr = filter_feats(xs_train_mm, xs_test_mm, current_best) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the Optimal Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning dataset from training data\n",
    "num_train = int(0.8 * len(xs_train_mm_fltr))\n",
    "tmp_train_copy = list(xs_train_mm_fltr)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.8109 Test Accuracy: 0.8069\n",
      "Epoch: 1 Train Accuracy: 0.8149 Test Accuracy: 0.8059\n",
      "Epoch: 2 Train Accuracy: 0.8162 Test Accuracy: 0.8066\n",
      "Epoch: 3 Train Accuracy: 0.8167 Test Accuracy: 0.8038\n",
      "Best Test Acc: 0.8069\n",
      "CPU times: user 1min 26s, sys: 201 ms, total: 1min 26s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=best_max_upd, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=3, train_instance_fn = train_cost_sensitive_instance,\n",
    "                                                        verbose=True,  early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for X Iterations on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.8123 Test Accuracy: 0.8257\n",
      "Best Test Acc: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=best_max_upd, initial_weight=initial_weight)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_TEST_COLLECTION = \"TEST_SC_RE-RANKER_TD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8270422535211268\n",
      "CPU times: user 28.3 s, sys: 88 ms, total: 28.4 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_folds = [(xs_train_mm_fltr, xs_test_mm_fltr)]\n",
    "\n",
    "params = {\n",
    "    'C': best_C,\n",
    "    'best_max_parses': best_max_parses,\n",
    "    'best_min_prob': best_min_prob,\n",
    "    'best_top_n': top_n,\n",
    "    'extractors': list(current_best),\n",
    "    'initial_weight': initial_weight,\n",
    "    'loss_type': loss_type,\n",
    "    'max_update_items': best_max_upd,\n",
    "    'min_feat_freq': min_feat_freq,\n",
    "    'pa_type': pa_type\n",
    "}\n",
    "\n",
    "test_f1 = train_model_parallel_logged(\n",
    "        training_collection_name=MONGO_TEST_COLLECTION, results_processor=results_processor,\n",
    "        feat_extractors=current_best, params=params,\n",
    "\n",
    "        cv_folds=test_folds, \n",
    "        \n",
    "        name2essay=name2essay, \n",
    "        C=best_C, pa_type=pa_type, loss_type=loss_type, max_update_items=best_max_upd, initial_weight=initial_weight,\n",
    "        set_cr_tags=set_cr_tags,\n",
    "        # use best iterations from above\n",
    "        max_epochs=best_iterations, early_stop_iters=best_iterations\n",
    "    )\n",
    "print(test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(870, 218)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xs_rr), len(xs_test_mm_fltr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(best_mdl.weights.items(), key = lambda tpl: (tpl[0]))[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Prob-min-prob', 0.22406471653724705),\n",
       " ('CREL_Causer:1->Result:2-MAX(prob)', 0.20337475889827955),\n",
       " ('Prob-5%-prob', 0.19850412752920427),\n",
       " ('Prob-10%-prob', 0.1725022015441227),\n",
       " ('CREL_1:50', 0.17),\n",
       " ('CREL_Causer:5->Result:50-MAX(prob)', 0.16625748312386457),\n",
       " ('CREL_2:50', 0.16),\n",
       " ('CREL_1:2', 0.16),\n",
       " ('Prob-geo-mean', 0.1558215246665996),\n",
       " ('CREL_3:4', 0.15)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_mdl.weights.items(), key = lambda tpl: -abs(tpl[1]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
