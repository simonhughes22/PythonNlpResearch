{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model_parallel_logged, train_model_parallel, train_model, train_cost_sensitive_instance\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from results_procesor import ResultsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "870 218\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.SKIN_CANCER\n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "crels_folder = \"./crels/SC\"\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "MONGO_COLLECTION = \"SC_RE-RANKER_FEATURE_SEL_TD\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "results_processor = ResultsProcessor(dbname=\"metrics_causal_model\")\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Causer:11->Result:3',\n",
       " 'Causer:12->Result:2',\n",
       " 'Causer:3->Result:50',\n",
       " 'Causer:50->Result:2',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:5->Result:4',\n",
       " 'Causer:5->Result:6',\n",
       " 'Causer:5->Result:5',\n",
       " 'Causer:12->Result:5',\n",
       " 'Causer:12->Result:12']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "print(len(cr_tags))\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Re-Ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Parses from Sentence Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_top_n = 2\n",
    "min_feat_freq = 1\n",
    "best_max_upd = 2 \n",
    "best_max_parses = 300\n",
    "best_min_prob = 0.0  # min prob of 0 seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(870, 218)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_fname = \"xs_rerank_\" + str(best_top_n) + \".dill\"\n",
    "with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "    xs_rerank = dill.load(f)\n",
    "\n",
    "rr_fname = \"xs_rerank_test\" + str(best_top_n) + \".dill\"\n",
    "with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "    xs_test_rerank = dill.load(f)\n",
    "    \n",
    "assert len(xs_rerank) == len(pred_tagged_essays_train),     \"Wrong number of train crels\"\n",
    "assert len(xs_test_rerank) == len(pred_tagged_essays_test), \"Wrong number of test crels\"\n",
    "len(xs_rerank), len(xs_test_rerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 4.12 s, total: 2min 16s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs = get_features_from_probabilities(xs_rerank, name2crels, best_max_parses, \n",
    "                                     causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                     min_feat_freq=min_feat_freq, min_prob=best_min_prob)\n",
    "\n",
    "cv_folds_rerank = cross_validation(xs, 5)\n",
    "cv_folds_mm = [min_max_normalize_feats(train, test) for (train, test) in cv_folds_rerank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 237 ms, total: 13.6 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs_test = get_features_from_probabilities(xs_test_rerank, name2crels, best_max_parses, \n",
    "                                          causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                          min_feat_freq=min_feat_freq, min_prob=best_min_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset \n",
    "  # training data comes from the test fold predictions from CV on the full training dataset\n",
    "xs_train = []\n",
    "for train, test in cv_folds_rerank:\n",
    "    xs_train.extend(test)\n",
    "\n",
    "# Normalize both using training data\n",
    "xs_train_mm, xs_test_mm = min_max_normalize_feats(xs_train,xs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 0.0025       # 0.0025\n",
    "C = best_C            # This needs to be a lot lower\n",
    "pa_type = 1\n",
    "loss_type= \"ml\"\n",
    "max_update_items = 2  # best_max_upd - 2\n",
    "initial_weight = 0.01  # was 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8059914772313782\n",
      "CPU times: user 3min 49s, sys: 47.7 s, total: 4min 37s\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1 = train_model_parallel(\n",
    "    cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "    set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "print(f1)\n",
    "# 0.80599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.8061 Test Accuracy: 0.8280\n",
      "Epoch: 1 Train Accuracy: 0.8061 Test Accuracy: 0.8280\n",
      "Epoch: 2 Train Accuracy: 0.8069 Test Accuracy: 0.8260\n",
      "Epoch: 3 Train Accuracy: 0.8074 Test Accuracy: 0.8269\n",
      "Best Test Acc: 0.8280\n",
      "CPU times: user 2min 39s, sys: 1.09 s, total: 2min 40s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test on test data\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "                                       name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=best_iterations, early_stop_iters=best_iterations, train_instance_fn = train_cost_sensitive_instance, v\n",
    "                                         erbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm))\n",
    "tmp_train_copy = list(xs_train_mm)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.8042 Test Accuracy: 0.8149\n",
      "Epoch: 1 Train Accuracy: 0.8050 Test Accuracy: 0.8155\n",
      "Epoch: 2 Train Accuracy: 0.8050 Test Accuracy: 0.8161\n",
      "Epoch: 3 Train Accuracy: 0.8051 Test Accuracy: 0.8167\n",
      "Epoch: 4 Train Accuracy: 0.8058 Test Accuracy: 0.8158\n",
      "Epoch: 5 Train Accuracy: 0.8061 Test Accuracy: 0.8149\n",
      "Epoch: 6 Train Accuracy: 0.8064 Test Accuracy: 0.8140\n",
      "Epoch: 7 Train Accuracy: 0.8063 Test Accuracy: 0.8140\n",
      "Epoch: 8 Train Accuracy: 0.8063 Test Accuracy: 0.8146\n",
      "Best Test Acc: 0.8167\n",
      "Best iterations: 4\n",
      "CPU times: user 4min 33s, sys: 3.16 s, total: 4min 37s\n",
      "Wall time: 1h 32min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use training data to determine number of iterations\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=5, \n",
    "     train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=True)\n",
    "print(\"Best iterations:\", best_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_features import filter_feats\n",
    "\n",
    "prefixes = [\n",
    "    \"Prob-\",\n",
    "    \"CREL_Pair-\",\n",
    "    \"Inv-\",\n",
    "    \"num_crels\",\n",
    "    \"Tally-\",\n",
    "    \"CChain-\",\n",
    "    \"CChainStats-\",\n",
    "    \"Above-\",\n",
    "    \"CREL_\",\n",
    "    \"Propn_\",\n",
    "    \"Diff_\"\n",
    "]\n",
    "# xs_fltr_train, xs_fltr_test = filter_feats(xs_train_mm, xs_test_mm, prefixes)\n",
    "assert len(prefixes) == len(set(prefixes)), \"Duplicate prefixes found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = -1\n",
    "current_best = []\n",
    "remaining = list(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CB_RE-RANKER_FEATURE_SEL_TD_3', 3, 0.01)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONGO_COLLECTION, best_iterations, initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feats, new Best F1: 0.7430 Prefixes: ['CREL_']\n",
      "2 feats, new Best F1: 0.7438 Prefixes: ['CREL_', 'Prob-']\n",
      "3 feats, new Best F1: 0.7461 Prefixes: ['CREL_', 'Prob-', 'CChainStats-']\n",
      "No further improvement, stopping\n",
      "CPU times: user 40min 53s, sys: 4min 32s, total: 45min 26s\n",
      "Wall time: 1h 13min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    \"best_top_n\": best_top_n,\n",
    "    \"best_max_upd\": best_max_upd,\n",
    "    \"best_max_parses\": best_max_parses,\n",
    "    \"best_min_prob\": best_min_prob,\n",
    "    \"min_feat_freq\": min_feat_freq\n",
    "}\n",
    "\n",
    "print(\"Starting...\")\n",
    "while True:\n",
    "    if len(remaining) == 0:\n",
    "        break\n",
    "    \n",
    "    f1_by_prefix = dict()\n",
    "    for prefix in remaining:\n",
    "        new_prefixes = current_best + [prefix]\n",
    "        \n",
    "        cv_filtered = []\n",
    "        for tr, test in cv_folds_mm:\n",
    "            x_tr,x_test = filter_feats(tr, test, new_prefixes)\n",
    "            cv_filtered.append((x_tr,x_test))\n",
    "        \n",
    "        f1_by_prefix[prefix] = train_model_parallel_logged(\n",
    "            training_collection_name=MONGO_COLLECTION, results_processor=results_processor,\n",
    "            feat_extractors=new_prefixes, params=params,\n",
    "            \n",
    "            cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "            pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "            set_cr_tags=set_cr_tags, initial_weight=initial_weight,\n",
    "            # use best iterations from above\n",
    "            max_epochs=best_iterations, early_stop_iters=best_iterations\n",
    "        )\n",
    "        print(\"\\t{length} feats F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(new_prefixes), f1=f1_by_prefix[prefix], prefixes=str(new_prefixes)))\n",
    "    \n",
    "    best_prefix, new_best_f1 = sorted(f1_by_prefix.items(), key = lambda tpl: -tpl[1])[0]\n",
    "    if new_best_f1 > best_f1:\n",
    "        best_f1 = new_best_f1\n",
    "        current_best.append(best_prefix)\n",
    "        remaining.remove(best_prefix)\n",
    "        print(\"{length} feats, new Best F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(current_best), f1=best_f1, prefixes=str(current_best)))\n",
    "    else:\n",
    "        print(\"No further improvement, stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CREL_', 'Prob-', 'CChainStats-'], 0.7460682777138474)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_best, best_f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run it against the full set of features for comparison\n",
    "# cv_filtered = []\n",
    "# for tr, test in cv_folds_mm:\n",
    "#     x_tr,x_test = filter_feats(tr, test, prefixes)\n",
    "#     cv_filtered.append((x_tr,x_test))\n",
    "\n",
    "# f1 = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "#                           pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "#                           set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "# f1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train_mm_fltr, xs_test_mm_fltr = filter_feats(xs_train_mm, xs_test_mm, current_best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm_fltr))\n",
    "tmp_train_copy = list(xs_train_mm_fltr)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the Optimal Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7441 Test Accuracy: 0.7533\n",
      "Epoch: 1 Train Accuracy: 0.7480 Test Accuracy: 0.7565\n",
      "Epoch: 2 Train Accuracy: 0.7496 Test Accuracy: 0.7597\n",
      "Epoch: 3 Train Accuracy: 0.7510 Test Accuracy: 0.7590\n",
      "Epoch: 4 Train Accuracy: 0.7525 Test Accuracy: 0.7592\n",
      "Epoch: 5 Train Accuracy: 0.7528 Test Accuracy: 0.7588\n",
      "Best Test Acc: 0.7597\n",
      "CPU times: user 1min 5s, sys: 86.5 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=3, train_instance_fn = train_cost_sensitive_instance,\n",
    "                                                        verbose=True,  early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for X Iterations on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7464 Test Accuracy: 0.7406\n",
      "Epoch: 1 Train Accuracy: 0.7505 Test Accuracy: 0.7418\n",
      "Epoch: 2 Train Accuracy: 0.7531 Test Accuracy: 0.7420\n",
      "Best Test Acc: 0.7420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7471 Test Accuracy: 0.7431\n",
      "Epoch: 1 Train Accuracy: 0.7515 Test Accuracy: 0.7438\n",
      "Epoch: 2 Train Accuracy: 0.7525 Test Accuracy: 0.7429\n",
      "Best Test Acc: 0.7438\n"
     ]
    }
   ],
   "source": [
    "# try initial weight of 0\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7499 Test Accuracy: 0.7409\n",
      "Epoch: 1 Train Accuracy: 0.7526 Test Accuracy: 0.7427\n",
      "Epoch: 2 Train Accuracy: 0.7530 Test Accuracy: 0.7434\n",
      "Epoch: 3 Train Accuracy: 0.7543 Test Accuracy: 0.7422\n",
      "Epoch: 4 Train Accuracy: 0.7550 Test Accuracy: 0.7399\n",
      "Epoch: 5 Train Accuracy: 0.7556 Test Accuracy: 0.7399\n",
      "Epoch: 6 Train Accuracy: 0.7563 Test Accuracy: 0.7406\n",
      "Epoch: 7 Train Accuracy: 0.7572 Test Accuracy: 0.7413\n",
      "Epoch: 8 Train Accuracy: 0.7570 Test Accuracy: 0.7426\n",
      "Epoch: 9 Train Accuracy: 0.7574 Test Accuracy: 0.7426\n",
      "Epoch: 10 Train Accuracy: 0.7577 Test Accuracy: 0.7433\n",
      "Epoch: 11 Train Accuracy: 0.7580 Test Accuracy: 0.7429\n",
      "Epoch: 12 Train Accuracy: 0.7588 Test Accuracy: 0.7429\n",
      "Epoch: 13 Train Accuracy: 0.7586 Test Accuracy: 0.7429\n",
      "Epoch: 14 Train Accuracy: 0.7586 Test Accuracy: 0.7429\n",
      "Epoch: 15 Train Accuracy: 0.7587 Test Accuracy: 0.7435\n",
      "Epoch: 16 Train Accuracy: 0.7591 Test Accuracy: 0.7435\n",
      "Epoch: 17 Train Accuracy: 0.7603 Test Accuracy: 0.7449\n",
      "Epoch: 18 Train Accuracy: 0.7610 Test Accuracy: 0.7449\n",
      "Epoch: 19 Train Accuracy: 0.7614 Test Accuracy: 0.7449\n",
      "Best Test Acc: 0.7449\n"
     ]
    }
   ],
   "source": [
    "# try initial weight of 0, more training iterations\n",
    "ITERATIONS = 20\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=ITERATIONS, early_stop_iters=ITERATIONS,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7417 Test Accuracy: 0.7407\n",
      "Epoch: 1 Train Accuracy: 0.7414 Test Accuracy: 0.7407\n",
      "Epoch: 2 Train Accuracy: 0.7414 Test Accuracy: 0.7414\n",
      "Best Test Acc: 0.7414\n"
     ]
    }
   ],
   "source": [
    "# try an initial weight of 1\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7403 Test Accuracy: 0.7409\n",
      "Epoch: 1 Train Accuracy: 0.7394 Test Accuracy: 0.7399\n",
      "Epoch: 2 Train Accuracy: 0.7382 Test Accuracy: 0.7384\n",
      "Best Test Acc: 0.7409\n"
     ]
    }
   ],
   "source": [
    "# initial weight of 1, all feats\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7383512544802866"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('num_crels<=4', 2.172499999999975),\n",
       " ('num_crels<=3', 2.1374999999999758),\n",
       " ('num_crels<=5', 1.9999999999999787),\n",
       " ('num_crels<=2', 1.844999999999982),\n",
       " ('num_crels<=6', 1.7274999999999845),\n",
       " ('CChainStats-num_distinct_chains <=1', 1.7099999999999849),\n",
       " ('Inv-not_inverted', 1.6224999999999867),\n",
       " ('CChainStats-MaxChain_Len=0', 1.590070667321122),\n",
       " ('CChainStats-num_distinct_chains=0', 1.590070667321122),\n",
       " ('CChainStats-num_distinct_chains <=0', 1.590070667321122),\n",
       " ('num_crels<=7', 1.5524999999999882),\n",
       " ('num_crels<=1', 1.5050706673211238),\n",
       " ('CChainStats-num_distinct_chains <=2', 1.47249999999999),\n",
       " ('num_crels=0', 1.4049999999999914),\n",
       " ('num_crels=2', 1.3399293326788582),\n",
       " ('Prob-prod-prob', 1.2996970063299125),\n",
       " ('num_crels=3', 1.2924999999999938),\n",
       " ('Above-All-Above-0.7', 1.279999999999994),\n",
       " ('CChainStats-num_distinct_chains <=3', 1.2674999999999943),\n",
       " ('Diff_adjacent_codes', 1.2378750000000023),\n",
       " ('num_crels<=8', 1.1949999999999958),\n",
       " ('Above-All-Above-0.9', 1.1275706673211319),\n",
       " ('CChainStats-num_distinct_chains=1', 1.1199293326788629),\n",
       " ('num_crels=1', 1.1000706673211325),\n",
       " ('Above-All-Above-0.8', 1.0999999999999979),\n",
       " ('Propn_unique_codes', 1.0976396906398203),\n",
       " ('Above-All-Above-0.95', 1.0900706673211327),\n",
       " ('CChainStats-num_distinct_chains <=4', 1.0824999999999982),\n",
       " ('CChainStats-num_distinct_chains <=5', 1.0674999999999986),\n",
       " ('Above-%-0.95', 1.0629460479462898),\n",
       " ('Above-%-0.9', 1.0399341431843954),\n",
       " ('num_crels=4', 1.0349999999999993),\n",
       " ('CREL_Pair-Causer:1->Result:3|Causer:6->Result:50', 1.0274999999999994),\n",
       " ('CChain-:3,1,50', 1.0224999999999995),\n",
       " ('CREL_Pair-Causer:11->Result:14|Causer:14->Result:50', 1.0174999999999996),\n",
       " ('CChain-:11,14,50', 1.0174999999999996),\n",
       " ('CChain-:3,1,2', 1.0149999999999997),\n",
       " ('CREL_Pair-Causer:11->Result:14|Causer:4->Result:14', 1.0124999999999997),\n",
       " ('CREL_Pair-Causer:11->Result:14|Causer:4->Result:50', 1.0124999999999997),\n",
       " ('CREL_Pair-Causer:5b->Result:50|Causer:7->Result:50', 1.0124999999999997),\n",
       " ('CREL_Pair-Causer:2->Result:3|Causer:6->Result:14', 1.0099999999999998),\n",
       " ('CREL_Pair-Causer:11->Result:13|Causer:6->Result:50', 1.0099999999999998),\n",
       " ('CREL_Pair-Causer:3->Result:5|Causer:4->Result:5b', 1.0099999999999998),\n",
       " ('CREL_Pair-Causer:4->Result:50|Causer:4->Result:5b', 1.0099999999999998),\n",
       " ('CChainStats-MaxChain_Len=3', 1.0099293326788652),\n",
       " ('CREL_Pair-Causer:13->Result:50|Causer:6->Result:7', 1.0074999999999998),\n",
       " ('CREL_Causer:4->Result:50-pred-count=6', 1.0074999999999998),\n",
       " ('CREL_Pair-Causer:11->Result:12|Causer:6->Result:50', 1.0074999999999998),\n",
       " ('CREL_Pair-Causer:12->Result:13|Causer:6->Result:50', 1.0074999999999998),\n",
       " ('CREL_Causer:3->Result:50-pred-count=10', 1.0074999999999998)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_mdl.weights.items(), key = lambda tpl: -abs(tpl[1]))[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "### Ideas\n",
    "- ~~num-crels - add back in the logic to threshold these? But only if needed to improve results here (seemed to help essay parser)~~\n",
    "- ~~Re-run with more realistic initial hyper params~~\n",
    "- ~~Add in logic to store results to mongo~~\n",
    "- ~~Switch back to using an initial_weight of 1~~\n",
    "- Approach seems very sensitive to the initial configuration of the algorithm. However, it also seems correlated to the training data performance on the first epoch. Run the algorithm multiple times, take the model with the best training performance and use that as the final selected model to train futher.\n",
    "- We need to add hyper parameter tuning\n",
    "- Do we want to just remove the BEAM search from this? It makes the explanation a lot more complex. But then again, it's the only way we can really add more crels that the model wouldn't otherwise parse\n",
    "- Do we use the BEAM search with some de-duping? Although we already de-dupe to some extent anyways\n",
    "\n",
    "### Needed to Finish\n",
    "- Record run on test data - needs optimal hyper parameters first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
