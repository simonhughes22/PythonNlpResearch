{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from MIRA import CostSensitiveMIRA\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model_parallel_logged, train_model_parallel, train_model, train_cost_sensitive_instance\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from results_procesor import ResultsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Data Set Partition\n",
    "CV_FOLDS = 5\n",
    "MIN_FEAT_FREQ = 5\n",
    "\n",
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.CORAL_BLEACHING\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "crels_folder = \"./crels/CB\"\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "MONGO_COLLECTION = \"CB_RE_RANKER_FEATURE_SEL_TD\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "results_processor = ResultsProcessor(dbname=\"metrics_causal_model\")\n",
    "\n",
    "train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:1->Result:2',\n",
       " 'Causer:3->Result:14',\n",
       " 'Causer:11->Result:3',\n",
       " 'Causer:1->Result:6',\n",
       " 'Causer:12->Result:5b',\n",
       " 'Causer:4->Result:14',\n",
       " 'Causer:5->Result:14',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:1->Result:5',\n",
       " 'Causer:12->Result:13']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "list(set_cr_tags)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Re-Ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Parses from Sentence Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_top_n = 2\n",
    "min_feat_freq = 1\n",
    "best_max_upd, best_max_parses, best_min_prob = (2, 300, 0.0)  # min prob of 0 seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_fname = \"xs_rerank_\" + str(best_top_n) + \".dill\"\n",
    "with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "    xs_rerank = dill.load(f)\n",
    "\n",
    "rr_fname = \"xs_rerank_test\" + str(best_top_n) + \".dill\"\n",
    "with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "    xs_test_rerank = dill.load(f)\n",
    "    \n",
    "assert len(xs_rerank) == len(pred_tagged_essays_train),     \"Wrong number of train crels\"\n",
    "assert len(xs_test_rerank) == len(pred_tagged_essays_test), \"Wrong number of test crels\"\n",
    "len(xs_rerank), len(xs_test_rerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 38s, sys: 1min 39s, total: 8min 18s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs = get_features_from_probabilities(xs_rerank, name2crels, best_max_parses, \n",
    "                                     causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                     min_feat_freq=min_feat_freq, min_prob=best_min_prob)\n",
    "\n",
    "cv_folds_rerank = cross_validation(xs, 5)\n",
    "cv_folds_mm = [min_max_normalize_feats(train, test) for (train, test) in cv_folds_rerank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 1.96 s, total: 23.7 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xs_test = get_features_from_probabilities(xs_test_rerank, name2crels, best_max_parses, \n",
    "                                          causal_model_type=CAUSAL_MODEL_TYPE,\n",
    "                                          min_feat_freq=min_feat_freq, min_prob=best_min_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset \n",
    "  # training data comes from the test fold predictions from CV on the full training dataset\n",
    "xs_train = []\n",
    "for train, test in cv_folds_rerank:\n",
    "    xs_train.extend(test)\n",
    "\n",
    "# Normalize both using training data\n",
    "xs_train_mm, xs_test_mm = min_max_normalize_feats(xs_train,xs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C = 0.0025       # 0.0025\n",
    "C = best_C            # This needs to be a lot lower\n",
    "pa_type = 1\n",
    "loss_type= \"ml\"\n",
    "max_update_items = 2  # best_max_upd - 2\n",
    "initial_weight = 1.0  # was 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f1 = train_model_parallel(\n",
    "    cv_folds=cv_folds_mm, name2essay=name2essay, C=best_C, pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "    set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "print(f1)  # 0.7421167703055035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm))\n",
    "tmp_train_copy = list(xs_train_mm)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # use training data to determine number of iterations\n",
    "# mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "#                         max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# # Determine number of training iterations\n",
    "# best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "#      max_epochs=20, early_stop_iters=5, \n",
    "#      train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_iterations, best_C, initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Test on test data\n",
    "# mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "#                         max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "# best_mdl, test_acc_df_ml,_ = train_model(mdl,  xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "#                                        name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "#      max_epochs=best_iterations, early_stop_iters=best_iterations, train_instance_fn = train_cost_sensitive_instance, verbose=True)\n",
    "# # Best Test Acc: 0.7406"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filter_features import filter_feats\n",
    "\n",
    "prefixes = [\n",
    "    \"Prob-\",\n",
    "    \"CREL_Pair-\",\n",
    "    \"Inv-\",\n",
    "    \"num_crels\",\n",
    "    \"Tally-\",\n",
    "    \"CChain-\",\n",
    "    \"CChainStats-\",\n",
    "    \"Above-\",\n",
    "    \"CREL_\",\n",
    "    \"Propn_\",\n",
    "    \"Diff_\"\n",
    "]\n",
    "# xs_fltr_train, xs_fltr_test = filter_feats(xs_train_mm, xs_test_mm, prefixes)\n",
    "assert len(prefixes) == len(set(prefixes)), \"Duplicate prefixes found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = -1\n",
    "current_best = []\n",
    "remaining = list(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feats, new Best F1: 0.7430 Prefixes: ['CREL_']\n",
      "2 feats, new Best F1: 0.7431 Prefixes: ['CREL_', 'Prob-']\n",
      "3 feats, new Best F1: 0.7432 Prefixes: ['CREL_', 'Prob-', 'Inv-']\n",
      "No further improvement, stopping\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "while True:\n",
    "    if len(remaining) == 0:\n",
    "        break\n",
    "    \n",
    "    f1_by_prefix = dict()\n",
    "    for prefix in remaining:\n",
    "        new_prefixes = current_best + [prefix]\n",
    "        \n",
    "        cv_filtered = []\n",
    "        for tr, test in cv_folds_mm:\n",
    "            x_tr,x_test = filter_feats(tr, test, new_prefixes)\n",
    "            cv_filtered.append((x_tr,x_test))\n",
    "        \n",
    "        f1_by_prefix[prefix] = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "                                  pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "                                  set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "    \n",
    "    best_prefix, new_best_f1 = sorted(f1_by_prefix.items(), key = lambda tpl: -tpl[1])[0]\n",
    "    if new_best_f1 > best_f1:\n",
    "        best_f1 = new_best_f1\n",
    "        current_best.append(best_prefix)\n",
    "        remaining.remove(best_prefix)\n",
    "        print(\"{length} feats, new Best F1: {f1:.4f} Prefixes: {prefixes}\".format(\n",
    "            length=len(current_best), f1=best_f1, prefixes=str(current_best)))\n",
    "    else:\n",
    "        print(\"No further improvement, stopping\")\n",
    "        break\n",
    "        \n",
    "# 1 feats, new Best F1: 0.7389 Prefixes: ['CREL_']\n",
    "# 2 feats, new Best F1: 0.7426 Prefixes: ['CREL_', 'Above-']\n",
    "\n",
    "# with num_crels fixed:\n",
    "# 1 feats, new Best F1: 0.7481 Prefixes: ['CREL_']\n",
    "# 2 feats, new Best F1: 0.7482 Prefixes: ['CREL_', 'num_crels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CREL_', 'Prob-', 'Inv-'], 0.7432279026710764)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_best, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run it against the full set of features for comparison\n",
    "# cv_filtered = []\n",
    "# for tr, test in cv_folds_mm:\n",
    "#     x_tr,x_test = filter_feats(tr, test, prefixes)\n",
    "#     cv_filtered.append((x_tr,x_test))\n",
    "\n",
    "# f1 = train_model_parallel(cv_folds=cv_filtered, name2essay=name2essay, C=best_C, \n",
    "#                           pa_type=1, loss_type=\"ml\", max_update_items=best_max_upd, \n",
    "#                           set_cr_tags=set_cr_tags, initial_weight=initial_weight)\n",
    "# f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train_mm_fltr, xs_test_mm_fltr = filter_feats(xs_train_mm, xs_test_mm, current_best) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(0.8 * len(xs_train_mm_fltr))\n",
    "tmp_train_copy = list(xs_train_mm_fltr)\n",
    "np.random.shuffle(tmp_train_copy)\n",
    "tmp_train, tmp_test = tmp_train_copy[:num_train], tmp_train_copy[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the Optimal Number of Training Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_weight = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7567 Test Accuracy: 0.7183\n",
      "Epoch: 1 Train Accuracy: 0.7572 Test Accuracy: 0.7187\n",
      "Epoch: 2 Train Accuracy: 0.7578 Test Accuracy: 0.7181\n",
      "Epoch: 3 Train Accuracy: 0.7587 Test Accuracy: 0.7181\n",
      "Epoch: 4 Train Accuracy: 0.7589 Test Accuracy: 0.7181\n",
      "Best Test Acc: 0.7187\n",
      "CPU times: user 1min, sys: 390 ms, total: 1min\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "# Determine number of training iterations\n",
    "best_mdl, test_acc_df_ml, best_iterations = train_model(mdl, xs_train=tmp_train, xs_test=tmp_test, name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "     max_epochs=20, early_stop_iters=3, train_instance_fn = train_cost_sensitive_instance,\n",
    "                                                        verbose=True,  early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7450 Test Accuracy: 0.7370\n",
      "Epoch: 1 Train Accuracy: 0.7498 Test Accuracy: 0.7378\n",
      "Best Test Acc: 0.7378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=initial_weight)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=best_iterations,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "best_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7470 Test Accuracy: 0.7412\n",
      "Epoch: 1 Train Accuracy: 0.7522 Test Accuracy: 0.7415\n",
      "Epoch: 2 Train Accuracy: 0.7541 Test Accuracy: 0.7403\n",
      "Epoch: 3 Train Accuracy: 0.7547 Test Accuracy: 0.7426\n",
      "Epoch: 4 Train Accuracy: 0.7559 Test Accuracy: 0.7426\n",
      "Best Test Acc: 0.7426\n"
     ]
    }
   ],
   "source": [
    "# try a smaller C\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=0)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=5, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7417 Test Accuracy: 0.7407\n",
      "Epoch: 1 Train Accuracy: 0.7417 Test Accuracy: 0.7407\n",
      "Best Test Acc: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# try a larger initial weight\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm_fltr, xs_test=xs_test_mm_fltr,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.7405 Test Accuracy: 0.7409\n",
      "Epoch: 1 Train Accuracy: 0.7394 Test Accuracy: 0.7399\n",
      "Best Test Acc: 0.7409\n"
     ]
    }
   ],
   "source": [
    "# initial weight of 1, all feats\n",
    "mdl = CostSensitiveMIRA(C=best_C, pa_type=pa_type, loss_type=loss_type, \n",
    "                        max_update_items=max_update_items, initial_weight=1)\n",
    "\n",
    "best_mdl, test_acc_df_ml,_ = train_model(mdl,  \n",
    "    xs_train=xs_train_mm, xs_test=xs_test_mm,\n",
    "    name2essay=name2essay, set_cr_tags=set_cr_tags,\n",
    "    max_epochs=best_iterations, early_stop_iters=5,\n",
    "    train_instance_fn = train_cost_sensitive_instance, verbose=True, early_stopping=False)\n",
    "\n",
    "# Best Test Acc: 0.7516\n",
    "\n",
    "# Best Test Acc: 0.7408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7426470588235294, 0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CREL_Causer:7->Result:50-MAX(prob)', 0.243912351364519),\n",
       " ('CREL_Pair-Causer:14->Result:50|Causer:6->Result:14', 0.23750000000000016),\n",
       " ('CREL_7:50', 0.22750000000000015),\n",
       " ('Inv-not_inverted', 0.22342509836073043),\n",
       " ('Inv-inverted', -0.22342509836073043),\n",
       " ('Prob-prod-prob', 0.20948981176216386),\n",
       " ('CREL_Causer:7->Result:50-MIN(prob)', 0.20565634400312116),\n",
       " ('CREL_Pair-Causer:6->Result:14|Causer:7->Result:50', 0.20500000000000013),\n",
       " ('CREL_Pair-Causer:1->Result:50|Causer:5->Result:50', 0.20250000000000012),\n",
       " ('CREL_3:50', 0.19800873456074375),\n",
       " ('CREL_Causer:1->Result:50-MIN(prob)', 0.19223590489813785),\n",
       " ('CREL_Causer:1->Result:50-MAX(prob)', 0.18130067370288777),\n",
       " ('CREL_Causer:1->Result:3-MAX(prob)', 0.18020632085293448),\n",
       " ('CREL_6:7', 0.1775000000000001),\n",
       " ('CREL_Causer:3->Result:4-MAX(prob)', 0.17621265697741062),\n",
       " ('CREL_Causer:6->Result:7-MAX(prob)', 0.1707054788910274),\n",
       " ('CREL_Causer:1->Result:3-MIN(prob)', 0.16853399258635784),\n",
       " ('CREL_1:50', 0.16798942509661055),\n",
       " ('CREL_Causer:3->Result:4-MIN(prob)', 0.1678738444264458),\n",
       " ('CREL_Causer:6->Result:7-MIN(prob)', 0.16424375989187195),\n",
       " ('CREL_Causer:3->Result:50-MAX(prob)', 0.1637842503960433),\n",
       " ('CREL_Causer:6->Result:7-pred-count=2', 0.15250000000000008),\n",
       " ('CREL_Causer:3->Result:5-MAX(prob)', 0.15150903025375853),\n",
       " ('CREL_Causer:3->Result:5-MIN(prob)', 0.15119851282836072),\n",
       " ('CREL_4:5', 0.15000000000000008),\n",
       " ('CREL_3:4', 0.15000000000000008),\n",
       " ('CREL_Causer:4->Result:50-MAX(prob)', 0.14734705609456622),\n",
       " ('CREL_Causer:3->Result:50-MIN(prob)', 0.145262200668395),\n",
       " ('CREL_Causer:3->Result:5-pred-count=4', 0.14500000000000007),\n",
       " ('CREL_Pair-Causer:1->Result:3|Causer:2->Result:3', -0.14250000000000007),\n",
       " ('CREL_Pair-Causer:11->Result:13|Causer:14->Result:50', 0.14000000000000007),\n",
       " ('CREL_Causer:4->Result:5-pred-count=2', 0.14000000000000007),\n",
       " ('CREL_Causer:4->Result:14-MIN(prob)', 0.13818258217770268),\n",
       " ('CREL_Causer:4->Result:14-pred-count=2', 0.13750000000000007),\n",
       " ('CREL_4:14', 0.13750000000000007),\n",
       " ('CREL_Pair-Causer:14->Result:50|Causer:7->Result:50', 0.13500000000000006),\n",
       " ('CREL_Causer:4->Result:14-MAX(prob)', 0.1317842631993773),\n",
       " ('CREL_Pair-Causer:1->Result:50|Causer:11->Result:50', 0.13000000000000006),\n",
       " ('CREL_Causer:11->Result:12-MAX(prob)', 0.12932267631956496),\n",
       " ('Prob-min-prob', 0.12791703280934616),\n",
       " ('CREL_3:5', 0.12750000000000006),\n",
       " ('CREL_Causer:7->Result:50-pred-count=4', 0.12750000000000006),\n",
       " ('CREL_Pair-Causer:14->Result:50|Causer:3->Result:4', -0.12750000000000006),\n",
       " ('CREL_Causer:11->Result:12-MIN(prob)', 0.1266874942319651),\n",
       " ('CREL_Causer:2->Result:3-MAX(prob)', 0.12588188886635718),\n",
       " ('CREL_Causer:3->Result:50-pred-count=4', 0.1255087345607437),\n",
       " ('CREL_Causer:13->Result:14-pred-count=2', 0.12500000000000006),\n",
       " ('CREL_4:50', 0.12442724251958726),\n",
       " ('CREL_Causer:1->Result:2-MAX(prob)', 0.1237561619559935),\n",
       " ('CREL_Causer:4->Result:5-MAX(prob)', 0.12284906791496576)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(best_mdl.weights.items(), key = lambda tpl: -abs(tpl[1]))[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- ~~num-crels - add back in the logic to threshold these? But only if needed to improve results here (seemed to help essay parser)~~\n",
    "- ~~Re-run with more realistic initial hyper params~~\n",
    "- ~~Add in logic to store results to mongo~~\n",
    "- ~~Switch back to using an initial_weight of 1~~\n",
    "- We need to add hyper parameter tuning\n",
    "- Do we want to just remove the BEAM search from this? It makes the explanation a lot more complex. But then again, it's the only way we can really add more crels that the model wouldn't otherwise parse\n",
    "- Do we use the BEAM search with some de-duping? Although we already de-dupe to some extent anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
