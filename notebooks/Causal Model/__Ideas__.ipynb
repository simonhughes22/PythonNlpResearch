{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tagging Model Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN - run across whole esssay (each training data row is a whole essay, assuming we can fit that into RAM ok).\n",
    "- Train a re-ranker or similar to run over initial model's predictions and re-score\n",
    "- Train a model that runs per sentence and not per word (using word level predictions and sentence level features)\n",
    "- Train a chunking model to run over the initial labelled words - see here http://www.cs.columbia.edu/~mcollins/cs4705-spring2018/slides/loglinear-historybasedparsing.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Model Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run parser in one pass across whole essay. Repeat running backwards. Combine predictions.\n",
    "  - Store predicted probabilities for each Crel, and use when deciding final parse\n",
    "  - Use sentence number (sents from start and end), previous sentence's predicted tags and relations, all predicted relations, etc.\n",
    "- Train a binary classifier to predict the probability of each possible crel (iterating over all predicted codes occuring in the current and between adjacent sentences).\n",
    "  - Use these probabilities to generate the top 50 or so causal models for each essay, and run thru a re-ranker\n",
    "- Experiment using xg boost as a re-ranking algorithm re-framing the problem as a LTR problem.\n",
    "- Feed Fwd. NNet Transition Based Parsers:\n",
    "  - Collins' notes - http://www.cs.columbia.edu/~mcollins/cs4705-spring2018/slides/ff3-slides.pdf\n",
    "  - Google Model (SOTA) - https://arxiv.org/pdf/1603.06042.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
