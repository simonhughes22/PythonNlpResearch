{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from structured_perceptron import StructuredPerceptron\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model, train_instance, get_essays_for_data, evaluate_ranker\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from results_procesor import ResultsProcessor\n",
    "from filter_features import filter_feats\n",
    "\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from evaluation import add_cr_labels\n",
    "\n",
    "from random import shuffle\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.CORAL_BLEACHING\n",
    "# CAUSAL_MODEL_TYPE = CausalModelType.SKIN_CANCER\n",
    "root = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/Re-Ranker Final Scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Global settings\n",
    "if CAUSAL_MODEL_TYPE == CausalModelType.CORAL_BLEACHING:\n",
    "    root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "    training_folder = root_folder + \"Training\" + \"/\"\n",
    "    test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "    crels_folder = root + \"/crels/CB\"\n",
    "    coref_root = root_folder + \"CoReference/\"\n",
    "    coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "    # first and second were with initial_weight set to 1.0\n",
    "    # thrid is with set to 0.001\n",
    "\n",
    "    config = get_config(training_folder)\n",
    "    \n",
    "    train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(train_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "    test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(test_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "else: # SC\n",
    "\n",
    "    root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "    training_folder = root_folder + \"Training\" + \"/\"\n",
    "    test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "    crels_folder = root + \"/crels/SC\"\n",
    "    coref_root = root_folder + \"CoReference/\"\n",
    "    coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "    MONGO_COLLECTION = \"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_TD\"\n",
    "    MONGO_TEST_COLLECTION = \"TEST_SC_STR_PCPTRN_RE-RANKER_TD\"\n",
    "\n",
    "    config = get_config(training_folder)\n",
    "    \n",
    "    train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(train_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "    test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(test_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "print(len(cr_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.568946796959826"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_lens = []\n",
    "for name, crels in name2crels.items():\n",
    "#     print(len(crels))\n",
    "    if crels:\n",
    "        c_lens.append(len(crels))\n",
    "np.mean(c_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/Re-Ranker Final Scripts/crels/CB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crels_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rerank(top_n):\n",
    "    rr_fname = \"xs_rerank_\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_rerank = dill.load(f)\n",
    "\n",
    "    rr_fname = \"xs_rerank_test\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_test_rerank = dill.load(f)\n",
    "    return xs_rerank, xs_test_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_crels_counts():    \n",
    "    lens = []\n",
    "    # Dict[str,Set[str]]\n",
    "    for ename, crels in name2crels.items():\n",
    "        lens.append(len(crels))\n",
    "    return lens\n",
    "\n",
    "def get_predicted_crels_counts(top_n):\n",
    "    # Td, Vd\n",
    "    a,b = load_rerank(top_n=top_n)\n",
    "    a.update(b)\n",
    "    \n",
    "    lens = []\n",
    "    # Dict[str,Dict[str,List[float]]]\n",
    "    for ename, dct in a.items():\n",
    "        lens.append(len(dct.keys()))\n",
    "    return lens\n",
    "\n",
    "topn2lens = {}\n",
    "for topn in [1,2,3,5,7,10]:\n",
    "    topn2lens[topn] = get_predicted_crels_counts(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c c c }\n",
      "  \\toprule\n",
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean }  \\\\\n",
      "\\midrule\n",
      "Human Labels & 15 & 2.914 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>15</td>\n",
       "      <td>2.914007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Beam Size  Max.      Mean\n",
       "0         -    15  2.914007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DP = 4 # decimal points\n",
    "cols = [\"Beam Size\", \"Max.\", \"Mean\",         \n",
    "        #\"25%\",\n",
    "#         \"50%\", \"75%\", \n",
    "#         \"90%\", \n",
    "#         \"95%\", \n",
    "#         \"99%\"\n",
    "       ]\n",
    "\n",
    "def list2stats(l, n):\n",
    "    d = {\n",
    "        \"Beam Size\": n,\n",
    "        \"Mean\": np.mean(l),\n",
    "        \"Max.\": np.max(l),\n",
    "        \"Min.\": np.min(l),\n",
    "        \"25%\": np.percentile(l,25),\n",
    "        \"50%\": np.percentile(l,50),\n",
    "        \"75%\": np.percentile(l,75),\n",
    "        \"90%\": np.percentile(l,90),\n",
    "        \"95%\": np.percentile(l,95),\n",
    "        \"98%\": np.percentile(l,98),\n",
    "        \"99%\": np.percentile(l,99),\n",
    "    }\n",
    "    return d\n",
    "        \n",
    "def df2latex_table(df, columns=None, dp=3):\n",
    "    # print header\n",
    "    if columns is None:\n",
    "        columns = list(df.columns)\n",
    "    s_col_def = \"\\\\begin{tabular}{\" + (\"c \" * len(columns)) + \"}\\n\"\n",
    "    s_col_def += \"  \\\\toprule\\n\"\n",
    "    s = s_col_def\n",
    "    for col in columns:\n",
    "        s += \"\\\\textbf{{ {col} }} & \".format(col=col.replace(\"%\", \"\\\\%\"))\n",
    "    print(s[:-2] + \" \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    del s\n",
    "    \n",
    "    # print rows\n",
    "    for i,row in df.iterrows():\n",
    "        s = \"\"\n",
    "        for col in columns:\n",
    "            oval = row[col]\n",
    "            if type(oval) == str or oval is None:\n",
    "                val = \"Human Labels\"\n",
    "            else:\n",
    "                v = round(oval,dp)\n",
    "                ival = int(oval)\n",
    "                if v == ival:\n",
    "                    val = str(int(v))\n",
    "                else:\n",
    "                    fmt = \"{val:.\" + str(dp) + \"f}\"\n",
    "                    val = fmt.format(val=oval)\n",
    "            s += val + \" & \"\n",
    "        print(s[:-2].strip() + \" \\\\\\\\\")\n",
    "    print(\"\\\\bottomrule\")\n",
    "    print(\"\\\\end{tabular}}\")\n",
    "        \n",
    "l = get_actual_crels_counts()\n",
    "df = pd.DataFrame([list2stats(l, \"-\")])[cols]\n",
    "\n",
    "df2latex_table(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Crels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c c c }\n",
      "  \\toprule\n",
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean }  \\\\\n",
      "\\midrule\n",
      "Human Labels & 15 & 2.9140 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>15</td>\n",
       "      <td>2.914007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Beam Size  Max.      Mean\n",
       "0         -    15  2.914007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = get_actual_crels_counts()\n",
    "df = pd.DataFrame([list2stats(l, \"-\")])[cols]\n",
    "\n",
    "df2latex_table(df, dp=DP)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Crels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c c c }\n",
      "  \\toprule\n",
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean }  \\\\\n",
      "\\midrule\n",
      "1 & 13 & 2.958 \\\\\n",
      "2 & 13 & 2.966 \\\\\n",
      "3 & 15 & 3.643 \\\\\n",
      "5 & 22 & 5.353 \\\\\n",
      "7 & 22 & 5.358 \\\\\n",
      "10 & 22 & 5.358 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2.966312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3.642730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5.352837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beam Size  Max.      Mean\n",
       "0          1    13  2.958333\n",
       "1          2    13  2.966312\n",
       "2          3    15  3.642730\n",
       "3          5    22  5.352837\n",
       "4          7    22  5.358156\n",
       "5         10    22  5.358156"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = []\n",
    "for n, l in topn2lens.items():    \n",
    "    dicts.append(list2stats(l, n))\n",
    "df_stats = pd.DataFrame(dicts)[cols]\n",
    "\n",
    "df2latex_table(df_stats)\n",
    "\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2latex_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences by Top N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 3 4\n",
      "503 5 6\n",
      "551 2 3\n",
      "585 12 13\n",
      "806 5 6\n",
      "996 7 8\n",
      "..........\n"
     ]
    }
   ],
   "source": [
    "# Are the counts different?\n",
    "# CB: 5 and 10, yes, marginally. 7 and 10 - Nope\n",
    "# SC: 1-3 and 5 diff, 5, 7 and 10 are the same\n",
    "\n",
    "# for i, (a,b) in enumerate(zip(topn2lens[3],topn2lens[5])):\n",
    "#     if a != b:\n",
    "#         print(i,a,b)\n",
    "\n",
    "for i, (a,b) in enumerate(zip(topn2lens[5],topn2lens[7])):\n",
    "    if a != b:\n",
    "        print(i,a,b)\n",
    "print(\".\" * 10)\n",
    "for i, (a,b) in enumerate(zip(topn2lens[7],topn2lens[10])):\n",
    "    if a != b:\n",
    "        print(i,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "client = pymongo.MongoClient(serverSelectionTimeoutMS=100, host=\"127.0.0.1\")\n",
    "db = client.metrics_causal_model_reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def query_params_for(db, collection):\n",
    "    project = {\n",
    "            \"params\": \"$parameters\",\n",
    "            \"micro_f1\": \"$MICRO_F1\",\n",
    "            \"asof\": \"$asof\",\n",
    "            \"_id\": 1\n",
    "        }\n",
    "    feats_pipeline = [{ \"$project\": project }]\n",
    "    return [row for row in db[collection].aggregate(feats_pipeline)]    \n",
    "\n",
    "def get_df(collection):\n",
    "    rows = query_params_for(db=client.metrics_causal_model_reranker, collection=collection)   \n",
    "    if len(rows) == 0:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "    results = []\n",
    "    for r in rows:\n",
    "        d = dict(r[\"params\"])\n",
    "        d.update(r[\"micro_f1\"])\n",
    "        d[\"asof\"] = str(r[\"asof\"])\n",
    "        results.append(d)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"extractors\"] = df[\"extractors\"].apply(lambda l: \",\".join(l))\n",
    "    df = df.sort_values(by=\"f1_score\",ascending=False)\n",
    "    cols = [\"f1_score\", \"precision\", \"recall\", \"asof\",\"best_top_n\"]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CoralBleaching'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAUSAL_MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.741353</td>\n",
       "      <td>0.782873</td>\n",
       "      <td>0.704015</td>\n",
       "      <td>2019-06-24 20:43:02.777000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740970</td>\n",
       "      <td>0.787033</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2019-06-24 19:41:12.771000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.740081</td>\n",
       "      <td>0.787804</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>2019-06-24 20:40:56.262000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.740054</td>\n",
       "      <td>0.785890</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>2019-06-24 19:42:20.087000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.739954</td>\n",
       "      <td>0.786125</td>\n",
       "      <td>0.698905</td>\n",
       "      <td>2019-06-24 19:43:32.740000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  precision    recall                        asof  best_top_n\n",
       "29  0.741353   0.782873  0.704015  2019-06-24 20:43:02.777000           1\n",
       "4   0.740970   0.787033  0.700000  2019-06-24 19:41:12.771000           2\n",
       "27  0.740081   0.787804  0.697810  2019-06-24 20:40:56.262000           1\n",
       "5   0.740054   0.785890  0.699270  2019-06-24 19:42:20.087000           2\n",
       "6   0.739954   0.786125  0.698905  2019-06-24 19:43:32.740000           2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CAUSAL_MODEL_TYPE == CausalModelType.CORAL_BLEACHING:\n",
    "    collection = \"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD\"\n",
    "elif CAUSAL_MODEL_TYPE == CausalModelType.SKIN_CANCER:\n",
    "    collection = \"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\"\n",
    "else:\n",
    "    raise Exception()\n",
    "    \n",
    "df = get_df(collection).copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Beam Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.741353</td>\n",
       "      <td>0.704015</td>\n",
       "      <td>0.782873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740970</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.787033</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.739610</td>\n",
       "      <td>0.698175</td>\n",
       "      <td>0.786272</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.739231</td>\n",
       "      <td>0.701460</td>\n",
       "      <td>0.781301</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.739139</td>\n",
       "      <td>0.698540</td>\n",
       "      <td>0.784748</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.738284</td>\n",
       "      <td>0.698540</td>\n",
       "      <td>0.782822</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score    recall  precision  Beam Size\n",
       "29  0.741353  0.704015   0.782873          1\n",
       "4   0.740970  0.700000   0.787033          2\n",
       "11  0.739610  0.698175   0.786272          3\n",
       "18  0.739231  0.701460   0.781301          5\n",
       "37  0.739139  0.698540   0.784748          7\n",
       "46  0.738284  0.698540   0.782822         10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rows = []\n",
    "for n in sorted(df.best_top_n.unique()):\n",
    "    sub = df[df.best_top_n == n].head(1).copy(deep=True)\n",
    "    top_rows.append(sub)\n",
    "\n",
    "df_by_bs = pd.concat(top_rows)[[\"best_top_n\",\"f1_score\", \"recall\", \"precision\"]]\n",
    "df_by_bs[\"Beam Size\"] = df_by_bs[\"best_top_n\"]\n",
    "del df_by_bs[\"best_top_n\"]\n",
    "df_by_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c c c c c c }\n",
      "  \\toprule\n",
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean } & \\textbf{ f1_score } & \\textbf{ recall } & \\textbf{ precision }  \\\\\n",
      "\\midrule\n",
      "1 & 13 & 2.9583 & 0.7414 & 0.7040 & 0.7829 \\\\\n",
      "2 & 13 & 2.9663 & 0.7410 & 0.7000 & 0.7870 \\\\\n",
      "3 & 15 & 3.6427 & 0.7396 & 0.6982 & 0.7863 \\\\\n",
      "5 & 22 & 5.3528 & 0.7392 & 0.7015 & 0.7813 \\\\\n",
      "7 & 22 & 5.3582 & 0.7391 & 0.6985 & 0.7847 \\\\\n",
      "10 & 22 & 5.3582 & 0.7383 & 0.6985 & 0.7828 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.958333</td>\n",
       "      <td>0.741353</td>\n",
       "      <td>0.704015</td>\n",
       "      <td>0.782873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2.966312</td>\n",
       "      <td>0.740970</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.787033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3.642730</td>\n",
       "      <td>0.739610</td>\n",
       "      <td>0.698175</td>\n",
       "      <td>0.786272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5.352837</td>\n",
       "      <td>0.739231</td>\n",
       "      <td>0.701460</td>\n",
       "      <td>0.781301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "      <td>0.739139</td>\n",
       "      <td>0.698540</td>\n",
       "      <td>0.784748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "      <td>0.738284</td>\n",
       "      <td>0.698540</td>\n",
       "      <td>0.782822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beam Size  Max.      Mean  f1_score    recall  precision\n",
       "0          1    13  2.958333  0.741353  0.704015   0.782873\n",
       "1          2    13  2.966312  0.740970  0.700000   0.787033\n",
       "2          3    15  3.642730  0.739610  0.698175   0.786272\n",
       "3          5    22  5.352837  0.739231  0.701460   0.781301\n",
       "4          7    22  5.358156  0.739139  0.698540   0.784748\n",
       "5         10    22  5.358156  0.738284  0.698540   0.782822"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(df_stats, df_by_bs, on = \"Beam Size\")\n",
    "df2latex_table(merged, dp=4)\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EBA1415_SDLC_6_CB_ES-04749.ann', ['12', '13', '6', '7', '1', '3', '50']),\n",
       " ('EBA1415_BLHT_5_CB_ES-05205.ann', ['1', '2', '3', '4', '5', '50']),\n",
       " ('EBA1415_LZBA_4_CB_ES-05530.ann', ['1', '2', '3', '4', '5', '5b']),\n",
       " ('EBA1415_SDMK_6_CB_ES-04773.ann', ['11', '13', '4', '5b', '7', '50']),\n",
       " ('EBA1415_SEKL_2_CB-04829.ann', ['1', '3', '4', '5', '7', '50'])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from build_chains import build_chains\n",
    "\n",
    "ename2chain = {}\n",
    "for ename, crels in name2crels.items():\n",
    "    if len(crels) >= 2:\n",
    "        tree = defaultdict(set)\n",
    "        for crel in crels:\n",
    "            l,r = crel.replace(\"Causer:\",\"\").replace(\"Result:\",\"\").split(\"->\")\n",
    "            tree[l].add(r)\n",
    "        chains = build_chains(tree)\n",
    "        if chains:\n",
    "            longest = sorted(chains, key = lambda ch: -len(ch))[0]\n",
    "            ename2chain[ename] = longest\n",
    "\n",
    "sorted(ename2chain.items(), key = lambda tpl: -len(tpl[1]))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chains = dict(((k,v) for k,v in ename2chain.items() if len(v) >= 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_BLHT_5_CB_ES-05205.ann           \t 10 \t ['1', '2', '3', '4', '5', '50']\n",
      "EBA1415_LZBA_4_CB_ES-05530.ann           \t 15 \t ['1', '2', '3', '4', '5', '5b']\n",
      "EBA1415_SDMK_6_CB_ES-04773.ann           \t 12 \t ['11', '13', '4', '5b', '7', '50']\n",
      "EBA1415_SEKL_2_CB-04829.ann              \t 6 \t ['1', '3', '4', '5', '7', '50']\n",
      "EBA1415_SERS_1314_CB_ES-05098.ann        \t 12 \t ['1', '3', '4', '14', '11', '13']\n",
      "EBA1415_TFHC_4_CB_ES-05828.ann           \t 10 \t ['1', '3', '4', '6', '7', '50']\n",
      "EBA1415_TRKM_2_CB_ES-6048.ann            \t 8 \t ['1', '3', '4', '5', '7', '50']\n",
      "EBA1415post_TWNB_3_CB_ES-04984.ann       \t 10 \t ['1', '2', '3', '4', '5', '5b']\n",
      "EBA1415_SDLC_6_CB_ES-04749.ann           \t 9 \t ['12', '13', '6', '7', '1', '3', '50']\n"
     ]
    }
   ],
   "source": [
    "for ename in top_chains.keys():\n",
    "    print(ename.ljust(40), \"\\t\", len(name2crels[ename]), \"\\t\", top_chains[ename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coral bleaching can occur when there is a strong enviromental change for coral .\n",
      "as water temperature increases , carbon dioxide decreases .\n",
      "['Causer:3->Result:4']\n",
      "coral is very sensitive to the amount of salt in the ocean water .\n",
      "since the algae provides coral with color , if the algae dies due to enviromental changes , the coral will lose its color .\n",
      "['Causer:7->Result:50']\n",
      "the algae could die form the constant temperature changes due to the many shifting trade winds .\n",
      "['Causer:1->Result:3', 'Causer:3->Result:7']\n",
      "the trade winds cause temperature to rise .\n",
      "['Causer:1->Result:3']\n",
      "that lowers the carbon dioxide that the algae needs to survive .\n",
      "['Causer:3->Result:4']\n",
      "without the carbon dioxide , algae cant feed itself using the INFREQUENT of photosynthesis .\n",
      "['Causer:4->Result:5']\n",
      "that causes the algae to die therefore , resulting in coral bleaching .\n",
      "['Causer:5->Result:7', 'Causer:7->Result:50']\n"
     ]
    }
   ],
   "source": [
    "e = [e for e in pred_tagged_essays_train if e.name ==\"EBA1415_SEKL_2_CB-04829.ann\" ][0]\n",
    "for sent in e.sentences:\n",
    "    wds,tags = list(zip(*sent))\n",
    "    print(\" \".join(wds))\n",
    "    cr = set()\n",
    "    for t in tags:\n",
    "        crels = [c for c in t if \"->\" in c and \"Anaphor\" not in c]\n",
    "        cr.update(crels)\n",
    "    if cr:\n",
    "        print(sorted(cr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as   '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"as \".ljust(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coral bleaching can occur when there is a strong enviromental change for coral . \n",
      "\n",
      "as water temperature increases , carbon dioxide decreases . \n",
      "C3->4 C3->4       C3->4       C3->4  C3->4   C3->4\n",
      "\n",
      "coral is very sensitive to the amount of salt in the ocean water . \n",
      "\n",
      "since the algae provides coral with color , if the algae  dies   due    to     enviromental changes , the    coral  will   lose   its    color  . \n",
      "C7->50 C7->50 C7->50 C7->50 C7->50       C7->50    C7->50 C7->50 C7->50 C7->50 C7->50 C7->50\n",
      "\n",
      "the algae could die   form  the   constant    temperature changes     due   to    the   many  shifting trade winds . \n",
      "C3->7 C3->7 C3->7 C3->7 C3->7 C1->3|C3->7 C1->3|C3->7 C1->3|C3->7 C1->3 C1->3 C1->3 C1->3 C1->3    C1->3 C1->3\n",
      "\n",
      "the   trade winds cause temperature to    rise  . \n",
      "C1->3 C1->3 C1->3 C1->3 C1->3       C1->3 C1->3\n",
      "\n",
      "that  lowers the   carbon dioxide that the algae needs to survive . \n",
      "C3->4 C3->4  C3->4 C3->4  C3->4\n",
      "\n",
      "without the   carbon dioxide , algae cant  feed  itself using the   INFREQUENT of    photosynthesis . \n",
      "C4->5   C4->5 C4->5  C4->5     C4->5 C4->5 C4->5 C4->5  C4->5 C4->5 C4->5      C4->5 C4->5\n",
      "\n",
      "that  causes the   algae        to           die          therefore , resulting in     coral  bleaching . \n",
      "C5->7 C5->7  C5->7 C5->7|C7->50 C5->7|C7->50 C5->7|C7->50 C7->50      C7->50    C7->50 C7->50 C7->50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = [e for e in pred_tagged_essays_train if e.name ==\"EBA1415_SEKL_2_CB-04829.ann\" ][0]\n",
    "\n",
    "for sent in e.sentences:\n",
    "    \n",
    "    pwds, pcrels = \"\",\"\"\n",
    "    for wd, tags in sent:\n",
    "        wd = wd.strip()\n",
    "        crels = [t for t in tags if \"->\" in t and \"Anaphor\" not in t]\n",
    "        s_crels = \"|\".join(sorted(crels)).replace(\"Causer:\",\"C\").replace(\"Result:\",\"\")\n",
    "        pad = max(len(s_crels), len(wd)) + 1\n",
    "        pwds   += wd.ljust(pad, \" \")\n",
    "        pcrels += s_crels.ljust(pad, \" \")\n",
    "        \n",
    "    print(pwds)\n",
    "    if pcrels.strip():\n",
    "        print(pcrels.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coral                50    \n",
      "bleaching            50    \n",
      "can                        \n",
      "occur                      \n",
      "when                       \n",
      "there                      \n",
      "is                         \n",
      "a                          \n",
      "strong                     \n",
      "enviromental               \n",
      "change                     \n",
      "for                        \n",
      "coral                      \n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "as                         \n",
      "water                3     3->4\n",
      "temperature          3     3->4\n",
      "increases            3     3->4\n",
      ",                          \n",
      "carbon               4     3->4\n",
      "dioxide              4     3->4\n",
      "decreases            4     3->4\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "coral                      \n",
      "is                         \n",
      "very                       \n",
      "sensitive            3     \n",
      "to                   3     \n",
      "the                  3     \n",
      "amount               3     \n",
      "of                   3     \n",
      "salt                 3     \n",
      "in                   3     \n",
      "the                  3     \n",
      "ocean                3     \n",
      "water                3     \n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "since                      \n",
      "the                        \n",
      "algae                      \n",
      "provides                   \n",
      "coral                      \n",
      "with                       \n",
      "color                      \n",
      ",                          \n",
      "if                         \n",
      "the                        \n",
      "algae                7     7->50\n",
      "dies                 7     7->50\n",
      "due                        7->50\n",
      "to                         7->50\n",
      "enviromental               7->50\n",
      "changes                    7->50\n",
      ",                          \n",
      "the                        7->50\n",
      "coral                50    7->50\n",
      "will                 50    7->50\n",
      "lose                 50    7->50\n",
      "its                  50    7->50\n",
      "color                50    7->50\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "the                        \n",
      "algae                7     3->7\n",
      "could                7     3->7\n",
      "die                  7     3->7\n",
      "form                       3->7\n",
      "the                        3->7\n",
      "constant             3     1->3|3->7\n",
      "temperature          3     1->3|3->7\n",
      "changes              3     1->3|3->7\n",
      "due                        1->3\n",
      "to                         1->3\n",
      "the                        1->3\n",
      "many                 1     1->3\n",
      "shifting             1     1->3\n",
      "trade                1     1->3\n",
      "winds                1     1->3\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "the                  1     1->3\n",
      "trade                1     1->3\n",
      "winds                1     1->3\n",
      "cause                      1->3\n",
      "temperature          3     1->3\n",
      "to                   3     1->3\n",
      "rise                 3     1->3\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "that                       3->4\n",
      "lowers               4     3->4\n",
      "the                  4     3->4\n",
      "carbon               4     3->4\n",
      "dioxide              4     3->4\n",
      "that                       \n",
      "the                        \n",
      "algae                      \n",
      "needs                      \n",
      "to                         \n",
      "survive                    \n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "without              4     4->5\n",
      "the                  4     4->5\n",
      "carbon               4     4->5\n",
      "dioxide              4     4->5\n",
      ",                          \n",
      "algae                      4->5\n",
      "cant                 5     4->5\n",
      "feed                 5     4->5\n",
      "itself               5     4->5\n",
      "using                5     4->5\n",
      "the                  5     4->5\n",
      "INFREQUENT           5     4->5\n",
      "of                   5     4->5\n",
      "photosynthesis       5     4->5\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n",
      "that                       5->7\n",
      "causes                     5->7\n",
      "the                        5->7\n",
      "algae                7     5->7|7->50\n",
      "to                   7     5->7|7->50\n",
      "die                  7     5->7|7->50\n",
      "therefore                  7->50\n",
      ",                          \n",
      "resulting                  7->50\n",
      "in                         7->50\n",
      "coral                50    7->50\n",
      "bleaching            50    7->50\n",
      ".                          \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e = [e for e in pred_tagged_essays_train if e.name ==\"EBA1415_SEKL_2_CB-04829.ann\" ][0]\n",
    "\n",
    "for sent in e.sentences:\n",
    "    \n",
    "    pwds, pcrels = \"\",\"\"\n",
    "    for wd, tags in sent:\n",
    "        wd = wd.strip()\n",
    "        crels = [t for t in tags if \"->\" in t and \"Anaphor\" not in t]\n",
    "        s_ccodes = \"|\".join(sorted([t for t in tags if t[0].isdigit() and \"->\" not in t]))\n",
    "        s_crels = \"|\".join(sorted(crels)).replace(\"Causer:\",\"\").replace(\"Result:\",\"\")\n",
    "        print(wd.ljust(20), s_ccodes.ljust(5), s_crels)\n",
    "        \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
