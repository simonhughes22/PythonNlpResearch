{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cm_folder = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/\"\n",
    "src_path = os.path.join(cm_folder, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from structured_perceptron import StructuredPerceptron\n",
    "from Settings import Settings\n",
    "\n",
    "from window_based_tagger_config import get_config\n",
    "from crel_helper import get_cr_tags\n",
    "from crel_processing import essay_to_crels_cv\n",
    "from evaluation import evaluate_model_essay_level, get_micro_metrics, metrics_to_df\n",
    "from feature_normalization import min_max_normalize_feats\n",
    "from function_helpers import get_function_names\n",
    "from results_procesor import ResultsProcessor\n",
    "from train_parser import essay_to_crels, create_extractor_functions\n",
    "from cost_functions import micro_f1_cost_plusepsilon\n",
    "from train_reranker import train_model, train_instance, get_essays_for_data, evaluate_ranker\n",
    "from searn_parser_breadth_first import SearnModelBreadthFirst\n",
    "from causal_model_features import CausalModelType\n",
    "from feature_extraction import get_features_from_probabilities\n",
    "from results_procesor import ResultsProcessor\n",
    "from filter_features import filter_feats\n",
    "\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from evaluation import add_cr_labels\n",
    "\n",
    "from random import shuffle\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "# Global settings\n",
    "settings = Settings()\n",
    "CAUSAL_MODEL_TYPE = CausalModelType.CORAL_BLEACHING\n",
    "# CAUSAL_MODEL_TYPE = CausalModelType.SKIN_CANCER\n",
    "root = \"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/Re-Ranker Final Scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 226\n"
     ]
    }
   ],
   "source": [
    "# Global settings\n",
    "if CAUSAL_MODEL_TYPE == CausalModelType.CORAL_BLEACHING:\n",
    "    root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "    training_folder = root_folder + \"Training\" + \"/\"\n",
    "    test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "    crels_folder = root + \"/crels/CB\"\n",
    "    coref_root = root_folder + \"CoReference/\"\n",
    "    coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "    # first and second were with initial_weight set to 1.0\n",
    "    # thrid is with set to 0.001\n",
    "\n",
    "    config = get_config(training_folder)\n",
    "    results_processor = ResultsProcessor(dbname=\"metrics_causal_model_reranker\")\n",
    "\n",
    "    train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(train_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "    test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(test_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "else: # SC\n",
    "\n",
    "    root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "    training_folder = root_folder + \"Training\" + \"/\"\n",
    "    test_folder = root_folder + \"Test\" + \"/\"\n",
    "\n",
    "    crels_folder = root + \"/crels/SC\"\n",
    "    coref_root = root_folder + \"CoReference/\"\n",
    "    coref_output_folder = coref_root + \"CRel/\"\n",
    "\n",
    "    MONGO_COLLECTION = \"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_TD\"\n",
    "    MONGO_TEST_COLLECTION = \"TEST_SC_STR_PCPTRN_RE-RANKER_TD\"\n",
    "\n",
    "    config = get_config(training_folder)\n",
    "    results_processor = ResultsProcessor(dbname=\"metrics_causal_model_reranker\")\n",
    "\n",
    "    train_fname = coref_output_folder + \"training_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(train_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "    test_fname = coref_output_folder + \"test_crel_anatagged_essays_most_recent_code.dill\"\n",
    "    with open(test_fname, \"rb\") as f:\n",
    "        pred_tagged_essays_test = dill.load(f)\n",
    "\n",
    "print(len(pred_tagged_essays_train), len(pred_tagged_essays_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "cr_tags = get_cr_tags(train_tagged_essays=pred_tagged_essays_train, tag_essays_test=pred_tagged_essays_test)\n",
    "\n",
    "set_cr_tags = set(cr_tags)\n",
    "print(len(cr_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = pred_tagged_essays_train + pred_tagged_essays_test\n",
    "name2essay = {}\n",
    "for essay in all_essays:\n",
    "    name2essay[essay.name] = essay\n",
    "\n",
    "name2crels = essay_to_crels(all_essays, set_cr_tags)\n",
    "assert len(name2crels) == len(all_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.568946796959826"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_lens = []\n",
    "for name, crels in name2crels.items():\n",
    "#     print(len(crels))\n",
    "    if crels:\n",
    "        c_lens.append(len(crels))\n",
    "np.mean(c_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Causal Model/Re-Ranker Final Scripts/crels/CB'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crels_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_rerank(top_n):\n",
    "    rr_fname = \"xs_rerank_\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_rerank = dill.load(f)\n",
    "\n",
    "    rr_fname = \"xs_rerank_test\" + str(top_n) + \".dill\"\n",
    "    with open(os.path.join(crels_folder, rr_fname), \"rb\") as f:\n",
    "        xs_test_rerank = dill.load(f)\n",
    "    return xs_rerank, xs_test_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_actual_crels_counts():    \n",
    "    lens = []\n",
    "    # Dict[str,Set[str]]\n",
    "    for ename, crels in name2crels.items():\n",
    "        lens.append(len(crels))\n",
    "    return lens\n",
    "\n",
    "def get_predicted_crels_counts(top_n):\n",
    "    # Td, Vd\n",
    "    a,b = load_rerank(top_n=top_n)\n",
    "    a.update(b)\n",
    "    \n",
    "    lens = []\n",
    "    # Dict[str,Dict[str,List[float]]]\n",
    "    for ename, dct in a.items():\n",
    "        lens.append(len(dct.keys()))\n",
    "    return lens\n",
    "\n",
    "topn2lens = {}\n",
    "for topn in [1,2,3,5,7,10]:\n",
    "    topn2lens[topn] = get_predicted_crels_counts(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean } & \\textbf{ 25\\% } & \\textbf{ 50\\% } & \\textbf{ 75\\% } & \\textbf{ 95\\% } & \\textbf{ 99\\% }  \\\\\n",
      "\\midrule\n",
      "Human Labels & 15.000 & 2.914 & 1 & 2 & 4 & 8 & 10.000 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DP = 3 # decimal points\n",
    "cols = [\"Beam Size\", \"Max.\", \"Mean\", \"25%\", \"50%\", \"75%\", \n",
    "        #\"90%\", \n",
    "        \"95%\", \"99%\"]\n",
    "\n",
    "def list2stats(l, n):\n",
    "    d = {\n",
    "        \"Beam Size\": n,\n",
    "        \"Mean\": np.mean(l),\n",
    "        \"Max.\": np.max(l),\n",
    "        \"Min.\": np.min(l),\n",
    "        \"25%\": np.percentile(l,25),\n",
    "        \"50%\": np.percentile(l,50),\n",
    "        \"75%\": np.percentile(l,75),\n",
    "        \"90%\": np.percentile(l,90),\n",
    "        \"95%\": np.percentile(l,95),\n",
    "        \"98%\": np.percentile(l,98),\n",
    "        \"99%\": np.percentile(l,99),\n",
    "    }\n",
    "    return d\n",
    "\n",
    "def df2latex_table(df):\n",
    "    # print header\n",
    "    s = \"\"\n",
    "    for col in cols:\n",
    "        s += \"\\\\textbf{{ {col} }} & \".format(col=col.replace(\"%\", \"\\\\%\"))\n",
    "    print(s[:-2] + \" \\\\\\\\\")\n",
    "    print(\"\\\\midrule\")\n",
    "    del s\n",
    "    \n",
    "    # print rows\n",
    "    for i,row in df.iterrows():\n",
    "        s = \"\"\n",
    "        for col in cols:\n",
    "            oval = row[col]\n",
    "            if type(oval) == str or oval is None:\n",
    "                val = \"Human Labels\"\n",
    "            else:\n",
    "                v = str(round(oval,DP))                \n",
    "                if v.endswith(\".0\") and \"99\" not in col:\n",
    "                    val = v[:-2]\n",
    "                else:     \n",
    "                    fmt = \"{val:.\" + str(DP) + \"f}\"\n",
    "                    val = fmt.format(val=oval)\n",
    "            s += val + \" & \"\n",
    "        print(s[:-2].strip() + \" \\\\\\\\\")\n",
    "    print()\n",
    "        \n",
    "l = get_actual_crels_counts()\n",
    "df = pd.DataFrame([list2stats(l, \"-\")])[cols]\n",
    "\n",
    "df2latex_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Crels (CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean } & \\textbf{ 25\\% } & \\textbf{ 50\\% } & \\textbf{ 75\\% } & \\textbf{ 95\\% } & \\textbf{ 99\\% }  \\\\\n",
      "\\midrule\n",
      "Human Labels & 15.000 & 2.914 & 1 & 2 & 4 & 8 & 10.000 \\\\\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>15</td>\n",
       "      <td>2.914007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Beam Size  Max.      Mean  25%  50%  75%  95%   99%\n",
       "0         -    15  2.914007  1.0  2.0  4.0  8.0  10.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = get_actual_crels_counts()\n",
    "df = pd.DataFrame([list2stats(l, \"-\")])[cols]\n",
    "\n",
    "df2latex_table(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Crels (CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{ Beam Size } & \\textbf{ Max. } & \\textbf{ Mean } & \\textbf{ 25\\% } & \\textbf{ 50\\% } & \\textbf{ 75\\% } & \\textbf{ 95\\% } & \\textbf{ 99\\% }  \\\\\n",
      "\\midrule\n",
      "1 & 13 & 2.958 & 1 & 2 & 4 & 8 & 10.000 \\\\\n",
      "2 & 13 & 2.966 & 1 & 2 & 4 & 8 & 10.000 \\\\\n",
      "3 & 15 & 3.643 & 1 & 3 & 5 & 10 & 12.730 \\\\\n",
      "5 & 22 & 5.353 & 2 & 4 & 8 & 14 & 17.000 \\\\\n",
      "7 & 22 & 5.358 & 2 & 4 & 8 & 14 & 17.000 \\\\\n",
      "10 & 22 & 5.358 & 2 & 4 & 8 & 14 & 17.000 \\\\\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beam Size</th>\n",
       "      <th>Max.</th>\n",
       "      <th>Mean</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2.966312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3.642730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5.352837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5.358156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Beam Size  Max.      Mean  25%  50%  75%   95%    99%\n",
       "0          1    13  2.958333  1.0  2.0  4.0   8.0  10.00\n",
       "1          2    13  2.966312  1.0  2.0  4.0   8.0  10.00\n",
       "2          3    15  3.642730  1.0  3.0  5.0  10.0  12.73\n",
       "3          5    22  5.352837  2.0  4.0  8.0  14.0  17.00\n",
       "4          7    22  5.358156  2.0  4.0  8.0  14.0  17.00\n",
       "5         10    22  5.358156  2.0  4.0  8.0  14.0  17.00"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = []\n",
    "for n, l in topn2lens.items():    \n",
    "    dicts.append(list2stats(l, n))\n",
    "df = pd.DataFrame(dicts)[cols]\n",
    "\n",
    "df2latex_table(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2latex_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences by Top N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 3 4\n",
      "503 5 6\n",
      "551 2 3\n",
      "585 12 13\n",
      "806 5 6\n",
      "996 7 8\n",
      "..........\n"
     ]
    }
   ],
   "source": [
    "# Are the counts different?\n",
    "# CB: 5 and 10, yes, marginally. 7 and 10 - Nope\n",
    "# SC: 1-3 and 5 diff, 5, 7 and 10 are the same\n",
    "\n",
    "# for i, (a,b) in enumerate(zip(topn2lens[3],topn2lens[5])):\n",
    "#     if a != b:\n",
    "#         print(i,a,b)\n",
    "\n",
    "for i, (a,b) in enumerate(zip(topn2lens[5],topn2lens[7])):\n",
    "    if a != b:\n",
    "        print(i,a,b)\n",
    "print(\".\" * 10)\n",
    "for i, (a,b) in enumerate(zip(topn2lens[7],topn2lens[10])):\n",
    "    if a != b:\n",
    "        print(i,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
