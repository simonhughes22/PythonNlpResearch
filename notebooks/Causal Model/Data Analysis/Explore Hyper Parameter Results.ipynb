{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best-Performing Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/anaconda3/envs/phd_py36/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appnope==0.1.0\n",
      "attrs==19.1.0\n",
      "backcall==0.1.0\n",
      "bleach==3.1.0\n",
      "boto==2.47.0\n",
      "boto3==1.9.18\n",
      "botocore==1.12.18\n",
      "bz2file==0.98\n",
      "certifi==2016.2.28\n",
      "costcla==0.5\n",
      "cycler==0.10.0\n",
      "cymem==1.31.2\n",
      "cytoolz==0.8.2\n",
      "decorator==4.4.0\n",
      "defusedxml==0.5.0\n",
      "dill==0.2.8.2\n",
      "docutils==0.14\n",
      "entrypoints==0.3\n",
      "ftfy==4.4.3\n",
      "gensim==0.13.4\n",
      "h5py==2.7.0\n",
      "html5lib==0.999\n",
      "ipykernel==5.1.1\n",
      "ipython==7.6.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.4.2\n",
      "jedi==0.14.0\n",
      "Jinja2==2.10.1\n",
      "jmespath==0.9.3\n",
      "joblib==0.9.4\n",
      "json5==0.8.4\n",
      "jsonschema==3.0.1\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.2.4\n",
      "jupyter-console==6.0.0\n",
      "jupyter-core==4.4.0\n",
      "jupyterlab==1.0.1\n",
      "jupyterlab-server==1.0.0\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==2.0.0\n",
      "mistune==0.8.4\n",
      "murmurhash==0.26.4\n",
      "nbconvert==5.5.0\n",
      "nbformat==4.4.0\n",
      "nltk==3.2.2\n",
      "nose==1.3.7\n",
      "notebook==5.7.8\n",
      "numpy==1.15.2\n",
      "pandas==0.19.2\n",
      "pandocfilters==1.4.2\n",
      "parso==0.5.0\n",
      "pathlib==1.0.1\n",
      "pexpect==4.7.0\n",
      "pickleshare==0.7.5\n",
      "plac==0.9.6\n",
      "preshed==1.0.1\n",
      "prometheus-client==0.7.1\n",
      "prompt-toolkit==2.0.9\n",
      "ptyprocess==0.6.0\n",
      "pyea==0.2\n",
      "Pygments==2.4.2\n",
      "pymongo==3.4.0\n",
      "pyparsing==2.2.2\n",
      "pyrsistent==0.15.2\n",
      "python-dateutil==2.8.0\n",
      "pytz==2018.5\n",
      "pyzmq==18.0.2\n",
      "qtconsole==4.4.1\n",
      "regex==2017.4.5\n",
      "requests==2.14.2\n",
      "s3transfer==0.1.13\n",
      "scikit-learn==0.18.1\n",
      "scikit-optimize==0.3\n",
      "scipy==1.1.0\n",
      "seaborn==0.7.1\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "six==1.12.0\n",
      "smart-open==1.7.1\n",
      "spacy==1.8.2\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.2\n",
      "testpath==0.4.2\n",
      "thinc==6.5.2\n",
      "toolz==0.9.0\n",
      "tornado==6.0.3\n",
      "tqdm==4.26.0\n",
      "traitlets==4.3.2\n",
      "ujson==1.35\n",
      "urllib3==1.23\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "widgetsnbextension==3.4.2\n",
      "wrapt==1.10.11\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(serverSelectionTimeoutMS=100, host=\"127.0.0.1\")\n",
    "db = client.metrics_causal_model_reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def fmt_dt(date_time_str):\n",
    "    dt= datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    return dt.strftime(\"%m-%d-%Y %H:%M\")\n",
    "\n",
    "def query_params_for(db, collection):\n",
    "#     print(\"DB:\" + db.name)\n",
    "    project = {\n",
    "            \"params\": \"$parameters\",\n",
    "            \"micro_f1\": \"$MICRO_F1\",\n",
    "            \"asof\": \"$asof\",\n",
    "            \"_id\": 1\n",
    "        }\n",
    "    feats_pipeline = [{ \"$project\": project }]\n",
    "    return [row for row in db[collection].aggregate(feats_pipeline)]    \n",
    "\n",
    "def query_collection(collection):\n",
    "    rows = query_params_for(db=client.metrics_causal_model_reranker, collection=collection)\n",
    " \n",
    "    if \"SENT_\" in collection or len(rows) == 0:\n",
    "        db = client.metrics_causal_model_parser        \n",
    "        rows = query_params_for(db=client.metrics_causal_model_parser, collection=collection)\n",
    "        \n",
    "    if len(rows) == 0:\n",
    "        return pd.DataFrame([])\n",
    "\n",
    "    results = []\n",
    "    for r in rows:\n",
    "        d = dict(r[\"params\"])\n",
    "        d.update(r[\"micro_f1\"])\n",
    "        d[\"asof\"] = str(r[\"asof\"])\n",
    "        results.append(d)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"extractors\"] = df[\"extractors\"].apply(lambda l: \",\".join(l))\n",
    "#     df[\"asof\"] = df[\"asof\"].apply(fmt_dt)\n",
    "    df = df.sort_values(by=\"f1_score\",ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(collection, training_only=False, cols=None):\n",
    "    if not training_only:\n",
    "        # Safety check for default params\n",
    "        assert \"_VD\" in collection\n",
    "    \n",
    "    if cols is None:\n",
    "        cols = [\"best_top_n\", \"C\", \"best_max_parses\", \n",
    "            #\"best_max_upd\", \n",
    "            \"max_update_items\", \n",
    "            # \"best_min_prob\", \"extractors\", \n",
    "            \"initial_weight\", \"loss_type\",\\\n",
    "            #\"min_feat_freq\",\n",
    "            \"pa_type\", \"early_stopping_iters\",]    \n",
    "\n",
    "        if \"SENT\" in collection:\n",
    "            cols = []\n",
    "        elif \"PCPTRN\" in collection:\n",
    "            cols = [\"best_top_n\", \"learning_rate\", \"best_max_parses\", \n",
    "            #\"best_max_upd\", \n",
    "            \"max_update_items\", \n",
    "            # \"best_min_prob\", \"extractors\", \n",
    "            \"initial_weight\",\"early_stopping_iters\",]\n",
    "            #\"min_feat_freq\"]\n",
    "    \n",
    "    # add common cols\n",
    "    cols = [\"f1_score\", \"precision\", \"recall\", \"asof\"] + cols + [\"extractors\", \"num_feats_MEAN\"]\n",
    "#     print(\"cols:\" + str(cols))\n",
    "    df = query_collection(collection)\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.813806</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.78037</td>\n",
       "      <td>2019-07-10 22:41:56.085000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>num_crels,Inv-,Prob-</td>\n",
       "      <td>50.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision   recall                        asof  best_top_n  \\\n",
       "4  0.813806   0.850235  0.78037  2019-07-10 22:41:56.085000           5   \n",
       "\n",
       "   learning_rate  best_max_parses  max_update_items  initial_weight  \\\n",
       "4           0.05              600                 1            0.01   \n",
       "\n",
       "   early_stopping_iters            extractors  num_feats_MEAN  \n",
       "4                     2  num_crels,Inv-,Prob-            50.8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\"\n",
    "get_df(col).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_COLLECTION = \"SC_RE-RANKER_HYPER_PARAM_VD\"\n",
    "# MONGO_COLLECTION = \"SC_COST_INSENS_RE-RANKER_HYPER_PARAM_VD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('beam size range:', [1, 2, 3, 5, 7, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"beam size range:\",sorted(get_df(\"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD\").best_top_n.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('learning rate range:', [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"learning rate range:\",sorted(get_df(\"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD\").learning_rate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.74358</td>\n",
       "      <td>0.758542</td>\n",
       "      <td>0.729197</td>\n",
       "      <td>2019-05-03 14:18:47.905000</td>\n",
       "      <td>single_words,between_word_features,label_set,t...</td>\n",
       "      <td>27479.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  \\\n",
       "0   0.74358   0.758542  0.729197  2019-05-03 14:18:47.905000   \n",
       "\n",
       "                                          extractors  num_feats_MEAN  \n",
       "0  single_words,between_word_features,label_set,t...         27479.6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SENT_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pa = query_collection(\"CB_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD\")[[\"f1_score\", \"early_stopping_iters\", \"extractors\"]]\n",
    "# df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.741353</td>\n",
       "      <td>0.782873</td>\n",
       "      <td>0.704015</td>\n",
       "      <td>2019-06-24 20:43:02.777000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>Prob-,Above-</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  precision    recall                        asof  best_top_n  \\\n",
       "29  0.741353   0.782873  0.704015  2019-06-24 20:43:02.777000           1   \n",
       "\n",
       "    learning_rate  best_max_parses  max_update_items  initial_weight  \\\n",
       "29            0.1              300                 1            0.01   \n",
       "\n",
       "    early_stopping_iters    extractors  num_feats_MEAN  \n",
       "29                     2  Prob-,Above-            33.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_collection(\"CB_PA_RE-RANKER_HYPER_PARAM_VD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.743145</td>\n",
       "      <td>0.760015</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>2019-06-30 15:00:24.686000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None - cost insens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CREL_</td>\n",
       "      <td>1371.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "8  0.743145   0.760015  0.727007  2019-06-30 15:00:24.686000           2   \n",
       "\n",
       "        C  best_max_parses  max_update_items  initial_weight  \\\n",
       "8  0.0005              300                 1            0.01   \n",
       "\n",
       "            loss_type  pa_type  early_stopping_iters extractors  \\\n",
       "8  None - cost insens        1                     1      CREL_   \n",
       "\n",
       "   num_feats_MEAN  \n",
       "8          1371.8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"CB_PA_RE-RANKER_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.746014</td>\n",
       "      <td>0.777294</td>\n",
       "      <td>0.717153</td>\n",
       "      <td>2019-06-18 01:55:37.752000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ml</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>CREL_,Prob-,CChainStats-</td>\n",
       "      <td>1410.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  precision    recall                        asof  best_top_n  \\\n",
       "37  0.746014   0.777294  0.717153  2019-06-18 01:55:37.752000           2   \n",
       "\n",
       "         C  best_max_parses  max_update_items  initial_weight loss_type  \\\n",
       "37  0.0025              300                 1            0.01        ml   \n",
       "\n",
       "    pa_type  early_stopping_iters                extractors  num_feats_MEAN  \n",
       "37        1                     3  CREL_,Prob-,CChainStats-          1410.6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"CB_RE-RANKER_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.737027</td>\n",
       "      <td>0.710169</td>\n",
       "      <td>0.765996</td>\n",
       "      <td>2019-05-03 14:19:17.204000</td>\n",
       "      <td>single_words,between_word_features,label_set,t...</td>\n",
       "      <td>30367.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  \\\n",
       "0  0.737027   0.710169  0.765996  2019-05-03 14:19:17.204000   \n",
       "\n",
       "                                          extractors  num_feats_MEAN  \n",
       "0  single_words,between_word_features,label_set,t...         30367.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.751838</td>\n",
       "      <td>0.747715</td>\n",
       "      <td>2019-07-05 14:21:05.573000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>Prob-,Above-</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.749771   0.751838  0.747715  2019-07-05 14:21:05.573000           1   \n",
       "\n",
       "   learning_rate  best_max_parses  max_update_items  initial_weight  \\\n",
       "0            0.1              300                 1            0.01   \n",
       "\n",
       "   early_stopping_iters    extractors  num_feats_MEAN  \n",
       "0                     2  Prob-,Above-            33.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"TEST_CB_STR_PCPTRN_RE-RANKER_VD\")\n",
    "df_pa.head(10) # Improved precision over recall. Top n was restricted to 1, so only capable of upping pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.767824</td>\n",
       "      <td>2019-07-05 14:40:40.998000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None - cost insens</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CREL_</td>\n",
       "      <td>1504.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.740741   0.715503  0.767824  2019-07-05 14:40:40.998000           2   \n",
       "\n",
       "        C  best_max_parses  max_update_items  initial_weight  \\\n",
       "0  0.0005              300                 1            0.01   \n",
       "\n",
       "            loss_type  pa_type  early_stopping_iters extractors  \\\n",
       "0  None - cost insens        1                     1      CREL_   \n",
       "\n",
       "   num_feats_MEAN  \n",
       "0          1504.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"TEST_CB_PA_RE-RANKER_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741208</td>\n",
       "      <td>0.731317</td>\n",
       "      <td>0.751371</td>\n",
       "      <td>2019-07-05 14:51:25.146000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ml</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>CREL_,Prob-,CChainStats-</td>\n",
       "      <td>1543.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.741208   0.731317  0.751371  2019-07-05 14:51:25.146000           2   \n",
       "\n",
       "        C  best_max_parses  max_update_items  initial_weight loss_type  \\\n",
       "0  0.0025              300                 1            0.01        ml   \n",
       "\n",
       "   pa_type  early_stopping_iters                extractors  num_feats_MEAN  \n",
       "0        1                     3  CREL_,Prob-,CChainStats-          1543.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To improve upon this, you can use early stopping\n",
    "df_pa = get_df(\"TEST_CB_RE-RANKER_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('beam size range:', [1, 2, 3, 5, 7, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"beam size range:\",sorted(get_df(\"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\").best_top_n.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('learning rate range:', [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"learning rate range:\",sorted(get_df(\"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\").learning_rate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.80962</td>\n",
       "      <td>0.860857</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>2019-05-03 14:27:42.611000</td>\n",
       "      <td>three_words,between_word_features,size_feature...</td>\n",
       "      <td>26260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  \\\n",
       "0   0.80962   0.860857  0.764139  2019-05-03 14:27:42.611000   \n",
       "\n",
       "                                          extractors  num_feats_MEAN  \n",
       "0  three_words,between_word_features,size_feature...         26260.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SENT_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>extractors</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.811784</td>\n",
       "      <td>Above-,Inv-,num_crels,CChainStats-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score                          extractors  early_stopping_iters\n",
       "30  0.811784  Above-,Inv-,num_crels,CChainStats-                     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"f1_score\", \"extractors\", \"early_stopping_iters\"]\n",
    "query_collection(\"SC_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD\").head(1)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.813806</td>\n",
       "      <td>0.850235</td>\n",
       "      <td>0.78037</td>\n",
       "      <td>2019-07-10 22:41:56.085000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>num_crels,Inv-,Prob-</td>\n",
       "      <td>50.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision   recall                        asof  best_top_n  \\\n",
       "4  0.813806   0.850235  0.78037  2019-07-10 22:41:56.085000           5   \n",
       "\n",
       "   learning_rate  best_max_parses  max_update_items  initial_weight  \\\n",
       "4           0.05              600                 1            0.01   \n",
       "\n",
       "   early_stopping_iters            extractors  num_feats_MEAN  \n",
       "4                     2  num_crels,Inv-,Prob-            50.8  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.806789</td>\n",
       "      <td>0.868206</td>\n",
       "      <td>0.753487</td>\n",
       "      <td>2019-06-30 15:13:25.720000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None - cost insens</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>num_crels,Inv-</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "4  0.806789   0.868206  0.753487  2019-06-30 15:13:25.720000           1   \n",
       "\n",
       "      C  best_max_parses  max_update_items  initial_weight  \\\n",
       "4  0.01              300                 1            0.01   \n",
       "\n",
       "            loss_type  pa_type  early_stopping_iters      extractors  \\\n",
       "4  None - cost insens        1                     6  num_crels,Inv-   \n",
       "\n",
       "   num_feats_MEAN  \n",
       "4            37.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SC_PA_RE-RANKER_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.808089</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>0.765153</td>\n",
       "      <td>2019-06-18 10:15:07.357000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CREL_,CChain-,Prob-</td>\n",
       "      <td>1386.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  precision    recall                        asof  best_top_n  \\\n",
       "41  0.808089   0.856129  0.765153  2019-06-18 10:15:07.357000           3   \n",
       "\n",
       "       C  best_max_parses  max_update_items  initial_weight loss_type  \\\n",
       "41  0.01              300                 1            0.01        ml   \n",
       "\n",
       "    pa_type  early_stopping_iters           extractors  num_feats_MEAN  \n",
       "41        1                     1  CREL_,CChain-,Prob-          1386.4  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SC_RE-RANKER_HYPER_PARAM_VD\")\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.856471</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2019-05-03 14:28:38.825000</td>\n",
       "      <td>three_words,between_word_features,size_feature...</td>\n",
       "      <td>28839.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision  recall                        asof  \\\n",
       "0  0.827273   0.856471     0.8  2019-05-03 14:28:38.825000   \n",
       "\n",
       "                                          extractors  num_feats_MEAN  \n",
       "0  three_words,between_word_features,size_feature...         28839.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829323</td>\n",
       "      <td>0.844926</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>2019-07-11 07:12:46.645000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>num_crels,Inv-,Prob-</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.829323   0.844926  0.814286  2019-07-11 07:12:46.645000           5   \n",
       "\n",
       "   learning_rate  best_max_parses  max_update_items  initial_weight  \\\n",
       "0           0.05              600                 1            0.01   \n",
       "\n",
       "   early_stopping_iters            extractors  num_feats_MEAN  \n",
       "0                     2  num_crels,Inv-,Prob-            51.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"TEST_SC_STR_PCPTRN_RE-RANKER_VD_3\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>0.793407</td>\n",
       "      <td>2019-07-05 14:45:29.204000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None - cost insens</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>num_crels,Inv-</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.828457   0.866747  0.793407  2019-07-05 14:45:29.204000           1   \n",
       "\n",
       "      C  best_max_parses  max_update_items  initial_weight  \\\n",
       "0  0.01              300                 1            0.01   \n",
       "\n",
       "            loss_type  pa_type  early_stopping_iters      extractors  \\\n",
       "0  None - cost insens        1                     6  num_crels,Inv-   \n",
       "\n",
       "   num_feats_MEAN  \n",
       "0            37.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"TEST_SC_PA_RE-RANKER_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>asof</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>C</th>\n",
       "      <th>best_max_parses</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>initial_weight</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>pa_type</th>\n",
       "      <th>early_stopping_iters</th>\n",
       "      <th>extractors</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826111</td>\n",
       "      <td>0.846597</td>\n",
       "      <td>0.806593</td>\n",
       "      <td>2019-07-05 14:54:53.566000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CREL_,CChain-,Prob-</td>\n",
       "      <td>1488.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall                        asof  best_top_n  \\\n",
       "0  0.826111   0.846597  0.806593  2019-07-05 14:54:53.566000           3   \n",
       "\n",
       "      C  best_max_parses  max_update_items  initial_weight loss_type  pa_type  \\\n",
       "0  0.01              300                 1            0.01        ml        1   \n",
       "\n",
       "   early_stopping_iters           extractors  num_feats_MEAN  \n",
       "0                     1  CREL_,CChain-,Prob-          1488.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = get_df(\"TEST_SC_RE-RANKER_VD\")\n",
    "df_pa.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>extractors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.740483</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>Prob-,Above-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  learning_rate  max_update_items    extractors\n",
       "15  0.740483            0.3                 2  Prob-,Above-"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = query_collection(\"CB_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD\")[[\"f1_score\",\"learning_rate\",\"max_update_items\", \"extractors\"]]\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_update_items</th>\n",
       "      <th>extractors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.740483</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>Prob-,Above-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  learning_rate  max_update_items    extractors\n",
       "15  0.740483            0.3                 2  Prob-,Above-"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = query_collection(\"CB_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD\")[[\"f1_score\",\"learning_rate\",\"max_update_items\", \"extractors\"]]\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_update_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.811784</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  learning_rate  max_update_items\n",
       "30  0.811784            0.3                 2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa = query_collection(\"SC_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD\")[[\"f1_score\",\"learning_rate\",\"max_update_items\"]]\n",
    "df_pa.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked by Dataset (for Results Section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.786</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.783</td>\n",
       "      <td>Valid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.752</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1_score  recall  precision Dataset  best_top_n  learning_rate\n",
       "29     0.743   0.704      0.786   Train           1            0.1\n",
       "29     0.741   0.704      0.783   Valid           1            0.1\n",
       "0      0.750   0.748      0.752    Test           1            0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "df_train = get_df(\"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_TD\", training_only=True).head(1)\n",
    "df_train[\"Dataset\"] = \"Train\"\n",
    "df_vd = get_df(\"CB_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD\").head(1)\n",
    "df_vd[\"Dataset\"] = \"Valid\"\n",
    "df_test = get_df(\"TEST_CB_STR_PCPTRN_RE-RANKER_VD\")\n",
    "df_test[\"Dataset\"] = \"Test\"\n",
    "\n",
    "df_concat = pd.concat([df_train, df_vd, df_test])[[\"f1_score\",\"recall\", \"precision\", \"Dataset\", \"best_top_n\", \"learning_rate\"]]\n",
    "df_concat.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rounding\n",
    "# df_concat.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>best_top_n</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.849</td>\n",
       "      <td>Train</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.814</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.850</td>\n",
       "      <td>Valid</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.845</td>\n",
       "      <td>Test</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  recall  precision Dataset  best_top_n  learning_rate\n",
       "6     0.812   0.779      0.849   Train           5           0.50\n",
       "4     0.814   0.780      0.850   Valid           5           0.05\n",
       "0     0.829   0.814      0.845    Test           5           0.05"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_df(\"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_TD_3\", training_only=True).head(1)\n",
    "df_train[\"Dataset\"] = \"Train\"\n",
    "df_vd = get_df(\"SC_STR_PCPTRN_RE-RANKER_HYPER_PARAM_VD_3\").head(1)\n",
    "df_vd[\"Dataset\"] = \"Valid\"\n",
    "df_test = get_df(\"TEST_SC_STR_PCPTRN_RE-RANKER_VD_3\")\n",
    "df_test[\"Dataset\"] = \"Test\"\n",
    "\n",
    "df_concat = pd.concat([df_train, df_vd, df_test])[[\"f1_score\",\"recall\", \"precision\", \"Dataset\", \"best_top_n\", \"learning_rate\"]]\n",
    "df_concat.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Summary Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.710</td>\n",
       "      <td>Sent. Parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.750</td>\n",
       "      <td>Essay Parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.752</td>\n",
       "      <td>Re-Ranker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  recall  precision         Model\n",
       "0     0.737   0.766      0.710  Sent. Parser\n",
       "0     0.740   0.729      0.750  Essay Parser\n",
       "0     0.750   0.748      0.752     Re-Ranker"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frp = [\"f1_score\", \"recall\", \"precision\"]\n",
    "\n",
    "df_sentp = get_df(\"SENT_TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD\")[frp].copy(deep=True)\n",
    "df_sentp[\"Model\"] = \"Sent. Parser\"\n",
    "\n",
    "df_essayp = get_df(\"TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\", cols=[])[frp].copy(deep=True)\n",
    "df_essayp[\"Model\"] = \"Essay Parser\"\n",
    "\n",
    "df_reranker = get_df(\"TEST_CB_STR_PCPTRN_RE-RANKER_VD\", cols=[])[frp].copy(deep=True)\n",
    "df_reranker[\"Model\"] = \"Re-Ranker\"\n",
    "\n",
    "df_concat_sum = pd.concat([df_sentp, df_essayp, df_reranker])\n",
    "df_concat_sum.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.856</td>\n",
       "      <td>Sent. Parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.829</td>\n",
       "      <td>Essay Parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.845</td>\n",
       "      <td>Re-Ranker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  recall  precision         Model\n",
       "0     0.827   0.800      0.856  Sent. Parser\n",
       "0     0.821   0.813      0.829  Essay Parser\n",
       "0     0.829   0.814      0.845     Re-Ranker"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frp = [\"f1_score\", \"recall\", \"precision\"]\n",
    "\n",
    "df_sentp = get_df(\"SENT_TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\")[frp].copy(deep=True)\n",
    "df_sentp[\"Model\"] = \"Sent. Parser\"\n",
    "\n",
    "df_essayp = get_df(\"TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\", cols=[])[frp].copy(deep=True)\n",
    "df_essayp[\"Model\"] = \"Essay Parser\"\n",
    "\n",
    "df_reranker = get_df(\"TEST_SC_STR_PCPTRN_RE-RANKER_VD_3\", cols=[])[frp].copy(deep=True)\n",
    "df_reranker[\"Model\"] = \"Re-Ranker\"\n",
    "\n",
    "df_concat_sum = pd.concat([df_sentp, df_essayp, df_reranker])\n",
    "df_concat_sum.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
