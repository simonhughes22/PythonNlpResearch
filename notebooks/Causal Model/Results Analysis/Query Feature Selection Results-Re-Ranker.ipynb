{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pymongo\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGO = \"STR_PCPTRN_RE-RANKER\"\n",
    "cb_td, cb_vd=  \"CB_\" + ALGO + \" _FEATURE_SEL_TD\", \"CB_\" + ALGO + \"_FEATURE_SEL_VD\"\n",
    "# set to be the same for now\n",
    "sc_td, sc_vd = \"SC_\" + ALGO + \"_FEATURE_SEL_TD\", \"SC_\" + ALGO + \"_FEATURE_SEL_VD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by(df, bycols, agg_map):\n",
    "    \"\"\"\n",
    "    @param df:      DataFrame\n",
    "    @param bycols:  str or list\n",
    "                        Column(s) to group by\n",
    "    @param agg_map: dictionary or list of 2-tuples\n",
    "                        Mapping from column to aggregate function e.g. [(\"city\", \"count\"), (\"salary\", \"mean\"]\n",
    "    @return:        DataFrame\n",
    "                        Flattened dataframe, with multi-level index removed\n",
    "    \"\"\"\n",
    "    grps = []\n",
    "    if type(bycols) == str:\n",
    "        bycols = [bycols]\n",
    "\n",
    "    if type(agg_map) == dict:\n",
    "        agg_map = agg_map.items()\n",
    "\n",
    "    for k,v in agg_map:\n",
    "        grp = df[bycols + [k]].groupby(bycols, ).agg(v)\n",
    "        grp.reset_index(inplace=True)\n",
    "        grp[\"%s(%s)\" % (v,k)] = grp[k]\n",
    "        del grp[k]\n",
    "        grps.append(grp)\n",
    "\n",
    "    m = grps[0]\n",
    "    for grp in grps[1:]:\n",
    "        m = pd.merge(m, grp, on=bycols, how=\"inner\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_causal_model_reranker'), 'CB_STR_PCPTRN_RE-RANKER _FEATURE_SEL_TD'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_causal_model_reranker'), 'CB_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_causal_model_reranker'), 'SC_STR_PCPTRN_RE-RANKER_FEATURE_SEL_TD'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_causal_model_reranker'), 'SC_STR_PCPTRN_RE-RANKER_FEATURE_SEL_VD'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client.metrics_causal_model_reranker\n",
    "\n",
    "cb_td, cb_vd = db[cb_td], db[cb_vd]\n",
    "sc_td, sc_vd = db[sc_td], db[sc_vd]\n",
    "\n",
    "cb_td, cb_vd , sc_td, sc_vd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27 34 34\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from bson.son import SON # needed to ensure dictionary is ordered (python default is not)\n",
    "\n",
    "feats_pipeline = [{\n",
    "    \"$project\": { \n",
    "            \"weighted_f1_score\":\"$WEIGHTED_MEAN_CONCEPT_CODES.f1_score\",\n",
    "            \"micro_f1_score\":  \"$MICRO_F1.f1_score\",\n",
    "            \"micro_recall\":    \"$MICRO_F1.recall\",\n",
    "            \"micro_precision\": \"$MICRO_F1.precision\",\n",
    "            #\"stemmed\":        \"$parameters.stemmed\",\n",
    "            \"num_feats\":      \"$parameters.num_feats_MEAN\",\n",
    "            \"feats\":          \"$parameters.extractors\",\n",
    "            \"count\": {        \"$size\" : \"$parameters.extractors\" },\n",
    "            \"asof\" :          \"$asof\",\n",
    "            \"_id\":1\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"$match\":{\n",
    "        \"micro_f1_score\": { \"$exists\" : True },\n",
    "        # how many feats\n",
    "        #\"count\": {          \"$eq\" :1 },\n",
    "        # window width\n",
    "        #\"window_size\": {    \"$eq\":13 }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"$sort\":{\n",
    "        #\"weighted_f1_score\":-1,\n",
    "        \"micro_f1_score\": -1\n",
    "        #\"asof\": -1\n",
    "        #\"count\": -1\n",
    "    }\n",
    "},\n",
    "]\n",
    "\n",
    "cb_td_rows = [row for row in cb_td.aggregate(feats_pipeline)]\n",
    "cb_vd_rows = [row for row in cb_vd.aggregate(feats_pipeline)]\n",
    "sc_td_rows = [row for row in sc_td.aggregate(feats_pipeline)]\n",
    "sc_vd_rows = [row for row in sc_vd.aggregate(feats_pipeline)]\n",
    "\n",
    "print(len(cb_td_rows), len(cb_vd_rows), len(sc_td_rows), len(sc_vd_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'micro_f1_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'micro_f1_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7091f18bc821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcb_td_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_sorted_by_f1score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_td_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcb_vd_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_sorted_by_f1score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb_vd_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msc_td_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_df_sorted_by_f1score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_td_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7091f18bc821>\u001b[0m in \u001b[0;36mget_df_sorted_by_f1score\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_df_sorted_by_f1score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"micro_f1_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hs_feats\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feats\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   3228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3230\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/phd_py36/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'micro_f1_score'"
     ]
    }
   ],
   "source": [
    "def hash_feats(fts):\n",
    "    return \"|\".join(sorted(fts))\n",
    "\n",
    "def get_df_sorted_by_f1score(rows):\n",
    "    df = pd.DataFrame(rows).sort_values(\"micro_f1_score\", ascending=False)\n",
    "    df[\"hs_feats\"] = df[\"feats\"].apply(hash_feats)\n",
    "    return df\n",
    "\n",
    "cb_td_df = get_df_sorted_by_f1score(cb_td_rows)\n",
    "cb_vd_df = get_df_sorted_by_f1score(cb_vd_rows)\n",
    "sc_td_df = get_df_sorted_by_f1score(sc_td_rows)\n",
    "sc_vd_df = get_df_sorted_by_f1score(sc_vd_rows)\n",
    "\n",
    "cb_vd_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(cb_vd_df[\"asof\"].values),max(cb_vd_df[\"asof\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"feats,count,micro_f1_score,micro_recall,micro_precision\".split(\",\")\n",
    "sc_cols = \"feats,count,micro_f1_score,micro_recall,micro_precision,num_feats\".split(\",\")\n",
    "\n",
    "def feat_name(ft):\n",
    "    if type(ft) == list:\n",
    "        ft=\",\".join(ft)\n",
    "    offset = (11-1)/2\n",
    "    offset_lbl = \"offset:%i\" % offset\n",
    "    ft=ft.replace(offset_lbl, \"\").replace(\"fn_\", \"\").replace(\" \",\"\")\n",
    "    return ft\n",
    "\n",
    "def get_top_individual_feats(df, cols=cols):\n",
    "    df_top_individual_feats = df[(df[\"count\"] == 1)][cols]\n",
    "    df_top_individual_feats[\"rank\"] = np.arange(len(df_top_individual_feats)) + 1\n",
    "    df_top_individual_feats[\"feats\"] = df_top_individual_feats[\"feats\"].apply(feat_name)\n",
    "    return df_top_individual_feats\n",
    "\n",
    "#get_top_individual_feats(cb_vd_df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Each Feature In Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(a,b, on=\"rank\", suffixes=[\"_CB\",\"_SC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stemmed = True\n",
    "a, b = get_top_individual_feats(cb_vd_df), get_top_individual_feats(sc_vd_df, sc_cols)\n",
    "merged = pd.merge(a,b, on=\"rank\", suffixes=[\"_CB\",\"_SC\"])\\\n",
    "[\"rank,feats_CB,micro_f1_score_CB,micro_recall_CB,micro_precision_CB,feats_SC,micro_f1_score_SC,micro_recall_SC,micro_precision_SC,num_feats\".split(\",\")]\n",
    "\n",
    "merged[\"num_feats_SC\"] = merged[\"num_feats\"]\n",
    "del merged[\"num_feats\"]\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2=merged[[\"rank\",\"feats_CB\", \"micro_f1_score_CB\", #\"num_feats_CB\",\n",
    "                \"feats_SC\", \"micro_f1_score_SC\", \"num_feats_SC\"]].copy()\n",
    "for c in merged2.columns:\n",
    "    if \"micro\" in c:\n",
    "        merged2[c]=merged2[c].apply(lambda d: \"{0:.3f}\".format(d) if type(d) == float else d)\n",
    "    elif \"num\" in c:\n",
    "        merged2[c]=merged2[c].apply(lambda d: \"{0:,.1f}\".format(d) if type(d) == float else d)\n",
    "merged2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rows for LaTex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def format_lbl(lbl):\n",
    "    return lbl.replace(\"[\",\" \").replace(\"]\",\"\").replace(\"_\",\" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in merged.iterrows():\n",
    "    feats_CB = format_lbl(row[\"feats_CB\"])\n",
    "    micro_f1_score_CB = row[\"micro_f1_score_CB\"]\n",
    "    \n",
    "    feats_SC = format_lbl(row[\"feats_SC\"])\n",
    "    micro_f1_score_SC = row[\"micro_f1_score_SC\"]\n",
    "    \n",
    "    print(\"{rank} & {feat_cb} & {cb_f1:0.3f} & & {feat_sc} & {sc_f1:0.3f}\\\\\\\\\"\\\n",
    "          .format(rank=i+1,feat_cb=feats_CB, cb_f1=micro_f1_score_CB,\n",
    "                  feat_sc=feats_SC, sc_f1=micro_f1_score_SC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance By Feature Set Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_featureset_size(df):\n",
    "    return group_by(df, bycols=[\"count\"], agg_map=[(\"micro_f1_score\", \"max\"),\n",
    "                                              (\"micro_f1_score\", \"mean\"),\n",
    "                                              #(\"micro_f1_score\", \"median\"),\n",
    "                                              #(\"micro_f1_score\", \"count\"),\n",
    "                                             ]).sort_values(\"count\")\n",
    "\n",
    "pd.merge(get_by_featureset_size(cb_vd_df), get_by_featureset_size(sc_vd_df), on=\"count\", how=\"outer\", suffixes=[\"_cb\", \"_sc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get F1 Score By Num Features As the Optimal Feature Set is Constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_filter = \"count,new_feat,micro_f1_score,num_feats\".split(\",\")\n",
    "cols_filter = \"count,new_feat,micro_f1_score\".split(\",\")\n",
    "\n",
    "def get_f1_by_feat_count(df):\n",
    "#     df=df[df[\"stemmed\"] == True]\n",
    "    top_feats = df[df[\"count\"] == df[\"count\"].max()]\n",
    "    top_feats = top_feats.sort_values(\"micro_f1_score\", ascending=False).iloc[0][\"feats\"]\n",
    "    \n",
    "    rows = []\n",
    "    for i in range(0,len(top_feats)):\n",
    "        new_feat = top_feats[i]\n",
    "        upto = top_feats[:i+1]\n",
    "        hs = hash_feats(upto)\n",
    "        new_row = df[df[\"hs_feats\"] == hs].iloc[0]\n",
    "        new_row[\"new_feat\"] = feat_name(new_feat)\n",
    "        copy = {}\n",
    "        for k in new_row.keys():\n",
    "            copy[str(k).strip()] = new_row[k]\n",
    "        rows.append(copy)\n",
    "\n",
    "    df_f1_by_feat_count = pd.DataFrame(rows)\n",
    "    return df_f1_by_feat_count[cols_filter]\n",
    "\n",
    "df_f1_score_by_feat_size= pd.merge(get_f1_by_feat_count(cb_vd_df), get_f1_by_feat_count(sc_vd_df), on=\"count\", how=\"outer\", suffixes=(\"_CB\", \"_SC\"))\n",
    "##df_f1_score_by_feat_size\n",
    "# Note that the optimal feature set for SC is only of size 4\n",
    "\n",
    "#get_f1_by_feat_count(cb_vd_df)\n",
    "#get_f1_by_feat_count(sc_vd_df)\n",
    "\n",
    "df_f1_score_by_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round to 4 d.p. for printing\n",
    "df = df_f1_score_by_feat_size[\"count,new_feat_CB,micro_f1_score_CB,new_feat_SC,micro_f1_score_SC\".split(\",\")].copy()\n",
    "df[\"micro_f1_score_CB\"] = df[\"micro_f1_score_CB\"].apply(lambda d: \"{0:.4f}\".format(d))\n",
    "# df[\"num_feats_CB\"]      = df[\"num_feats_CB\"].apply(lambda d: \"{0:,.1f}\".format(d))\n",
    "df[\"micro_f1_score_SC\"] = df[\"micro_f1_score_SC\"].apply(lambda d: \"{0:.4f}\".format(d))  \n",
    "# df[\"num_feats_SC\"]      = df[\"num_feats_SC\"].apply(lambda d: \"{0:,.1f}\".format(d))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F1 Score Against # Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Max F1 Score for Each Size of Feature Set (Win = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_max_f1_by_feat_count(df):\n",
    "    max_feats = df[\"count\"].values.max()\n",
    "    rows = []\n",
    "    for cnt in range(1, max_feats+1):\n",
    "        \n",
    "        row = df[df[\"count\"] == cnt].sort_values(\"micro_f1_score\", ascending=False).iloc[0]        \n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb = get_max_f1_by_feat_count(cb_vd_df)[[\"count\", \"feats\", \"micro_f1_score\", \"micro_precision\", \"micro_recall\"]]\n",
    "df_sc = get_max_f1_by_feat_count(sc_vd_df)[[\"count\", \"feats\", \"micro_f1_score\", \"micro_precision\", \"micro_recall\"]]\n",
    "by_feat_size = pd.merge(df_cb, df_sc, on=\"count\", how=\"outer\", suffixes=[\"_CB\", \"_SC\"])\n",
    "by_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FONT_SIZE = 15\n",
    "\n",
    "df = by_feat_size\n",
    "\n",
    "STYLE = \"whitegrid\"\n",
    "sns.set_style(STYLE)\n",
    "sns.set_style(STYLE, {\"xtick.major.size\": 1})\n",
    "\n",
    "fig = plt.figure(figsize=(12,6.5))\n",
    "\n",
    "x = df[\"count\"].values\n",
    "y_cb = df[\"micro_f1_score_CB\"].values\n",
    "y_sc = df[\"micro_f1_score_SC\"].values\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x,y_cb, label=\"Coral Bleaching\")\n",
    "ax1.plot(x,y_sc, label=\"Skin Cancer\")\n",
    "\n",
    "legend = ax1.legend(loc='upper left', shadow=True, fontsize=FONT_SIZE)\n",
    "\n",
    "ax1.set_xlim([1, 4])\n",
    "ax1.set_ylim([0.695, 0.77])\n",
    "ax1.set_xlabel('Number of Feature Sets', fontsize=FONT_SIZE)\n",
    "ax1.set_ylabel('Micro F1 Score', fontsize=FONT_SIZE)\n",
    "\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 1.0), fontsize=10)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(\"/Users/simon.hughes/BitBucket/Dissertation/Dissertation/images/re-ranker_f1_score_by_num_feats.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rows for LaTex Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score As Individual Features are Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_f1_score_by_feat_size.iterrows():\n",
    "    #pprint(row)\n",
    "    \n",
    "    feats_CB = format_lbl(row[\"new_feat_CB\"])\n",
    "    micro_f1_score_CB = row[\"micro_f1_score_CB\"]\n",
    "    \n",
    "    feats_SC = format_lbl(str(row[\"new_feat_SC\"]))\n",
    "    if feats_SC == \"nan\":\n",
    "        feats_SC = \"-\"\n",
    "        \n",
    "    micro_f1_score_SC = row[\"micro_f1_score_SC\"]\n",
    "    if str(micro_f1_score_SC) != \"nan\":\n",
    "        micro_f1_score_SC = \"{0:0.4f}\".format(micro_f1_score_SC)\n",
    "    else:\n",
    "        micro_f1_score_SC = \"-\"\n",
    "    count = row[\"count\"]\n",
    "    print(\"{count} & {feat_cb} & {cb_f1:0.4f} & & {feat_sc} & {sc_f1}\\\\\\\\\"\\\n",
    "          .format(count=count,feat_cb=feats_CB, cb_f1=micro_f1_score_CB,\n",
    "                  feat_sc=feats_SC, sc_f1=micro_f1_score_SC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check - Do Any Datasets have Duplicate Feature Sets with Different F1 Scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SH: There were some issues with the CB_VD dataset initially for a couple of collections\n",
    "for df in [cb_td_df, cb_vd_df, sc_td_df, sc_vd_df]:\n",
    "    gb = group_by(df, bycols=[\"hs_feats\"], agg_map=[\n",
    "        (\"micro_f1_score\", \"count\"),\n",
    "        (\"micro_f1_score\", \"min\"),\n",
    "        (\"micro_f1_score\", \"max\"),\n",
    "    ])\n",
    "    gb = gb[gb[\"count(micro_f1_score)\"] > 1]\n",
    "    miss_match = gb[gb[\"min(micro_f1_score)\"] != gb[\"max(micro_f1_score)\"]]\n",
    "    \n",
    "    assert len(miss_match) == 0, \"Some errors occurred during data capture\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
