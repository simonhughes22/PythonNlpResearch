{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymongo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host=\"127.0.0.1\")\n",
    "db = client.metrics_causal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(df, bycols, agg_map):\n",
    "    \"\"\"\n",
    "\n",
    "    @param df:      DataFrame\n",
    "    @param bycols:  str or list\n",
    "                        Column(s) to group by\n",
    "    @param agg_map: dictionary or list of 2-tuples\n",
    "                        Mapping from column to aggregate function e.g. [(\"city\", \"count\"), (\"salary\", \"mean\"]\n",
    "    @return:        DataFrame\n",
    "                        Flattened dataframe, with multi-level index removed\n",
    "    \"\"\"\n",
    "    grps = []\n",
    "    if type(bycols) == str:\n",
    "        bycols = [bycols]\n",
    "\n",
    "    if type(agg_map) == dict:\n",
    "        agg_map = agg_map.items()\n",
    "\n",
    "    for k,v in agg_map:\n",
    "        grp = df[bycols + [k]].groupby(bycols, ).agg(v)\n",
    "        grp.reset_index(inplace=True)\n",
    "        grp[\"%s(%s)\" % (v,k)] = grp[k]\n",
    "        del grp[k]\n",
    "        grps.append(grp)\n",
    "\n",
    "    m = grps[0]\n",
    "    for grp in grps[1:]:\n",
    "        m = pd.merge(m, grp, on=bycols, how=\"inner\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.son import SON # needed to ensure dictionary is ordered (python default is not)\n",
    "import hashlib\n",
    "\n",
    "def hash_feats(fts):\n",
    "    vals = fts.values\n",
    "    joined = \"|\".join(map(lambda s: str(s),vals)).encode('utf-8') \n",
    "    return hashlib.sha224(joined).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Metrics import rpf1a_from_tp_fp_tn_fn\n",
    "from collections import defaultdict\n",
    "\n",
    "def tally_counts(r, filter):\n",
    "    tally = defaultdict(int)\n",
    "    for k,v in r.items():\n",
    "        if filter(k):\n",
    "            for prop in \"tp,tn,fp,fn\".split(\",\"):\n",
    "                tally[prop] += v[prop]\n",
    "    return tally\n",
    "\n",
    "def get_causal_relation_metrics(collection, params, include_concept_codes=True):\n",
    "    dicts = []\n",
    "    for r in db[collection].find({}):\n",
    "        d = {}\n",
    "        cr_counts = tally_counts(r, lambda c: \"->\" in c)\n",
    "        (rec, p, cr_f1, a) = rpf1a_from_tp_fp_tn_fn(cr_counts[\"tp\"],cr_counts[\"fp\"],cr_counts[\"tn\"],cr_counts[\"fn\"])\n",
    "        d[\"cr_micro_f1\"] = cr_f1\n",
    "        d[\"cr_micro_rec\"]  = rec\n",
    "        d[\"cr_micro_prec\"] = p\n",
    "        if include_concept_codes:\n",
    "            concept_counts = tally_counts(r, lambda c: c[0].isdigit())\n",
    "            (rec, p, concept_f1, a) = rpf1a_from_tp_fp_tn_fn(concept_counts[\"tp\"],concept_counts[\"fp\"],concept_counts[\"tn\"],concept_counts[\"fn\"])\n",
    "            d[\"concept_micro_f1\"] = concept_f1\n",
    "            d[\"concept_micro_rec\"]  = rec\n",
    "            d[\"concept_micro_prec\"] = p\n",
    "        parms = r[\"parameters\"]\n",
    "        for p in params:\n",
    "            d[p] = parms[p]\n",
    "        dicts.append(d)\n",
    "    df = pd.DataFrame(dicts)\n",
    "    fields = (\"cr_micro_f1,cr_micro_rec,cr_micro_prec,concept_micro_f1,concept_micro_rec,concept_micro_prec,\" + \",\".join(params)).split(\",\")\n",
    "    if not include_concept_codes:\n",
    "        fields = [f for f in fields if \"concept\" not in f]\n",
    "    return df[fields].sort_values(\"cr_micro_f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_data(df, places=3):\n",
    "    df_copy = df.copy()\n",
    "    fmt_str = \"{0:.\" + str(places) + \"f}\"\n",
    "    cols = set([v for v in df_copy.columns.values if \"micro_\" in v])\n",
    "    for c in cols:\n",
    "        df_copy[c] = df[c].apply(lambda d: fmt_str.format(d))  \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection on Shift Reduce Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE the non generic parameters, like window size\n",
    "def get_df_sorted_by_f1score_generic(collection, params=None, filter_cols=True):\n",
    "    if not params:\n",
    "        params = []\n",
    "    if type(params) == str:\n",
    "        params = params.split(\",\")\n",
    "    \n",
    "    project = {\n",
    "            \"weighted_f1_score\":\"$WEIGHTED_MEAN_CONCEPT_CODES.f1_score\",\n",
    "            \"micro_f1_score\":  \"$MICRO_F1.f1_score\",\n",
    "            \"micro_recall\":    \"$MICRO_F1.recall\",\n",
    "            \"micro_precision\": \"$MICRO_F1.precision\",\n",
    "    \n",
    "    # PARAMETERS            \n",
    "            \"feats\":          \"$parameters.extractors\",\n",
    "            \n",
    "            \"asof\" :          \"$asof\",\n",
    "            \"_id\":1\n",
    "    }\n",
    "    \n",
    "    # No count for HMM\n",
    "    if \"_hmm\" in collection.lower():\n",
    "        del project[\"count\"]\n",
    "    \n",
    "    for param in params:\n",
    "        project[param] = \"$parameters.\" + param\n",
    "\n",
    "    feats_pipeline = [{\n",
    "        \"$project\": project\n",
    "    },\n",
    "    {\n",
    "        \"$match\":{\n",
    "            \"micro_f1_score\": { \"$exists\" : True }        \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\":{\n",
    "            \"micro_f1_score\": -1\n",
    "        }\n",
    "    },\n",
    "    ]\n",
    "    \n",
    "    rows = [row for row in db[collection].aggregate(feats_pipeline)]\n",
    "    df = pd.DataFrame(rows).sort_values(\"micro_f1_score\", ascending=False)\n",
    "    if params:\n",
    "        df[\"hs_params\"] = df[params].apply(hash_feats, axis=1)\n",
    "        \n",
    "    if filter_cols:\n",
    "        cols = [\"micro_f1_score\", \"micro_recall\" ,\"micro_precision\" ] + params\n",
    "        return df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Result (Best VD Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...</td>\n",
       "      <td>0.748462</td>\n",
       "      <td>0.791057</td>\n",
       "      <td>0.710219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Algo  micro_f1_score  \\\n",
       "0  CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...        0.748462   \n",
       "\n",
       "   micro_precision  micro_recall  \n",
       "0         0.791057      0.710219  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"]\n",
    "\n",
    "rows = []\n",
    "for coll in col:\n",
    "    df = get_df_sorted_by_f1score_generic(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...</td>\n",
       "      <td>0.810981</td>\n",
       "      <td>0.841144</td>\n",
       "      <td>0.782906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Algo  micro_f1_score  \\\n",
       "0  CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...        0.810981   \n",
       "\n",
       "   micro_precision  micro_recall  \n",
       "0         0.841144      0.782906  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"]\n",
    "\n",
    "rows = []\n",
    "for coll in col:\n",
    "    df = get_df_sorted_by_f1score_generic(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Sorted by Hyper Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_parameter(s, param_name):\n",
    "    s = s.replace(\"(\",\" \").replace(\")\",\" \")\n",
    "    keys = s.split(\" \")\n",
    "    return [(key,val.replace(\",\",\"\").replace(\"'\",\"\")) for key,val in [k.split(\"=\") for k in keys if \"=\" in k] if key == param_name][0][-1]\n",
    "\n",
    "extract_c_val = lambda s: extract_parameter(s, \"C\")\n",
    "extract_penalty_val = lambda s: extract_parameter(s, \"penalty\")\n",
    "extract_dual_val = lambda s: extract_parameter(s, \"dual\")\n",
    "\n",
    "s = \"LogisticRegression(C=0.1, class_weight=None, dual=True, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\"\n",
    "extract_c_val(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyper_param_results(collection):\n",
    "    df_feat_sel = get_df_sorted_by_f1score_generic(collection, \"algorithm,beta,max_epochs,num_feats_MEAN\", filter_cols=True) \n",
    "    df_feat_sel[\"C\"] = df_feat_sel[\"algorithm\"].apply(extract_c_val)\n",
    "    df_feat_sel[\"penalty\"] = df_feat_sel[\"algorithm\"].apply(extract_penalty_val)\n",
    "    df_feat_sel[\"dual\"] = df_feat_sel[\"algorithm\"].apply(extract_dual_val)\n",
    "    del df_feat_sel[\"algorithm\"]\n",
    "    return df_feat_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>94761.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>82068.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>96791.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>98675.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>98614.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.748        0.710           0.791   0.5          10   \n",
       "1          0.748        0.716           0.783   0.3           3   \n",
       "2          0.748        0.710           0.790   0.5          20   \n",
       "3          0.748        0.712           0.788   0.1          15   \n",
       "4          0.748        0.712           0.788   0.3          20   \n",
       "\n",
       "   num_feats_MEAN    C penalty   dual  \n",
       "0         94761.2  0.1      l2   True  \n",
       "1         82068.4  0.1      l2  False  \n",
       "2         96791.0  0.1      l2   True  \n",
       "3         98675.6  0.1      l2  False  \n",
       "4         98614.4  0.1      l2   True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "micro_f1_score\tmicro_recall\tmicro_precision\tbeta\tmax_epochs\tnum_feats_MEAN\tC\tpenalty\tdual\n",
    "0\t0.748462\t0.710219\t0.791057\t0.5\t10\t94761.2\t0.1\tl2\tTrue\n",
    "\"\"\"\n",
    "col = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"\n",
    "top_row = get_hyper_param_results(col).iloc[0]\n",
    "round_data(get_hyper_param_results(col)).head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>78583.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "102          0.861        0.787           0.950   0.3           5   \n",
       "\n",
       "     num_feats_MEAN    C penalty  dual  \n",
       "102         78583.6  0.5      l2  True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_td = \"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_TD\"\n",
    "df = get_hyper_param_results(col_td)\n",
    "df = df[(df.beta == top_row.beta) & (df.max_epochs == top_row.max_epochs) & (df.C == top_row.C)]\n",
    "df = df[(df.penalty == top_row.penalty) & (df.dual == top_row.dual)]\n",
    "round_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5</td>\n",
       "      <td>64879.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5</td>\n",
       "      <td>69780.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>73494.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.30</td>\n",
       "      <td>15</td>\n",
       "      <td>70825.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15</td>\n",
       "      <td>72145.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.811        0.783           0.841  0.30           5   \n",
       "1          0.810        0.790           0.832  0.75           5   \n",
       "2          0.810        0.785           0.835  0.50          10   \n",
       "3          0.809        0.781           0.841  0.30          15   \n",
       "4          0.809        0.786           0.834  1.00          15   \n",
       "\n",
       "   num_feats_MEAN    C penalty   dual  \n",
       "0         64879.2  0.5      l2   True  \n",
       "1         69780.4  0.1      l2   True  \n",
       "2         73494.0  0.1      l2   True  \n",
       "3         70825.6  0.5      l2  False  \n",
       "4         72145.0  0.1      l2  False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "micro_f1_score\tmicro_recall\tmicro_precision\tbeta\tmax_epochs\tnum_feats_MEAN\tC\tpenalty\tdual\n",
    "0\t0.813308\t0.805985\t0.820764\t1.00\t3\t55036.8\t0.5\tl2\tFalse\n",
    "\"\"\"\n",
    "col = \"CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"\n",
    "top_row = get_hyper_param_results(col).iloc[0]\n",
    "round_data(get_hyper_param_results(col)).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>64879.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "71          0.898        0.851           0.951   0.3           5   \n",
       "\n",
       "    num_feats_MEAN    C penalty  dual  \n",
       "71         64879.2  0.5      l2  True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_TD\"\n",
    "df = get_hyper_param_results(col)\n",
    "df = df[(df.beta == top_row.beta) & (df.max_epochs == top_row.max_epochs) & (df.C == top_row.C)]\n",
    "df = df[(df.penalty == top_row.penalty) & (df.dual == top_row.dual)]\n",
    "round_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>103694.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.740        0.729           0.750   0.5          10   \n",
       "\n",
       "   num_feats_MEAN    C penalty  dual  \n",
       "0        103694.0  0.1      l2  True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"TEST_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"\n",
    "round_data(get_hyper_param_results(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>69382.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.821        0.813           0.829   0.3           5   \n",
       "\n",
       "   num_feats_MEAN    C penalty  dual  \n",
       "0         69382.0  0.5      l2  True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"TEST_CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM2_VD\"\n",
    "round_data(get_hyper_param_results(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTENCE LEVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>30553.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.786        0.762           0.811   0.5           2   \n",
       "\n",
       "   num_feats_MEAN    C penalty  dual  \n",
       "0         30553.0  0.5      l2  True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"SENT_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_TD\"\n",
    "round_data(get_hyper_param_results(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>30553.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  micro_f1_score micro_recall micro_precision  beta  max_epochs  \\\n",
       "0          0.740        0.764           0.717   0.5           2   \n",
       "\n",
       "   num_feats_MEAN    C penalty  dual  \n",
       "0         30553.0  0.5      l2  True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"SENT_CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_FIXED_VD\"\n",
    "round_data(get_hyper_param_results(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
