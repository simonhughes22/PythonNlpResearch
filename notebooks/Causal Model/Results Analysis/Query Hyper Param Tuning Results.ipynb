{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymongo\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client.metrics_causal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_by(df, bycols, agg_map):\n",
    "    \"\"\"\n",
    "\n",
    "    @param df:      DataFrame\n",
    "    @param bycols:  str or list\n",
    "                        Column(s) to group by\n",
    "    @param agg_map: dictionary or list of 2-tuples\n",
    "                        Mapping from column to aggregate function e.g. [(\"city\", \"count\"), (\"salary\", \"mean\"]\n",
    "    @return:        DataFrame\n",
    "                        Flattened dataframe, with multi-level index removed\n",
    "    \"\"\"\n",
    "    grps = []\n",
    "    if type(bycols) == str:\n",
    "        bycols = [bycols]\n",
    "\n",
    "    if type(agg_map) == dict:\n",
    "        agg_map = agg_map.items()\n",
    "\n",
    "    for k,v in agg_map:\n",
    "        grp = df[bycols + [k]].groupby(bycols, ).agg(v)\n",
    "        grp.reset_index(inplace=True)\n",
    "        grp[\"%s(%s)\" % (v,k)] = grp[k]\n",
    "        del grp[k]\n",
    "        grps.append(grp)\n",
    "\n",
    "    m = grps[0]\n",
    "    for grp in grps[1:]:\n",
    "        m = pd.merge(m, grp, on=bycols, how=\"inner\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bson.son import SON # needed to ensure dictionary is ordered (python default is not)\n",
    "import hashlib\n",
    "\n",
    "def hash_feats(fts):\n",
    "    vals = fts.values\n",
    "    joined = \"|\".join(map(lambda s: str(s),vals)).encode('utf-8') \n",
    "    return hashlib.sha224(joined).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Metrics import rpf1a_from_tp_fp_tn_fn\n",
    "from collections import defaultdict\n",
    "\n",
    "def tally_counts(r, filter):\n",
    "    tally = defaultdict(int)\n",
    "    for k,v in r.items():\n",
    "        if filter(k):\n",
    "            for prop in \"tp,tn,fp,fn\".split(\",\"):\n",
    "                tally[prop] += v[prop]\n",
    "    return tally\n",
    "\n",
    "def get_causal_relation_metrics(collection, params, include_concept_codes=True):\n",
    "    dicts = []\n",
    "    for r in db[collection].find({}):\n",
    "        d = {}\n",
    "        cr_counts = tally_counts(r, lambda c: \"->\" in c)\n",
    "        (rec, p, cr_f1, a) = rpf1a_from_tp_fp_tn_fn(cr_counts[\"tp\"],cr_counts[\"fp\"],cr_counts[\"tn\"],cr_counts[\"fn\"])\n",
    "        d[\"cr_micro_f1\"] = cr_f1\n",
    "        d[\"cr_micro_rec\"]  = rec\n",
    "        d[\"cr_micro_prec\"] = p\n",
    "        if include_concept_codes:\n",
    "            concept_counts = tally_counts(r, lambda c: c[0].isdigit())\n",
    "            (rec, p, concept_f1, a) = rpf1a_from_tp_fp_tn_fn(concept_counts[\"tp\"],concept_counts[\"fp\"],concept_counts[\"tn\"],concept_counts[\"fn\"])\n",
    "            d[\"concept_micro_f1\"] = concept_f1\n",
    "            d[\"concept_micro_rec\"]  = rec\n",
    "            d[\"concept_micro_prec\"] = p\n",
    "        parms = r[\"parameters\"]\n",
    "        for p in params:\n",
    "            d[p] = parms[p]\n",
    "        dicts.append(d)\n",
    "    df = pd.DataFrame(dicts)\n",
    "    fields = (\"cr_micro_f1,cr_micro_rec,cr_micro_prec,concept_micro_f1,concept_micro_rec,concept_micro_prec,\" + \",\".join(params)).split(\",\")\n",
    "    if not include_concept_codes:\n",
    "        fields = [f for f in fields if \"concept\" not in f]\n",
    "    return df[fields].sort_values(\"cr_micro_f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def round_data(df, places=3):\n",
    "    df_copy = df.copy()\n",
    "    fmt_str = \"{0:.\" + str(places) + \"f}\"\n",
    "    cols = set([v for v in df_copy.columns.values if \"micro_\" in v])\n",
    "    for c in cols:\n",
    "        df_copy[c] = df[c].apply(lambda d: fmt_str.format(d))  \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection on Shift Reduce Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REMOVE the non generic parameters, like window size\n",
    "def get_df_sorted_by_f1score_generic(collection, params=None, filter_cols=True):\n",
    "    if not params:\n",
    "        params = []\n",
    "    if type(params) == str:\n",
    "        params = params.split(\",\")\n",
    "    \n",
    "    project = {\n",
    "            \"weighted_f1_score\":\"$WEIGHTED_MEAN_CONCEPT_CODES.f1_score\",\n",
    "            \"micro_f1_score\":  \"$MICRO_F1.f1_score\",\n",
    "            \"micro_recall\":    \"$MICRO_F1.recall\",\n",
    "            \"micro_precision\": \"$MICRO_F1.precision\",\n",
    "    \n",
    "    # PARAMETERS            \n",
    "            \"feats\":          \"$parameters.extractors\",\n",
    "            \n",
    "            \"asof\" :          \"$asof\",\n",
    "            \"_id\":1\n",
    "    }\n",
    "    \n",
    "    # No count for HMM\n",
    "    if \"_hmm\" in collection.lower():\n",
    "        del project[\"count\"]\n",
    "    \n",
    "    for param in params:\n",
    "        project[param] = \"$parameters.\" + param\n",
    "\n",
    "    feats_pipeline = [{\n",
    "        \"$project\": project\n",
    "    },\n",
    "    {\n",
    "        \"$match\":{\n",
    "            \"micro_f1_score\": { \"$exists\" : True }        \n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$sort\":{\n",
    "            \"micro_f1_score\": -1\n",
    "        }\n",
    "    },\n",
    "    ]\n",
    "    \n",
    "    rows = [row for row in db[collection].aggregate(feats_pipeline)]\n",
    "    df = pd.DataFrame(rows).sort_values(\"micro_f1_score\", ascending=False)\n",
    "    if params:\n",
    "        df[\"hs_params\"] = df[params].apply(hash_feats, axis=1)\n",
    "        \n",
    "    if filter_cols:\n",
    "        cols = [\"micro_f1_score\", \"micro_recall\" ,\"micro_precision\" ] + params\n",
    "        return df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Result (Best VD Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...</td>\n",
       "      <td>0.756325</td>\n",
       "      <td>0.750193</td>\n",
       "      <td>0.762559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Algo  micro_f1_score  \\\n",
       "0  CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARA...        0.756325   \n",
       "\n",
       "   micro_precision  micro_recall  \n",
       "0         0.750193      0.762559  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\"]\n",
    "\n",
    "rows = []\n",
    "for coll in col:\n",
    "    df = get_df_sorted_by_f1score_generic(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\"]\n",
    "\n",
    "rows = []\n",
    "for coll in col:\n",
    "    df = get_df_sorted_by_f1score_generic(coll, \"\")\n",
    "    dct = df.iloc[0].to_dict()\n",
    "    dct[\"Algo\"] = coll\n",
    "    rows.append(dct)\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.sort_values(\"micro_f1_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Sorted by Hyper Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_parameter(s, param_name):\n",
    "    s = s.replace(\"(\",\" \").replace(\")\",\" \")\n",
    "    keys = s.split(\" \")\n",
    "    return [(key,val.replace(\",\",\"\").replace(\"'\",\"\")) for key,val in [k.split(\"=\") for k in keys if \"=\" in k] if key == param_name][0][-1]\n",
    "\n",
    "extract_c_val = lambda s: extract_parameter(s, \"C\")\n",
    "extract_penalty_val = lambda s: extract_parameter(s, \"penalty\")\n",
    "extract_dual_val = lambda s: extract_parameter(s, \"dual\")\n",
    "\n",
    "s = \"LogisticRegression(C=0.1, class_weight=None, dual=True, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\"\n",
    "extract_c_val(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.756325</td>\n",
       "      <td>0.762559</td>\n",
       "      <td>0.750193</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>68757.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755356</td>\n",
       "      <td>0.760989</td>\n",
       "      <td>0.749807</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>68656.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.754813</td>\n",
       "      <td>0.753925</td>\n",
       "      <td>0.755704</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>61782.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753384</td>\n",
       "      <td>0.753532</td>\n",
       "      <td>0.753237</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>61804.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753104</td>\n",
       "      <td>0.726060</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>81615.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.752877</td>\n",
       "      <td>0.757457</td>\n",
       "      <td>0.748352</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>69071.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.752600</td>\n",
       "      <td>0.724097</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>78385.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.750999</td>\n",
       "      <td>0.737441</td>\n",
       "      <td>0.765065</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>69650.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.750862</td>\n",
       "      <td>0.726845</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>80386.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750739</td>\n",
       "      <td>0.747645</td>\n",
       "      <td>0.753858</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>59726.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   micro_f1_score  micro_recall  micro_precision  beta  max_epochs ngrams  \\\n",
       "0        0.756325      0.762559         0.750193  0.75           2      1   \n",
       "1        0.755356      0.760989         0.749807  0.75           2      1   \n",
       "2        0.754813      0.753925         0.755704  0.75           2      1   \n",
       "3        0.753384      0.753532         0.753237  0.75           2      1   \n",
       "4        0.753104      0.726060         0.782241  1.00           3      1   \n",
       "5        0.752877      0.757457         0.748352  0.75           2      1   \n",
       "6        0.752600      0.724097         0.783439  0.75           3      1   \n",
       "7        0.750999      0.737441         0.765065  1.00           2      1   \n",
       "8        0.750862      0.726845         0.776520  0.50           3      1   \n",
       "9        0.750739      0.747645         0.753858  0.75           2      1   \n",
       "\n",
       "  stemmed  num_feats_MEAN    C penalty   dual  \n",
       "0    True         68757.2  0.1      l2   True  \n",
       "1    True         68656.2  0.1      l2  False  \n",
       "2    True         61782.0  0.5      l2  False  \n",
       "3    True         61804.8  0.5      l2   True  \n",
       "4    True         81615.4  0.1      l2   True  \n",
       "5    True         69071.2  0.5      l1  False  \n",
       "6    True         78385.8  0.1      l2   True  \n",
       "7    True         69650.2  0.1      l2  False  \n",
       "8    True         80386.0  0.1      l2   True  \n",
       "9    True         59726.8  1.0      l2  False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"CR_CB_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\"]\n",
    "\n",
    "df_feat_sel = get_df_sorted_by_f1score_generic(col[0], \"algorithm,beta,max_epochs,ngrams,stemmed,num_feats_MEAN\", filter_cols=True) \n",
    "df_feat_sel[\"C\"] = df_feat_sel[\"algorithm\"].apply(extract_c_val)\n",
    "df_feat_sel[\"penalty\"] = df_feat_sel[\"algorithm\"].apply(extract_penalty_val)\n",
    "df_feat_sel[\"dual\"] = df_feat_sel[\"algorithm\"].apply(extract_dual_val)\n",
    "del df_feat_sel[\"algorithm\"]\n",
    "#df = df_feat_sel.head(20).style.set_properties(subset=['algorithm'], **{'width': '500px'})\n",
    "df_feat_sel.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>beta</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>num_feats_MEAN</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>dual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.766909</td>\n",
       "      <td>0.710092</td>\n",
       "      <td>0.833609</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25594.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.766800</td>\n",
       "      <td>0.712304</td>\n",
       "      <td>0.830326</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25616.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.766602</td>\n",
       "      <td>0.712505</td>\n",
       "      <td>0.829588</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25528.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.766580</td>\n",
       "      <td>0.711098</td>\n",
       "      <td>0.831453</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25665.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766512</td>\n",
       "      <td>0.715119</td>\n",
       "      <td>0.825865</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26560.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.766396</td>\n",
       "      <td>0.710696</td>\n",
       "      <td>0.831569</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25715.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766367</td>\n",
       "      <td>0.711902</td>\n",
       "      <td>0.829857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25620.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.766363</td>\n",
       "      <td>0.710897</td>\n",
       "      <td>0.831218</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25601.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.766311</td>\n",
       "      <td>0.714314</td>\n",
       "      <td>0.826471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25730.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.766266</td>\n",
       "      <td>0.711500</td>\n",
       "      <td>0.830167</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25660.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   micro_f1_score  micro_recall  micro_precision  beta  max_epochs ngrams  \\\n",
       "0        0.766909      0.710092         0.833609   0.2           5      1   \n",
       "1        0.766800      0.712304         0.830326   0.4          20      1   \n",
       "2        0.766602      0.712505         0.829588   0.5          10      1   \n",
       "3        0.766580      0.711098         0.831453   0.3          20      1   \n",
       "4        0.766512      0.715119         0.825865   0.1          20      1   \n",
       "5        0.766396      0.710696         0.831569   0.2          15      1   \n",
       "6        0.766367      0.711902         0.829857   0.4          20      1   \n",
       "7        0.766363      0.710897         0.831218   0.4          10      1   \n",
       "8        0.766311      0.714314         0.826471   0.2           5      1   \n",
       "9        0.766266      0.711500         0.830167   0.3          15      1   \n",
       "\n",
       "  stemmed  num_feats_MEAN    C penalty   dual  \n",
       "0    True         25594.2  0.5      l2  False  \n",
       "1    True         25616.0  0.5      l2  False  \n",
       "2    True         25528.0  0.5      l2  False  \n",
       "3    True         25665.8  0.5      l2  False  \n",
       "4    True         26560.8  0.5      l1  False  \n",
       "5    True         25715.8  0.5      l2   True  \n",
       "6    True         25620.0  0.5      l2   True  \n",
       "7    True         25601.0  0.5      l2   True  \n",
       "8    True         25730.6  0.1      l2   True  \n",
       "9    True         25660.2  0.5      l2   True  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\"CR_SC_SHIFT_REDUCE_PARSER_TEMPLATED_HYPER_PARAM_VD\"]\n",
    "\n",
    "df_feat_sel = get_df_sorted_by_f1score_generic(col[0], \"algorithm,beta,max_epochs,ngrams,stemmed,num_feats_MEAN\", filter_cols=True) \n",
    "df_feat_sel[\"C\"] = df_feat_sel[\"algorithm\"].apply(extract_c_val)\n",
    "df_feat_sel[\"penalty\"] = df_feat_sel[\"algorithm\"].apply(extract_penalty_val)\n",
    "df_feat_sel[\"dual\"] = df_feat_sel[\"algorithm\"].apply(extract_dual_val)\n",
    "del df_feat_sel[\"algorithm\"]\n",
    "#df = df_feat_sel.head(20).style.set_properties(subset=['algorithm'], **{'width': '500px'})\n",
    "df_feat_sel.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Got here without error\n",
    "print(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
