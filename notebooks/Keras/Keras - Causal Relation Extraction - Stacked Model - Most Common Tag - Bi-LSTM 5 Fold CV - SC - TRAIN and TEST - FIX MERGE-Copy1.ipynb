{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on this code: https://github.com/codekansas/keras-language-modeling/blob/master/keras_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check mongo is running\n",
    "import pymongo\n",
    "client = pymongo.MongoClient()\n",
    "db = client.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - To Get this working:\n",
    "\n",
    "* Install CUDA and associated libraries, setup path\n",
    "* Install bleeding edge theano (from src)\n",
    "* Make sure the THEANO_FLAGS are set correctly via the environment var, or via the ~/.theanorc file\n",
    "* Install and compile bleeding edge Keras (from src)\n",
    "* `export KERAS_BACKEND=theano`\n",
    "* `export KERAS_IMAGE_DIM_ORDERING='th'`\n",
    "* `sh <project_root>/shell_scipts/setup_environment.sh` to install additional dependencies\n",
    "* **DO NOT SET UNROLL=True** when creating RNN's - causes max recursion issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouble-Shooting\n",
    "\n",
    "* You may need to clean the theano cache. To do so thoroughly, run this command from the shell:\n",
    " * `theano-cache purge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import dill\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, TimeDistributedDense\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from Metrics import rpf1\n",
    "from load_data import load_process_essays\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from IdGenerator import IdGenerator as idGen\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Rpfa import micro_rpfa\n",
    "from collections import defaultdict\n",
    "\n",
    "import Settings\n",
    "import logging\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "WARNING - No db name specified - should be either 'metrics_causal' or 'metrics'. Defaulting to 'metrics' \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from Settings import Settings\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"SkinCancer/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"SkinCancer/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/Bi-LSTM_Stacked/\"\n",
    "cv_folder = root_folder + \"CV_Data_Pickled/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "processor = ResultsProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/Thesis_Dataset/CV_Data_Pickled/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_folder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "tagged_essays_tmp = load_process_essays(**config)\n",
    "\n",
    "with open(training_pickled, \"wb+\") as f:\n",
    "    pickle.dump(tagged_essays_tmp, f)\n",
    "del tagged_essays_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 files found\n",
      "218 essays processed\n"
     ]
    }
   ],
   "source": [
    "test_config = get_config(test_folder)\n",
    "tagged_essays_test = load_process_essays(**test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2019-10-09 00:27:24.445766\n"
     ]
    }
   ],
   "source": [
    "import datetime, logging\n",
    "print(\"Started at: \" + str(datetime.datetime.now()))\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "shuffle(tagged_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1623"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit()))\n",
    "cr_tags = list((t for t in tag_freq.keys() if ( \"->\" in t) \n",
    "                and not \"Anaphor\" in t \n",
    "                and not \"other\" in t \n",
    "                and not \"rhetorical\" in t))\n",
    "\n",
    "vtags = set(regular_tags)\n",
    "vtags.add(EMPTY_TAG)\n",
    "\n",
    "cr_vtags = set(cr_tags)\n",
    "cr_vtags.add(EMPTY_TAG)\n",
    "\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '11', '12', '2', '3', '4', '5', '50', '6', 'Empty']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cr_vtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Causer:1->Result:2',\n",
       " 'Causer:1->Result:3',\n",
       " 'Causer:1->Result:4',\n",
       " 'Causer:1->Result:5',\n",
       " 'Causer:1->Result:50',\n",
       " 'Causer:11->Result:12',\n",
       " 'Causer:11->Result:3',\n",
       " 'Causer:11->Result:4',\n",
       " 'Causer:11->Result:5',\n",
       " 'Causer:11->Result:50',\n",
       " 'Causer:12->Result:12',\n",
       " 'Causer:12->Result:2',\n",
       " 'Causer:12->Result:3',\n",
       " 'Causer:12->Result:4',\n",
       " 'Causer:12->Result:5',\n",
       " 'Causer:12->Result:50',\n",
       " 'Causer:2->Result:1',\n",
       " 'Causer:2->Result:11',\n",
       " 'Causer:2->Result:2',\n",
       " 'Causer:2->Result:3',\n",
       " 'Causer:2->Result:4',\n",
       " 'Causer:2->Result:5',\n",
       " 'Causer:2->Result:50',\n",
       " 'Causer:2->Result:6',\n",
       " 'Causer:3->Result:11',\n",
       " 'Causer:3->Result:2',\n",
       " 'Causer:3->Result:4',\n",
       " 'Causer:3->Result:5',\n",
       " 'Causer:3->Result:50',\n",
       " 'Causer:3->Result:6',\n",
       " 'Causer:4->Result:11',\n",
       " 'Causer:4->Result:12',\n",
       " 'Causer:4->Result:4',\n",
       " 'Causer:4->Result:5',\n",
       " 'Causer:4->Result:50',\n",
       " 'Causer:4->Result:6',\n",
       " 'Causer:5->Result:12',\n",
       " 'Causer:5->Result:4',\n",
       " 'Causer:5->Result:5',\n",
       " 'Causer:5->Result:50',\n",
       " 'Causer:5->Result:6',\n",
       " 'Causer:50->Result:2',\n",
       " 'Causer:50->Result:3',\n",
       " 'Causer:50->Result:4',\n",
       " 'Causer:50->Result:5',\n",
       " 'Causer:6->Result:3',\n",
       " 'Causer:6->Result:4',\n",
       " 'Causer:6->Result:5',\n",
       " 'Causer:6->Result:50',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cr_vtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Essays into Training Data (Word Ids)\n",
    "\n",
    "* Computes `xs`, `ys`, `ys_bytag` and `seq_lens`\n",
    "* `ys_bytag` includes **all tags** and does **not** focus only on the most common tag\n",
    "* `ys` only includes the most common tag (so we can use cross entropy)\n",
    "* `seq_lens` is without the start and end tags included (so we have to map back and forth to maintain mappings)\n",
    "* `ys_bytag` also excludes the START and END tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Max Sequence Length, Generate All Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2tag = {}\n",
    "for ix, t in enumerate(vtags):\n",
    "    ix2tag[ix] = t\n",
    "\n",
    "ix2crtag = {}\n",
    "for ix, t in enumerate(cr_vtags):\n",
    "    ix2crtag[ix] = t\n",
    "    \n",
    "generator = idGen(seed=1) # important as we zero pad sequences\n",
    "\n",
    "maxlen = 0\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "        \n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "\n",
    "def ids2tags(ids):\n",
    "    return [generator.get_key(j) for j in ids]\n",
    "\n",
    "def lbls2tags(ixs):\n",
    "    return [ix2tag[ix] for ix in ixs]\n",
    "        \n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"<start>\"\n",
    "END   = \"<end>\"\n",
    "\n",
    "def get_training_data(tessays):\n",
    "    # outputs\n",
    "    xs = []\n",
    "    ys = []\n",
    "    ys_bytag_concept_sent = defaultdict(list)\n",
    "    ys_bytag_cr_sent = defaultdict(list)\n",
    "    seq_lens = []\n",
    "    \n",
    "    # cut texts after this number of words (among top max_features most common words)\n",
    "    for essay in tessays:\n",
    "        for sentence in essay.sentences:\n",
    "            row = []\n",
    "            y_found = False\n",
    "            y_seq = []\n",
    "            unique_tags = set() # get all unique tags in sentence\n",
    "            for word, tags in [(START, set())] + sentence + [(END, set())]:\n",
    "                id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "                row.append(id)  \n",
    "                \n",
    "                # Make sure to include Causer:<num> and Result:<num> tags, as we do for the parser model\n",
    "                missing_tags = [t.replace(\"Causer:\",\"\").replace(\"Result:\",\"\") \n",
    "                                    for t in tags\n",
    "                                ]\n",
    "                # Filter to just concept codes that were missing\n",
    "                missing_tags = set([t for t in missing_tags if t[0].isdigit() and \"->\" not in t])\n",
    "                \n",
    "                new_tags = tags.union(missing_tags)\n",
    "                #if missing_tags:\n",
    "                #    diff = missing_tags - tags\n",
    "                #    if diff:\n",
    "                #        print(diff, tags)\n",
    "\n",
    "                tags = new_tags                \n",
    "                \n",
    "                unique_tags.update(tags)\n",
    "                \n",
    "                # remove unwanted tags, filter to concept tags\n",
    "                concept_tags = vtags.intersection(tags)\n",
    "\n",
    "                # encode ys with most common tag only\n",
    "                if len(concept_tags) > 1:\n",
    "                    most_common = max(concept_tags, key=lambda t: tag_freq[t])\n",
    "                    concept_tags = set([most_common])\n",
    "                if len(concept_tags) == 0:\n",
    "                    concept_tags.add(EMPTY_TAG)\n",
    "\n",
    "                one_hot = []\n",
    "                for t in vtags:\n",
    "                    if t in concept_tags:\n",
    "                        one_hot.append(1)\n",
    "                    else:\n",
    "                        one_hot.append(0)\n",
    "                y_seq.append(one_hot)\n",
    "                #end for each word\n",
    "            \n",
    "            # sentence level tags\n",
    "            for tag in vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_concept_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_concept_sent[tag].append(0)\n",
    "            \n",
    "            for tag in cr_vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_cr_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_cr_sent[tag].append(0)\n",
    "                \n",
    "            seq_lens.append(len(row)-2)\n",
    "            ys.append(y_seq)\n",
    "            xs.append(row)\n",
    "    \n",
    "    xs = sequence.pad_sequences(xs, maxlen=maxlen)\n",
    "    ys = sequence.pad_sequences(ys, maxlen=maxlen)\n",
    "    assert xs.shape[0] == ys.shape[0], \"Sequences should have the same number of rows\"\n",
    "    assert xs.shape[1] == ys.shape[1] == maxlen, \"Sequences should have the same lengths\"\n",
    "    return xs, ys, ys_bytag_concept_sent, ys_bytag_cr_sent, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        for pred_tag in pred_ys:\n",
    "            pred_ys_by_tag[pred_tag].append(1)\n",
    "            # for all other tags, a 0\n",
    "            for tag in(vtags - set([EMPTY_TAG, pred_tag])):\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results_sentence_level(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = set(pred_ys[1:-1])\n",
    "        for tag in vtags:\n",
    "            if tag == EMPTY_TAG:\n",
    "                continue\n",
    "            if tag in pred_ys:\n",
    "                pred_ys_by_tag[tag].append(1)\n",
    "            else:\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_dev_split(lst, dev_split, randomize=True):\n",
    "    # random shuffle\n",
    "    if randomize:\n",
    "        shuffle(lst)\n",
    "    num_training = int((1.0 - dev_split) * len(lst))\n",
    "    return lst[:num_training], lst[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.6 s, sys: 404 ms, total: 7 s\n",
      "Wall time: 6.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this name for a different function later\n",
    "from CrossValidation import cross_validation as cv\n",
    "\n",
    "folds = cv(tagged_essays, CV_FOLDS)\n",
    "fold2training_data = {}\n",
    "fold2dev_data = {}\n",
    "fold2test_data = {}\n",
    "\n",
    "for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "    # further split into train and dev test\n",
    "    essays_train, essays_dev = train_dev_split(essays_TD, DEV_SPLIT)\n",
    "    fold2training_data[i] = get_training_data(essays_train)\n",
    "    fold2dev_data[i]      = get_training_data(essays_dev)\n",
    "    # Test Data\n",
    "    fold2test_data[i]     = get_training_data(essays_VD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(cv_folder + \"td.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_data, f)\n",
    "\n",
    "with open(cv_folder + \"devd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_data, f)\n",
    "\n",
    "with open(cv_folder + \"vd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the generator is incremented on the test data too\n",
    "_,_,_,_,_, = get_training_data(tagged_essays_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Glove 100 Dim Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/DeepLearning/WordVectors/pickle_glove_embedding.py\n",
    "# for creating pre-filtered embeddings file\n",
    "import pickle, os\n",
    "from numpy.linalg import norm\n",
    "\n",
    "embeddings_file = \"/Users/simon.hughes/data/word_embeddings/glove.6B/sc_dict_glove.6B.100d.txt\"\n",
    "# read data file\n",
    "with open(embeddings_file, \"rb+\") as f:\n",
    "    cb_emb_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1623 0.9900000000000001 %\n"
     ]
    }
   ],
   "source": [
    "missed = set()\n",
    "for wd in unique_words:\n",
    "    if wd not in cb_emb_index:\n",
    "        missed.add(wd)\n",
    "print(len(missed), len(unique_words), 100.0 * round(len(missed)/  len(unique_words),4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = list(cb_emb_index.values())[0].shape[0]\n",
    "\n",
    "def get_embedding_matrix(words, idgenerator, max_features, init='uniform', unit_length=False):\n",
    "    embedding_dim = list(cb_emb_index.values())[0].shape[0]\n",
    "    # initialize with a uniform distribution\n",
    "    if init == 'uniform':\n",
    "        # NOTE: the max norms for these is quite low relative to the embeddings\n",
    "        embedding_matrix = np.random.uniform(low=-0.05, high=0.05,size=(max_features, embedding_dim))\n",
    "    elif init =='zeros':\n",
    "        embedding_matrix = np.zeros(shape=(max_features, embedding_dim), dtype=np.float32)\n",
    "    elif init == 'normal':\n",
    "        embedding_matrix = np.random.normal(mean, sd, size=(max_features, embedding_dim))\n",
    "    else:\n",
    "        raise Exception(\"Unknown init type\")\n",
    "    for word in words:\n",
    "        i = idgenerator.get_id(word)\n",
    "        embedding_vector = cb_emb_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    if unit_length:\n",
    "        norms = np.linalg.norm(embedding_matrix, axis=1,keepdims=True)\n",
    "        # remove 0 norms to prevent divide by zero\n",
    "        norms[norms == 0.0] = 1.0\n",
    "        embedding_matrix = embedding_matrix / norms\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_predictions(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict_classes(xs, batch_size=batch_size, verbose=0)   \n",
    "    pred_ys_by_tag = collapse_results_sentence_level(seq_len, preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pivot_predictions_to_dict(preds):\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(preds.shape[0]):\n",
    "        row = preds[i]\n",
    "        for tag_ix, pred in enumerate(row):\n",
    "            tag = ix2crtag[tag_ix]\n",
    "            pred_ys_by_tag[tag].append(pred)\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_predictions_sent_level(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict(xs, batch_size=batch_size, verbose=0)\n",
    "    preds = np.where(preds >= 0.5, 1, 0)\n",
    "    pred_ys_by_tag = pivot_predictions_to_dict(preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2019-10-09 00:27:38.299743', '20191009_002738_299769')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "from datetime import datetime\n",
    "\n",
    "def get_ts():\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "def get_file_ts():\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "\n",
    "embedding_size = EMBEDDING_DIM\n",
    "hidden_size    = 128\n",
    "out_size = len(vtags)\n",
    "batch_size = 128\n",
    "\n",
    "get_ts(), get_file_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Bi-Directional LSTM With Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1627"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features=len(generator.get_ids())+2 #Need plus one maybe due to masking of sequences\n",
    "max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/SkinCancer/Thesis_Dataset/Models/Bi-LSTM_Stacked/fold_ix-0_bi_directional-True_hidden_size-128_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.h5'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    lcls = locals()\n",
    "    s = \"\"\n",
    "    for k, val in sorted(lcls.items(), key = lambda tpl: (0,tpl[0]) if tpl[0] == 'fold_ix' else (1,tpl[0])):\n",
    "        s += \"{key}-{val}_\".format(key=k, val=str(val))\n",
    "    return models_folder + s[:-1] + \".h5\"\n",
    "\n",
    "get_file_name(0, True, True, 2, 'sum', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_fold(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "\n",
    "    if use_pretrained_embedding:\n",
    "        embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "        embedding_layer = Embedding(max_features,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=maxlen,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    else:\n",
    "        embedding_layer = Embedding(max_features, embedding_size, input_length=maxlen, trainable=True, mask_zero=True)\n",
    "\n",
    "    if bi_directional:\n",
    "        rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "    else:\n",
    "        rnn_layer_fact = lambda : GRU(hidden_size, return_sequences=True, consume_less=\"cpu\")\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    X_train, y_train, train_ys_bytag_con_sent, train_ys_by_tag_cr_sent, seq_len_train = fold2training_data[fold_ix]\n",
    "    X_dev,   y_dev,   dev_ys_bytag_con_sent,   dev_ys_by_tag_cr_sent,   seq_len_dev   = fold2dev_data[fold_ix]\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  test_ys_by_tag_cr_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "    #for i in range(2):\n",
    "        #print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        epochs = 1 # epochs per training instance\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        #print(micro_metrics)\n",
    "        #print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fold2model = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = evaluate_fold(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        fname = get_file_name(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        model.save(fname)    \n",
    "        fold2model[i] = model\n",
    "    return fold2model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Params 2019-10-09 00:27:38.507334 - Embeddings=True, Bi-Direct=False Num_Rnns=1 Hidden_Size=64\n",
      "Fold[0] - Best F1 Score=0.8818126148193508\n",
      "Fold[1] - Best F1 Score=0.886653252850436\n",
      "Fold[2] - Best F1 Score=0.8868778280542987\n",
      "Fold[3] - Best F1 Score=0.8618581907090465\n",
      "Fold[4] - Best F1 Score=0.8647781934794228\n",
      "2019-10-09 00:46:13.121800\n"
     ]
    }
   ],
   "source": [
    "# temp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "i = 0\n",
    "for use_pretrained_embedding in [True]:\n",
    "    for bi_directional in [False]:\n",
    "        for num_rnns in [1]:\n",
    "            for merge_mode in [\"sum\"]:\n",
    "                for hidden_size in [64]:\n",
    "\n",
    "                    i += 1\n",
    "                    print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "                          .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))\n",
    "                    fold2model = cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "                    #print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))\n",
    "                    print(get_ts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Params 2019-10-09 00:46:13.137016 - Embeddings=True, Bi-Direct=True Num_Rnns=2 Hidden_Size=256\n",
      "Fold[0] - Best F1 Score=0.944686140459913\n",
      "Fold[1] - Best F1 Score=0.9286199864038069\n",
      "Fold[2] - Best F1 Score=0.9307958477508651\n",
      "Fold[3] - Best F1 Score=0.9090909090909091\n",
      "Fold[4] - Best F1 Score=0.9166666666666667\n",
      "2019-10-09 04:07:22.708468\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "i = 0\n",
    "for use_pretrained_embedding in [True]:\n",
    "    for bi_directional in [True]:\n",
    "        for num_rnns in [2]:\n",
    "            for merge_mode in [\"sum\"]:\n",
    "                for hidden_size in [256]:\n",
    "\n",
    "                    i += 1\n",
    "                    print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "                          .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))\n",
    "                    fold2model = cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "                    #print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))\n",
    "                    print(get_ts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fname = get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return keras.models.load_model(fname)\n",
    "\n",
    "def load_models(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    models_by_fold = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = load_model(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        models_by_fold[i] = model\n",
    "    return models_by_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 13s    \n",
      "1745/1745 [==============================] - 13s    \n",
      "1683/1683 [==============================] - 12s    \n",
      "1771/1771 [==============================] - 13s    \n",
      "1670/1670 [==============================] - 12s    \n"
     ]
    }
   ],
   "source": [
    "predicts_by_fold = {}\n",
    "for fold_ix in range(CV_FOLDS):\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  test_ys_by_tag_cr_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "    model = fold2model[fold_ix]\n",
    "    probs = model.predict_proba(X_test)\n",
    "    predicts_by_fold[fold_ix] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_test(num_rnns, merge_mode, hidden_size):\n",
    "    embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "    embedding_layer = Embedding(max_features,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    essays_train, essays_dev = train_dev_split(tagged_essays, DEV_SPLIT)\n",
    "    X_train, y_train,  train_ys_bytag_con_sent,  train_ys_by_tag_cr_sent,  seq_len_train = get_training_data(essays_train)\n",
    "    X_dev,   y_dev,    dev_ys_bytag_con_sent,    dev_ys_by_tag_cr_sent,    seq_len_dev   = get_training_data(essays_dev)\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "        print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        print(micro_metrics)\n",
    "        print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-09 04:08:29.296254: Epoch=0\n",
      "Recall: 0.8498, Precision: 0.9088, F1: 0.8783, Accuracy: 0.9672, Codes:  1032\n",
      "\n",
      "2019-10-09 04:13:28.344629: Epoch=1\n",
      "Recall: 0.8953, Precision: 0.9185, F1: 0.9068, Accuracy: 0.9744, Codes:  1032\n",
      "\n",
      "2019-10-09 04:18:01.067972: Epoch=2\n",
      "Recall: 0.9322, Precision: 0.9188, F1: 0.9254, Accuracy: 0.9791, Codes:  1032\n",
      "\n",
      "2019-10-09 04:22:34.180647: Epoch=3\n",
      "Recall: 0.9331, Precision: 0.9260, F1: 0.9295, Accuracy: 0.9803, Codes:  1032\n",
      "\n",
      "2019-10-09 04:27:07.028032: Epoch=4\n",
      "Recall: 0.9118, Precision: 0.9401, F1: 0.9257, Accuracy: 0.9796, Codes:  1032\n",
      "\n",
      "2019-10-09 04:31:39.930049: Epoch=5\n",
      "Recall: 0.9360, Precision: 0.9288, F1: 0.9324, Accuracy: 0.9811, Codes:  1032\n",
      "\n",
      "2019-10-09 04:36:12.990878: Epoch=6\n",
      "Recall: 0.9360, Precision: 0.9351, F1: 0.9356, Accuracy: 0.9821, Codes:  1032\n",
      "\n",
      "2019-10-09 04:40:46.184855: Epoch=7\n",
      "Recall: 0.8934, Precision: 0.9370, F1: 0.9147, Accuracy: 0.9768, Codes:  1032\n",
      "\n",
      "2019-10-09 04:45:19.557704: Epoch=8\n",
      "Recall: 0.9409, Precision: 0.9195, F1: 0.9301, Accuracy: 0.9803, Codes:  1032\n",
      "\n",
      "2019-10-09 04:49:52.851647: Epoch=9\n",
      "Recall: 0.9380, Precision: 0.9272, F1: 0.9326, Accuracy: 0.9811, Codes:  1032\n",
      "\n",
      "Fold[4] - Best F1 Score=0.9355932203389831\n"
     ]
    }
   ],
   "source": [
    "test_model = evaluate_test(2, \"sum\", 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097/2097 [==============================] - 15s    \n"
     ]
    }
   ],
   "source": [
    "X_test,  y_test,   test_ys_bytag_con_sent,   test_ys_by_tag_cr_sent,   seq_len_test = get_training_data(tagged_essays_test)\n",
    "test_probs = test_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2097, 119, 10), 2097)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs.shape, len(test_ys_by_tag_cr_sent['Causer:3->Result:50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Train and Test Data For Each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_feat_from_probs(probs, max_feats, min_feats, average_feats, binary_feats, combo_feats):\n",
    "    xs = []\n",
    "    for i in range(len(probs)):\n",
    "        preds = probs[i,:]\n",
    "        max_preds = np.max(preds, axis=0)\n",
    "        min_preds = np.max(preds, axis=0)\n",
    "        mean_preds = np.mean(preds, axis=0)\n",
    "        \n",
    "        predicted_ixs = set(np.argwhere(max_preds > 0.5).flatten())\n",
    "        binary = [0] * len(max_preds)\n",
    "        for ix in predicted_ixs:\n",
    "            binary[ix] = 1\n",
    "        \n",
    "        x = []\n",
    "        if binary_feats:\n",
    "            x += binary\n",
    "        if max_feats:\n",
    "            x += max_preds.tolist()\n",
    "        if min_feats:            \n",
    "            x += min_preds.tolist()\n",
    "        if average_feats:\n",
    "            x += mean_preds.tolist()\n",
    "\n",
    "        # combination tags\n",
    "        if combo_feats:\n",
    "            ixs = ix2tag.keys()\n",
    "            for a in ixs:\n",
    "                for b in ixs:\n",
    "                    if b < a:\n",
    "                        if a in predicted_ixs and b in predicted_ixs:\n",
    "                            x.append(1)\n",
    "                        else:\n",
    "                            x.append(0)\n",
    "        xs.append(x)\n",
    "    return np.asarray(xs)\n",
    "\n",
    "def get_stacked_feats_by_fold(fold_ix, predicts_by_fold, max_feats, min_feats, average_feats, binary_feats, combo_feats):\n",
    "    probs = predicts_by_fold[fold_ix]\n",
    "    xs = get_stacked_feat_from_probs(probs, max_feats, min_feats, average_feats, binary_feats, combo_feats)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "stacked_feats_by_code = {}\n",
    "for fold_ix in range(CV_FOLDS):\n",
    "    stacked_feats_by_code[fold_ix] = get_stacked_feats_by_fold(fold_ix, predicts_by_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Thru Each Fold, Merge the Xs and Ys from the Other Folds as TD, and then Use Fold as VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordtagginghelper import merge_dictionaries\n",
    "\n",
    "def generate_stacked_features(max_feats, min_feats, average_feats, binary_feats, combo_feats):\n",
    "    stacked_feats_by_code = {}\n",
    "    for fold_ix in range(CV_FOLDS):\n",
    "        stacked_feats_by_code[fold_ix] = get_stacked_feats_by_fold(fold_ix, predicts_by_fold, max_feats, min_feats, average_feats, binary_feats, combo_feats)\n",
    "    \n",
    "    td_xs_by_fold = {}\n",
    "    vd_xs_by_fold = {}\n",
    "\n",
    "    td_ys_by_fold = {}\n",
    "    vd_ys_by_fold = {}\n",
    "    for vd_ix in range(CV_FOLDS):\n",
    "        td = []\n",
    "\n",
    "        td_ys = defaultdict(list)\n",
    "        vd_ys = defaultdict(list)\n",
    "        for td_ix in range(CV_FOLDS):\n",
    "            if td_ix == vd_ix:\n",
    "                continue\n",
    "            xs = stacked_feats_by_code[td_ix]\n",
    "            td.append(xs)\n",
    "\n",
    "            _, _, _, td_ys_by_tag_cr_sent, _ = fold2test_data[td_ix]\n",
    "            merge_dictionaries(td_ys_by_tag_cr_sent, td_ys)\n",
    "\n",
    "        vd_xs_by_fold[vd_ix] = stacked_feats_by_code[vd_ix]\n",
    "        td_xs_by_fold[vd_ix] = np.vstack(td)\n",
    "\n",
    "        del td_ys[EMPTY_TAG]\n",
    "        td_ys_by_fold[vd_ix] = td_ys\n",
    "\n",
    "        _, _, _, vd_ys_by_tag_cr_sent, _ = fold2test_data[vd_ix]\n",
    "        # make a copy (so can delete EMPTY tag)\n",
    "        merge_dictionaries(vd_ys_by_tag_cr_sent, vd_ys)\n",
    "        del vd_ys[EMPTY_TAG]    \n",
    "        vd_ys_by_fold[vd_ix] = vd_ys\n",
    "    return td_xs_by_fold, td_ys_by_fold, vd_xs_by_fold, vd_ys_by_fold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Validate the sizes of the arrays match expected\n",
    "for i in range(CV_FOLDS):\n",
    "    print(i)\n",
    "    print(td_xs_by_fold[i].shape)\n",
    "    print(vd_xs_by_fold[i].shape)\n",
    "    print(\"\")\n",
    "    key = \"Causer:1->Result:50\"\n",
    "    print(len(td_ys_by_fold[i].keys()))\n",
    "    print(len(vd_ys_by_fold[i].keys()))\n",
    "    print(len(td_ys_by_fold[i][key]))\n",
    "    print(len(vd_ys_by_fold[i][key]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordtagginghelper import train_classifier_per_code, test_classifier_per_code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def train_stacked_classifier(dual, penalty, C, max_feats, min_feats, average_feats, binary_feats, combo_feats):\n",
    "    # capture param values\n",
    "    fn_args  = dict(locals())\n",
    "    \n",
    "    td_xs_by_fold, td_ys_by_fold, vd_xs_by_fold, vd_ys_by_fold = generate_stacked_features(max_feats, min_feats, average_feats, binary_feats, combo_feats)\n",
    "    \n",
    "    fn_create_sent_cls  = lambda : LogisticRegression(dual=dual, C=C, penalty=penalty)\n",
    "\n",
    "    cv_wd_td_ys_by_tag, cv_wd_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_wd_vd_ys_by_tag, cv_wd_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "    cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    num_feats = []\n",
    "    for i in range(CV_FOLDS):\n",
    "        sent_td_xs = td_xs_by_fold[i]\n",
    "        sent_vd_xs = vd_xs_by_fold[i]\n",
    "            \n",
    "        num_feats.append(sent_vd_xs.shape[1])\n",
    "        \n",
    "        sent_td_ys_bycode = td_ys_by_fold[i]\n",
    "        sent_vd_ys_bycode = vd_ys_by_fold[i]\n",
    "\n",
    "        tags = sent_td_ys_bycode.keys()\n",
    "\n",
    "        tag2sent_classifier = train_classifier_per_code(sent_td_xs, sent_td_ys_bycode , fn_create_sent_cls, tags, verbose=False)\n",
    "        td_sent_predictions_by_code \\\n",
    "            = test_classifier_per_code(sent_td_xs, tag2sent_classifier, tags )\n",
    "\n",
    "        vd_sent_predictions_by_code \\\n",
    "            = test_classifier_per_code(sent_vd_xs, tag2sent_classifier, tags )\n",
    "\n",
    "        merge_dictionaries(sent_td_ys_bycode, cv_sent_td_ys_by_tag)\n",
    "        merge_dictionaries(sent_vd_ys_bycode, cv_sent_vd_ys_by_tag)\n",
    "        merge_dictionaries(td_sent_predictions_by_code, cv_sent_td_predictions_by_tag)\n",
    "        merge_dictionaries(vd_sent_predictions_by_code, cv_sent_vd_predictions_by_tag)\n",
    "\n",
    "    sent_algo = str(fn_create_sent_cls())\n",
    "\n",
    "    SUFFIX = \"\"\n",
    "    CB_SENT_TD, CB_SENT_VD = \"CR_SC_STACKED_TD\" + SUFFIX, \"CR_SC_STACKED_VD\" + SUFFIX\n",
    "    parameters = dict(config)\n",
    "    parameters[\"extractors\"] = []\n",
    "    parameters[\"num_feats_MEAN\"] = np.mean(num_feats)\n",
    "    # merge in function args\n",
    "    parameters.update(fn_args)\n",
    "\n",
    "    sent_td_objectid = processor.persist_results(CB_SENT_TD, cv_sent_td_ys_by_tag, cv_sent_td_predictions_by_tag, parameters, sent_algo)\n",
    "    sent_vd_objectid = processor.persist_results(CB_SENT_VD, cv_sent_vd_ys_by_tag, cv_sent_vd_predictions_by_tag, parameters, sent_algo)\n",
    "    \n",
    "    avg_f1 = float(processor.get_metric(CB_SENT_VD, sent_vd_objectid, __MICRO_F1__)[\"f1_score\"])\n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Optimal Stacked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-09 04:56:42.389669 1 MICRO: F1: 0.766317 Max:True Min:True Avg:True Binary:True Combo:True\n",
      "2019-10-09 04:58:41.246004 2 MICRO: F1: 0.761317 Max:True Min:True Avg:True Binary:True Combo:False\n",
      "2019-10-09 05:00:39.949236 3 MICRO: F1: 0.766217 Max:True Min:True Avg:True Binary:False Combo:True\n",
      "2019-10-09 05:02:33.723245 4 MICRO: F1: 0.756385 Max:True Min:True Avg:True Binary:False Combo:False\n",
      "2019-10-09 05:04:32.705545 5 MICRO: F1: 0.766185 Max:True Min:True Avg:False Binary:True Combo:True\n",
      "2019-10-09 05:06:30.012990 6 MICRO: F1: 0.760728 Max:True Min:True Avg:False Binary:True Combo:False\n",
      "2019-10-09 05:08:26.350415 7 MICRO: F1: 0.765720 Max:True Min:True Avg:False Binary:False Combo:True\n",
      "2019-10-09 05:10:18.556637 8 MICRO: F1: 0.756692 Max:True Min:True Avg:False Binary:False Combo:False\n",
      "2019-10-09 05:12:15.718415 9 MICRO: F1: 0.766717 Max:True Min:False Avg:True Binary:True Combo:True\n",
      "2019-10-09 05:14:11.749650 10 MICRO: F1: 0.762626 Max:True Min:False Avg:True Binary:True Combo:False\n",
      "2019-10-09 05:16:06.971062 11 MICRO: F1: 0.766026 Max:True Min:False Avg:True Binary:False Combo:True\n",
      "2019-10-09 05:17:58.164739 12 MICRO: F1: 0.753003 Max:True Min:False Avg:True Binary:False Combo:False\n",
      "2019-10-09 05:19:53.767245 13 MICRO: F1: 0.766026 Max:True Min:False Avg:False Binary:True Combo:True\n",
      "2019-10-09 05:21:48.373649 14 MICRO: F1: 0.761338 Max:True Min:False Avg:False Binary:True Combo:False\n",
      "2019-10-09 05:23:42.093942 15 MICRO: F1: 0.765530 Max:True Min:False Avg:False Binary:False Combo:True\n",
      "2019-10-09 05:25:32.416432 16 MICRO: F1: 0.752674 Max:True Min:False Avg:False Binary:False Combo:False\n",
      "2019-10-09 05:27:32.190113 17 MICRO: F1: 0.766717 Max:False Min:True Avg:True Binary:True Combo:True\n",
      "2019-10-09 05:29:25.468330 18 MICRO: F1: 0.762626 Max:False Min:True Avg:True Binary:True Combo:False\n",
      "2019-10-09 05:31:20.702247 19 MICRO: F1: 0.766026 Max:False Min:True Avg:True Binary:False Combo:True\n",
      "2019-10-09 05:33:11.917341 20 MICRO: F1: 0.753003 Max:False Min:True Avg:True Binary:False Combo:False\n",
      "2019-10-09 05:35:10.334536 21 MICRO: F1: 0.766026 Max:False Min:True Avg:False Binary:True Combo:True\n",
      "2019-10-09 05:37:02.290190 22 MICRO: F1: 0.761338 Max:False Min:True Avg:False Binary:True Combo:False\n",
      "2019-10-09 05:38:55.842147 23 MICRO: F1: 0.765530 Max:False Min:True Avg:False Binary:False Combo:True\n",
      "2019-10-09 05:40:46.356076 24 MICRO: F1: 0.752674 Max:False Min:True Avg:False Binary:False Combo:False\n",
      "2019-10-09 05:42:43.330285 25 MICRO: F1: 0.760055 Max:False Min:False Avg:True Binary:True Combo:True\n",
      "2019-10-09 05:44:34.240597 26 MICRO: F1: 0.752083 Max:False Min:False Avg:True Binary:True Combo:False\n",
      "2019-10-09 05:46:26.807970 27 MICRO: F1: 0.758356 Max:False Min:False Avg:True Binary:False Combo:True\n",
      "2019-10-09 05:48:16.153411 28 MICRO: F1: 0.008350 Max:False Min:False Avg:True Binary:False Combo:False\n",
      "2019-10-09 05:50:11.752865 29 MICRO: F1: 0.758343 Max:False Min:False Avg:False Binary:True Combo:True\n",
      "2019-10-09 05:52:01.613545 30 MICRO: F1: 0.750082 Max:False Min:False Avg:False Binary:True Combo:False\n",
      "2019-10-09 05:53:53.007710 31 MICRO: F1: 0.756481 Max:False Min:False Avg:False Binary:False Combo:True\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for max_feats in [True, False]:\n",
    "    for min_feats in [True, False]:\n",
    "        for average_feats in [True, False]:\n",
    "            for binary_feats in [True,False]:\n",
    "                for combo_feats in [True,False]:\n",
    "                    if not any([max_feats, min_feats, average_feats, binary_feats, combo_feats]):\n",
    "                        continue\n",
    "                        \n",
    "                    counter +=1\n",
    "                    micro_f1 = train_stacked_classifier(dual=True, penalty='l2', C=1.0, \\\n",
    "                                                      max_feats=max_feats, min_feats=min_feats, average_feats=average_feats,\\\n",
    "                                                      binary_feats=binary_feats, combo_feats=combo_feats)\n",
    "                    print(\"{ts} {counter} MICRO: F1: {f1:.6f} Max:{max} Min:{min} Avg:{average} Binary:{binary} Combo:{combo}\".format(\\\n",
    "                        ts=get_ts(), counter=counter, f1=micro_f1, max=max_feats, min=min_feats, \\\n",
    "                        average=average_feats, binary=binary_feats, combo=combo_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Best 2017-12-04 02:47:40.843997 11 MICRO: F1: 0.763158 Max:True Min:False Avg:True Binary:False Combo:True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - GOT UP TO HERE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23529411764705882, 0.7647058823529411)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_feats = 65\n",
    "max_feats = 85\n",
    "\n",
    "(max_feats-optimal_feats)/max_feats, optimal_feats/max_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Features are Max Prob, Binary and Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MICRO: F1: 0.753255 dual: True penalty: l2 C:  0.1\n",
      "2 MICRO: F1: 0.764977 dual: True penalty: l2 C:  0.5\n",
      "3 MICRO: F1: 0.766026 dual: True penalty: l2 C:  1.0\n",
      "4 MICRO: F1: 0.763994 dual: True penalty: l2 C:  5.0\n",
      "5 MICRO: F1: 0.762851 dual: True penalty: l2 C: 10.0\n",
      "6 MICRO: F1: 0.751405 dual: True penalty: l2 C:100.0\n",
      "7 MICRO: F1: 0.752019 dual: False penalty: l1 C:  0.1\n",
      "8 MICRO: F1: 0.763073 dual: False penalty: l1 C:  0.5\n",
      "9 MICRO: F1: 0.761854 dual: False penalty: l1 C:  1.0\n",
      "10 MICRO: F1: 0.760401 dual: False penalty: l1 C:  5.0\n",
      "11 MICRO: F1: 0.757682 dual: False penalty: l1 C: 10.0\n",
      "12 MICRO: F1: 0.743817 dual: False penalty: l1 C:100.0\n",
      "13 MICRO: F1: 0.753255 dual: False penalty: l2 C:  0.1\n",
      "14 MICRO: F1: 0.764977 dual: False penalty: l2 C:  0.5\n",
      "15 MICRO: F1: 0.766026 dual: False penalty: l2 C:  1.0\n",
      "16 MICRO: F1: 0.763994 dual: False penalty: l2 C:  5.0\n",
      "17 MICRO: F1: 0.762556 dual: False penalty: l2 C: 10.0\n",
      "18 MICRO: F1: 0.754259 dual: False penalty: l2 C:100.0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for dual in [True, False]:\n",
    "    for penalty in [\"l1\", \"l2\"]:\n",
    "        # dual only support l2\n",
    "        if dual and penalty != \"l2\":\n",
    "            continue\n",
    "        for C in [0.1, 0.5, 1.0, 5.0, 10.0, 100.0]:\n",
    "            counter += 1\n",
    "            micro_f1 = train_stacked_classifier(dual=dual, penalty=penalty, C=C, \\\n",
    "                                                      max_feats=True, min_feats=False, average_feats=True,\\\n",
    "                                                      binary_feats=False, combo_feats=True)                \n",
    "            print(\"%i MICRO: F1: %s dual: %s penalty: %s C:%s\"\n",
    "                   % (counter, str(round(micro_f1, 6)).rjust(8), str(dual), str(penalty), str(round(C, 3)).rjust(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best:  2017-12-4 - 3 MICRO: F1: 0.763158 dual: True penalty: l2 C:  1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Test Metric Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8573, 119, 10), 8573)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = []\n",
    "td_ys = defaultdict(list)\n",
    "for i in range(CV_FOLDS):\n",
    "    tmp_xs = predicts_by_fold[i]\n",
    "    td.append(tmp_xs)\n",
    "\n",
    "    _, _, _, td_ys_by_tag_cr_sent, _ = fold2test_data[i]\n",
    "    merge_dictionaries(td_ys_by_tag_cr_sent, td_ys)\n",
    "\n",
    "xs = np.vstack(td)\n",
    "# ensure the same number of rows\n",
    "xs.shape, len(list(td_ys.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8573, 65)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_feats_train = get_stacked_feat_from_probs(xs,  max_feats=True, min_feats=False, average_feats=True,\\\n",
    "                                                      binary_feats=False, combo_feats=True)\n",
    "xs_feats_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097, 65)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_feats_test = get_stacked_feat_from_probs(test_probs,  max_feats=True, min_feats=False, average_feats=True,\\\n",
    "                                                      binary_feats=False, combo_feats=True)\n",
    "xs_feats_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.079120603580585855, 0.075166455496904067, 1.0, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xs_feats_train), np.mean(xs_feats_test), np.max(xs_feats_train), np.max(xs_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal from earlier\n",
    "fn_create_sent_cls = lambda: LogisticRegression(dual=True, C=1.0, penalty='l2')\n",
    "tag2sent_classifier = train_classifier_per_code(xs_feats_train, td_ys , fn_create_sent_cls, cr_vtags, verbose=False)\n",
    "train_sent_predictions_by_code \\\n",
    "    = test_classifier_per_code(xs_feats_train, tag2sent_classifier, cr_vtags )\n",
    "\n",
    "test_sent_predictions_by_code \\\n",
    "    = test_classifier_per_code(xs_feats_test, tag2sent_classifier, cr_vtags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB_SENT_TD, CB_SENT_VD = \"TEST_CR_SC_STACKED_TD\", \"TEST_CR_SC_STACKED_VD\"\n",
    "parameters = dict(config)\n",
    "parameters[\"extractors\"] = []\n",
    "# merge in function args\n",
    "sent_algo = \"stacked\"\n",
    "parameters.update({'dual': True, 'C':10.0, 'penalty':'l2', \n",
    "                   'max_feats': True, 'min_feats': False, 'average_feats': False, \n",
    "                   'binary_feats': True, 'combo_feats': True})\n",
    "\n",
    "sent_td_objectid = processor.persist_results(CB_SENT_TD, td_ys,                  train_sent_predictions_by_code, parameters, sent_algo)\n",
    "sent_vd_objectid = processor.persist_results(CB_SENT_VD, test_ys_by_tag_cr_sent, test_sent_predictions_by_code,  parameters, sent_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
