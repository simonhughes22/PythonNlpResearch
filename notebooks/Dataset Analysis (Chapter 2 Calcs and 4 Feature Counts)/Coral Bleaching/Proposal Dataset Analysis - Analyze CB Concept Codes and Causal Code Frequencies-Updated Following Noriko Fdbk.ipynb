{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 files found\n",
      "901 essays processed\n",
      "226 files found\n",
      "226 essays processed\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"CoralBleaching\"\n",
    "# DATASET = \"SkinCancer\"\n",
    "\n",
    "tr_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/Training\"\n",
    "br_train_essays = load_bratt_essays(tr_folder)\n",
    "\n",
    "test_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/Test\"\n",
    "br_test_essays = load_bratt_essays(test_folder)\n",
    "\n",
    "essays = br_train_essays + br_test_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 226, 1127)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(br_train_essays), len(br_test_essays), len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BrattEssay import load_bratt_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "\n",
    "wd_sent_freq = defaultdict(int)\n",
    "all_codes = set()\n",
    "#Stores all words for the spelling corrector\n",
    "words = []\n",
    "all_sentences = []\n",
    "sentencesForCode = defaultdict(list)\n",
    "for essay in essays:\n",
    "    for sentence in essay.tagged_sentences:\n",
    "        wdsInSent = set()\n",
    "        codes4sentence = set()\n",
    "        sent = []\n",
    "        for w, tags in sentence:\n",
    "            words.append(w)\n",
    "            all_codes.update(tags)\n",
    "            codes4sentence.update(tags)\n",
    "            if w not in wdsInSent:\n",
    "                wdsInSent.add(w)\n",
    "                wd_sent_freq[w] += 1\n",
    "            sent.append(w)\n",
    "        all_sentences.append(sent)\n",
    "        for code in codes4sentence:\n",
    "            sentencesForCode[code].append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Stats over the Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_counts = []\n",
    "sent_counts = []\n",
    "concept_codes = []\n",
    "cr_concept_codes = []\n",
    "sent_multi_word_tags = {}\n",
    "sent_codes = []\n",
    "sent_cr_codes = []\n",
    "\n",
    "num_sents = 0\n",
    "un_wd_counts = []\n",
    "vocab = set()\n",
    "for e_ix, essay in enumerate(essays):\n",
    "    wds = 0\n",
    "    un_words = set()\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        num_sents += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        for w, tags in sentence:\n",
    "            un_words.add(w)\n",
    "            vocab.add(w)\n",
    "            wds += 1\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                sent_tags.update(ccodes)\n",
    "                concept_codes.append(ccodes)\n",
    "                if len(ccodes) > 1:\n",
    "                    sent_multi_word_tags[(e_ix, i)] = [(w,[tag for tag in t if tag[0].isdigit()]) for w,t in sentence]\n",
    "            cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            if cr_codes:\n",
    "                cr_concept_codes.append(cr_codes)\n",
    "                sent_cr_tags.update(cr_codes)\n",
    "        if len(sent_tags) > 0:\n",
    "            sent_codes.append(sent_tags)\n",
    "            if len(sent_cr_tags) > 0:\n",
    "                sent_cr_codes.append(sent_cr_tags)\n",
    "                \n",
    "    un_wd_counts.append(len(un_words))\n",
    "    sent_counts.append(len(essay.tagged_sentences))\n",
    "    wd_counts.append(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((61, 1),\n",
       " [('The', []),\n",
       "  ('algae', ['7']),\n",
       "  ('dies', ['7']),\n",
       "  ('out', ['7']),\n",
       "  ('&', []),\n",
       "  ('the', []),\n",
       "  ('coral', ['5b', '50']),\n",
       "  ('loses', ['5b', '50']),\n",
       "  (\"it's\", ['5b']),\n",
       "  ('food', ['5b']),\n",
       "  ('source', ['5b']),\n",
       "  ('&', []),\n",
       "  ('color', ['50']),\n",
       "  ('.', [])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sent_multi_word_tags), num_sents)\n",
    "list(sent_multi_word_tags.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7085, 3132)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_codes), len([tags for tags in sent_codes if len(tags) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 5),\n",
       " [('The', []),\n",
       "  ('strength', ['3', '1']),\n",
       "  ('of', ['3', '1']),\n",
       "  ('the', ['3']),\n",
       "  ('water', ['3']),\n",
       "  ('and', []),\n",
       "  ('wind', ['1']),\n",
       "  ('get', []),\n",
       "  ('algae', ['7']),\n",
       "  ('out', ['7']),\n",
       "  ('of', ['7']),\n",
       "  ('control', ['7']),\n",
       "  ('and', []),\n",
       "  ('turns', ['50']),\n",
       "  ('coral', ['50']),\n",
       "  ('white', ['50']),\n",
       "  ('.', [])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sent_multi_word_tags.items())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Length Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1127"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167656.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "148.76308784383318 * len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.76308784383318 142.0 1 461 81.70546658124215\n",
      "9.048802129547472 8.0 1 31 5.167325839259755\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(wd_counts), np.median(wd_counts), np.min(wd_counts), np.max(wd_counts), np.std(wd_counts))\n",
    "print(np.mean(sent_counts), np.median(sent_counts), np.min(sent_counts), np.max(sent_counts), np.std(sent_counts))\n",
    "# 148.76308784383318 142.0 1 461 81.70546658124215\n",
    "# 9.048802129547472 8.0 1 31 5.167325839259755"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words: 4770\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Unique Words:\" , len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 226, 83.85625554569654, 83.0, 37.825015236458725)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(un_wd_counts), np.max(un_wd_counts), np.mean(un_wd_counts), np.median(un_wd_counts), np.std(un_wd_counts)\n",
    "#(1, 226, 83.85625554569654, 83.0, 37.825015236458725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '11', '12', '13', '14', '2', '3', '4', '5', '50', '5b', '6', '7'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IterableFP import flatten\n",
    "unique = set(flatten(concept_codes))\n",
    "unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Tagged Words Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52014 167656 0.31\n",
      "12 0.00023070711731456916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['5b', '50'],\n",
       " ['5b', '50'],\n",
       " ['3', '1'],\n",
       " ['3', '1'],\n",
       " ['7', '50'],\n",
       " ['14', '7'],\n",
       " ['14', '7'],\n",
       " ['7', '50'],\n",
       " ['13', '4'],\n",
       " ['13', '4'],\n",
       " ['13', '4'],\n",
       " ['14', '50']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(concept_codes), sum(wd_counts), round(len(concept_codes) / float(sum(wd_counts)),2))\n",
    "multiple = [tags for tags in concept_codes if len(tags) > 1]\n",
    "print(len(multiple), len(multiple) / float(len(concept_codes)))\n",
    "multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '5b',\n",
       " '6',\n",
       " '7',\n",
       " 'Causer',\n",
       " 'Result',\n",
       " 'explicit'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cr = set(flatten(cr_concept_codes))\n",
    "unique_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57458 167656 0.34\n",
      "27971 0.48680775522990705\n"
     ]
    }
   ],
   "source": [
    "print(len(cr_concept_codes), sum(wd_counts), round(len(cr_concept_codes) / float(sum(wd_counts)),2))\n",
    "multiple = [tags for tags in cr_concept_codes if len(tags) > 1]\n",
    "print(len(multiple), len(multiple) / float(len(cr_concept_codes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Proportion of Sentences With Codes Have Multiple Codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6947440674642087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44206069160197603"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents = float(num_sents)\n",
    "print(len(sent_codes) / num_sents)\n",
    "num_multiple_codes = len([tags for tags in sent_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49978828510938605"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_cr_codes) / num_sents\n",
    "num_multiple_codes = len([tags for tags in sent_cr_codes if len(tags) > 1])\n",
    "num_multiple_codes / float(len(sent_cr_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probabilities of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "priors = defaultdict(float)\n",
    "joints = defaultdict(float)\n",
    "\n",
    "for sent in sent_codes:\n",
    "    for a in sorted(sent):\n",
    "        priors[a] += 1\n",
    "        for b in sorted(sent):\n",
    "            if b >= a:\n",
    "                break\n",
    "            joints[(b,a)] +=1\n",
    "\n",
    "conditional = {}\n",
    "for a, cnt in priors.items():\n",
    "    for b in priors.keys():\n",
    "        if a == b:\n",
    "            continue\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) / p(B) \"\"\"\n",
    "        \"\"\" p(A/B) = p(B/A)p(A) \"\"\"\n",
    "        if a < b:\n",
    "            joint = joints[(a,b)]\n",
    "        else:\n",
    "            joint = joints[(b,a)]\n",
    "        conditional[(a,b)] = joint / priors[b]\n",
    "    \n",
    "lifts = {}\n",
    "total = float(sum(joints.values()))\n",
    "totalPrior = float(sum(priors.values()))\n",
    "for (a,b),cnt in joints.items():\n",
    "    joint = cnt / total\n",
    "    pA = priors[a] / totalPrior\n",
    "    pB = priors[b] / totalPrior\n",
    "    lift = joint / (pA * pB)\n",
    "    if lift:\n",
    "        lifts[(a,b)] = lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& 1     & 2     &  2.24 \\\\\n",
      "& 2     & 3     &  1.53 \\\\\n",
      "& 3     & 4     &  1.73 \\\\\n",
      "& 4     & 5     &  2.11 \\\\\n",
      "& 5     & 5b    &  2.11 \\\\\n",
      "& 5b    & 14    & -0.68 \\\\\n",
      "& 6     & 7     &  2.23 \\\\\n",
      "& 6     & 14    &  2.34 \\\\\n",
      "& 7     & 50    &   1.2 \\\\\n",
      "& 11    & 12    &  3.93 \\\\\n",
      "& 12    & 13    &  3.58 \\\\\n",
      "& 13    & 14    &  2.59 \\\\\n"
     ]
    }
   ],
   "source": [
    "def get_num(a):\n",
    "    s = \"\"\n",
    "    for c in a:\n",
    "        if c.isdigit():\n",
    "            s += c\n",
    "    return int(s)\n",
    "\n",
    "consec_pmi = {}\n",
    "for (a,b), lift in lifts.items():\n",
    "    ia = get_num(a)\n",
    "    ib = get_num(b)\n",
    "    diff = abs(ia-ib)\n",
    "    pmi = np.log(lift)\n",
    "    if \"Coral\" in DATASET:\n",
    "        if diff == 1 and b != \"6\" and b != \"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"5\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"5b\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"14\" and b ==\"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a ==\"50\" and b ==\"7\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "    elif \"Skin\" in DATASET:\n",
    "        if diff == 1:\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"12\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi\n",
    "        elif a == \"50\" and b == \"6\":\n",
    "            consec_pmi[(a,b)] = pmi        \n",
    "            \n",
    "for k,v in sorted(consec_pmi.items(), key = lambda tpl: (min(int(tpl[0][0]),int(tpl[0][1].replace(\"b\",\"\"))))):\n",
    "    a = k[0]\n",
    "    b = k[1]\n",
    "    if len(a) > len(b.replace(\"b\",\"\")):\n",
    "        a,b = b,a\n",
    "    print(\"&\", str(a).ljust(5), \"&\", str(b).ljust(5), \"&\", str(round(v,2)).rjust(5), \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.854998010043765"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(lifts.values()))\n",
    "#sorted(lifts.items(), key=lambda (tpl,p):-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4014010258798711"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(lambda l: np.log(l), lifts.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Relative Class Frequencies At Word and Sentence Levels (Class Imbalances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_cc_tally = defaultdict(int)\n",
    "sent_cc_tally = defaultdict(int)\n",
    "wd_cnt = 0\n",
    "sent_cnt = 0\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        sent_cnt += 1\n",
    "        sent_tags = set()\n",
    "        \n",
    "        for w, tags in sentence:\n",
    "            wd_cnt += 1\n",
    "            # Concept Codes\n",
    "            ccodes = [t for t in tags if t[0].isdigit()]\n",
    "            if ccodes:\n",
    "                for cc in ccodes:\n",
    "                    wd_cc_tally[cc] += 1\n",
    "                    sent_tags.add(cc)\n",
    "            #Causal Codes\n",
    "            #This is wrong\n",
    "            #cr_codes = [t for t in tags if t[0].isdigit() or t == \"Causer\" or t == \"Result\" or t == \"explicit\"]\n",
    "            #if cr_codes:\n",
    "                 \n",
    "        if len(sent_tags) > 0:\n",
    "            for tag in sent_tags:\n",
    "                sent_cc_tally[tag] +=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167656 10198\n",
      "1   & 3.33 & 12.69 \\\\\n",
      "2   & 0.85 & 2.27 \\\\\n",
      "3   & 5.36 & 14.61 \\\\\n",
      "4   & 1.88 & 5.38 \\\\\n",
      "5   & 1.46 & 6.26 \\\\\n",
      "5b  & 1.44 & 2.69 \\\\\n",
      "6   & 0.88 & 4.00 \\\\\n",
      "7   & 3.03 & 9.17 \\\\\n",
      "11  & 0.63 & 3.67 \\\\\n",
      "12  & 0.51 & 1.23 \\\\\n",
      "13  & 1.34 & 4.92 \\\\\n",
      "14  & 1.47 & 3.34 \\\\\n",
      "50  & 8.86 & 39.36 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(wd_cnt, sent_cnt)\n",
    "#Code, Number of Words, Proportion\n",
    "for code, wd_tally in sorted(wd_cc_tally.items(), key = lambda tpl: int(tpl[0].replace(\"b\",\"\"))):\n",
    "    wd_pct = 100* (float(wd_tally) / wd_cnt)\n",
    "    sent_pct = 100*(float(sent_cc_tally[code]) / sent_cnt)\n",
    "    #print(code.ljust(2), str(tally).ljust(6), \"{0:.4f}\".format(float(tally)/wd_cnt))\n",
    "    # Print Latex Output (Near End of chapter 2)\n",
    "    print(\"{code} & {wd_pct:.2f} & {sent_pct:.2f} \\\\\\\\\".format(code=code.ljust(3),wd_pct=wd_pct, sent_pct=sent_pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Counts for Metrics By Class Notebook (See Mongo Queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167656\n",
      "\n",
      "{'1': 5577,\n",
      " '11': 1052,\n",
      " '12': 851,\n",
      " '13': 2244,\n",
      " '14': 2470,\n",
      " '2': 1426,\n",
      " '3': 8989,\n",
      " '4': 3158,\n",
      " '5': 2440,\n",
      " '50': 14847,\n",
      " '5b': 2418,\n",
      " '6': 1467,\n",
      " '7': 5087}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(wd_cnt)\n",
    "print(\"\")\n",
    "pprint(dict(wd_cc_tally))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Relative Frequencies of Each Causal Relation (Word and Sentence Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_cr_tally = defaultdict(int)\n",
    "sent_cr_tally = defaultdict(int)\n",
    "wd_cr_cnt = 0\n",
    "sent_cr_cnt = 0\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):\n",
    "        sent_cr_cnt += 1\n",
    "        sent_tags = set()\n",
    "        sent_cr_tags = set()\n",
    "        \n",
    "        for w, tags in sentence:\n",
    "            wd_cr_cnt += 1\n",
    "            # Concept Codes\n",
    "            cr_codes = list((t for t in tags if ( \"->\" in t) and not \"factor\" in t and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "            if cr_codes:\n",
    "                for cr in cr_codes:\n",
    "                    wd_cr_tally[cr] += 1\n",
    "                    sent_tags.add(cr)           \n",
    "        if len(sent_tags) > 0:\n",
    "            for tag in sent_tags:\n",
    "                sent_cr_tally[tag] +=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_to_float(cc):\n",
    "    if \"b\" in cc:\n",
    "        cc = cc.replace(\"b\",\"\")\n",
    "        cc += \".1\"\n",
    "    return float(cc)\n",
    "\n",
    "def sort_key(tpl):\n",
    "    cr,cnt = tpl\n",
    "    cr = cr.replace(\"Causer:\",\"\")\n",
    "    cr = cr.replace(\"Result:\",\"\")\n",
    "    l,r = cr.split(\"->\")\n",
    "    l,r = cc_to_float(l), cc_to_float(r)\n",
    "    return (l,r)\n",
    "\n",
    "srtd_cnts = sorted(wd_cr_tally.items(), key = sort_key)\n",
    "\n",
    "prev = \"\"\n",
    "\n",
    "lines = []\n",
    "for cr, wd_tally in srtd_cnts:\n",
    "    l,r = cr.split(\"->\")\n",
    "    if l != prev:\n",
    "        #print(\"\\cmidrule{1-3}\")\n",
    "        prev = l\n",
    "    wd_pct = 100 * (float(wd_tally) / wd_cr_cnt)\n",
    "    sent_pct = 100 *(float(sent_cr_tally[cr]) / sent_cnt)\n",
    "    # Print Latex Output (Near End of chapter 2)\n",
    "    cr = cr.replace(\"->\",\"\\\\textrightarrow \")\n",
    "    cr = cr.replace(\"Causer:\",\"\").replace(\"Result:\",\"\")\n",
    "    lines.append(\"{cr} & {wd_pct:.2f} & {sent_pct:.2f}\".format(cr=cr.ljust(25),wd_pct=wd_pct, sent_pct=sent_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\\textrightarrow 2        & 0.70 & 1.05 & & 5b\\textrightarrow 14      & 0.01 & 0.02 \\\\\n",
      "1\\textrightarrow 3        & 1.75 & 2.60 & & 5b\\textrightarrow 50      & 0.26 & 0.34 \\\\\n",
      "1\\textrightarrow 4        & 0.05 & 0.08 & & 6\\textrightarrow 5        & 0.01 & 0.01 \\\\\n",
      "1\\textrightarrow 5        & 0.04 & 0.06 & & 6\\textrightarrow 5b       & 0.00 & 0.01 \\\\\n",
      "1\\textrightarrow 6        & 0.00 & 0.01 & & 6\\textrightarrow 7        & 1.16 & 1.51 \\\\\n",
      "1\\textrightarrow 7        & 0.05 & 0.07 & & 6\\textrightarrow 14       & 0.41 & 0.55 \\\\\n",
      "1\\textrightarrow 11       & 0.01 & 0.01 & & 6\\textrightarrow 50       & 0.48 & 0.74 \\\\\n",
      "1\\textrightarrow 13       & 0.02 & 0.02 & & 7\\textrightarrow 1        & 0.01 & 0.01 \\\\\n",
      "1\\textrightarrow 14       & 0.02 & 0.03 & & 7\\textrightarrow 4        & 0.01 & 0.01 \\\\\n",
      "1\\textrightarrow 50       & 2.57 & 4.27 & & 7\\textrightarrow 5        & 0.01 & 0.01 \\\\\n",
      "2\\textrightarrow 1        & 0.01 & 0.01 & & 7\\textrightarrow 5b       & 0.03 & 0.04 \\\\\n",
      "2\\textrightarrow 3        & 0.41 & 0.50 & & 7\\textrightarrow 13       & 0.01 & 0.01 \\\\\n",
      "2\\textrightarrow 6        & 0.01 & 0.01 & & 7\\textrightarrow 14       & 0.03 & 0.05 \\\\\n",
      "2\\textrightarrow 50       & 0.07 & 0.08 & & 7\\textrightarrow 50       & 3.32 & 4.78 \\\\\n",
      "3\\textrightarrow 1        & 0.11 & 0.19 & & 11\\textrightarrow 3       & 0.03 & 0.06 \\\\\n",
      "3\\textrightarrow 2        & 0.01 & 0.01 & & 11\\textrightarrow 4       & 0.01 & 0.02 \\\\\n",
      "3\\textrightarrow 4        & 0.94 & 1.57 & & 11\\textrightarrow 6       & 0.02 & 0.03 \\\\\n",
      "3\\textrightarrow 5        & 0.94 & 1.26 & & 11\\textrightarrow 11      & 0.00 & 0.01 \\\\\n",
      "3\\textrightarrow 5b       & 0.03 & 0.03 & & 11\\textrightarrow 12      & 0.53 & 0.86 \\\\\n",
      "3\\textrightarrow 6        & 0.10 & 0.15 & & 11\\textrightarrow 13      & 0.73 & 1.06 \\\\\n",
      "3\\textrightarrow 7        & 0.18 & 0.24 & & 11\\textrightarrow 14      & 0.10 & 0.19 \\\\\n",
      "3\\textrightarrow 13       & 0.02 & 0.04 & & 11\\textrightarrow 50      & 0.40 & 0.72 \\\\\n",
      "3\\textrightarrow 14       & 0.05 & 0.06 & & 12\\textrightarrow 5b      & 0.01 & 0.01 \\\\\n",
      "3\\textrightarrow 50       & 2.48 & 3.84 & & 12\\textrightarrow 7       & 0.02 & 0.03 \\\\\n",
      "4\\textrightarrow 3        & 0.01 & 0.02 & & 12\\textrightarrow 11      & 0.01 & 0.01 \\\\\n",
      "4\\textrightarrow 5        & 0.57 & 0.80 & & 12\\textrightarrow 13      & 0.64 & 0.82 \\\\\n",
      "4\\textrightarrow 5b       & 0.17 & 0.18 & & 12\\textrightarrow 14      & 0.04 & 0.05 \\\\\n",
      "4\\textrightarrow 6        & 0.01 & 0.01 & & 12\\textrightarrow 50      & 0.06 & 0.07 \\\\\n",
      "4\\textrightarrow 7        & 0.06 & 0.08 & & 13\\textrightarrow 4       & 0.01 & 0.01 \\\\\n",
      "4\\textrightarrow 11       & 0.01 & 0.01 & & 13\\textrightarrow 5       & 0.01 & 0.01 \\\\\n",
      "4\\textrightarrow 13       & 0.01 & 0.01 & & 13\\textrightarrow 6       & 0.03 & 0.03 \\\\\n",
      "4\\textrightarrow 14       & 0.72 & 0.87 & & 13\\textrightarrow 7       & 0.02 & 0.04 \\\\\n",
      "4\\textrightarrow 50       & 0.76 & 1.00 & & 13\\textrightarrow 11      & 0.02 & 0.04 \\\\\n",
      "5\\textrightarrow 3        & 0.01 & 0.02 & & 13\\textrightarrow 12      & 0.02 & 0.03 \\\\\n",
      "5\\textrightarrow 4        & 0.01 & 0.01 & & 13\\textrightarrow 14      & 0.63 & 0.93 \\\\\n",
      "5\\textrightarrow 5b       & 0.30 & 0.37 & & 13\\textrightarrow 50      & 0.66 & 0.97 \\\\\n",
      "5\\textrightarrow 7        & 0.09 & 0.16 & & 14\\textrightarrow 6       & 0.01 & 0.01 \\\\\n",
      "5\\textrightarrow 11       & 0.01 & 0.01 & & 14\\textrightarrow 7       & 0.03 & 0.03 \\\\\n",
      "5\\textrightarrow 13       & 0.01 & 0.01 & & 14\\textrightarrow 50      & 0.61 & 0.58 \\\\\n",
      "5\\textrightarrow 14       & 0.01 & 0.03 & & 50\\textrightarrow 1       & 0.02 & 0.03 \\\\\n",
      "5\\textrightarrow 50       & 0.36 & 0.57 & & 50\\textrightarrow 3       & 0.01 & 0.02 \\\\\n",
      "5b\\textrightarrow 5       & 0.03 & 0.04 & & 50\\textrightarrow 7       & 0.04 & 0.08 \\\\\n",
      "5b\\textrightarrow 7       & 0.07 & 0.09 & & 50\\textrightarrow 50      & 0.01 & 0.03 \\\\\n"
     ]
    }
   ],
   "source": [
    "half = int(len(lines)+1)//2\n",
    "if len(lines) % 2 != 0:\n",
    "    half += 1\n",
    "\n",
    "for i in range(0,half):\n",
    "    left = lines[i]\n",
    "    right = \"\"\n",
    "    if i + half  < (len(lines)):\n",
    "        right = lines[i+half]\n",
    "    print(left + \" & & \" + right + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Aggregate Frequences of Concept Codes (Word and Sentence Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "9\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "L.pop([index]) -> item -- remove and return item at index (default last).\n",
       "Raises IndexError if list is empty or index is out of range.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = list(range(10))\n",
    "print(l)\n",
    "l.pop?\n",
    "print(l.pop())\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sents = 0\n",
    "sents_with_codes = 0\n",
    "# sents where one or more words has overlapping codes\n",
    "sents_with_overlapping_codes = 0\n",
    "# sents with >1 code\n",
    "sents_with_multiple_codes = 0\n",
    "\n",
    "num_words = 0\n",
    "words_with_codes = 0\n",
    "words_with_overlapping_codes = 0\n",
    "\n",
    "seq_lens = defaultdict(list)\n",
    "long_seqs = defaultdict(set)\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):    \n",
    "        has_code_in_sent = False\n",
    "        has_overlapping_codes_in_sent = False\n",
    "        unique_ccodes = set()\n",
    "        \n",
    "        last_ccodes = set()\n",
    "        for w, tags in sentence:\n",
    "            # Concept Codes\n",
    "            ccodes = set([t for t in tags if t[0].isdigit()])\n",
    "            # update word stats\n",
    "            if ccodes:\n",
    "                unique_ccodes.update(ccodes)\n",
    "                has_code_in_sent = True\n",
    "                words_with_codes +=1\n",
    "                \n",
    "                if len(ccodes) > 1:\n",
    "                    words_with_overlapping_codes +=1\n",
    "                    has_overlapping_codes_in_sent = True\n",
    "            num_words +=1\n",
    "            # end update word stats\n",
    "            \n",
    "            # Update seq length stats\n",
    "            for code in ccodes:\n",
    "                if code in last_ccodes:\n",
    "                    # get list\n",
    "                    lst = seq_lens[code]\n",
    "                    # remove last entry\n",
    "                    last_item = lst.pop()\n",
    "                    lst.append(last_item+1)\n",
    "                    # store indexes for debugging\n",
    "                    #if last_item > 15:\n",
    "                    #    long_seqs[code].add((e_ix,i))\n",
    "                else:\n",
    "                    seq_lens[code].append(1)\n",
    "            # reset last_ccodes\n",
    "            last_ccodes = ccodes            \n",
    "            # end update seq length stats\n",
    "        # update sent stats\n",
    "        if has_code_in_sent:\n",
    "            sents_with_codes +=1\n",
    "            if has_overlapping_codes_in_sent:\n",
    "                sents_with_overlapping_codes +=1\n",
    "            if len(unique_ccodes) > 1:\n",
    "                sents_with_multiple_codes +=1\n",
    "        num_sents +=1\n",
    "        # end update sent       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167656, 52014, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words, words_with_codes, words_with_overlapping_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10198, 7085, 7, 3132)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents, sents_with_codes, sents_with_overlapping_codes, sents_with_multiple_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% words with codes: \t \t \t31.024%\n",
      "% words with multiple codes: \t \t0.0072%\n",
      "\n",
      "% sents with codes: \t \t \t69.474%\n",
      "% sents with wds. with mult. codes: \t0.069%\n",
      "% sents with multiple codes: \t \t30.712%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "print(\"% words with codes: \\t \\t \\t{pct:.3f}%\".format(pct=100*words_with_codes/ num_words) )\n",
    "print(\"% words with multiple codes: \\t \\t{pct:.4f}%\".format(pct=100*words_with_overlapping_codes/ num_words) )\n",
    "print(\"\")\n",
    "print(\"% sents with codes: \\t \\t \\t{pct:.3f}%\".format(pct=100*sents_with_codes/ num_sents) )\n",
    "print(\"% sents with wds. with mult. codes: \\t{pct:.3f}%\".format(pct=100*sents_with_overlapping_codes/ num_sents) )\n",
    "print(\"% sents with multiple codes: \\t \\t{pct:.3f}%\".format(pct=100*sents_with_multiple_codes/ num_sents) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1          - 3.88\n",
      "11         - 2.47\n",
      "12         - 6.60\n",
      "13         - 4.01\n",
      "14         - 7.06\n",
      "2          - 5.75\n",
      "3          - 4.31\n",
      "4          - 4.93\n",
      "5          - 3.59\n",
      "50         - 3.32\n",
      "5b         - 6.25\n",
      "6          - 3.45\n",
      "7          - 4.40\n",
      "All        - 4.00\n"
     ]
    }
   ],
   "source": [
    "all_lens = []\n",
    "for code in sorted(seq_lens.keys()):\n",
    "    print(\"{code} - {mean_len:.2f}\".format(code=code.ljust(10), mean_len=np.mean(seq_lens[code])))\n",
    "    all_lens.extend(seq_lens[code])\n",
    "print\n",
    "print(\"{code} - {mean_len:.2f}\".format(code=\"All\".ljust(10), mean_len=np.mean(all_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Aggregate Frequencies of Causal Relations (Word and Sentence Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sents = 0\n",
    "sents_with_causal = 0\n",
    "sents_with_overlapping_causal = 0\n",
    "sents_with_multiple_causal = 0\n",
    "\n",
    "num_words = 0\n",
    "words_with_causal = 0\n",
    "words_with_overlapping_causal = 0\n",
    "\n",
    "cr_sents = []\n",
    "\n",
    "cr_seq_lens = defaultdict(list)\n",
    "\n",
    "for e_ix, essay in enumerate(essays):\n",
    "\n",
    "    for i, sentence in enumerate(essay.tagged_sentences):    \n",
    "        has_cr_in_sent = False\n",
    "        has_overlapping_cr_in_sent = False\n",
    "        unique_causal = set()\n",
    "        cr_codes_seq = []\n",
    "        \n",
    "        for w, tags in sentence:\n",
    "            # Concept Codes\n",
    "            cr_codes = set((t for t in tags if ( \"->\" in t) \n",
    "                             and not \"factor\" in t \n",
    "                             and not \"Anaphor\" in t \n",
    "                             and not \"other\" in t \n",
    "                             and not \"rhetorical\" in t))\n",
    "            # update word stats\n",
    "            if cr_codes:\n",
    "                unique_causal.update(cr_codes)\n",
    "                has_cr_in_sent = True\n",
    "                words_with_causal +=1\n",
    "                \n",
    "                if len(cr_codes) > 1:\n",
    "                    words_with_overlapping_causal +=1\n",
    "                    has_overlapping_cr_in_sent = True\n",
    "            num_words +=1\n",
    "            # end update word stats\n",
    "            \n",
    "            # Update seq length stats\n",
    "            for code in cr_codes:\n",
    "                # go upto 2 back as can be 1 word gaps for punct\n",
    "                if (len(cr_codes_seq) > 0 and code in cr_codes_seq[-1]) \\\n",
    "                    or (len(cr_codes_seq) > 1 and code in cr_codes_seq[-2]):\n",
    "                    # get list\n",
    "                    lst = cr_seq_lens[code]\n",
    "                    # remove last entry\n",
    "                    last_item = lst.pop()\n",
    "                    lst.append(last_item+1)\n",
    "                else:\n",
    "                    cr_seq_lens[code].append(1)\n",
    "            # reset last_ccodes\n",
    "            cr_codes_seq.append(cr_codes)\n",
    "                    \n",
    "        # update sent stats\n",
    "        if has_cr_in_sent:\n",
    "            cr_sents.append(sentence)\n",
    "            sents_with_causal +=1\n",
    "            if has_overlapping_cr_in_sent:\n",
    "                sents_with_overlapping_causal +=1\n",
    "            if len(unique_causal) > 1:\n",
    "                sents_with_multiple_causal +=1\n",
    "        num_sents +=1\n",
    "        # end update sent       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167656, 0.21056806794865676)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words, words_with_causal/float(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10198, 0.2727005295155913)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents, sents_with_causal/ float(num_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167656, 35303, 4883, 0.1383168569243407)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words, words_with_causal, words_with_overlapping_causal, words_with_overlapping_causal/float(words_with_causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10198, 2781, 619, 676, 0.22258180510607695)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sents, sents_with_causal, sents_with_overlapping_causal, sents_with_multiple_causal, sents_with_overlapping_causal/ float(sents_with_causal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% words with cr codes: \t \t \t 21.0568%\n",
      "% words with multiple cr codes: \t 2.9125%\n",
      "\n",
      "% sents with cr codes: \t \t \t 27.2701%\n",
      "% sents with multiple cr codes: \t 6.6288%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "print(\"% words with cr codes: \\t \\t \\t {pct:.4f}%\".format(pct=100*words_with_causal/ num_words) )\n",
    "print(\"% words with multiple cr codes: \\t {pct:.4f}%\".format(pct=100*words_with_overlapping_causal/ num_words) )\n",
    "print(\"\")\n",
    "print(\"% sents with cr codes: \\t \\t \\t {pct:.4f}%\".format(pct=100*sents_with_causal/ num_sents) )\n",
    "print(\"% sents with multiple cr codes: \\t {pct:.4f}%\".format(pct=100*sents_with_multiple_causal/ num_sents) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Relation Sequence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All        - 11.17\n"
     ]
    }
   ],
   "source": [
    "all_cr_lens = []\n",
    "for code in sorted(cr_seq_lens.keys()):\n",
    "    #print(\"{code} - {mean_len:.2f}\".format(code=code.ljust(10), mean_len=np.mean(cr_seq_lens[code])))\n",
    "    all_cr_lens.extend(cr_seq_lens[code])\n",
    "print(\"{code} - {mean_len:.2f}\".format(code=\"All\".ljust(10), mean_len=np.mean(all_cr_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
