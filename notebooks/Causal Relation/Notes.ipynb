{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code locations:\n",
    "\n",
    "1. RNN Tagger:    See notebooks in /PythonNlpResearch/tree/master/notebooks/Keras\n",
    "2. Stacked Model: See notebooks in /PythonNlpResearch/tree/master/notebooks/Keras\n",
    "3. Shift-Reduce Parser: See scripts in \n",
    "  * PythonNlpResearch/tree/master/Experiments/CoralBleachingCausalRelation\n",
    "  * PythonNlpResearch/tree/master/Experiments/SkinCancerCausalRelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling of 'Causer:50' and 'Result:1' Type Tags \n",
    "\n",
    "When working on RQ2, I discovered there are quite a few examples where a word is tagged with a 'Causer:3' or 'Result:5' sort of tag, but NOT with the underlying concept code, which is often missing from the entire sentence in that case. That makes it very hard for the stacked model and shift reduce parser to pick up those relations and so negatively impacted their performance w.r.t. the RNN classifier. So I went back and retroactively inserted those missing tags for the Causal Relation Work. I did NOT do this for the RNN, as that was trained on causal relations as actual labels, and so was not impacted by this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
