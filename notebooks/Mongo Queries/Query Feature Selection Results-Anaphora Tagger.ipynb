{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pymongo\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def group_by(df, bycols, agg_map):\n",
    "    \"\"\"\n",
    "\n",
    "    @param df:      DataFrame\n",
    "    @param bycols:  str or list\n",
    "                        Column(s) to group by\n",
    "    @param agg_map: dictionary or list of 2-tuples\n",
    "                        Mapping from column to aggregate function e.g. [(\"city\", \"count\"), (\"salary\", \"mean\"]\n",
    "    @return:        DataFrame\n",
    "                        Flattened dataframe, with multi-level index removed\n",
    "    \"\"\"\n",
    "    grps = []\n",
    "    if type(bycols) == str:\n",
    "        bycols = [bycols]\n",
    "\n",
    "    if type(agg_map) == dict:\n",
    "        agg_map = agg_map.items()\n",
    "\n",
    "    for k,v in agg_map:\n",
    "        grp = df[bycols + [k]].groupby(bycols, ).agg(v)\n",
    "        grp.reset_index(inplace=True)\n",
    "        grp[\"%s(%s)\" % (v,k)] = grp[k]\n",
    "        del grp[k]\n",
    "        grps.append(grp)\n",
    "\n",
    "    m = grps[0]\n",
    "    for grp in grps[1:]:\n",
    "        m = pd.merge(m, grp, on=bycols, how=\"inner\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_coref_new'), 'CB_TAGGING_TD_FEAT_SELECTION'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_coref_new'), 'CB_TAGGING_VD_FEAT_SELECTION'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_coref_new'), 'SC_TAGGING_TD_FEAT_SELECTION'),\n",
       " Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'metrics_coref_new'), 'SC_TAGGING_VD_FEAT_SELECTION'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client.metrics_coref_new\n",
    "\n",
    "cb_td, cb_vd, sc_td, sc_vd = \"CB_TAGGING_TD_FEAT_SELECTION\", \"CB_TAGGING_VD_FEAT_SELECTION\", \\\n",
    "    \"SC_TAGGING_TD_FEAT_SELECTION\", \"SC_TAGGING_VD_FEAT_SELECTION\",\n",
    "cb_td, cb_vd, sc_td, sc_vd = db[cb_td], db[cb_vd], db[sc_td], db[sc_vd]\n",
    "cb_td, cb_vd, sc_td, sc_vd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 242 293 293\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from bson.son import SON # needed to ensure dictionary is ordered (python default is not)\n",
    "\n",
    "feats_pipeline = [{\n",
    "    \"$project\": { \n",
    "            \"weighted_f1_score\":\"$WEIGHTED_MEAN_CONCEPT_CODES.f1_score\",\n",
    "            \"micro_f1_score\":  \"$MICRO_F1.f1_score\",\n",
    "            \"micro_recall\":    \"$MICRO_F1.recall\",\n",
    "            \"micro_precision\": \"$MICRO_F1.precision\",\n",
    "            #\"stemmed\":        \"$parameters.stemmed\",\n",
    "            #\"num_feats\":      \"$parameters.num_feats_MEAN\",\n",
    "            \"feats\":          \"$parameters.extractors\",\n",
    "            \"count\": {        \"$size\" : \"$parameters.extractors\" },\n",
    "            \"asof\" :          \"$asof\",\n",
    "            \"_id\":1\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"$match\":{\n",
    "        \"micro_f1_score\": { \"$exists\" : True },\n",
    "        # how many feats\n",
    "        #\"count\": {          \"$eq\" :1 },\n",
    "        # window width\n",
    "        #\"window_size\": {    \"$eq\":13 }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"$sort\":{\n",
    "        #\"weighted_f1_score\":-1,\n",
    "        \"micro_f1_score\": -1\n",
    "        #\"asof\": -1\n",
    "        #\"count\": -1\n",
    "    }\n",
    "},\n",
    "]\n",
    "\n",
    "cb_td_rows = [row for row in cb_td.aggregate(feats_pipeline)]\n",
    "cb_vd_rows = [row for row in cb_vd.aggregate(feats_pipeline)]\n",
    "sc_td_rows = [row for row in sc_td.aggregate(feats_pipeline)]\n",
    "sc_vd_rows = [row for row in sc_vd.aggregate(feats_pipeline)]\n",
    "\n",
    "print(len(cb_td_rows), len(cb_vd_rows), len(sc_td_rows), len(sc_vd_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>asof</th>\n",
       "      <th>count</th>\n",
       "      <th>feats</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>weighted_f1_score</th>\n",
       "      <th>hs_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b594e509d1fa2c2325787b7</td>\n",
       "      <td>2018-07-25 23:30:08.857</td>\n",
       "      <td>5</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fn_bow_ngram_feat[ngram_size:1 offset:4]|fn_po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b59513c9d1fa2c2325787bf</td>\n",
       "      <td>2018-07-25 23:42:36.274</td>\n",
       "      <td>6</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fn_bow_ngram_feat[ngram_size:1 offset:4]|fn_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b594fc29d1fa2c2325787bb</td>\n",
       "      <td>2018-07-25 23:36:18.773</td>\n",
       "      <td>6</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fn_bow_POS_feats[offset:4]|fn_bow_ngram_feat[n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                    asof  count  \\\n",
       "0  5b594e509d1fa2c2325787b7 2018-07-25 23:30:08.857      5   \n",
       "1  5b59513c9d1fa2c2325787bf 2018-07-25 23:42:36.274      6   \n",
       "2  5b594fc29d1fa2c2325787bb 2018-07-25 23:36:18.773      6   \n",
       "\n",
       "                                               feats  micro_f1_score  \\\n",
       "0  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...        0.299145   \n",
       "1  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...        0.291845   \n",
       "2  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...        0.285714   \n",
       "\n",
       "   micro_precision  micro_recall  weighted_f1_score  \\\n",
       "0         0.546875      0.205882                0.0   \n",
       "1         0.539683      0.200000                0.0   \n",
       "2         0.500000      0.200000                0.0   \n",
       "\n",
       "                                            hs_feats  \n",
       "0  fn_bow_ngram_feat[ngram_size:1 offset:4]|fn_po...  \n",
       "1  fn_bow_ngram_feat[ngram_size:1 offset:4]|fn_bo...  \n",
       "2  fn_bow_POS_feats[offset:4]|fn_bow_ngram_feat[n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_feats(fts):\n",
    "    return \"|\".join(sorted(fts))\n",
    "\n",
    "def get_df_sorted_by_f1score(rows):\n",
    "    df = pd.DataFrame(rows).sort_values(\"micro_f1_score\", ascending=False)\n",
    "    df[\"hs_feats\"] = df[\"feats\"].apply(hash_feats)\n",
    "    return df\n",
    "\n",
    "cb_td_df = get_df_sorted_by_f1score(cb_td_rows)\n",
    "cb_vd_df = get_df_sorted_by_f1score(cb_vd_rows)\n",
    "sc_td_df = get_df_sorted_by_f1score(sc_td_rows)\n",
    "sc_vd_df = get_df_sorted_by_f1score(sc_vd_rows)\n",
    "\n",
    "cb_vd_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2018-07-25T21:24:55.611000000'),\n",
       " numpy.datetime64('2018-07-26T03:17:39.975000000'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(cb_vd_df[\"asof\"].values),max(cb_vd_df[\"asof\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.datetime64('2018-07-29T10:30:50.220000000'),\n",
       " numpy.datetime64('2018-07-29T17:54:26.759000000'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sc_vd_df[\"asof\"].values),max(sc_vd_df[\"asof\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = \"feats,count,micro_f1_score,micro_recall,micro_precision\".split(\",\")\n",
    "\n",
    "def feat_name(ft):\n",
    "    if type(ft) == list:\n",
    "        ft=\",\".join(ft)\n",
    "    offset = (11-1)/2\n",
    "    offset_lbl = \"offset:%i\" % offset\n",
    "    ft=ft.replace(offset_lbl, \"\").replace(\"fn_\", \"\").replace(\" \",\"\")\n",
    "    return ft\n",
    "\n",
    "def get_top_individual_feats(df, stemmed=True):\n",
    "    df_top_individual_feats = df[(df[\"count\"] == 1)][cols]\n",
    "    df_top_individual_feats[\"rank\"] = np.arange(len(df_top_individual_feats)) + 1\n",
    "    df_top_individual_feats[\"feats\"] = df_top_individual_feats[\"feats\"].apply(feat_name)\n",
    "    return df_top_individual_feats\n",
    "\n",
    "#get_top_individual_feats(cb_vd_df, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Each Feature In Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats_CB</th>\n",
       "      <th>count_CB</th>\n",
       "      <th>micro_f1_score_CB</th>\n",
       "      <th>micro_recall_CB</th>\n",
       "      <th>micro_precision_CB</th>\n",
       "      <th>rank</th>\n",
       "      <th>feats_SC</th>\n",
       "      <th>count_SC</th>\n",
       "      <th>micro_f1_score_SC</th>\n",
       "      <th>micro_recall_SC</th>\n",
       "      <th>micro_precision_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247492</td>\n",
       "      <td>0.155789</td>\n",
       "      <td>0.601626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_wd_feats_stemmed[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>2</td>\n",
       "      <td>pos_wd_feats[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.151579</td>\n",
       "      <td>0.637168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_wd_feats[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>pos_wd_feats_stemmed[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243655</td>\n",
       "      <td>0.151579</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227603</td>\n",
       "      <td>0.138235</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>4</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239168</td>\n",
       "      <td>0.145263</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos_wd_feats[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224880</td>\n",
       "      <td>0.138235</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>5</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235094</td>\n",
       "      <td>0.145263</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos_wd_feats[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220624</td>\n",
       "      <td>0.135294</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>6</td>\n",
       "      <td>pos_wd_feats[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235094</td>\n",
       "      <td>0.145263</td>\n",
       "      <td>0.616071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>7</td>\n",
       "      <td>pos_wd_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228471</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.691489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193069</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>8</td>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220641</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.712644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.192593</td>\n",
       "      <td>0.114706</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>9</td>\n",
       "      <td>pos_wd_feats[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217993</td>\n",
       "      <td>0.132632</td>\n",
       "      <td>0.611650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190955</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>10</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217469</td>\n",
       "      <td>0.128421</td>\n",
       "      <td>0.709302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188295</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>11</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217082</td>\n",
       "      <td>0.128421</td>\n",
       "      <td>0.701149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182741</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212996</td>\n",
       "      <td>0.124211</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pos_wd_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.180905</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>13</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179551</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>14</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211849</td>\n",
       "      <td>0.124211</td>\n",
       "      <td>0.719512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pos_ngram_feat[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>15</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.122105</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>16</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206406</td>\n",
       "      <td>0.122105</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>17</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205776</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>18</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.686747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170426</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>19</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.117895</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201802</td>\n",
       "      <td>0.117895</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159794</td>\n",
       "      <td>0.091176</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>21</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201097</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.763889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153453</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>22</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198915</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.149871</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>23</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196721</td>\n",
       "      <td>0.113684</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.082353</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>24</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196660</td>\n",
       "      <td>0.111579</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141361</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>25</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196007</td>\n",
       "      <td>0.113684</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>26</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.107368</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130890</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>27</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186472</td>\n",
       "      <td>0.107368</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.061765</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>28</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183178</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109290</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>29</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181481</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.753846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106952</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>30</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.173112</td>\n",
       "      <td>0.098947</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>42</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150579</td>\n",
       "      <td>0.082105</td>\n",
       "      <td>0.906977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>43</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145315</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>bow_ngram_feat[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>44</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139963</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>45</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138728</td>\n",
       "      <td>0.075789</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pos_wd_feats[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>46</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134357</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>47</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130354</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>0.564516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>48</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126923</td>\n",
       "      <td>0.069474</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>49</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125693</td>\n",
       "      <td>0.071579</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>50</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125461</td>\n",
       "      <td>0.071579</td>\n",
       "      <td>0.507463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bow_POS_feats[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124756</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>pos_POS_feats[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55</td>\n",
       "      <td>pos_POS_feats[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>pos_POS_feats[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>pos_POS_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59</td>\n",
       "      <td>bow_POS_feats[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>bow_POS_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>pos_POS_feats[offset:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>bow_POS_feats[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>bow_POS_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pos_wd_feats_stemmed[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>pos_POS_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>pos_wd_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>pos_wd_feats[offset:0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>bow_POS_feats[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>bow_POS_feats[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66</td>\n",
       "      <td>pos_POS_feats[offset:6]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bow_POS_feats[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67</td>\n",
       "      <td>bow_POS_feats[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>bow_POS_feats[offset:4]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>bow_POS_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>bow_POS_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pos_POS_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>pos_POS_feats[offset:3]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>bow_POS_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71</td>\n",
       "      <td>bow_POS_feats[offset:2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feats_CB  count_CB  micro_f1_score_CB  \\\n",
       "0                 pos_wd_feats_stemmed[offset:6]         1           0.240000   \n",
       "1                         pos_wd_feats_stemmed[]         1           0.239437   \n",
       "2                         pos_wd_feats[offset:6]         1           0.228571   \n",
       "3                 pos_wd_feats_stemmed[offset:4]         1           0.227603   \n",
       "4                                 pos_wd_feats[]         1           0.224880   \n",
       "5                         pos_wd_feats[offset:4]         1           0.220624   \n",
       "6                 pos_wd_feats_stemmed[offset:3]         1           0.196078   \n",
       "7   pos_ngram_feat_stemmed[ngram_size:2offset:6]         1           0.193069   \n",
       "8           pos_ngram_feat_stemmed[ngram_size:2]         1           0.192593   \n",
       "9                 pos_wd_feats_stemmed[offset:2]         1           0.190955   \n",
       "10                        pos_wd_feats[offset:2]         1           0.188295   \n",
       "11  pos_ngram_feat_stemmed[ngram_size:3offset:6]         1           0.182741   \n",
       "12                        pos_wd_feats[offset:3]         1           0.180905   \n",
       "13          pos_ngram_feat[ngram_size:2offset:6]         1           0.179551   \n",
       "14                  pos_ngram_feat[ngram_size:2]         1           0.179104   \n",
       "15          pos_ngram_feat_stemmed[ngram_size:3]         1           0.177215   \n",
       "16  pos_ngram_feat_stemmed[ngram_size:2offset:3]         1           0.175000   \n",
       "17  pos_ngram_feat_stemmed[ngram_size:2offset:4]         1           0.175000   \n",
       "18          pos_ngram_feat[ngram_size:2offset:4]         1           0.170426   \n",
       "19          pos_ngram_feat[ngram_size:3offset:6]         1           0.164948   \n",
       "20                  pos_ngram_feat[ngram_size:3]         1           0.159794   \n",
       "21          pos_ngram_feat[ngram_size:2offset:3]         1           0.153453   \n",
       "22  pos_ngram_feat_stemmed[ngram_size:3offset:4]         1           0.149871   \n",
       "23  pos_ngram_feat_stemmed[ngram_size:2offset:2]         1           0.145455   \n",
       "24          pos_ngram_feat[ngram_size:3offset:4]         1           0.141361   \n",
       "25  pos_ngram_feat_stemmed[ngram_size:3offset:3]         1           0.140625   \n",
       "26          pos_ngram_feat[ngram_size:3offset:3]         1           0.130890   \n",
       "27          pos_ngram_feat[ngram_size:2offset:2]         1           0.110526   \n",
       "28          bow_ngram_feat[ngram_size:3offset:2]         1           0.109290   \n",
       "29          pos_ngram_feat[ngram_size:3offset:2]         1           0.106952   \n",
       "..                                           ...       ...                ...   \n",
       "41          bow_ngram_feat[ngram_size:1offset:2]         1           0.017241   \n",
       "42          bow_ngram_feat[ngram_size:2offset:4]         1           0.017045   \n",
       "43                  bow_ngram_feat[ngram_size:2]         1           0.011494   \n",
       "44  pos_ngram_feat_stemmed[ngram_size:2offset:1]         1           0.011396   \n",
       "45                        pos_wd_feats[offset:1]         1           0.005831   \n",
       "46          bow_ngram_feat[ngram_size:2offset:6]         1           0.005814   \n",
       "47          bow_ngram_feat[ngram_size:3offset:6]         1           0.005797   \n",
       "48          bow_ngram_feat[ngram_size:1offset:6]         1           0.005747   \n",
       "49          bow_ngram_feat[ngram_size:1offset:3]         1           0.005731   \n",
       "50                       bow_POS_feats[offset:1]         1           0.000000   \n",
       "51          bow_ngram_feat[ngram_size:1offset:1]         1           0.000000   \n",
       "52                pos_wd_feats_stemmed[offset:1]         1           0.000000   \n",
       "53                       pos_POS_feats[offset:1]         1           0.000000   \n",
       "54  pos_ngram_feat_stemmed[ngram_size:3offset:1]         1           0.000000   \n",
       "55          pos_ngram_feat[ngram_size:3offset:1]         1           0.000000   \n",
       "56          bow_ngram_feat[ngram_size:3offset:1]         1           0.000000   \n",
       "57                       pos_POS_feats[offset:0]         1           0.000000   \n",
       "58                       pos_POS_feats[offset:2]         1           0.000000   \n",
       "59                       bow_POS_feats[offset:0]         1           0.000000   \n",
       "60                       bow_POS_feats[offset:6]         1           0.000000   \n",
       "61                pos_wd_feats_stemmed[offset:0]         1           0.000000   \n",
       "62          bow_ngram_feat[ngram_size:1offset:0]         1           0.000000   \n",
       "63                        pos_wd_feats[offset:0]         1           0.000000   \n",
       "64                               bow_POS_feats[]         1           0.000000   \n",
       "65                  bow_ngram_feat[ngram_size:1]         1           0.000000   \n",
       "66                       bow_POS_feats[offset:4]         1           0.000000   \n",
       "67          bow_ngram_feat[ngram_size:1offset:4]         1           0.000000   \n",
       "68                       bow_POS_feats[offset:3]         1           0.000000   \n",
       "69                       pos_POS_feats[offset:3]         1           0.000000   \n",
       "70                       bow_POS_feats[offset:2]         1           0.000000   \n",
       "\n",
       "    micro_recall_CB  micro_precision_CB  rank  \\\n",
       "0          0.150000            0.600000     1   \n",
       "1          0.150000            0.593023     2   \n",
       "2          0.141176            0.600000     3   \n",
       "3          0.138235            0.643836     4   \n",
       "4          0.138235            0.602564     5   \n",
       "5          0.135294            0.597403     6   \n",
       "6          0.117647            0.588235     7   \n",
       "7          0.114706            0.609375     8   \n",
       "8          0.114706            0.600000     9   \n",
       "9          0.111765            0.655172    10   \n",
       "10         0.108824            0.698113    11   \n",
       "11         0.105882            0.666667    12   \n",
       "12         0.105882            0.620690    13   \n",
       "13         0.105882            0.590164    14   \n",
       "14         0.105882            0.580645    15   \n",
       "15         0.102941            0.636364    16   \n",
       "16         0.102941            0.583333    17   \n",
       "17         0.102941            0.583333    18   \n",
       "18         0.100000            0.576271    19   \n",
       "19         0.094118            0.666667    20   \n",
       "20         0.091176            0.645833    21   \n",
       "21         0.088235            0.588235    22   \n",
       "22         0.085294            0.617021    23   \n",
       "23         0.082353            0.622222    24   \n",
       "24         0.079412            0.642857    25   \n",
       "25         0.079412            0.613636    26   \n",
       "26         0.073529            0.595238    27   \n",
       "27         0.061765            0.525000    28   \n",
       "28         0.058824            0.769231    29   \n",
       "29         0.058824            0.588235    30   \n",
       "..              ...                 ...   ...   \n",
       "41         0.008824            0.375000    42   \n",
       "42         0.008824            0.250000    43   \n",
       "43         0.005882            0.250000    44   \n",
       "44         0.005882            0.181818    45   \n",
       "45         0.002941            0.333333    46   \n",
       "46         0.002941            0.250000    47   \n",
       "47         0.002941            0.200000    48   \n",
       "48         0.002941            0.125000    49   \n",
       "49         0.002941            0.111111    50   \n",
       "50         0.000000            0.000000    51   \n",
       "51         0.000000            0.000000    52   \n",
       "52         0.000000            0.000000    53   \n",
       "53         0.000000            0.000000    54   \n",
       "54         0.000000            0.000000    55   \n",
       "55         0.000000            0.000000    56   \n",
       "56         0.000000            0.000000    57   \n",
       "57         0.000000            0.000000    58   \n",
       "58         0.000000            0.000000    59   \n",
       "59         0.000000            0.000000    60   \n",
       "60         0.000000            0.000000    61   \n",
       "61         0.000000            0.000000    62   \n",
       "62         0.000000            0.000000    63   \n",
       "63         0.000000            0.000000    64   \n",
       "64         0.000000            0.000000    65   \n",
       "65         0.000000            0.000000    66   \n",
       "66         0.000000            0.000000    67   \n",
       "67         0.000000            0.000000    68   \n",
       "68         0.000000            0.000000    69   \n",
       "69         0.000000            0.000000    70   \n",
       "70         0.000000            0.000000    71   \n",
       "\n",
       "                                        feats_SC  count_SC  micro_f1_score_SC  \\\n",
       "0                 pos_wd_feats_stemmed[offset:6]         1           0.247492   \n",
       "1                                 pos_wd_feats[]         1           0.244898   \n",
       "2                         pos_wd_feats_stemmed[]         1           0.243655   \n",
       "3                 pos_wd_feats_stemmed[offset:3]         1           0.239168   \n",
       "4                 pos_wd_feats_stemmed[offset:4]         1           0.235094   \n",
       "5                         pos_wd_feats[offset:6]         1           0.235094   \n",
       "6                         pos_wd_feats[offset:3]         1           0.228471   \n",
       "7                         pos_wd_feats[offset:2]         1           0.220641   \n",
       "8                         pos_wd_feats[offset:4]         1           0.217993   \n",
       "9   pos_ngram_feat_stemmed[ngram_size:2offset:6]         1           0.217469   \n",
       "10          pos_ngram_feat_stemmed[ngram_size:2]         1           0.217082   \n",
       "11  pos_ngram_feat_stemmed[ngram_size:2offset:3]         1           0.212996   \n",
       "12  pos_ngram_feat_stemmed[ngram_size:2offset:4]         1           0.212766   \n",
       "13                  pos_ngram_feat[ngram_size:2]         1           0.211849   \n",
       "14          pos_ngram_feat[ngram_size:2offset:6]         1           0.209386   \n",
       "15                pos_wd_feats_stemmed[offset:2]         1           0.206406   \n",
       "16  pos_ngram_feat_stemmed[ngram_size:3offset:6]         1           0.205776   \n",
       "17          pos_ngram_feat_stemmed[ngram_size:3]         1           0.204301   \n",
       "18          pos_ngram_feat[ngram_size:3offset:6]         1           0.202899   \n",
       "19          pos_ngram_feat[ngram_size:2offset:4]         1           0.201802   \n",
       "20          pos_ngram_feat[ngram_size:2offset:3]         1           0.201097   \n",
       "21  pos_ngram_feat_stemmed[ngram_size:3offset:4]         1           0.198915   \n",
       "22  pos_ngram_feat_stemmed[ngram_size:2offset:2]         1           0.196721   \n",
       "23          pos_ngram_feat[ngram_size:2offset:1]         1           0.196660   \n",
       "24                  pos_ngram_feat[ngram_size:3]         1           0.196007   \n",
       "25  pos_ngram_feat_stemmed[ngram_size:2offset:1]         1           0.188889   \n",
       "26          pos_ngram_feat[ngram_size:3offset:4]         1           0.186472   \n",
       "27          bow_ngram_feat[ngram_size:2offset:1]         1           0.183178   \n",
       "28          pos_ngram_feat[ngram_size:2offset:2]         1           0.181481   \n",
       "29  pos_ngram_feat_stemmed[ngram_size:3offset:3]         1           0.173112   \n",
       "..                                           ...       ...                ...   \n",
       "41                  bow_ngram_feat[ngram_size:3]         1           0.150579   \n",
       "42          pos_ngram_feat[ngram_size:3offset:2]         1           0.145315   \n",
       "43          bow_ngram_feat[ngram_size:1offset:4]         1           0.139963   \n",
       "44                  bow_ngram_feat[ngram_size:2]         1           0.138728   \n",
       "45          bow_ngram_feat[ngram_size:2offset:4]         1           0.134357   \n",
       "46          bow_ngram_feat[ngram_size:1offset:3]         1           0.130354   \n",
       "47          bow_ngram_feat[ngram_size:1offset:2]         1           0.126923   \n",
       "48          bow_ngram_feat[ngram_size:1offset:6]         1           0.125693   \n",
       "49                  bow_ngram_feat[ngram_size:1]         1           0.125461   \n",
       "50          bow_ngram_feat[ngram_size:3offset:6]         1           0.124756   \n",
       "51          bow_ngram_feat[ngram_size:3offset:1]         1           0.091633   \n",
       "52  pos_ngram_feat_stemmed[ngram_size:3offset:1]         1           0.091633   \n",
       "53          pos_ngram_feat[ngram_size:3offset:1]         1           0.091633   \n",
       "54                       pos_POS_feats[offset:4]         1           0.004141   \n",
       "55                               pos_POS_feats[]         1           0.004124   \n",
       "56          bow_ngram_feat[ngram_size:1offset:0]         1           0.000000   \n",
       "57                       pos_POS_feats[offset:2]         1           0.000000   \n",
       "58                       bow_POS_feats[offset:1]         1           0.000000   \n",
       "59                       pos_POS_feats[offset:1]         1           0.000000   \n",
       "60                       bow_POS_feats[offset:0]         1           0.000000   \n",
       "61                       pos_POS_feats[offset:0]         1           0.000000   \n",
       "62                pos_wd_feats_stemmed[offset:0]         1           0.000000   \n",
       "63                        pos_wd_feats[offset:0]         1           0.000000   \n",
       "64                       bow_POS_feats[offset:6]         1           0.000000   \n",
       "65                       pos_POS_feats[offset:6]         1           0.000000   \n",
       "66                               bow_POS_feats[]         1           0.000000   \n",
       "67                       bow_POS_feats[offset:4]         1           0.000000   \n",
       "68                       bow_POS_feats[offset:3]         1           0.000000   \n",
       "69                       pos_POS_feats[offset:3]         1           0.000000   \n",
       "70                       bow_POS_feats[offset:2]         1           0.000000   \n",
       "\n",
       "    micro_recall_SC  micro_precision_SC  \n",
       "0          0.155789            0.601626  \n",
       "1          0.151579            0.637168  \n",
       "2          0.151579            0.620690  \n",
       "3          0.145263            0.676471  \n",
       "4          0.145263            0.616071  \n",
       "5          0.145263            0.616071  \n",
       "6          0.136842            0.691489  \n",
       "7          0.130526            0.712644  \n",
       "8          0.132632            0.611650  \n",
       "9          0.128421            0.709302  \n",
       "10         0.128421            0.701149  \n",
       "11         0.124211            0.746835  \n",
       "12         0.126316            0.674157  \n",
       "13         0.124211            0.719512  \n",
       "14         0.122105            0.734177  \n",
       "15         0.122105            0.666667  \n",
       "16         0.120000            0.721519  \n",
       "17         0.120000            0.686747  \n",
       "18         0.117895            0.727273  \n",
       "19         0.117895            0.700000  \n",
       "20         0.115789            0.763889  \n",
       "21         0.115789            0.705128  \n",
       "22         0.113684            0.729730  \n",
       "23         0.111579            0.828125  \n",
       "24         0.113684            0.710526  \n",
       "25         0.107368            0.784615  \n",
       "26         0.107368            0.708333  \n",
       "27         0.103158            0.816667  \n",
       "28         0.103158            0.753846  \n",
       "29         0.098947            0.691176  \n",
       "..              ...                 ...  \n",
       "41         0.082105            0.906977  \n",
       "42         0.080000            0.791667  \n",
       "43         0.080000            0.558824  \n",
       "44         0.075789            0.818182  \n",
       "45         0.073684            0.760870  \n",
       "46         0.073684            0.564516  \n",
       "47         0.069474            0.733333  \n",
       "48         0.071579            0.515152  \n",
       "49         0.071579            0.507463  \n",
       "50         0.067368            0.842105  \n",
       "51         0.048421            0.851852  \n",
       "52         0.048421            0.851852  \n",
       "53         0.048421            0.851852  \n",
       "54         0.002105            0.125000  \n",
       "55         0.002105            0.100000  \n",
       "56         0.000000            0.000000  \n",
       "57         0.000000            0.000000  \n",
       "58         0.000000            0.000000  \n",
       "59         0.000000            0.000000  \n",
       "60         0.000000            0.000000  \n",
       "61         0.000000            0.000000  \n",
       "62         0.000000            0.000000  \n",
       "63         0.000000            0.000000  \n",
       "64         0.000000            0.000000  \n",
       "65         0.000000            0.000000  \n",
       "66         0.000000            0.000000  \n",
       "67         0.000000            0.000000  \n",
       "68         0.000000            0.000000  \n",
       "69         0.000000            0.000000  \n",
       "70         0.000000            0.000000  \n",
       "\n",
       "[71 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "stemmed = True\n",
    "a, b = get_top_individual_feats(cb_vd_df, True), get_top_individual_feats(sc_vd_df, True)\n",
    "# merged = pd.merge(a,b, on=\"rank\", suffixes=[\"_CB\",\"_SC\"])\\\n",
    "# [\"rank,feats_CB,micro_f1_score_CB,micro_recall_CB,micro_precision_CB,num_feats_CB,feats_SC,micro_f1_score_SC,micro_recall_SC,micro_precision_SC,num_feats_SC\".split(\",\")]\n",
    "merged = pd.merge(a,b, on=\"rank\", suffixes=[\"_CB\",\"_SC\"])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>feats_CB</th>\n",
       "      <th>micro_f1_score_CB</th>\n",
       "      <th>feats_SC</th>\n",
       "      <th>micro_f1_score_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:6]</td>\n",
       "      <td>0.240</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:6]</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pos_wd_feats_stemmed[]</td>\n",
       "      <td>0.239</td>\n",
       "      <td>pos_wd_feats[]</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pos_wd_feats[offset:6]</td>\n",
       "      <td>0.229</td>\n",
       "      <td>pos_wd_feats_stemmed[]</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>0.228</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:3]</td>\n",
       "      <td>0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pos_wd_feats[]</td>\n",
       "      <td>0.225</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>pos_wd_feats[offset:4]</td>\n",
       "      <td>0.221</td>\n",
       "      <td>pos_wd_feats[offset:6]</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:3]</td>\n",
       "      <td>0.196</td>\n",
       "      <td>pos_wd_feats[offset:3]</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:6]</td>\n",
       "      <td>0.193</td>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2]</td>\n",
       "      <td>0.193</td>\n",
       "      <td>pos_wd_feats[offset:4]</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:2]</td>\n",
       "      <td>0.191</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:6]</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>0.188</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2]</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:6]</td>\n",
       "      <td>0.183</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:3]</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>pos_wd_feats[offset:3]</td>\n",
       "      <td>0.181</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>0.180</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2]</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2]</td>\n",
       "      <td>0.179</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3]</td>\n",
       "      <td>0.177</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:2]</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:3]</td>\n",
       "      <td>0.175</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:6]</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>0.175</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3]</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.170</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>0.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>0.165</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3]</td>\n",
       "      <td>0.160</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:3]</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:3]</td>\n",
       "      <td>0.153</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>0.150</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:2]</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:2]</td>\n",
       "      <td>0.145</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:1]</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:4]</td>\n",
       "      <td>0.141</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3]</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:3]</td>\n",
       "      <td>0.141</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:1]</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:3]</td>\n",
       "      <td>0.131</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:4]</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.111</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:1]</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>0.109</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>0.107</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:3]</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>0.017</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3]</td>\n",
       "      <td>0.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.017</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2]</td>\n",
       "      <td>0.011</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:1]</td>\n",
       "      <td>0.011</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2]</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>pos_wd_feats[offset:1]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:6]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:3]</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:6]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:6]</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:3]</td>\n",
       "      <td>0.006</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1]</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>bow_POS_feats[offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:6]</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:1]</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>pos_POS_feats[offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:4]</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[]</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>bow_ngram_feat[ngram_size:3offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>pos_POS_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>bow_POS_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:1]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>bow_POS_feats[offset:6]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>pos_wd_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_wd_feats[offset:0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>bow_POS_feats[]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:6]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:6]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>bow_POS_feats[offset:4]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:4]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>bow_POS_feats[offset:3]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:3]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>pos_POS_feats[offset:3]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>pos_POS_feats[offset:3]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>bow_POS_feats[offset:2]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bow_POS_feats[offset:2]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank                                      feats_CB micro_f1_score_CB  \\\n",
       "0      1                pos_wd_feats_stemmed[offset:6]             0.240   \n",
       "1      2                        pos_wd_feats_stemmed[]             0.239   \n",
       "2      3                        pos_wd_feats[offset:6]             0.229   \n",
       "3      4                pos_wd_feats_stemmed[offset:4]             0.228   \n",
       "4      5                                pos_wd_feats[]             0.225   \n",
       "5      6                        pos_wd_feats[offset:4]             0.221   \n",
       "6      7                pos_wd_feats_stemmed[offset:3]             0.196   \n",
       "7      8  pos_ngram_feat_stemmed[ngram_size:2offset:6]             0.193   \n",
       "8      9          pos_ngram_feat_stemmed[ngram_size:2]             0.193   \n",
       "9     10                pos_wd_feats_stemmed[offset:2]             0.191   \n",
       "10    11                        pos_wd_feats[offset:2]             0.188   \n",
       "11    12  pos_ngram_feat_stemmed[ngram_size:3offset:6]             0.183   \n",
       "12    13                        pos_wd_feats[offset:3]             0.181   \n",
       "13    14          pos_ngram_feat[ngram_size:2offset:6]             0.180   \n",
       "14    15                  pos_ngram_feat[ngram_size:2]             0.179   \n",
       "15    16          pos_ngram_feat_stemmed[ngram_size:3]             0.177   \n",
       "16    17  pos_ngram_feat_stemmed[ngram_size:2offset:3]             0.175   \n",
       "17    18  pos_ngram_feat_stemmed[ngram_size:2offset:4]             0.175   \n",
       "18    19          pos_ngram_feat[ngram_size:2offset:4]             0.170   \n",
       "19    20          pos_ngram_feat[ngram_size:3offset:6]             0.165   \n",
       "20    21                  pos_ngram_feat[ngram_size:3]             0.160   \n",
       "21    22          pos_ngram_feat[ngram_size:2offset:3]             0.153   \n",
       "22    23  pos_ngram_feat_stemmed[ngram_size:3offset:4]             0.150   \n",
       "23    24  pos_ngram_feat_stemmed[ngram_size:2offset:2]             0.145   \n",
       "24    25          pos_ngram_feat[ngram_size:3offset:4]             0.141   \n",
       "25    26  pos_ngram_feat_stemmed[ngram_size:3offset:3]             0.141   \n",
       "26    27          pos_ngram_feat[ngram_size:3offset:3]             0.131   \n",
       "27    28          pos_ngram_feat[ngram_size:2offset:2]             0.111   \n",
       "28    29          bow_ngram_feat[ngram_size:3offset:2]             0.109   \n",
       "29    30          pos_ngram_feat[ngram_size:3offset:2]             0.107   \n",
       "..   ...                                           ...               ...   \n",
       "41    42          bow_ngram_feat[ngram_size:1offset:2]             0.017   \n",
       "42    43          bow_ngram_feat[ngram_size:2offset:4]             0.017   \n",
       "43    44                  bow_ngram_feat[ngram_size:2]             0.011   \n",
       "44    45  pos_ngram_feat_stemmed[ngram_size:2offset:1]             0.011   \n",
       "45    46                        pos_wd_feats[offset:1]             0.006   \n",
       "46    47          bow_ngram_feat[ngram_size:2offset:6]             0.006   \n",
       "47    48          bow_ngram_feat[ngram_size:3offset:6]             0.006   \n",
       "48    49          bow_ngram_feat[ngram_size:1offset:6]             0.006   \n",
       "49    50          bow_ngram_feat[ngram_size:1offset:3]             0.006   \n",
       "50    51                       bow_POS_feats[offset:1]             0.000   \n",
       "51    52          bow_ngram_feat[ngram_size:1offset:1]             0.000   \n",
       "52    53                pos_wd_feats_stemmed[offset:1]             0.000   \n",
       "53    54                       pos_POS_feats[offset:1]             0.000   \n",
       "54    55  pos_ngram_feat_stemmed[ngram_size:3offset:1]             0.000   \n",
       "55    56          pos_ngram_feat[ngram_size:3offset:1]             0.000   \n",
       "56    57          bow_ngram_feat[ngram_size:3offset:1]             0.000   \n",
       "57    58                       pos_POS_feats[offset:0]             0.000   \n",
       "58    59                       pos_POS_feats[offset:2]             0.000   \n",
       "59    60                       bow_POS_feats[offset:0]             0.000   \n",
       "60    61                       bow_POS_feats[offset:6]             0.000   \n",
       "61    62                pos_wd_feats_stemmed[offset:0]             0.000   \n",
       "62    63          bow_ngram_feat[ngram_size:1offset:0]             0.000   \n",
       "63    64                        pos_wd_feats[offset:0]             0.000   \n",
       "64    65                               bow_POS_feats[]             0.000   \n",
       "65    66                  bow_ngram_feat[ngram_size:1]             0.000   \n",
       "66    67                       bow_POS_feats[offset:4]             0.000   \n",
       "67    68          bow_ngram_feat[ngram_size:1offset:4]             0.000   \n",
       "68    69                       bow_POS_feats[offset:3]             0.000   \n",
       "69    70                       pos_POS_feats[offset:3]             0.000   \n",
       "70    71                       bow_POS_feats[offset:2]             0.000   \n",
       "\n",
       "                                        feats_SC micro_f1_score_SC  \n",
       "0                 pos_wd_feats_stemmed[offset:6]             0.247  \n",
       "1                                 pos_wd_feats[]             0.245  \n",
       "2                         pos_wd_feats_stemmed[]             0.244  \n",
       "3                 pos_wd_feats_stemmed[offset:3]             0.239  \n",
       "4                 pos_wd_feats_stemmed[offset:4]             0.235  \n",
       "5                         pos_wd_feats[offset:6]             0.235  \n",
       "6                         pos_wd_feats[offset:3]             0.228  \n",
       "7                         pos_wd_feats[offset:2]             0.221  \n",
       "8                         pos_wd_feats[offset:4]             0.218  \n",
       "9   pos_ngram_feat_stemmed[ngram_size:2offset:6]             0.217  \n",
       "10          pos_ngram_feat_stemmed[ngram_size:2]             0.217  \n",
       "11  pos_ngram_feat_stemmed[ngram_size:2offset:3]             0.213  \n",
       "12  pos_ngram_feat_stemmed[ngram_size:2offset:4]             0.213  \n",
       "13                  pos_ngram_feat[ngram_size:2]             0.212  \n",
       "14          pos_ngram_feat[ngram_size:2offset:6]             0.209  \n",
       "15                pos_wd_feats_stemmed[offset:2]             0.206  \n",
       "16  pos_ngram_feat_stemmed[ngram_size:3offset:6]             0.206  \n",
       "17          pos_ngram_feat_stemmed[ngram_size:3]             0.204  \n",
       "18          pos_ngram_feat[ngram_size:3offset:6]             0.203  \n",
       "19          pos_ngram_feat[ngram_size:2offset:4]             0.202  \n",
       "20          pos_ngram_feat[ngram_size:2offset:3]             0.201  \n",
       "21  pos_ngram_feat_stemmed[ngram_size:3offset:4]             0.199  \n",
       "22  pos_ngram_feat_stemmed[ngram_size:2offset:2]             0.197  \n",
       "23          pos_ngram_feat[ngram_size:2offset:1]             0.197  \n",
       "24                  pos_ngram_feat[ngram_size:3]             0.196  \n",
       "25  pos_ngram_feat_stemmed[ngram_size:2offset:1]             0.189  \n",
       "26          pos_ngram_feat[ngram_size:3offset:4]             0.186  \n",
       "27          bow_ngram_feat[ngram_size:2offset:1]             0.183  \n",
       "28          pos_ngram_feat[ngram_size:2offset:2]             0.181  \n",
       "29  pos_ngram_feat_stemmed[ngram_size:3offset:3]             0.173  \n",
       "..                                           ...               ...  \n",
       "41                  bow_ngram_feat[ngram_size:3]             0.151  \n",
       "42          pos_ngram_feat[ngram_size:3offset:2]             0.145  \n",
       "43          bow_ngram_feat[ngram_size:1offset:4]             0.140  \n",
       "44                  bow_ngram_feat[ngram_size:2]             0.139  \n",
       "45          bow_ngram_feat[ngram_size:2offset:4]             0.134  \n",
       "46          bow_ngram_feat[ngram_size:1offset:3]             0.130  \n",
       "47          bow_ngram_feat[ngram_size:1offset:2]             0.127  \n",
       "48          bow_ngram_feat[ngram_size:1offset:6]             0.126  \n",
       "49                  bow_ngram_feat[ngram_size:1]             0.125  \n",
       "50          bow_ngram_feat[ngram_size:3offset:6]             0.125  \n",
       "51          bow_ngram_feat[ngram_size:3offset:1]             0.092  \n",
       "52  pos_ngram_feat_stemmed[ngram_size:3offset:1]             0.092  \n",
       "53          pos_ngram_feat[ngram_size:3offset:1]             0.092  \n",
       "54                       pos_POS_feats[offset:4]             0.004  \n",
       "55                               pos_POS_feats[]             0.004  \n",
       "56          bow_ngram_feat[ngram_size:1offset:0]             0.000  \n",
       "57                       pos_POS_feats[offset:2]             0.000  \n",
       "58                       bow_POS_feats[offset:1]             0.000  \n",
       "59                       pos_POS_feats[offset:1]             0.000  \n",
       "60                       bow_POS_feats[offset:0]             0.000  \n",
       "61                       pos_POS_feats[offset:0]             0.000  \n",
       "62                pos_wd_feats_stemmed[offset:0]             0.000  \n",
       "63                        pos_wd_feats[offset:0]             0.000  \n",
       "64                       bow_POS_feats[offset:6]             0.000  \n",
       "65                       pos_POS_feats[offset:6]             0.000  \n",
       "66                               bow_POS_feats[]             0.000  \n",
       "67                       bow_POS_feats[offset:4]             0.000  \n",
       "68                       bow_POS_feats[offset:3]             0.000  \n",
       "69                       pos_POS_feats[offset:3]             0.000  \n",
       "70                       bow_POS_feats[offset:2]             0.000  \n",
       "\n",
       "[71 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged2=merged[[\"rank\",\"feats_CB\", \"micro_f1_score_CB\", \"feats_SC\", \"micro_f1_score_SC\"]].copy()\n",
    "for c in merged2.columns:\n",
    "    if \"micro\" in c:\n",
    "        merged2[c]=merged2[c].apply(lambda d: \"{0:.3f}\".format(d) if type(d) == float else d)\n",
    "    elif \"num\" in c:\n",
    "        merged2[c]=merged2[c].apply(lambda d: \"{0:,.1f}\".format(d) if type(d) == float else d)\n",
    "merged2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rows for LaTex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_lbl(lbl):\n",
    "    return lbl.replace(\"[\",\" \").replace(\"]\",\"\").replace(\"_\",\" \").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, row in merged.iterrows():\n",
    "#     feats_CB = format_lbl(row[\"feats_CB\"])\n",
    "#     micro_f1_score_CB = row[\"micro_f1_score_CB\"]\n",
    "    \n",
    "#     feats_SC = format_lbl(row[\"feats_SC\"])\n",
    "#     micro_f1_score_SC = row[\"micro_f1_score_SC\"]\n",
    "    \n",
    "#     print(\"{rank} & {feat_cb} & {cb_f1:0.3f} & & {feat_sc} & {sc_f1:0.3f}\\\\\\\\\"\\\n",
    "#           .format(rank=i+1,feat_cb=feats_CB, cb_f1=micro_f1_score_CB,\n",
    "#                   feat_sc=feats_SC, sc_f1=micro_f1_score_SC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance By Feature Set Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>max(micro_f1_score)_cb</th>\n",
       "      <th>mean(micro_f1_score)_cb</th>\n",
       "      <th>max(micro_f1_score)_sc</th>\n",
       "      <th>mean(micro_f1_score)_sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.083476</td>\n",
       "      <td>0.247492</td>\n",
       "      <td>0.137324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.207128</td>\n",
       "      <td>0.272436</td>\n",
       "      <td>0.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.273128</td>\n",
       "      <td>0.224627</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>0.264139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.216923</td>\n",
       "      <td>0.298887</td>\n",
       "      <td>0.274702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.233628</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.281892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.232259</td>\n",
       "      <td>0.319620</td>\n",
       "      <td>0.289893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  max(micro_f1_score)_cb  mean(micro_f1_score)_cb  \\\n",
       "0      1                0.240000                 0.083476   \n",
       "1      2                0.276316                 0.207128   \n",
       "2      3                0.273128                 0.224627   \n",
       "3      4                0.285106                 0.216923   \n",
       "4      5                0.299145                 0.233628   \n",
       "5      6                0.291845                 0.232259   \n",
       "\n",
       "   max(micro_f1_score)_sc  mean(micro_f1_score)_sc  \n",
       "0                0.247492                 0.137324  \n",
       "1                0.272436                 0.239223  \n",
       "2                0.286656                 0.264139  \n",
       "3                0.298887                 0.274702  \n",
       "4                0.307200                 0.281892  \n",
       "5                0.319620                 0.289893  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_by_featureset_size(df):\n",
    "    return group_by(df, bycols=[\"count\"], agg_map=[(\"micro_f1_score\", \"max\"),\n",
    "                                              (\"micro_f1_score\", \"mean\"),\n",
    "                                              #(\"micro_f1_score\", \"median\"),\n",
    "                                              #(\"micro_f1_score\", \"count\"),\n",
    "                                             ]).sort_values(\"count\")\n",
    "\n",
    "pd.merge(get_by_featureset_size(cb_vd_df), get_by_featureset_size(sc_vd_df), on=\"count\", how=\"outer\", suffixes=[\"_cb\", \"_sc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get F1 Score By Num Features As the Optimal Feature Set is Constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>new_feat_CB</th>\n",
       "      <th>micro_f1_score_CB</th>\n",
       "      <th>new_feat_SC</th>\n",
       "      <th>micro_f1_score_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>0.227603</td>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>0.220641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pos_POS_feats[offset:4]</td>\n",
       "      <td>0.269912</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>0.286656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>0.307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>0.319620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                   new_feat_CB  micro_f1_score_CB  \\\n",
       "0      1                pos_wd_feats_stemmed[offset:4]           0.227603   \n",
       "1      2  pos_ngram_feat_stemmed[ngram_size:2offset:4]           0.249423   \n",
       "2      3                       pos_POS_feats[offset:4]           0.269912   \n",
       "3      4          bow_ngram_feat[ngram_size:1offset:4]           0.285106   \n",
       "4      5  pos_ngram_feat_stemmed[ngram_size:3offset:4]           0.299145   \n",
       "5      6          bow_ngram_feat[ngram_size:2offset:4]           0.291845   \n",
       "\n",
       "                            new_feat_SC  micro_f1_score_SC  \n",
       "0                pos_wd_feats[offset:2]           0.220641  \n",
       "1  bow_ngram_feat[ngram_size:2offset:2]           0.271186  \n",
       "2  bow_ngram_feat[ngram_size:1offset:2]           0.286656  \n",
       "3  pos_ngram_feat[ngram_size:2offset:2]           0.298701  \n",
       "4               pos_POS_feats[offset:2]           0.307200  \n",
       "5  pos_ngram_feat[ngram_size:3offset:2]           0.319620  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cols_filter = \"count,new_feat,micro_f1_score,micro_recall,micro_precision,window_size\".split(\",\")\n",
    "cols_filter = \"count,new_feat,micro_f1_score\".split(\",\")\n",
    "\n",
    "def get_f1_by_feat_count(df):\n",
    "#     df=df[df[\"stemmed\"] == True]\n",
    "    top_feats = df[df[\"count\"] == df[\"count\"].max()]\n",
    "    top_feats = top_feats.sort_values(\"micro_f1_score\", ascending=False).iloc[0][\"feats\"]\n",
    "    \n",
    "    rows = []\n",
    "    for i in range(0,len(top_feats)):\n",
    "        new_feat = top_feats[i]\n",
    "        upto = top_feats[:i+1]\n",
    "        hs = hash_feats(upto)\n",
    "        new_row = df[df[\"hs_feats\"] == hs].iloc[0]\n",
    "        new_row[\"new_feat\"] = feat_name(new_feat)\n",
    "        copy = {}\n",
    "        for k in new_row.keys():\n",
    "            copy[str(k).strip()] = new_row[k]\n",
    "        rows.append(copy)\n",
    "\n",
    "    df_f1_by_feat_count = pd.DataFrame(rows)\n",
    "    return df_f1_by_feat_count[cols_filter]\n",
    "\n",
    "df_f1_score_by_feat_size= pd.merge(get_f1_by_feat_count(cb_vd_df), get_f1_by_feat_count(sc_vd_df), on=\"count\", how=\"outer\", suffixes=(\"_CB\", \"_SC\"))\n",
    "##df_f1_score_by_feat_size\n",
    "# Note that the optimal feature set for SC is only of size 4\n",
    "\n",
    "#get_f1_by_feat_count(cb_vd_df)\n",
    "#get_f1_by_feat_count(sc_vd_df)\n",
    "\n",
    "df_f1_score_by_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>new_feat_CB</th>\n",
       "      <th>micro_f1_score_CB</th>\n",
       "      <th>new_feat_SC</th>\n",
       "      <th>micro_f1_score_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pos_wd_feats_stemmed[offset:4]</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>pos_wd_feats[offset:2]</td>\n",
       "      <td>0.2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:2offset:4]</td>\n",
       "      <td>0.2494</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.2712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pos_POS_feats[offset:4]</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:2]</td>\n",
       "      <td>0.2867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bow_ngram_feat[ngram_size:1offset:4]</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>pos_ngram_feat[ngram_size:2offset:2]</td>\n",
       "      <td>0.2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>pos_ngram_feat_stemmed[ngram_size:3offset:4]</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>pos_POS_feats[offset:2]</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>bow_ngram_feat[ngram_size:2offset:4]</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>pos_ngram_feat[ngram_size:3offset:2]</td>\n",
       "      <td>0.3196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                   new_feat_CB micro_f1_score_CB  \\\n",
       "0      1                pos_wd_feats_stemmed[offset:4]            0.2276   \n",
       "1      2  pos_ngram_feat_stemmed[ngram_size:2offset:4]            0.2494   \n",
       "2      3                       pos_POS_feats[offset:4]            0.2699   \n",
       "3      4          bow_ngram_feat[ngram_size:1offset:4]            0.2851   \n",
       "4      5  pos_ngram_feat_stemmed[ngram_size:3offset:4]            0.2991   \n",
       "5      6          bow_ngram_feat[ngram_size:2offset:4]            0.2918   \n",
       "\n",
       "                            new_feat_SC micro_f1_score_SC  \n",
       "0                pos_wd_feats[offset:2]            0.2206  \n",
       "1  bow_ngram_feat[ngram_size:2offset:2]            0.2712  \n",
       "2  bow_ngram_feat[ngram_size:1offset:2]            0.2867  \n",
       "3  pos_ngram_feat[ngram_size:2offset:2]            0.2987  \n",
       "4               pos_POS_feats[offset:2]            0.3072  \n",
       "5  pos_ngram_feat[ngram_size:3offset:2]            0.3196  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round to 4 d.p. for printing\n",
    "df = df_f1_score_by_feat_size[\"count,new_feat_CB,micro_f1_score_CB,new_feat_SC,micro_f1_score_SC\".split(\",\")].copy()\n",
    "df[\"micro_f1_score_CB\"] = df[\"micro_f1_score_CB\"].apply(lambda d: \"{0:.4f}\".format(d))\n",
    "# df[\"num_feats_CB\"]      = df[\"num_feats_CB\"].apply(lambda d: \"{0:,.1f}\".format(d))\n",
    "df[\"micro_f1_score_SC\"] = df[\"micro_f1_score_SC\"].apply(lambda d: \"{0:.4f}\".format(d))  \n",
    "# df[\"num_feats_SC\"]      = df[\"num_feats_SC\"].apply(lambda d: \"{0:,.1f}\".format(d))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot F1 Score Against # Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Max F1 Score for Each Size of Feature Set (Win = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_f1_by_feat_count(df):\n",
    "    max_feats = df[\"count\"].values.max()\n",
    "    rows = []\n",
    "    for cnt in range(1, max_feats+1):\n",
    "        \n",
    "        row = df[df[\"count\"] == cnt].sort_values(\"micro_f1_score\", ascending=False).iloc[0]        \n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>feats_CB</th>\n",
       "      <th>micro_f1_score_CB</th>\n",
       "      <th>micro_precision_CB</th>\n",
       "      <th>micro_recall_CB</th>\n",
       "      <th>feats_SC</th>\n",
       "      <th>micro_f1_score_SC</th>\n",
       "      <th>micro_precision_SC</th>\n",
       "      <th>micro_recall_SC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:6]]</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:6]]</td>\n",
       "      <td>0.247492</td>\n",
       "      <td>0.601626</td>\n",
       "      <td>0.155789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:5], fn_bow_ngr...</td>\n",
       "      <td>0.276316</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_bow_ngr...</td>\n",
       "      <td>0.272436</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.178947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:5], fn_bow_ngr...</td>\n",
       "      <td>0.273128</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>[fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...</td>\n",
       "      <td>0.286656</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.183158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>0.197059</td>\n",
       "      <td>[fn_pos_wd_feats[offset:5], fn_bow_ngram_feat[...</td>\n",
       "      <td>0.298887</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.197895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>[fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.202105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...</td>\n",
       "      <td>0.319620</td>\n",
       "      <td>0.643312</td>\n",
       "      <td>0.212632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                           feats_CB  \\\n",
       "0      1                [fn_pos_wd_feats_stemmed[offset:6]]   \n",
       "1      2  [fn_pos_wd_feats_stemmed[offset:5], fn_bow_ngr...   \n",
       "2      3  [fn_pos_wd_feats_stemmed[offset:5], fn_bow_ngr...   \n",
       "3      4  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...   \n",
       "4      5  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...   \n",
       "5      6  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...   \n",
       "\n",
       "   micro_f1_score_CB  micro_precision_CB  micro_recall_CB  \\\n",
       "0           0.240000            0.600000         0.150000   \n",
       "1           0.276316            0.543103         0.185294   \n",
       "2           0.273128            0.543860         0.182353   \n",
       "3           0.285106            0.515385         0.197059   \n",
       "4           0.299145            0.546875         0.205882   \n",
       "5           0.291845            0.539683         0.200000   \n",
       "\n",
       "                                            feats_SC  micro_f1_score_SC  \\\n",
       "0                [fn_pos_wd_feats_stemmed[offset:6]]           0.247492   \n",
       "1  [fn_pos_wd_feats_stemmed[offset:4], fn_bow_ngr...           0.272436   \n",
       "2  [fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...           0.286656   \n",
       "3  [fn_pos_wd_feats[offset:5], fn_bow_ngram_feat[...           0.298887   \n",
       "4  [fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...           0.307200   \n",
       "5  [fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...           0.319620   \n",
       "\n",
       "   micro_precision_SC  micro_recall_SC  \n",
       "0            0.601626         0.155789  \n",
       "1            0.570470         0.178947  \n",
       "2            0.659091         0.183158  \n",
       "3            0.610390         0.197895  \n",
       "4            0.640000         0.202105  \n",
       "5            0.643312         0.212632  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cb = get_max_f1_by_feat_count(cb_vd_df)[[\"count\", \"feats\", \"micro_f1_score\", \"micro_precision\", \"micro_recall\"]]\n",
    "df_sc = get_max_f1_by_feat_count(sc_vd_df)[[\"count\", \"feats\", \"micro_f1_score\", \"micro_precision\", \"micro_recall\"]]\n",
    "by_feat_size = pd.merge(df_cb, df_sc, on=\"count\", how=\"outer\", suffixes=[\"_CB\", \"_SC\"])\n",
    "by_feat_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtsAAAGSCAYAAAAyzw2RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xlc1QXa9/HPgcMmILKIirIrKOYSuIAbuNQktow1U1bW\n02PL3UxOTc1dzW2ONaZmli1jTzrN2DJTdznNXd2maaOToiKgobiRgMJhdwVBUNZznj8OHDUxcWH/\nvl+veb3kbL/r6C/my4/rXJfBYrFYEBERERGR686urQsQEREREemsFLZFRERERFqIwraIiIiISAtR\n2BYRERERaSEK2yIiIiIiLaTThe3U1NS2LkHaoQMHDrR1CdIO6byQH9M5IU3ReSHXotOFbZGmVFVV\ntXUJ0g7pvJAf0zkhTdF5IddCYVtEREREpIUobIuIiIiItBCFbRERERGRFqKwLSIiIiLSQhS2RURE\nRERaiMK2iIiIiEgLUdgWEREREWkhCtsiIiIiIi1EYVtEREREpIUobIuIiIiItBBjax3IbDbz0ksv\nkZGRgaOjIwsWLCAwMNB2/yeffMIXX3yBwWBg1qxZxMfHc/r0aZ599lkqKiqora3l97//PTfeeGNr\nlSwiIiIick1aLWxv3LiRmpoaVq1aRVpaGosXL2b58uUAlJSU8Omnn/Lll19SXV3NtGnTmDp1Kh98\n8AHR0dE89NBDZGdn87vf/Y4vv/yytUoWEREREbkmrRa2U1NTGT9+PADDhw9n//79tvu8vLz46quv\nMBqNFBYW4uTkhMFg4KGHHsLR0RGA+vp6nJycWqtcEREREZFr1mphu6KiAjc3N9vX9vb21NXVYTRa\nSzAajXz88ccsW7aMBx54AIDu3bsDcPz4cZ599lnmzJnTrGOlpqZe5+rbl7q6OtatW8f27ds5cuQI\nTk5O9O/fnzvvvJOQkJAWPfaKFSs4efIkL7zwQpP333fffRd87eTkhJ+fH3fddReRkZGA9d/zqaee\nYt68eQwcOLBF621Ozenp6SxYsIBly5bh7e3d4vVI+9LZv1/IldM5IU3ReSHnK6s9zaTouGY9ttXC\ntpubG5WVlbavzWazLWg3mjlzJnfffTePPvooycnJREdHk5GRwTPPPMNzzz3HqFGjmnWsqKio61p7\ne3L27FkefPBBSktLefLJJxk2bBiVlZX87W9/4+WXX+a9994jOjq6xY7v7e1NbW3tT/4dz5s3j5tv\nvhmLxUJFRQXffPMNb731Fv/zP//DwIEDKSgoACA8PLxV/q28vb05efLkJY81ZMgQbrnlFry9vbGz\n02eGu5LU1NRO/f1CrpzOCWmKzgsBqKqrJiV/N5tNSRw4ltn+wnZkZCSbNm0iPj6etLQ0wsLCbPdl\nZ2fzxhtvsGzZMhwcHHB0dMTOzo5Dhw7x1FNP8dZbb7XKFdCO4K233sJkMrFmzRp69eplu33x4sWc\nPHmSl19+mTVr1mAwGNqsRjc3N3r27AmAr68vs2fP5uuvv+brr79ul/+Ojo6OtnpFREREGpktZg4e\nP8TmnGSSC3ZRVVcNwKCeA5r9Gq0Wtm+66SYSExOZMWMGFouFRYsW8cEHHxAQEMDkyZMZOHAg99xz\nDwaDgfHjxzNq1Ch+9atfUVNTw8KFCwFriGv8UGVXVFNTwxdffMEvfvGLC4J2o3nz5lFZWWkL2kVF\nRbz22mskJSVRXV1NTEwM//Vf/4W/vz8AkyZN4mc/+xnfffcdZWVlrFy5Eg8PD5YsWUJKSgoVFRX0\n6tWL++67j0ceeeSaau/WrdslfwAwm8289957rFq1itLSUkJDQ3nyySeJjY21PebTTz/lk08+ITc3\nF6PRyI033siLL75om2hz4sQJXnnlFbZu3YrFYiEmJoa5c+fi6+sLWHv+Fy5cyOrVq6mtrWXKlCm8\n9NJLdOvWjZSUFB588EESEhLo3bs3kyZNYubMmezYsYOkpCTc3Ny49957mT17tq2eL7/8khUrVlBc\nXMzw4cMZNWoUX3zxBd999901/T2JiIhI2ztWcYIEUzIJpmSOVZ4EoKerN7eGTyE2aDS93Jp/ka7V\nwradnR3z58+/4LbQ0FDbn2fPnn1BmAFaJVi///UBEvcUtvhxmjJ2WF9m3Ta42Y/Pz8+nvLycYcOG\nNXl/Y4gGa4/8vffeS2hoKCtXrsRisfDqq68yc+ZM1qxZg7u7O2ANse+99x5OTk4MGjSIO+64g759\n+/K3v/0NZ2dnvvrqK1577TXGjh3LoEGDrvg91tXVsX79eg4fPsySJUuafMzSpUvZsGED8+fPJyAg\ngK1btzJ79mz++te/Mnr0aNavX88rr7zC4sWLGTZsGIWFhfzhD3/g1Vdf5d1336Wuro5Zs2bh4uLC\ne++9h4uLC3/84x958skn+eyzzwA4ePAgkZGRrFq1CpPJxJNPPklAQMBF51yjt99+mzlz5vDCCy+w\nfv16Xn/9daKjoxkxYgT//ve/mTt3Ls8//zzjx49nw4YNvPnmm/Tp0+eK/35ERESkfaiqrSK5YDcJ\npmQOHMsEwMnoRFxQDLHB0Qzq2R87w5W3m7Za2JZrV15eDpz74OhP+d///V/Ky8t544036NGjB2AN\nkJMmTWL16tXcf//9gPXqdmMvfFVVFdOnT2fatGm2K+dPPPEEK1asICMjo9lhe+7cubz00ksAVFdX\nU19fz8yZMy/44apRY7/5smXLbNNqAgMDOXjwIO+99x6jR4/Gy8uLRYsWER8fD0Dfvn2ZNm0aq1ev\nBiApKYmMjAw2btxo+4FjwYIFfPHFF1RXW3/d4+Xlxbx58zAYDAQFBTF27NgLJuL82MSJE7nnnnsA\nePTRR3nvvfdIS0tjxIgRfPDBB0ybNo0HH3wQgMcee4z9+/f/5OuJiIhI+2O2mEk/lkWCKZnkgt1U\nN7SJDPYNIzYomuh+N+Ls4HxNx+jyYXvWbYOv6OpyW/L09ATg1KlTl31sVlYWwcHBtqAN1sAZGhpK\nZmam7bbzr4Y7Ozszc+ZMvvnmG/bu3Utubi4//PADZrMZs9nc7DqffvppJk+eDFgD/P79+1m8eDH1\n9fW2EN7o8OHD1NTU8NRTT13w4cTa2lp8fHwAGDVqFJmZmbzzzjtkZ2eTk5NDZmam7QeCzMxMvLy8\nLngvISEh/Od//qft6969e1/QxuLh4cHRo0cv+R6CgoIu+Nrd3Z3a2loADhw4YAv+jSIjIxW2RURE\nOogjFcfZYkomISeZ42dKAPB19SZu4E1MCIrG1/X6TSfr8mG7IwkICMDb25s9e/ZcFPYAUlJS+OCD\nD5g/fz7Ozk3/FGY2m3FwcLB9ff7s8srKSu6//37q6+v52c9+xujRoxk2bBgTJ068ojq9vb0v2A4a\nHh7OsWPHePvtty8IwIBtjvqyZcsueA5gC99fffUVc+fO5fbbb2fEiBHMnDmTLVu22K5s/3iqTVOa\n6he3WCyXfHxjXU093mg0/uRzRUREpP05W1tFUv4uEkzJ/HA8CwBnoxNxwTHEBcUwsGfoVbWJXI7C\ndgdiZ2fH9OnTWbVqFbNmzbrgQ5IWi4X33nuPgoICevbsSWhoKKtWreLUqVO2q9slJSXk5ORw9913\nN/n627Zt44cffiAlJcX2nOzsbMxm8zWHy8bn//h1AgMDcXBw4OjRo0yYMMF2+zvvvEN9fT1PPfUU\nK1euZMaMGcydO9d2/8cff2x7rdDQUEpKSigsLKRv376A9Yr5/fffzz//+c9rqrsp4eHh7Nmzx9aK\nA7B3797rfhwRERG5NtY2kUw25ySTUrCb6voaAG7wDScuOIZR/YbjbGzZpYkK2x3Mr3/9axITE7nv\nvvt4+umnGTZsGCdOnOD9999n586dvP/++xgMBm6//XZWrFjBM888w+9+9zsAXnvtNbp37860adOa\nfO3GD/h9/fXXTJo0iby8PF555RXAOgmluSoqKjh+/DhgvZK+b98+PvroIyZNmoS7uztlZWW2x7q4\nuPDQQw+xdOlSXF1dGTJkCJs2beL//b//Z5tC07t3b1JTUzl48CDOzs6sWbOGb775xraAZsyYMURE\nRPD888/z+9//HqPRyPz58wkNDaVfv35X+Dd8eY888ghPPPEEw4YNY+zYsWzevJl169bpA5IiIiLt\nxJHTx0gwpZBgSuZEQ5tIL7eexAZFExs0mp7XsU3kchS2OxhXV1c+/vhj/vKXv/DOO+9QXFyMu7s7\nw4YNY9WqVbYPMTo5ObFy5UoWL17MzJkzsbe3JyYmhk8++eSSH7AcOnQozz33HH/5y194/fXXbZsf\nt2zZwr59+7j33nubVeP8+fNtk2eMRiO+vr7Ex8fzzDPPNPn43/72tzg4OLBkyRJOnDiBv78/8+fP\n58477wTgD3/4A3PnzmXGjBm4uLgwdOhQ5s+fz7x58ygqKsLPz4/ly5ezcOFCHnjgARwdHRk3blyz\nN45eqbi4OObOnctf/vIXXnnlFUaMGMH06dO1XUxERKQNnak9S3L+LjbnJHHwxGEAXIzOTAoeQ1xw\nDOE+oW2yh8Rg6WTNp9ryJE25nufFzp078fX1vaDHfN68eeTm5vLRRx9dl2NI69D3C/kxnRPSFJ0X\n7ZfZbGb/sQw2m5LZUbCbmvpaDBi4oVc4sUHRrdImcjm6si1yhbZs2cK3337LokWL6NOnD7t27WL1\n6tX84Q9/aOvSREREuoTi08dIMCWRYErh5JlSAHq79SQuOIYJgaPxcfVq4wrPUdgWuUKzZ8+msrKS\n3/72t5w6dQp/f3+effZZ7rrrrrYuTUREpNM6U3OW7fmpJOQkkXEyGwAXB2cmh4wjLjiaMO+QNmkT\nuRyFbZEr5OTkxLx585g3b15blyIiItKp2dpEcpJIKUyjtqFNZGivQcQFRzOy73CcjBeP621PFLZF\nREREpF0pKj/CZlMyW0wplJy1LvPr4+5LXFAM44NG4dOt/bSJXI7CtoiIiIi0ucqaM2zPSyXBlExm\nQ5tINwcXpoSMIy44hgHewe2yTeRyFLZFREREpE2YzWb2Hj3IZlMSOwvSqDXXYTAYGNY7wtom4jcM\nx3beJnI5CtsiIiIi0qoKyotJyElmS24KpWety+76uvcmNjiaCYGj8erWo40rvH4UtkVERESkxVXU\nVFrbRHKSyCoxAdY2kZtCxxMXHEN/r6AO2SZyOQrbIiIiItIi6s317D36A5tzkvm+cI+tTeTGPoOJ\nDYphRN+hONo7tHWZLUphuwP66quv+Pjjjzl06BAGg4Hw8HAefPBB4uPjbY8JDw9nyZIl3HHHHRc9\nf9myZaxevZoNGzZcUx1JSUl89NFH7Nmzh6qqKgIDA7nnnnuYMWNGp/zJVERERJqnoKyYzaZktppS\nKK1qaBPp3ts2TcTLpfO0iVyOwnYHs2rVKl599VXmzp1LVFQUtbW1bNiwgWeeeYbq6mqmT59+2deY\nNWsW999//zXVsXLlSt58801mzZrFU089Rbdu3UhJSWHx4sX88MMPzJ8//5peX0RERDqWiupKEvO+\nZ7MpicMluQC4Orhwc/8JxAXFEOoV2CUvxilsdzCrVq3i7rvv5s4777Td1r9/f0wmE3/729+aFbZd\nXV1xdXW96hrS09NZunQpL7zwwgWhPTAwEDc3N55++mnuuusuhg0bdtXHEBERkfav3lzPniPp1jaR\nor3U2dpEbiAuOJoov87fJnI5CtsdjJ2dHbt27eL06dO4u7vbbn/++ec5c+ZMk88pKipi5syZDBky\nhKVLl7J8+XJbG0lBQQGTJ0/mT3/6EytWrCArK4u+ffvy7LPPMmXKlCZf7/PPP6dHjx7MmDHjovtu\nueUWPD09CQsLA+DUqVO8+uqrbN26ldLSUjw9Pbntttt49tlnsbOzY9myZaSlpREZGcmnn35KeXk5\n0dHRvPzyy/Tq1QuAEydO8Morr7B161YsFgsxMTHMnTsXX19fAP7xj3+wcuVKiouLCQwMZNasWbYf\nOlJSUnjkkUe44447+NWvfkV4eDh///vfr/4fQERERMg7VUiCKZmtuTs4VVUOgH/3PsQGxzA+cBSe\nLh5tXGH70eXD9t/T/ofk/F1tcuxo/0geGH7XFT3n4Ycf5umnn2b8+PFER0czcuRIxowZw6BBg/Dy\nunib0rFjx3jooYcYOnQor7/+OkZj0//kS5Ys4cUXXyQwMJA333yT559/nq1bt9KtW7eLHnvgwAGG\nDBmCvb39RffZ2dkRExNj+/r555+ntLSU5cuX06NHD7Zs2cLLL79MVFSULcynpKTg6urKBx98QFlZ\nGb/97W/505/+xMKFC6mrq2PWrFm4uLjw3nvv4eLiwh//+EeefPJJPvvsM/77v/+bZcuW8eKLLxIR\nEcHu3bt5+eWXAWyBu6amhvT0dD7//HOqqqqu6O9bRERErE5XV5CY9z0JOckcLrW2ibg5unJL/zhi\ng6MJ8Qzokm0il9Plw3ZHM3XqVHr16sVHH31EYmIimzZtAiAiIoIlS5YwYMAA22NLS0t56KGHGDx4\nMK+//nqT4bjRww8/zIQJEwB4/PHHWbduHYcOHWLo0KEXPbasrIyAgIBm1Tt+/HhGjx5tq+v+++/n\nr3/9KxkZGbawbbFYWLRoEW5ubgDEx8eTmJgIWD+EmZGRwcaNG/H39wdgwYIFfPHFF1RXV7NixQpm\nz57NLbfcAkBAQABFRUWsWLHigpaaW2+9lcDAwGbVLCIiIlZ15nrSig+QYLK2idSb67Ez2BHpN4S4\noGii/Ibg0MXbRC6ny4ftB4bfdcVXl9taZGQkkZGR1NfXc+DAAb777js+/vhjHn30Uf71r3/h6Gjd\ntLR06VJqa2uJjY39yaANEBwcbPtzY+itra1t8rGenp6UlZU1q9Z7772Xf//733z++eeYTCYyMjI4\ncuQIZrPZ9hgfHx/bMQHc3d1tx87MzMTLy8sWtAFCQkL4z//8T0pKSjh69Civvvoqr7/+uu3+uro6\n6uvrqampsd3W2HIiIiIil5d3qpDNOUlszd1BWfVpAPw9/JgYHMO4gJH0UJtIs3X5sN2RFBcX8+c/\n/5knnniCnj17Ym9vz9ChQxk6dCgjRozg4YcfJiMjgyFDhgAwYcIEbrrpJubMmcPUqVObvErdyMHh\n4p9KLRZLk4+98cYb+fLLLzGbzdjZ2V1wn9ls5vHHH+fOO+/k5ptv5rHHHiMnJ4fbbruNO+64g6FD\nh/J//s//ueA5jT8cNHXsS7W9nF/zH/7wB0aNGnXR/ec/t6ljiIiIyDnl1RVsy91BgimZnNJ8oKFN\nZEAccUExBHv6q03kKthd/iHSXjg5OfHPf/6TNWvWXHRf9+7dMRgMeHt72267+eab+fnPf86YMWOY\nM2fOBVd6r8X06dMpLy/n008/vei+tWvXkpCQgI+PD+np6Wzbto1ly5bx9NNPM23aNDw9PTl+/Pgl\ng/yPhYaGUlJSQmFhoe22w4cPEx0dTVlZGb169aKgoIDAwEDb/7Zv387KlSsv+kFARERELlRnruf7\nwj28vu3P/Mfq3/Ph7s/JPVXICL+h/G7sY/z59leYFXkPIV7qx75aurLdgXh5efHwww+zdOlSKioq\nuPnmm3F2diYzM5O33nqL6dOn4+fnd9HzXnrpJW699VZWrFjBk08+ec11hIWFMXv2bBYuXMixY8eI\nj4/HaDSSkJDAn/70J2bOnMmIESM4evQoRqORdevW4eHhwfHjx3nzzTepqalpdvAfM2YMERERPP/8\n8/z+97/HaDQyf/58QkND6devH7/61a9YvHgxfn5+xMTEsGfPHhYvXswjjzxyze9TRESkszKVFjRM\nE0mhvLoCgECPvsQGxzAucCQ9nLu3cYWdh8J2B/P0008TGBjIP/7xDz788EOqq6sJCAhg+vTpPPTQ\nQ00+p1+/fsyePZu33nqLm2+++brU8etf/5rQ0FD+/ve/89lnn1FTU0NwcDAvvPACd91l7YHv1asX\nixYtYtmyZXz00Uf06tXL9gHPffv2Nes4dnZ2LF++nIULF/LAAw/g6OjIuHHjmDNnDmDtCa+pqWHl\nypW2cYG//vWveeyxx67L+xQREeksyqtOsy1vJ5tzkjCdKgDA3cmN+AETiQuOIcjT/zKvIFfDYGnu\n7/M7iNTUVKKiotq6DGlndF5IU3ReyI/pnJCmdOTzoq6+jl3F+9lsSmZ30T7qLWbsDXbc2DBNJLLP\nDRjtde21JelvV0RERKSTMZXmW6eJ5O3kdEObSFCPfsQ1TBPp7ux+mVeQ60VhW0RERKQTKKsqZ2vu\nThJyksgtsw4W6O7kRnzYJOKCotUm0kYUtkVEREQ6KFubSE4Su4v3W9tE7OwZ1Xc4ccHRDO9zA0a7\nn961IS1LYVtERESkA7FYLOSU5rPZlERi7k5O11QCEOzpT1xQDGMDR9Ldye0yryKtRWFbREREpAM4\ndbbM2iZiSiavoU3Ew8mdW8MmExscTWCPfm1coTSl1cK22WzmpZdeIiMjA0dHRxYsWEBgYKDt/k8+\n+YQvvvgCg8HArFmziI+Pt923YcMG1q9fz9KlS1urXBEREZE2V1tfS2rRPjabkkkrPoC5oU1kdL8b\niQuOYVjvCLWJtHOtFrY3btxITU0Nq1atIi0tjcWLF7N8+XIASkpK+PTTT/nyyy+prq5m2rRpTJ06\nFYPBwIIFC9i2bRuDBg1qrVJFRERE2ozFYiG7NI/NOUkk5n1PRUObSIhnAHHBMYwNGIG72kQ6jFYL\n26mpqYwfPx6A4cOHs3//ftt9Xl5efPXVVxiNRgoLC3FycrKtBI2MjGTKlCmsWrXqio4l8mM6L6Qp\nOi/kx3ROSFNa47yoqDvDgdOH2H86ixM1pQC42rswqscQbnAfQE8nLyiHzP0ZLV6LXF5zZ6+3Wtiu\nqKjAze3cT2H29vbU1dVhNFpLMBqNfPzxxyxbtowHHnjA9rj4+HhSUlKu6FgddfC8tJyOvJBAWo7O\nC/kxnRPSlJY8L2rqa0kt2svmnGT2HEnHbDFjtDMS7R9JXFA0w3pHYK82kQ6t1cK2m5sblZWVtq/N\nZrMtaDeaOXMmd999N48++ijJyclER0e3VnkiIiIircJisXC4JNc6TSTveyprzgAQ6hVonSYSMAI3\nJ9c2rlKul1YL25GRkWzatIn4+HjS0tIICwuz3Zednc0bb7zBsmXLcHBwwNHRETs7u9YqTURERKTF\nlZw9xVbTDjabkigsPwKAp7MHkwfeTFxQNP08+rRxhdISWi1s33TTTSQmJjJjxgwsFguLFi3igw8+\nICAggMmTJzNw4EDuueceDAYD48ePZ9SoUa1VmoiIiEiLqKmv5fvCPSSYkkk7ko7FYsFoZyTGP4q4\n4GiG9hqkNpFOrtXCtp2dHfPnz7/gttDQUNufZ8+ezezZs5t87ujRoxk9enSL1iciIiJyPVgsFg6V\nmNick8T2vO+prD0LwACvIGKDYxgTEIWbo9pEugottRERERG5DkrOnGJLbgoJOckUnm5oE3HxYEro\neGKDo+nXXW0iXZHCtoiIiMhVqqmrYWfRHjbnJLP36A9YLBYc7IyMCRhBXFAMQ3sN1OfQujiFbRER\nEZErYLFYyDqZY20TyU/lTEObSJh3CLFB0YwJiMLVsVsbVynthcK2iIiISDOcPFPKFlMKm01JFJ8+\nBoCXSw9u7j+BuKBo/Lr3buMKpT1S2BYRERG5hIqaStJPH2Ld5kT2HT2IBQsO9g6MCxhJbHA0Q3zV\nJiI/TWFbREREpEFlzRl+OH6IA8cyST+WielUARYsAIR7h1inifhH0c3RpY0rlY5CYVtERES6rMZw\nnX4skwPHMzGVngvXDnZGBvXsj2e9O7+Mvh0/915tXK10RArbIiIi0mX8VLg2NoTrCN8wBvuGMcA7\nGEd7B1JTUxW05aopbIuIiEindabmLD+cONcWknMqH4vlEuHaKwhHo2MbVyydjcK2iIiIdBqXC9cD\nffoz2HcAET3DCPMOVriWFqewLSIiIh3WmZqzHDxxiP0K19JOKWyLiIhIh9EYrq1XrrPIPpVnC9f2\ndvYM9AklomcYg30HMMA7BCeFa2ljCtsiIiLSbilcS0ensC0iIiLtxpnasxw8fpj045kcOJZJdumF\n4TrcO4QI3zBu8A1TuJYOQWFbRERE2kxzw/Vg3zDCFK6lA1LYFhERkVZzpvYsGScOc+BYFukN4dps\nMQPWcB3mHcJg3wEM9g1XuJZOQWFbREREWszZ2qqGnuumw/UA7+Bz00J8QnA2OrVxxSLXl8K2iIiI\nXDdna6vIOHHYNorvgnBtsFO4li5HYVtERESuWmO4blwic/jH4dor6FzPtcK1dEEK2yIiItJsCtci\nV0ZhW0RERC6pqraKgyeybdNCDpfkXhCu+3sFEeE7gMG+YYR7h+Ds4NzGFYu0LwrbIiIiYqNwLXJ9\nKWyLiIh0YVW1VWSczObAsYY51yW51DeEazuDHaFegQxuaAtRuBa5cgrbIiIiXcj54Tr9WBaHS0xN\nhuuInmEM9FG4FrlWCtsiIiKdWFVd9XkfaGwiXHsGNHygMZxwnxBcFK5FriuFbRERkU6kqq6azBPZ\ntmkhhy4ZrsMI9wlVuBZpYQrbIiIiHZjCtUj7prAtIiLSgTSGa+u0kCxruDbXA9ZwHWIL1wMI9wml\nm4NLG1cs0rUpbIuIiLRj1XU1ZJw43GS4NhgMhHoGKlyLtGMK2yIiIu1IdV0NmSezOXAso8lwHeIZ\ncG5aSE+Fa5H2TmFbRESkDZ0L19ae6yyFa5FORWFbRESkFV02XPcIaNjQGM5An1C6OSpci3RkrRa2\nzWYzL730EhkZGTg6OrJgwQICAwNt93/yySd88cUXGAwGZs2aRXx8PFVVVTz77LOcPHkSV1dXXn31\nVby8vFqrZBERkWtWYwvXWaQfzyTrpIk6cx3w43AdxkCf/grXIp1Mq4XtjRs3UlNTw6pVq0hLS2Px\n4sUsX74cgJKSEj799FO+/PJLqqurmTZtGlOnTuXTTz8lLCyM3/zmN6xdu5Z3332XuXPntlbJIiIi\nV+xy4Tq4hz8RvmHcoHAt0iW0WthOTU1l/PjxAAwfPpz9+/fb7vPy8uKrr77CaDRSWFiIk5MTBoOB\n1NRUHnme/n3/AAAgAElEQVTkEQAmTJjAu+++21rlioiINIs1XOdY20J+Ilxbr1yH4urYrY0rFpHW\n1Gphu6KiAjc3N9vX9vb21NXVYTRaSzAajXz88ccsW7aMBx54wPYcd3d3AFxdXTl9+nSzjpWamnqd\nq5fOQOeFNEXnhfzY5c6JWnMdRVXHyDtbTP7ZYoqqjlGP2XZ/bycf/F36EODSh37OvXC2d4J6oLiG\ng8U/tHD10lL0vUJ+LCoqqlmPa7Ww7ebmRmVlpe1rs9lsC9qNZs6cyd13382jjz5KcnLyBc+prKyk\ne/fuzTpWc9+8dB2pqak6L+QiOi/kx5o6JxqvXDfOuc46mXPuyjUGgjz7MbhnGBG+YQzq2V9Xrjsh\nfa+Qa9FqYTsyMpJNmzYRHx9PWloaYWFhtvuys7N54403WLZsGQ4ODjg6OmJnZ0dkZCQJCQkMHTqU\nLVu26EQXEZEWV1NfS1ZjW8ixTLJO5lCrcN0lnT5Tw4aUPBJ3n2D/kXTCAz0JD/TE010r76X5Wi1s\n33TTTSQmJjJjxgwsFguLFi3igw8+ICAggMmTJzNw4EDuueceDAYD48ePZ9SoUQwZMoTnn3+ee++9\nFwcHB5YuXdpa5YqISBdyurqCxLzv2Vi4hTeyP7wwXPfoZ9vQOLBnf9wcXdu4Wmlp2YVlrNmWTcKu\nAmrqrC1CmYVZtvt7eXWzBe+BgV4E+3ngYLRrq3KlnTNYLBZLWxdxPelXPdIUnRfSFJ0XXVtdfR27\nivezxZRCavE+26zrcx9oVLjuSurqzSTtLWZNYjbpOSUA9PbuxrSxwbgbTuLdO5iM3FIO5paSkVvC\n6TO1tuc6GO3o36+HLXyHB3ri00NTZsRKS21ERKTLsFgsHC7JZYsphcS8nZyusX4uKMCjL7FB0XQv\ncyJ29Pg2rlJaU2l5FeuTTKxPNlFSXg1A5EBfbh0bTNTAXtjZGUhNLWN4mC/Dw3wB63lUfKKSg7kl\nDeG7lIy8Un4wlQCHAfDxcCa8IXgPDPQitJ8Hjg72bfQupS0pbIuISKd34kwJ23J3kmBKprD8CAAe\nTu5MC5tMbNBoAnv0s42clc7PYrFw0FTKmsRstu8toq7eQjdnI7dPCGHamGD8err95PMNBgN+Pd3w\n6+nGpBEBAFRV15FVcMoavBtCeOLeIhL3FgFgtDcQ7OdxwdXvXl7dMBgMLf5+pW0pbIuISKdUVVvF\njsI9JJiS2H80EwsWHOyMxPhHERs0mqG9IzDa6UpjV1JdW8/W3QWsSczhcEEZAAG93bl1bDBxUf64\nOF19LHJ2MjIk1IchoT6ANdAfKz1rC94ZuSVkF5aRlX+KNdtyAOjh7kR4wLne7wH+PXC+hhqkfdK/\nqIiIdBpmi5n0Y5lsNiWTUpBGdZ21LSDcJ5TYoNFE+0eqB7sLOlpyhnXbc/hXSi6nz9RiZ4CYIX24\nbVwIN4R6t8jVZYPBQC+vbvTy6saEG/sBUFNbT3Zh2QXtJykHjpBywPrbFjsDBPXxOPfhyyAv/Hxc\ndfW7g1PYFhGRDq+w/AgJpmS25u7g5JlSAHq6ehMbPpkJgaPp7e7bxhVKa7NYLOzJOs6abTnsTD+C\n2QLdXR355eQB3BIThK9n649sdHSwZ2CQFwODvGy3nSw7awveB00lHC44RXZRGeuSTAC4d3MgLMAa\nvMMDPAkL8MTVxaHVa5erp7AtIiIdUuO4vi2mFA6VmABwMTozKXgME4KiGdgzFDuDxrF1NWeqatn0\nfT5rEnMoOFYBQH//Htw2Lphxw/q2uw8penu4MHaoC2OH+gFQW2fGVFzGQVPjBy9LSD14jNSDxwAw\nGKCfrzsDAz0JD/RiYKAn/r3csbPT1e/2SmFbREQ6jKbG9RkMBob3jmBCUDQj+w7DyejY1mVKG8g/\neppvEnP49/f5nK2uw2hvR1xUP24bF0JYgGdbl9dsDkY7Bvh7MsDfk9saBuOcOl1NRm4JGXnWAJ6Z\nV0r+0dNs2JEHQDdnI2H+nrb2k/BAL7q76r+D9kJhW0RE2rVLjevz9/AjNiia8YGj8HTxaOMqpS3U\nmy18n36ENYk5pGUeB8Dbw5m7JvXn5tGBnWbTYw93J0bf0IfRN/QBoL7eTN7R07YPXh40lZKWdZy0\nrOO25/j5uNr6vsMDPAnq0x17e/2mpy0obIuISLt08kwpW3N3XDSuLz5sEnFB0bZxfdL1lFfWsHFH\nLmu3mzhWcgaAG0K9uXVcCNGDe3f6UGlvb0ewnwfBfh5MjQkCrKvlM/NKG9pPSsjMK2VTagGbUgsA\ncHK0Z4B/j4bpJ9b2E8/uneOHkfZOYVtERNqNc+P6ktl/NEPj+uQChwtOsTYxx7ZG3cnRnltigpg2\nNpigPt3burw25d7NkaiBvYga2AsAs9lC4fEKDprOtZ8cyD7J/sMnbc/x9erGwIBzk0+0dr5lKGyL\niEibahzXl2BKIblg97lxfd4hxAZHa1xfF1dbZyZpXxFrtuU0bGiEPt6uxI8NZspIf9y6qTe5KXZ2\nBvx7uePfy52bRgcC1g+PZuWd4mBeie0DmFvSCtmSVghY+8VD+3pYW08CPQkP8KKnp9bOXyuFbRER\naRNF5UdIMKWwJTdF4/rkIiWNa9STTJSetv4AFjXQl1vHhRAZ7qvpG1ehm7MDw8J6MiysJ9Cwdv5k\npW3sYEZeKZn5pziYW2p7jreHsy14hwd60t+/B07tbKJLe6ewLSIireZ0dQXb81JJMCVrXJ9cxGKx\n8IOphLXbckjcW0S92YKrs5E7JoQSPzYIP5+fXqMuV8ZgMODn44afjxsTo/wBqKqp41B+w9r5PGsI\n3763mO17iwGwtzMQ3NfD2n4SZO391tr5n6awLSIiLaquvo7dRw6QkJOscX3SpOraerbsKmDNthyy\ni6xr1AN7uzNtXAhxkf2uaY26XBlnRyM3hPpww3lr54+XnrVe/c4rIcNUyuHCUxzKP8WaxIa1825O\n540dtI4t1L/ZOfqbEBGR685isZBdmkdCTrLG9cklHS05wzeJOWzY0bBG3c7A2KF+TBsXzA0hLbNG\nXa6MwWDA16sbvl7dGH9jX6Bh7XxRmW3ySUbexWvnA/t0JzzQq2H6iSd9e7p12dYfhW0REblumhrX\n193JTeP6xMZisZCWeZy1iTnsSD+CxQIebo7cPSWMW6KD9IG8DsDRwZ6BgV4MDPQCQgHr2vmMxrXz\nuSUcyj9FTlE565NMALi5OBAW6GlrPwkL8MSti6ydV9gWEZFrUlVXzY6CtAvG9RntjET7RxIbFM0w\njesTrJMwvvs+nzXbcig8bl2jHhbQg2ljQxg/3A8Ho86Rjszbw4UxQ10Y07B2vq7ejKmo3Lp0pyGE\n7zp4jF0Na+cB/Hu5MTDQy7b10r+XO/ad8Oq3wraIiFwxjeuT5so/epq1iTl8930eZ6vrMdrbMWmE\nP9PGBneoNepyZYz2dvT370F//x5MG2e9rayi2nblOyO3lKz8UjYczbOtnXdxMhIW0MPafhLoSXiA\nJx5uTm34Lq4PhW0REWk2jeuT5qg3W9iZfoS123JsK8R9PJz5xaQwbh4dSA/3jh+g5Mp5uDkxanBv\nRg3uDVjPk7wj5Re0n+zJOsGerBO25/RpXDvfEMCD+nTH2ME2hCpsi4jIT2oc17fFlEyWxvXJTyiv\nrGFDSi7fbM/hWOlZAIaE+jBtXHCXWKMuV8bezmBbO39Lw9r5ijM1ZOadsl39zsgrZXNqAZsb1s47\nOljXzg+0TT/xwqudr51X2BYRkYvYxvWZkkkt0rg++WmHCk6xdlsOW3afW6M+tWGNemAXX6MuV8at\nmyORA32JHGj9LVnj2vnze79/yDnJgezz1s57uthaTwYGehLS16NdfQZAYVtERIDzxvWZkknM+57T\n1dYPsTWO6xsXOBIvlx5tXKW0F7V1ZrbvLWJt4nlr1H1cmTY2mMkjA7rMpAlpWeevnZ8y6ry18w2L\ndxqvgG9NK2Rrw9p5o70dof08Lmg/6dnDpc0mISlsi4h0cY3j+raYUigot26JaxzXFxsUTZDG9cl5\nTpadZX1SLuuTTZw6XY3BACMG9eLWccHcGKY16tLyujk7MGxAT4YNOLd2/sjJM+daT3JLbGF8NdkA\neHV3IjzQq6H9xIvQfh44O7ZODFbYFhHpgjSuT66ExWIhPaeEtYk5bG9co+7iwM9jQ5k6RmvUpW0Z\nDAb6+LjSx8f1grXzhwvKzms/KSFpXzFJ+85bO+/X/YIA3tu7ZdbOK2yLiHQR1nF9WSSYki8a1zch\nKJqYAI3rkwtV1dSxZXcha89box7UpzvTxgYTF9kPZ63klnbK2dHI4BBvBod4Aw1r50+dvaD15HBB\nGYcKyljbsHa+u6vjBa0nA/x70M352tuh9F+JiEgnd6lxfRPCJjMhaDR9NK5PfuTIyUq+2W5iQ0ou\nFWfPrVG/dVwwg7VGXTogg8GAr2c3fD27MX64de18bV09hwvLbKMHM3JL2Jl+lJ3pRwHr2vmA3t1t\nH7wMD/S6qrXzCtsiIp1QRXUliXnfXzSub2LwGGI1rk+aYDZbSMs6ztptOez8wbpGvYebE/dMCeOW\nmCB8emiNunQuDsbz185bnSw7S2Ze49zvUrLyT2EqLufb5FwAXF0cCA+wjh2872cDm3UchW0RkU5C\n4/rkapypquXfO/NZm5hN4fFKAMIDPLl1XDBjh2mNunQt3h4uxAxxIWbIeWvni8svaD/ZlXGMXRnH\nrn/Yzs3N5f333yc7O5vXX3+djRs3EhoaSnR09NW9GxERuWYa1ydXK+9IOWsTc9iUmq816iKXYLS3\no3+/HvTv14NpY4OBhrXzeaXNf43mPGjPnj08+OCDREVFsXv3bmpqajh06BCLFi3inXfeYeLEiVf3\nDkRE5KpoXJ9cjfp6MzvSj7JmWzZ7D1lXYvv0cOGXk4O4eXQgHm5aoy5yOR5uToyK6N3sxzcrbL/+\n+us89thjPPHEE9x4440AvPjii3Tv3p1ly5YpbIuItILGcX1bTCnsO3pQ4/qk2coqqvlXSi7rkkwc\nb1ijPrS/D7eOC2ZUhNaoi7SkZoXt9PR0FixYcNHtv/jFL/joo4+ue1EiImLVOK5viymF5IJdVGlc\nn1yBQ/mnWJOYzZbdhdTWmXF2tGfqmIY16r21Rl2kNTQrbLu4uHDy5EkCAwMvuD0nJwc3t+YNsjeb\nzbz00ktkZGTg6OjIggULLni9Dz/8kLVr1wIQGxvL7NmzOXXqFM8++ywVFRX06NGDBQsW4O3t3dz3\nJiLSYRWVH2FLbgpbTDs4cca6CrunqzfTNK5PLqO2zkzi3iLWbsvmYK61r9SvYY36JK1RF2l1zQrb\nt956K6+88gqLFy/GYDBQXV1NUlISL7/8MrfcckuzDrRx40ZqampYtWoVaWlpLF68mOXLlwOQn5/P\n6tWr+fzzz7Gzs+Pee+9lypQp/O///i9RUVE8/vjjbN++nTfeeIOFCxde/bsVEWnHKqor2Z7/PQk5\nGtcnV+5k2VnWJZn4NjnXtkZ9ZEQvbh0bwvCwnlqjLtJGmhW2n3nmGZ577jmmTZsGwG233QbA1KlT\n+d3vftesA6WmpjJ+/HgAhg8fzv79+2339e7dm7/+9a/Y21t7Devq6nBycuLQoUM8/fTTAERGRjJ/\n/vxmvi0RkY6hrr6OtCMH2GxKZlfRfurMdRgMBob1jiA2aDQj+w7XuD65pMY16mu2ZZO0r/iCNerx\nY4Lp46MWI5G21qywffjwYd58802eeeYZ0tPTcXBwYMCAAQQEBDT7QBUVFRe0nNjb21NXV4fRaMTB\nwQEvLy8sFgtLliwhIiKC4OBgBg0axHfffUdERATfffcdVVVVzTpWampqs+uSrkPnhTSlLc4Li8XC\n0eqT7D+dSfrpbM6ard/bfBw9ucF9ABHuobgbXeEE7D+xr9Xr6+o6wveKmjoz+0xn2ZFZwdFTtQD0\n6uHAqDBXhgR1w9FYTVHuQYpy27jQTqQjnBfSuqKiopr1uGaF7YcffpgVK1YwdOjQKwrY53Nzc6Oy\nstL2tdlsxmg8d/jq6mrmzJmDq6srL774IgCPPfYYCxcu5P777yc2NpbevZs3ZqW5b166jtTUVJ0X\ncpHWPi9Kzpxq6MO+cFzfxECN62sv2vv3iiMnK1mbmMOGHXlUNqxRHzfMj1vHhRAR7KXzp4W09/NC\n2rdmhe3u3btTU1NzTQeKjIxk06ZNxMfHk5aWRlhYmO0+i8XCr3/9a0aPHs1jjz1mu/3777/nl7/8\nJZGRkXz77bdERkZeUw0iIq1N4/rkWpnNFtIyj7MmMZvvfzh6bo36TWFMjQnC20Nr1EXas2aF7YkT\nJ/Loo48yadIk/P39cXZ2vuD+xx9//LKvcdNNN5GYmMiMGTOwWCwsWrSIDz74gICAAMxmMzt27KCm\npoatW7cC1j7x4OBgnn/+eQB8fX1ZtGjRlb4/EZFWp3F9cj1Unq3l39/n8U1izrk16oGe3DpWa9RF\nOpJmhe1vv/0WT09Pdu/eze7duy+4z2AwNCts29nZXfQBx9DQUNuf9+1rui/xs88+a06JIiJtrslx\nfd28NK5Prkhu4xr17/OpqqnHwWjH5JHWNeoD/LVGXaSjaVbY/u6771q6DhGRDumnx/WNZmDP/hrX\nJ5dlXaN+hDXbci5Yo373FK1RF+nomhW2wTpNZPXq1WRlZWE0GhkwYADx8fHNXmojItJZ1JnrSSve\nT4IphdSifRrXJ1etcY36N9tNnDh1/hr1EEZF9NIadZFOoFlhOz8/nwceeICysjJCQ0Mxm83885//\n5N133+WTTz6hb9++LV2niEibslgs5JTmkWBKYVveTk5XVwDg7+FHbFA04wJH4uXSo42rlI4iK7+U\nNdty2Jp2bo16fMMa9QCtURfpVJoVthcvXkxAQABvv/02np7WfrGSkhKeeeYZlixZwttvv92iRYqI\ntJVLjeuLHzCR2OAYjeuTZqutqydxTxFrtuWQkXfeGvVxwUweEYCr1qiLdErNCttJSUl8/PHHtqAN\n4OXlxbPPPsv//b//t8WKExFpC1V11ews2EOCKfnCcX39IokN1rg+uTIny86ybnvDGvWK89aojwth\n+ACtURfp7JoVtp2cnLCzu7hvzGAwUFdXd92LEhFpbWaLmR+OHyIhJ1nj+uSaWSwWDmSfZE1iDkn7\nijGbLbi5ODA9rj/xY4Lo7a1zSaSraFbYjo6O5rXXXuOtt97C3d0dgPLycpYuXcro0aNbtEARkZZU\ndPooW0zJGtcn10VVdR0JuwtYsy0HU3E5AMF+3Zk2NoTYyL44OzZ7LoGIdBLN+q/+ueeeY8aMGcTG\nxhISEgJAdnY2Xl5evP/++y1aoIjI9Xam9izbcnfyTf6/KTp0DNC4Prk2xScq+Wb7uTXq9nYGxg/v\ny7SxwVqjLtLFNSts9+nTh7Vr19pG/zk7OzNjxgxuv/12HB013kpEOoai00dZn7WZhJxkztZVYUDj\n+uTqmc0WdmceY822HFIPNqxRd3dixk3h3BITqDXqIgJcwZztvXv3EhAQwH333QfAwoUL2bVrF9HR\n0S1WnIjItTJbzOw5ks76rM3sLj4AgJdLD+4YdDNep12JGz2hjSuUjqbybC0bd+axNjGH4hPWNeoD\nAz25dVwIY4b64WDUb0VE5Jxmhe2vvvqKuXPn8txzzzFu3DgAysrKeOSRR3jttdeYOnVqixYpInKl\nztSeJSEnmfVZmymusLaKDPQJ5ZYBExnVbzhGO3tSU1PbuErpSHKLG9aop55boz5lZADTxgbT318z\n1kWkac0K23/+85958cUX+eUvf2m7bcmSJYwYMYJ3331XYVtE2o3GVpHNOUlU1VXjYGckLiiGWwbE\nEeIV0NblSQdTX28m5cAR1iaeW6Pe09OFe24K5qZRAVqjLiKX1aywXVRU1GS7SExMDAsXLrzuRYmI\nXInGVpF1mZtIO5IOWFtFfj7oZ0wJGUd3Z/c2rlA6mrKKar5NzmXd9hxOlFUBMGyAdY36yIje2Gs2\ntog0U7PCdkBAAAkJCcycOfOC2xMTE+nTp0+LFCYicjlnas+yOSeJb7MSLmgVmRo2kZF9h2vxjFwR\ni8VC4ckatny6iy27C6mrN+PiZM+0scFMGxuMfy/90CYiV65ZYfvhhx9m7ty5pKenM2TIEAD279/P\n6tWrmTdvXosWKCLyY0XlR1iflcBm03mtIsExTB0wkWBP/7YuTzqYE6fOkrCrgE2p+eQeOQ1A356u\nTBsbwuSR/nRz1hp1Ebl6zQrbP//5z3F0dORvf/sb69atw8HBgZCQEN58802mTJnS0jWKiGC2mEkr\nTmd9llpF5Nqdqapl+94iNqUWsO/wCSwWMNrbMcjfhXunDmeY1qiLyHXS7NF/8fHxxMfHt2QtIiIX\nUauIXC919WZ2ZRxjc2oBKfuLqakzAzA4xJu4yH6MG+ZHxg/7uDFcW0NF5Pq5bNjOzMwkKCjItrxm\n69atJCQk4OPjw913342Xl1eLFykiXY9aReR6sFgsZOaVsjm1gC1phZRX1gDQt6cbE0f0I/bGfvT2\ndm3jKkWkM7tk2K6oqOCJJ55gx44drFmzhtDQUD777DP++Mc/0qdPH7p168Ynn3zCqlWr8PPza82a\nRaSTulSryPRBtzA5ZKxaRaTZik9UsnlXAZtT8ylqWDzTw82J28eHEBfVj/79emiFuoi0ikuG7eXL\nl1NUVMSHH35ISEgI1dXVvP766wwePJhPP/0UBwcHXnjhBd5++21effXV1qxZRDqZMzVn2WxKYn3W\nZo5UHAdgUM/+3DIgTq0i0mzllTVs21PIpu/zOZhbCoCjgz2xN/YjLqofN4b1xN5e2x1FpHVdMmxv\n2LCBOXPmMHr0aACSk5OpqKjgvvvuw8HB+sns6dOn89vf/rZ1KhWRTketInKtamrr2Zl+lE2p+aQe\nPEpdvQU7AwwP68nEqH5E39BH00REpE1dMmwXFxcTHh5u+zolJQWDwcCYMWNst/n5+VFWVtayFYpI\np9LYKrIuaxN7GlpFvF08ra0ioePo7uTWxhVKe2c2WziQc5LNqQUk7imksqoOgGC/7kyM8mfCjX3x\n9nBp4ypFRKwuGbbd3NwoLy+39WMnJycTGBhI7969bY/Jy8vD09Oz5asUkQ7vUq0iUwdMZGTfYdir\nVUQuI+9IubUPe1cBx0vPAuDt4cwtMUHERfkT1Kd7G1coInKxS4bt0aNH89///d/Mnz+fXbt2kZ6e\nzn/8x3/Y7rdYLKxcuZKRI0e2SqEi0jEVlh9hfdZmEkzJtlaRicFjmDogjiC1ishllJZXkbC7kM27\n8jlcYP1NqouTkSkjA5g4oh+DQ3y0Ol1E2rVLhu3f/OY33HfffWzYsIHTp0/j5+fHrFmzAPjXv/7F\nihUrMJlM/OMf/2i1YkWkY7C2ihxgXdZmtYrIFauqriNpfzGbUwtIyzyG2QL2dgZGRvRiYpQ/owb3\nxslBvwkRkY7hkmE7NDSUtWvXsn79euzs7Jg2bRoeHh4AmEwm+vbty6JFi+jfv3+rFSsi7ZtaReRq\n1deb2ZN1gk278kneV0xVTT0A4QGeTIzqx7jhffFwc2rjKkVErtxPLrXx8fFh5syZF93+2GOPtVhB\nItLxqFVErobFYiG7sIxNqQVs2V1A6elqAHp7dyMu0p+JUf3w66nfgohIx9bsde0iIuc71yqyiT1H\nfgCsrSJ3RkxlUshYtYrIJR0rPUPCrgI2pRaQf/Q0AO7dHJg6JohJUf6EB3pq4YyIdBoK2yJyRc7U\nnGVTzna+PZRwXqvIAKYOiFOriFxSxdlaEvcUsXlXPvsPnwTAwWjH2KF+xEX1I2pgLxyMWjgjIp2P\nwraINEtjq8hmUzLVddU42DuoVUR+Um2dmV0Hj7IptYAd6UeorTMDcEOoN3GR/owd5oebixbOiEjn\nprAtIpd0qVaRu9QqIpdgsVjIyC3lu9R8tqUVcvpMLQD+vdyYGOVP7I398PXq1sZVioi0HoVtEblI\nY6vI+kMJHFWriDRD0fEKNqUWsHlXPkdOngGgh7sTd0wIJS6qH6F9PdSHLSJdksK2iNgUlBc3TBVJ\nUauIXFZZRTXb0grZlFpARl4pAE6O9sRF9WNipD/DBvhgb68+bBHp2i4ZtlesWNHsF3n88ccv+xiz\n2cxLL71ERkYGjo6OLFiwgMDAQNv9H374IWvXrgUgNjaW2bNnc/r0aZ5++mnOnDmDo6Mjr732Gj17\n9mx2XSJyeWaLmd3FB1ivVhFphuraenYcOMKm1Hx2HTxGvdmCnQEiw32Ji+pH9A19cHHSdRwRkUaX\n/I6YmprKtm3b6N69O66urpd8AYPB0KywvXHjRmpqali1ahVpaWksXryY5cuXA5Cfn8/q1av5/PPP\nsbOz495772XKlCmkpKQQFhbGc889xz/+8Q9WrlzJ73//+6t4myLyY2oVkeYymy3szz7B5tQCEvcW\ncaaqDoCQvh5MjPJnwo198eru3MZVioi0T5cM23/5y1+YM2cOO3fu5KuvvvrJwN0cqampjB8/HoDh\nw4ezf/9+2329e/fmr3/9K/b21v9zr6urw8nJibCwMLKzswGoqKjAaGze1ZLU1NRrqlU6J50XVidq\nStlVls7+8ixqLXUYDfYM7R5GlMdgfJ284ZiFtGNpbV1mq9F5cWlHT9Wy13SGfaYzlJ+xbnT06GbP\nuAh3hgZ1w7eHA3CKnKxT5LRtqdeVzglpis4L+bGoqKhmPe4n0+sf//hH7r77bv70pz/xX//1X9dU\nUEVFBW5u534dbW9vT11dHUajEQcHB7y8vLBYLCxZsoSIiAiCg4Oprq4mMTGR+Ph4ysrK+OSTT5p1\nrOa+eek6UlNTu/R50dgqsi5zE3uPNrSKdPPkZ/1ju3SrSFc/L5pysuwsW3YXsik1n5yicgBcnY3c\nPDqQuKh+DA72xs6u837QUeeENEXnhVyLnwzbDg4OLFy4kMTExGs+kJubG5WVlbavzWbzBVeqq6ur\nmRJo9f8AACAASURBVDNnDq6urrz44osAvPPOOzzyyCPMmDGDgwcP8pvf/Iavv/76mmsR6Soqa86w\nKSeJb9UqIj/hTFUtyfuL2ZRawN6s45gtYG9nYPTg3kyM8mdkRC8cHXSuiIhcjcv2ZURERBAREXHN\nB4qMjOT/t3ffcVnV/R/HX9fFliHgXiDiTlNBRUxz5Ei6825oaaU5qcyGlnc/rRzk7ai7acPceme3\nNswsS8tSU8EBiuEeOcCBA5EhcAHX+f2hUSgoKnAx3s/Ho4dc55zrnM+5OOmbw+d8v2vXriUkJITo\n6GgaNmyYs84wDEaMGEFQUBChoaE5yz08PHB3dwegUqVKucK6iOQvr1FFuvq1594GXajrVdvW5UkJ\nkJ1tZceBs6yLiiNi1yksmZfbRBr7etGldR3uurMmFd2cbFyliEjpl2/YPnToEPXq1cNsLpxhm7p3\n786mTZvo168fhmEwZcoU5s+fj4+PD1arla1bt2KxWNiwYQMAo0eP5oUXXuC1117j888/Jysrizfe\neKNQahEpi6xWKztOX9sq8nDTXtxT7y7cy2mriPzFMAwOxSWyLiqO33acIDElA4AalV3pEliHzgG1\nqVH59p7PERGR3PIN2/fffz8bN26kUqVKOcuWL19O9+7db+lhSbPZTFhYWK5l/v7+OV/HxMTk+b7Z\ns2ff9LFEypOcVpGD64hPPQdA0yoNuFetInJFfMIl1m2PZV1UHHFnUgDwcHXkH3f50TmwNg19vDTh\njIhIEck3bBuGcc2ysLAwAgMDb3tkEhG5fXFJp1h1YB3rj6lVRK6VcsnCxp0nWbc9jt1/nAfA0d5M\nhxY16dK6DgGNqmKvCWdERIrcTc08kFcAF5HiY7Va2X5qF6sOrlOriFwjMyubyL3xrI2KY9ueeLKy\nrZhMcGf9ynQOqE37O2vi6uJg6zJFRMoVTfMlUgrk1yrSq2EXWte8U60i5ZhhGOw5ksC67XFsjD5B\nSlomAD7V3ekSWIdOrWpTxcvFxlWKiJRfCtsiJVjcxSujivy9VaTeXfRq0BlfT7WKlGdxZ5JZFxXH\nuu1xxCdcAsDbw4kH2vrTtXUd6tbwUB+2iEgJcN2w/dNPP+WaiMZqtfLLL7/kemgSLj9MKSKF489W\nkR8PriUmfh8AlSt4q1VESEzO4LfoONZFxXEwNhEAZ0c7ura+PJLInQ2qYFeGJ5wRESmNbjiD5NWm\nTZuW67XJZFLYFikEl1tFwll1cB1nUi8/0KZWEUm3ZLFl12nWbY9j+/4zWK0GZrOJwMZV6RxYh3Z3\nVMfZSb+kFBEpqfL9G3rfvn3FWYdIuRV38RQ/HlzLb0e3kJFtUauIkG01iDl0lrVRcUTEnCQt4/KE\nM/XreNIloDYdW9XCy93ZxlWKiEhB6HaIiA3k1yrSp34nutZrr1aRcurIyYusjYpj/fY4EpLSAajq\n5cL9HS+3idSp5m7jCkVE5GYpbEuZlpRq4ctfDnDyVCKHLxzA28MJLw9nvNyd8fJwwsPVqVh7XPNq\nFbmjakPubdBZrSLl1LnENNZvv/yg49FTSQC4ujjQs50vXQLr0KSuN2b1YYuIlFoK21JmpWdkETZn\nM/uPXwBg64G912xjNpvwdHP8K4C7Xw7j3u5OeHo4430llHt5OOPkcOtBWK0i8neX0jMJ//0Ua6Ni\niTl8DsMAezsTwc1r0DmgNq2bVMPxNq43EREpORS2pUzKyrYyddE29h+/QOeA2jSqaqF67XpcSEon\nITmdxKQMEpLTuZCUwYXkdGLjUzgcd/G6+3R1tsfT3RlvjysB3N0Zbw+nK8v+umPuXsEBk8l0pVUk\n5kqryH5ArSLlWVa2lR37z7A2Ko4tu05hybIC0NTPm86BdejQoibuFRxtXKWIiBS2mw7bCQkJ2Nvb\n4+HhURT1iNw2q9Xg/SU72L7vDIGNq/JCv1bsjN5BYJNq+b7HMAzSMrJISErnQnIGF/7259XLTpxN\nue7x7R2zcK11mmyvI2TbpwJQ2b42d3q2oUXVO6jkWoH0S3Y421lxsNd02WWZYRgcjE1kbWQsv0Wf\nICnVAkCtKq6XJ5wJqE31Sq42rlJERIpSgcP2ggULmDNnDufPX+4zrVy5MkOGDGHw4MFFVpzIzTIM\ng7krdrFuexyNfb34v4FtsLe7caA1mUxUcHaggrMDtate/yG0zCwricmX74j/PZTHJZ3icMZOLtgd\nwmLOxrCayT5Tm6x4X2LT3IkljZVE5tqXewXHy3fFr7SreHs4/3Wn3P2vO+gVnO01QUkpcvp8Kuu2\nx7EuKpYTZy//wFXRzZH7O9ajc0BtGtTx1PdTRKScKFDYXrx4Me+++y4DBgygTZs2ZGdnExkZyXvv\nvUeFChV49NFHi7pOkQL56teDrNjwB3WquTN+WLsiGX/Ywd5MFS8Xqni55LSKbDu4lhjrfnC43CrS\ns34nuvgFY7I6Xb4zftXd8YSkdBKv/HkuMY1jp5Ove0xHB7trAriXh9OVnvK/es0ruhXvA5/yl6RU\nC5t2nmBtVBx7jyYA4Ghv5u6WtejSug4tG1Yp0A9+IiJSthQoiSxcuJBXX32VRx55JGdZ165dqVu3\nLgsXLlTYlhJh9eZjLPphL1W8XAgLDS7S/tcUSypr/4hg9aHco4r0atCFwJrNc40q4l7BEd/q12+7\nysjM5sLfAvjfQ/mFv91F338sAauR/37MJvBwc/rrwU73v/eX517m7KhHNm6XJTObbXvjWRsZS9S+\neLKyDUwmaNGgMl0C6xDcvAYVnB1sXaaIiNhQgf61jY+Pp127dtcsb9euHZMnTy70okRuVkTMST7+\nKhoPV0fCQoOp7OlSJMeJvXiSHw+uY8OVUUUc7Ry4p14HejXojI9nrVver5ODHdUrud6wfzfbapCU\nmpF/KL/y58lzKfxx8voPfLo42V8zFKJXrhaWy3fM3Ss4aui5v7FaDfYcOc/aqDg27TxBanoWAHVr\neFzpw65FpYpFc/2JiEjpU6Cw7ePjw7Zt2/Dx8cm1fMuWLVSvXr1IChMpqJhD53jrsygcHeyYMKzd\nDXuub5bVaiXqVAyrrhpVpG+DTnT1uws3p+J7wM3ObLoyRKEzfjUrXnfbS+mZf4XyfB72vJCcntNT\nnB97OxOeblcNhZjnSCxOONiX3eHqYuOTWRsVy/rtcZy5kAaAt4czPdvVpXNg7Rt+P0REpHwqUNh+\n8skneeONN4iNjaVVq1YAbN++nUWLFjFq1KgiLVDkeg7HJfLGvC0YhsG4QUE09PEqtH3/2Sqy6tA6\nzt6gVaQk+vOBz5pVrj/EYFa2lYsp194dv7rX/NipJA7FJl53X+4VHK56wPOqUH5lmWspeeDzQlI6\nv0WfYF1ULIeuDA3p4mTPPW3q0CWwDs38K6tHXkRErqtAYbtPnz4kJyczd+5cZs6cCUD16tX5v//7\nP/Vri82cPJfCxNmbSbdkMeaJ1rRqVLVQ9ltUrSIllb2dmUoVXW7Y+mAYBqlpmXmG8r/uoF8O6LHx\nN3jg09585U75X3fF8xqJxdPNCbtifqgwPSOLzbtOsXZ7HNH7z2A1Lk9+1LpJNboG1qHNHdXU7y4i\nIgVWoH8xlixZQu/evRk8eDAJCQk4OTnh6qqxYcV2EpLSmTArgsSUDJ5+6E46try9EPxnq8iPB9ay\n64xtW0VKKpPJhFsFR9wqOOJzg+4xS2b25QCenJ53KL+y7GBsItnXeeLTZIKKrk7XPOz55zCJf1/m\nchsjz2RbDXYePMu6qFgiYk6RbskGoKGPJ50D6tCxZS083Z1uef8iIlJ+Fehfp7fffpugoCAqVaqE\nt7d3Udckcl0paZlMnB3B6fOX6N+jEffd5Xfr+7Kk8usf4aw+tL5UtoqUVI4OdlT1rkBV7wrX3c5q\nNUi+ZLmmr/zqXvPT51M5cjLpuvtycbLL9WBnzp9XjcTi4Xr5gU/DMDiVYGHuil2s3x7HheQMAKp5\nV+CfgbXpHFC70Pv/RUSk/ClQ2G7SpAnh4eH4+d16qBEpDBmZ2Uyet4UjJ5Po1b4u/Xs0uqX95NUq\n0q1eB+4to60iJZXZbKKimxMV3Zy40d8uaRlZV9pUMnL9eXVby6kj5zGuNzyi+fIDn/b2Zs4kXALO\n4ObiQK/gyw86NqnrXSr6yUVEpHQoUNiuVKkSkydPZubMmdSpUwdnZ+dc6+fNm1ckxYn8XXa2lbf+\nG8nuP85zV4uaPPXgnTcVivJqFalSwZueahUpFVyc7HFxcqNm5es/8JmdbSUxJSP3qCt5jMSSmpZJ\nkzouPHhPc1o3qVqmR1IRERHbKVDYdnZ25oEHHijqWkTyZRgGH321ky27T9OiQWVeeiygwKNApFhS\n2XLhd+b98M01rSKta96J2axZ/coSuwI+8AkQFRVFYPMaxVCViIiUVwUK21OnTgXAYrHg6Hh5Vr6T\nJ09Ss2bNoqtM5G8W/bCXn7cep37tiowb1LbAdyHXHYlg7valZGRlqFVEREREil2BwvbZs2d54YUX\naN26NaNHjwbg4Ycfpn79+rz//vt6aFKK1PL1h/jq14PUquLKxOHBBZr+Oj0rg7lRS1h/dDMVHFzo\nXKkNAzs+qlYRERERKVYF+v355MmTMZlMPPTQQznLPvvsM6xWK9OmTSuy4kR+jYxl7ordeHs4Mym0\nPRXdbjz8WuzFk4z9eRrrj27G38uXN3uMI8irhYK2iIiIFLsC3dmOiIhg8eLF1K1bN2eZv78/r7/+\nOoMGDSqi0qS827bnNO8v3YGriwNhocFUu8EwcnClbSRqCRnZFno16MITLR7Ewc6BWI4VQ8UiIiIi\nuRUobJtMJtLS0q5Znp2dTWZmZqEXJbL3SALTFkVib2dm/NAgfGt4XHf79KwM5kUtZd3RCCo4uPBS\nu1CCarcqpmpFRERE8lagNpIOHTowZcoUTp48mbPs1KlTTJs2jbvuuqvIipPy6dipJCbN3UxWtpX/\nG9iapn6Vrrt93MVTjPt5OuuORlDPy4fpPcYqaIuIiEiJUKA72+PGjWPw4MHcc889OQ9DJiQk0KRJ\nE/7zn/8UaYFSvpxJuMT4WRGkpmUyqn8r2jS9/rzg649sZk7U/8jItnBv/c4MaPkQDnY3foBSRERE\npDgUeFKbb775hvDwcA4ePIi9vT3+/v60b99eM61JobmYksH4WeEkJKUztPcddG3tk++2GVkW5m1f\nytoj4bg4ODM6aDjt6gQUY7UiIiIiN1agsA1gZ2dHx44d6dix4y0dyGq1MnHiRPbv34+joyOTJ0/G\n19c3Z/2CBQtYuXIlAJ06dWLkyJHMmjWLDRs2AJCUlMS5c+fYtGnTLR1fSrZL6ZlMnLOZE2dTebhL\nfR7oVD/fbeOSTvHuptnEJp3Cz6sOo9oPp7pblWKsVkRERKRg8g3bPXv2ZOnSpXh6etKjR4/r3sFe\nvXr1DQ+0Zs0aLBYLS5cuJTo6mmnTpvHJJ58AEBsby4oVK/jyyy8xm83079+fbt26ERoaSmhoKABP\nPfUUY8aMudnzk1IgMyubKQu2cig2ke5tfXjyvqb5bvvb0S3MjvofGVkZ9KzfiQEtH8ZRbSMiIiJS\nQuUbtu+//36cnJxyvr7ddpGoqKicu+ItW7Zk165dOeuqV6/OnDlzsLO7PCtgVlZWzrEBfvrpJzw8\nPOjQocNt1SAlT7bV4O3Pt7Pz4DmC7qjOs31a5HmtZWRZmL99Kb8eCcfF3plR7YcRXCfQBhWLiIiI\nFJzJMAyjOA706quv0qNHDzp16gRA586dWbNmDfb2f+V9wzB48803SU1NJSwsLGf5ww8/zDvvvJOr\n7SQ/UVFRhV+8FAnDMPghMpFtB1PxqeLIgC5VcLC/NmiftySy/PQvnLNcoKpjJR6o3hUvx4o2qFhE\nRETkssDAgt30y/fO9nfffVegHZhMJv7xj3/ccDs3NzdSU1NzXlut1lxBOyMjg3HjxuHq6sqECRNy\nlh86dAgPD48CBe0/FfTkxbb+t3of2w6eoG4ND6Y+2wE3l2vbQTYc3cp/o74jIyuDHv53M7BVn1tq\nG4mKitJ1IdfQdSFX0zUhedF1Ibcj37A9ZsyYnF/nX+/md0HDdkBAAGvXriUkJITo6GgaNmyYs84w\nDEaMGEFQUFBOj/afwsPDufvuu2+4fyldVm46wuc/7aeadwUmhQZfE7QtWRbm7/iSX/7YiIu9My8G\nD6W9T2sbVSsiIiJya/IN2x06dGDLli20aNGCkJAQ7r333pwxtm9F9+7d2bRpE/369cMwDKZMmcL8\n+fPx8fHBarWydetWLBZLzugjo0ePplWrVhw5ckQT55QxG6JP8Ok3v+Pp5kTYU8F4ezjnWn8y6TTv\nhM/h+MUT1PWszaj2w6nhXtVG1YqIiIjcunzD9pw5c7h48SI//fQTq1atYvr06QQEBBASEkKPHj2o\nWPHmembNZnOuPmwAf3//nK9jYmLyfN/fW0qk9Is+cIZ3Po/C2dGeicPbUbOyW671G49tY1bkYtKz\nMuju35EnW/XVaCMiIiJSal13nO2KFSvSt29f+vbtS0JCAj///DMrV67kjTfeICgoiJCQELp3746b\nm9v1diMCwIHjF/j3/K2AideHBOFf2zNnnSXLwoIdX7Lmj4042zvxQvAQ7vJpY7tiRURERAqBuaAb\nent78+ijj7JgwQLWrVtH+/btmTx5Mu3bty/K+qSMiDuTzKQ5m7FkZjPmiUCa16+cs+5kcjyv/vIW\na/7YiG/FWkzrMVZBW0RERMqEAs8gCZCcnMwvv/zCqlWrCA8Pp2LFivTs2bOoapMy4vzFNMbPiiAp\n1cLIvi1of2fNnHWbjm/j022X20a61evAoFZ9cbR3tGG1IiIiIoXnhmE7MTGRn3/+mZ9++omIiAi8\nvb3p0aMH8+bNIzAw8LYnu5GyLfmShfGzIjh7IY0BvZrQs11dACzZmSzc8SU/H96As70Tz7cbTAff\ntrYtVkRERKSQ5Ru2lyxZwurVq9m2bRuVK1emR48ePP300xpnUgos3ZJF2JzNHD+dTO+O9eh7TwMA\nTiWf4Z3w2RxLjMOnYi1Gtx9GTY/qNq5WREREpPDlG7YnTpyIg4MD7du3p1WrVphMJrZt28a2bduu\n2fbpp58u0iKl9MnKtjJ9UST7jl2gU6vaDO3dDJPJRPjxSD7dtpi0rHTuqdeBwWobERERkTIs37Bd\ns+blvtpDhw5x6NChfHdgMpkUtiUXq9Xg/aU7iNwbT0DjqrzQrxVZRhaLIr/ip8O/4WTvxHNBg+lY\nV20jIiIiUrblG7Z//fXX4qxDygjDMJj33W7WRcXRyMeLsQPbcD7tHO+Gz+FIYix1KtZkdPvh1FLb\niIiIiJQDNzUaiciNfL32EN/+dpg61dwYP6wdO87sZObWz0jLSqerX3sGBzyKk9pGREREpJxQ2JZC\n89OWYyxcuYfKni68NqQNX+5bxupD63Gyc2Rk0CDurhtk6xJFREREipXCthSKiJhTfPRlNO4VHHl+\nQEPe3/4hRy5cbhsZ1X4YtT1q2LpEERERkWKnsC23bdfhc7z1WSSODnb0eciV97a/T1pmOl382jNE\nbSMiIiJSjilsy205cvIib8zbgkEWgd0SWXJgJU52jjzb9kk6+bWzdXkiIiIiNqWwLbfs9PlUxs+K\nIJ0kagcfYPu509T2qMHo9sOpXVFtIyIiIiIK23JLLiSlM/7TCJLsj+HWdA9nMyx0rhvMkMBHcbZ3\nsnV5IiIiIiWCwrbctNS0TCbM3sQ510icqh/DZHZgROBAOvsF27o0ERERkRJFYVtuiiUzmwkLf+Gk\n51rs3ZKo7VGDUe2HUadiTVuXJiIiIlLiKGxLgWVnW3ntf19zzH0DZvssOvoGMbx1f7WNiIiIiORD\nYVsKJDMrkzFfz+Kk0y7Mhh3DA5+gW/27bF2WiIiISImmsC03dCb1PK/+8AEXOYN9pjsTezxLw6q+\nti5LREREpMRT2Jbr2hoXzQfhC7AYGTgk+/D2w89S3cvD1mWJiIiIlAoK25KnrOwsFv++nJUHfsGw\nmnGMb8l/nnic6l5uti5NREREpNRQ2JZrnEk9z3vhcziUcBQjzRVzbGv+PSyEGpUVtEVERERuhsK2\n5BJ5YicfbVlIamYa1oSaGMebMXH43dStodYRERERkZulsC3A5baRz39fzvcHfsHebI8prgWZp2vw\n6qAg7qhXydbliYiIiJRKCtvC2SttIwcTjlK1QhWS9jQj+YwTL/ZrRds7qtu6PBEREZFSS2G7nIs8\n8TsfbV1IquUSbWsGcjC8NhfOZDD4H3dwTxsfW5cnIiIiUqopbJdTWdZs/vf7cr7bvwYHsz2DW/bj\npx8NTp65yEOd6/NQl/q2LlFERESk1FPYLofOpSbwbsQcDp4/Qg33qjzXdigLv47jUOxZ7mlTh0H/\naGrrEkVERETKBIXtcibqZAwfbVlIiiWV9j6tGR7wGB99sZvoA2dp07Qaz/VticlksnWZIiIiImWC\nwnY5kWXNZknMt6zY9zMOZntCWz9GV7+7mL18FxuiT9DUz5t/DWiNnZ3Z1qWKiIiIlBkK2+XAuUsJ\nvB8+l/3n/6CGW1VGtR9GXa86LPl5P99vOkLdGh68PiQIZ0ddDiIiIiKFqdjSldVqZeLEiezfvx9H\nR0cmT56Mr69vzvoFCxawcuVKADp16sTIkSPJzs5m6tSp7Nq1C4vFwnPPPUeXLl2Kq+QyYfvJXXy4\nZcHltpE6gYS2eZwKDi78GH6Exav2UdW7AhOHt8OtgqOtSxUREREpc4otbK9ZswaLxcLSpUuJjo5m\n2rRpfPLJJwDExsayYsUKvvzyS8xmM/3796dbt27s2bOHrKwslixZQnx8PD/++GNxlVvqZVmzWRqz\ngm/3/YSD2Z5hgf3p7t8Rk8nEpp0n+WTZ71R0c+SN0GAqVXSxdbkiIiIiZVKxhe2oqCg6duwIQMuW\nLdm1a1fOuurVqzNnzhzs7OwAyMrKwsnJiY0bN9KgQQNCQ0MxDIPXX3+9uMot1c5fusB7EXPZf+4w\n1d2qMKr9cPy86gCw88BZ/rM4CmdHeyYOD6ZmFTcbVysiIiJSdhVb2E5JScHN7a9gZ2dnR1ZWFvb2\n9jg4OODt7Y1hGLz55ps0bdoUPz8/Lly4wPHjx/n000/Ztm0bY8eOZfHixTc8VlRUVFGeSol2ODWW\nlfHrSLNm0MjNj15VO5LwxxkSOMPJBAsL1pzFMAz63uXNxfjDRMXbuuLiU56vC8mfrgu5mq4JyYuu\nC7laYGBggbYrtrDt5uZGampqzmur1Yq9/V+Hz8jIYNy4cbi6ujJhwgQAPD096dy5MyaTibZt23L0\n6NECHaugJ1+WZFuzWbrrO5afWo292Z5hgf3o7n93zjB+J86m8O6KDWRmG7wysA133VnTxhUXr6io\nqHJ5Xcj16bqQq+makLzoupDbUWzjvAUEBPDbb78BEB0dTcOGDXPWGYbBiBEjaNSoEWFhYTntJIGB\ngaxfvx6Affv2UaNGjeIqt1RJuJTIpLXvsnzvaqq5VWHyPWPoUb9TTtA+fzGN8Z+GczHFwjMPtyh3\nQVtERETEVortznb37t3ZtGkT/fr1wzAMpkyZwvz58/Hx8cFqtbJ161YsFgsbNmwAYPTo0TzyyCNM\nmDCBRx55BMMwmDRpUnGVW2pEn9rNjC0LSM5IoV3tAJ5u8wQVHP964DHlkoUJsyI4cyGNJ+5tTK/g\nurYrVkRERKScKbawbTabCQsLy7XM398/5+uYmJg83zd16tQirau0yrZm88Wu7/lm7yrszfYMCXiU\nnn+7mw2QbskibO4Wjp1O5h8d/HikW8Pr7FFERERECptmMSmFEi4l8v7muew9e4hqrpUZ1X4Y9bx9\nc22TlW1l+qJI9h5N4O5WtRj+z+aahl1ERESkmClslzI7T+9hxub5JGWkEFS7Fc+0GZCrbQTAajWY\n8UU0kXvjadWwCi/2C8BsVtAWERERKW4K26VEtjWbL3d/zzd7VmM2m/NsG/nTgpV7+DUyloY+nowd\n1BYH+2J7DlZERERE/kZhuxRISEvkg4h57Dl7kKqulRjVfjj+V7WN/GnZ2oN8s+4Qtau6MX5oO1yc\n9C0WERERsRUlsRLu99N7+WDzPJIyUmhbuyXPtBmAq2OFPLdds/UY87/fQ+WKzkwKDaaim1MxVysi\nIiIif6ewXUJZrVa+3L2SZXt+xGw2M6hVX3o16JLvQ45bdp1ixpc7ca/gwKTQYKp65R3IRURERKT4\nKGyXQBfSLvLB5nnsPnOAKq6VGBU8jPqV6ua7/e4/zvPmfyNxsDczflg7fKp7FF+xIiIiIpIvhe0S\n5vfTe5mxeT4XM5JpW6slz7TNv20E4MjJi7wxdzPZVoPXB7elsa93MVYrIiIiItejsF1CWK1Wvtqz\nkq93F6xtBOD0+VQmzIogNT2Llx4PJLBxtWKsWERERERuRGG7BEhMu8j7f7aNVPBmVPvh120bAbiQ\nnM74WRFcSM5g+APN6BxQu3iKFREREZECU9i2sZj4fXyweT4X05NoXasFI9oOwM3R9brvuZSeycTZ\nmzl1LpVHujWkd0f/624vIiIiIrahsG0jVquVr/f8wFe7f8BsMjGwZR/ua9j1hlOqWzKz+ff8rfxx\n4iI92/nyxL2Ni6liEREREblZCts2kJh2kQ82z2fXmf1UruDNqPbDaFDJ74bvy7Ya/GdxFL8fOkdw\n8xo883CLG4ZzEREREbEdhe1itit+Px9snkdiehKta97JiLYDcXO6ftsIgGEYfPL1TiJiTtHcvzIv\nPx6InVlBW0RERKQkU9guJlarlWV7f+TL3SsxY2Jgy4e5r+E9Bb4zvXjVPlZvPka9WhV5bUhbHB3s\nirhiEREREbldCtvFIDE9iRmb5xMTv49KFbwYFTyMhpXrFfj9KzYcZumaA9So5MrE4e2o4OxQhNWK\niIiISGFR2C5iu88c4P2IuSSmJxFQszkj2z5ZoLaRP63bHsfs5bvwcnci7KlgvNydi7BaERERkuf3\nrwAAHJ9JREFUESlMCttFxGq18s3eVXyx+3tMmHiixUPc36jbTT3QGLUvnvf+tx1XZ3smhQZTvVLB\nQ7qIiIiI2J7CdhG4mJ7EjM0L+D1+L5UqePFi8FAaVb65sbD3H0tg6sJt2JlNvD60HX41KxZRtSIi\nIiJSVBS2C9meMwd4P2IeF9IvElCjGc8GPYm7k9tN7SM2PplJczaTmWVl3JNtuKNepSKqVkRERESK\nksJ2IbEaVpbvXc3SXd9daRt5kH806obZZL6p/Zy9kMb4T8NJvpTJC4+2JKhZjSKqWERERESKmsJ2\nIUhKT2bGlvnsPL2XSi5evBA8lMZVbn4K9aRUC+NnhXPuYjqD7mtKt7a+RVCtiIiIiBQXhe3btOfM\nQd7fPJcLaRdpdaVtxOMm20YA0jKyCJuzmbgzKTzQyZ+HutQvgmpFREREpDgpbN8iq2Hl270/sWTX\nCkyYeOzOB+jduPtNt40AZGZZmbZwG/uPX6Br6zoM/scdmoZdREREpAxQ2L4Fl9tGFrDz9B68XTx5\nMXgojavc2p1oq9XgvSXb2b7/DK2bVOO5R1pi1jTsIiIiImWCwvZN2nf2EO9FzCUhLZGW1Zsyst3g\nW2obATAMg9nfxvDbjhM0qevNKwNbY29383fGRURERKRkUtguIKthZcW+n1kSswLgttpG/vTFLwf4\nfuMRfKu7M35oEM6O+naIiIiIlCVKdwWQlJHCR1sWsOPUbrxcKvJi8FCaVGlwW/tcFXGUz37cR1Uv\nFyaFBuNWwbFwihURERGREkNh+wb2nT3MexFzSEhLpEX1pjwXNAgPZ/fb2uem30/yydc78XB1JOyp\n9lSq6FJI1YqIiIhISaKwnQ+rYeW7fWv4X8y3GBj0a96bB5r0vK22EYDfD53lP59F4eRox8Th7ahV\n5db6vUVERESk5FPYzkNyRgofblnIjlO78HKuyAvBQ2la9fbaRgAOxSUyed5WAF4dFESDOl63vU8R\nERERKbkUtq+y/9xh3gufy/m0C7So3oSRQYOo6Oxx2/s9eTaFibMjSLdk8a8BrWnRsEohVCsiIiIi\nJZnC9hVWw8r3+9fw+e+F2zYCcP5iGq/PiuBiioVnHr6TDi1qFULFIiIiIlLSFVvYtlqtTJw4kf37\n9+Po6MjkyZPx9fXNWb9gwQJWrlwJQKdOnRg5ciSGYXD33XdTt25dAFq2bMlLL71U6LUlZ6Tw0ZaF\nbM9pGxlC06oNC2XfKWmZTJy9mTMJl3isZ2NC2vsVyn5FREREpOQrtrC9Zs0aLBYLS5cuJTo6mmnT\npvHJJ58AEBsby4oVK/jyyy8xm83079+fbt264eLiwh133MHMmTOLrK4D5/7g3Yg5nL90gebVGvNc\nu8F4FkLbCEBGZjZvzN3M0VNJ3HeXH/26F06AFxEREZHSwWQYhlEcB5o6dSp33nkn9913HwAdO3Zk\nw4YNAGRmZpKcnIy3tzcAffr04a233mLv3r3Mnj0bNzc3nJ2dGTt2LPXq1bvucaKiogpUj2EYbEuM\nYf35bRhAB+8A2nm1KJS2EYBsq8HSDec5cCKdO3xcePgub8wmTcMuIiIiUhYEBgYWaLtiu7OdkpKC\nm9tfw9zZ2dmRlZWFvb09Dg4OeHt7YxgGb775Jk2bNsXPz49z584RGhpKr169iIyMZMyYMXz99dc3\nPNaNTj4lI5WPti4k6nwMns4ePN9uCM2qNbrtc/yTYRi8v3QHB06k07JhFcYPbYeDvaZht6WoqKgC\n/08h5YeuC7margnJi64LuR3FFrbd3NxITU3NeW21WrG3/+vwGRkZjBs3DldXVyZMmABAs2bNsLOz\nA6B169acOXMGwzAw3cYd4gPn/uC9iLmcu5RA82qNeK7dkEJrG/nTwpV7+GVbLA3qeDL2yTYK2iIi\nIiLlVLGF7YCAANauXUtISAjR0dE0bPhX/7JhGIwYMYKgoCBCQ0Nzln/44Yd4enoyfPhw9u3bR40a\nNW45aBuGwcoDv7B45zdYDYNHmv2Dh5r0wmwu3CC8bO0hvl57iFpV3JgwrB0VnB0Kdf8iIiIiUnoU\nW9ju3r07mzZtol+/fhiGwZQpU5g/fz4+Pj5YrVa2bt2KxWLJ6eMePXo0oaGhjBkzhvXr12NnZ8fU\nqVNv6dgpllQ+3rKIyJO/U9HZgxfaDaZZtcaFeXoA/LLtOPO/302lis6EhQZT0c2p0I8hIiIiIqVH\nsYVts9lMWFhYrmX+/v45X8fExOT5vlmzZt3WcQ+eP8J74XM4eymBZlUb8Xy7wXi6VLytfeZl657T\nfPBFNG4uDkwKDaaqd4VCP4aIiIiIlC5ldlIbwzD44cCvfPb7N1itVvrecR8PNw0p9LYRgN1/nGf6\nwm3Y25mZMKwdvtULtwdcREREREqnMhm2UyypfLz1v0Se2ElFJ3eeDx5C8yJoGwE4eiqJN+ZtIdtq\n8NqQtjSu610kxxERERGR0qdMhu1XfprK2dTz3FG1Ic+3G4JXEbSNAMQnXGLCrHBS0zIZ/VgArZtU\nK5LjiIiIiEjpVCbD9rnUBPrcEUKfpvcVSdsIQGJyBuM/DSchKYNh/2xGl8A6RXIcERERESm9ymTY\nfrXTc9xZvUmR7f9SeiYT50Rw8lwqfe9pwD/v9r/xm0RERESk3CmTs60UZdDOzMrm3/O3cjjuIt3b\n+jCgV9EdS0RERERKtzIZtotKttXg7cXb+f3QOdo1q86zfVrc1myWIiIiIlK2KWwXkGEYzFz2O5t+\nP0kz/0qMeaI1dnb6+EREREQkf0qLBfT56v2sijiKX00PXhschKODna1LEhEREZESTmG7AL7f+AdL\nft5P9UoVmDQ8GFcXB1uXJCIiIiKlgML2Dfy2I45Zy2PwdHciLLQ9Xh7Oti5JREREREoJhe3r2L7/\nDO/+bzsuTvZMGh5Mjcquti5JREREREoRhe18HDh+gakLtmIymXhtSBD1ahXNLJQiIiIiUnYpbOch\nNj6ZibM3Y8nMZswTrWnuX9nWJYmIiIhIKaSwfZVziWmMnxVB8iULz/ZtSXDzGrYuSURERERKKYXt\nv0lKtTB+VjjnEtMYGNKEHkG+ti5JREREREoxhe0r0jOyCJu7mdj4FP55tz99ujawdUkiIiIiUsop\nbANZ2VamLtrG/mMX6BxYmyH336Fp2EVERETktpX7sG21Gry/ZAfb950hsHFVXni0FWazgraIiIiI\n3L5yHbYNw2Duil2s2x5HY18v/m9gG+ztyvVHIiIiIiKFqFwny69+PciKDX9Qp5o744e1w9nJ3tYl\niYiIiEgZUm7D9urNx1j0w16qeLkQFhqMewVHW5ckIiIiImVMuQzbETEn+firaDxcHQkLDaayp4ut\nSxIRERGRMqjche2YQ+d467MoHB3smDCsHbWrutu6JBEREREpo8pV2D4cl8gb87ZgGAbjBrWloY+X\nrUsSERERkTKs3ITtk+dSmDh7M+mWLEY/FkirRlVtXZKIiIiIlHHlImwnJKUzYVYEiSkZPPXgnXRs\nWcvWJYmIiIhIOVDmw3ZKWiYTZ0dw+vwl+vdoxH13+dm6JBEREREpJ8p02M7IzGbyvC0cOZlEr/Z1\n6d+jka1LEhEREZFypMyG7exsK2/9N5Ldf5znrhY1eerBOzGZNA27iIiIiBSfMhm2DcPgo692smX3\naVo0qMxLjwVgZ1bQFhEREZHiVSbD9qIf9vLz1uPUr12RcYPa4mBvZ+uSRERERKQcKrawbbVaGT9+\nPI8++igDBgzg2LFjudYvWLCAvn370rdvXz788MNc6w4fPkxgYCAZGRkFOtZXvx6kVhVXJg4PpoKz\nQ6Gdg4iIiIjIzSi2sL1mzRosFgtLly7lpZdeYtq0aTnrYmNjWbFiBUuWLOGLL75g48aN7Nu3D4CU\nlBSmT5+Oo6NjgY/l7eHMpND2VHRzKvTzEBEREREpqGIL21FRUXTs2BGAli1bsmvXrpx11atXZ86c\nOdjZ2WEymcjKysLJyQnDMHj99dcZPXo0Li4uBT5WWGgw1bwrFPo5iIiIiIjcDPviOlBKSgpubm45\nr+3s7MjKysLe3h4HBwe8vb0xDIM333yTpk2b4ufnx4wZM+jUqRONGze+qWOdO3mQcycL+wyktIuK\nirJ1CVIC6bqQq+makLzoupCrBQYGFmi7Ygvbbm5upKam5ry2Wq3Y2/91+IyMDMaNG4erqysTJkwA\nYMWKFVSvXp2vv/6as2fPMmTIEBYvXnzDYxX05KX8iIqK0nUh19B1IVfTNSF50XUht6PYwnZAQABr\n164lJCSE6OhoGjZsmLPOMAxGjBhBUFAQoaGhOct//vnnnK+7du3KvHnziqtcEREREZHbVmxhu3v3\n7mzatIl+/fphGAZTpkxh/vz5+Pj4YLVa2bp1KxaLhQ0bNgAwevRoWrVqVVzliYiIiIgUumIL22az\nmbCwsFzL/P39c76OiYm57vt//fXXIqlLRERERKSolMlJbURERERESgKFbRERERGRIqKwLSIiIiJS\nRBS2RURERESKiMK2iIiIiEgRUdgWERERESkiCtsiIiIiIkVEYVtEREREpIgobIuIiIiIFBGFbRER\nERGRIqKwLSIiIiJSREyGYRi2LqIwRUVF2boEERERESkHAgMDb7iNfTHUUazCw8N57rnnbF2GlDAz\nZszQdSHX0HUhV9M1IXnRdSF5mTFjRoHCdpm7sy0iIiIiUlKoZ1tEREREpIgobIuIiIiIFBGFbRER\nERGRIqKwLSIiIiJSRBS2RURERESKiMK2iIiIiEgRKVNhe+fOnQwYMMDWZUgJkZmZyZgxY3jsscfo\n06cPv/zyi61LkhIgOzubsWPH0q9fP/r378+BAwdsXZKUIOfPn6dTp04cPnzY1qVICfHggw8yYMAA\nBgwYwNixY21djpQQn376KY8++igPPfQQX3755XW3LTOT2syePZsVK1bg4uJi61KkhFixYgWenp68\n9dZbJCYm8sADD3DPPffYuiyxsbVr1wKwZMkStmzZwrvvvssnn3xi46qkJMjMzGT8+PE4OzvbuhQp\nITIyMjAMg//+97+2LkVKkC1btrBjxw7+97//kZaWxrx58667fZm5s+3j48OMGTNsXYaUIPfeey8v\nvPACAIZhYGdnZ+OKpCTo1q0bb7zxBgAnT57Ew8PDxhVJSTF9+nT69etH1apVbV2KlBD79u0jLS2N\nIUOGMHDgQKKjo21dkpQAGzdupGHDhjz77LM8/fTTdO7c+brbl5k72z179iQuLs7WZUgJ4urqCkBK\nSgrPP/88L774oo0rkpLC3t6eV155hZ9//pkPPvjA1uVICbBs2TK8vb3p2LEjs2bNsnU5UkI4Ozsz\ndOhQ+vbty9GjRxk+fDirVq3C3r7MxCe5BRcuXODkyZPMnDmTuLg4nnnmGVatWoXJZMpz+zJzZ1sk\nL6dOnWLgwIH885//5P7777d1OVKCTJ8+ndWrV/P6669z6dIlW5cjNvb1118THh7OgAED2Lt3L6+8\n8gpnz561dVliY35+fvTu3RuTyYSfnx+enp66LgRPT086dOiAo6Mj9erVw8nJiYSEhHy3V9iWMuvc\nuXMMGTKEMWPG0KdPH1uXIyXE8uXL+fTTTwFwcXHBZDJhNuuvwvJu8eLFfPbZZ/z3v/+lSZMmTJ8+\nnSpVqti6LLGxr776imnTpgEQHx9PSkqKrgshMDCQDRs2YBgG8fHxpKWl4enpme/2+j2IlFkzZ84k\nKSmJjz/+mI8//hi4/CCtHn4q33r06MHYsWN5/PHHycrKYty4cbomRCRPffr0YezYsfTv3x+TycSU\nKVPUQiJ06dKFbdu20adPHwzDYPz48dd9LsxkGIZRjPWJiIiIiJQb+t2piIiIiEgRUdgWERERESki\nCtsiIiIiIkVEYVtEREREpIgobIuIiIiIFBGFbREpE7p27Uq3bt1IS0u7Zt2AAQN49dVXi+zYcXFx\nNGrUiMjIyCI7RkHt3r2bkJAQmjVrxvTp069Zv2zZMho1apTnfw899FCh1XHq1ClWrlxZaPu7GevX\nr+eJJ56gVatWtGzZkgcffJDFixdzM4NvZWVlsWDBgqIrUkTKDQ0WKSJlRmxsLO+8806RBuuSbtas\nWdjb2/PDDz/g7u6e5zZ2dnasX7/+muWFOX7wuHHjqFatGvfdd1+h7bMgNmzYwLPPPsvLL7/MpEmT\nsLOzIyIigqlTp3LhwgVGjhxZoP388MMPTJ06lUGDBhVtwSJS5ilsi0iZUadOHT777DN69epFQECA\nrcuxiaSkJJo0aYKPj891tyvqWfBsNYXDF198QZcuXXKF5Lp163L27FkWLVpU4LCtKShEpLCojURE\nyowHH3yQVq1a8eqrr5KRkZHnNnm1fFy9bMCAAfznP//hpZdeomXLlnTo0IEvvviCyMhIevfuTYsW\nLejfvz/Hjx/Pte/IyEhCQkJo3rw5/fr1Y9euXTnrrFYrM2fOpEuXLrRs2ZKHH344193lZcuW0bNn\nTyZOnEhgYCD/+te/8qz/wIEDDB8+nDZt2tC2bVv+9a9/kZCQAFxupQkPD2f58uU0atSIuLi4W/sg\ngTVr1tC7d2+aN2/Ovffey9y5c7FarTnrt2zZktOq0axZM/75z3/y22+/AfB///d/RERE8M0339Co\nUaOcz/Tq3zj8fVl+5x8ZGUm/fv248847ueeee3j77bfz/d4CmM1m9uzZw5kzZ3ItHzRoEEuXLs15\nbbFYmDZtGh06dCAgIIAnnniC6OjonHP78/iNGjVi2bJlXLp0ibFjx9K+fXuaN2/OI488QkRExC19\ntiJSvihsi0iZYTKZ+Pe//82JEyeYMWPGbe1rwYIF3HHHHXz33Xfcc889hIWFMWnSJF577TU+++wz\n4uPjeeedd3K9Z/78+YwePZply5ZRtWpVQkNDuXTpEgBvv/02y5YtIywsjG+//ZYHH3yQkSNHsmXL\nlpz3Hz16lJSUFJYvX85TTz11TU1xcXH079+fihUrsnjxYj7++GP27dvHkCFDyM7O5quvvqJ169b0\n6tWLjRs3UqNGjVs69/Xr1/Pyyy8zcOBAVq5cyZgxY1i0aBEff/wxcLkfe/jw4QQGBrJixQq++uor\natSowSuvvILFYuHVV1/NVUdBXX3+e/fuZejQoXTv3p3vvvuOyZMns3btWiZOnJjvPp588knOnDlD\n165dGTx4MJ988gk7duzAzc0NPz+/nO3+9a9/sW3bNt577z2+/vpr2rVrx4ABAzhy5AitWrVi/Pjx\nAGzcuJGQkBA++OADDh06xNy5c/nhhx9o0qQJI0eOzPn+iojkR20kIlKm+Pn58fzzz/POO+9w7733\n0qxZs1vaT7NmzRgyZAgATzzxBEuWLGHQoEG0bdsWgF69erFu3bpc73nxxRfp1q0bAFOmTOHuu+9m\n5cqVhISEsGjRImbMmEHHjh0B8PX1Zd++fcyaNYugoKCcfYwYMYI6derkWdPnn3+Oh4cHU6dOxcHB\nAYB3332XkJAQNmzYQOfOnXFwcMDZ2fm6bSLZ2dm0atXqmuWRkZHY2dkxc+ZM+vfvT58+fQDw8fEh\nNTWV119/nREjRpCZmckLL7zAkCFDMJlMwOU7x08++STnz5+nRo0aBaojL38//5dffplOnToxdOjQ\nnM9s0qRJPPbYY4waNYqqVate8/6AgACWLVvGvHnzWLduHeHh4TnnMHXqVFq3bs2xY8f48ccf+f77\n72nQoAEAI0eOJCoqivnz5xMWFoabmxvwV7vNsWPHcHV1pXbt2ri7u/PKK6/Qs2dP7Ozsbur8RKT8\nUdgWkTJn8ODBrF69mrFjx7Js2bJb2oevr2/O1y4uLgC5+qCdnZ2xWCy53vP3AOvm5ka9evU4cOAA\njRo1wmKx8MILL2A2//ULxczMTCpXrpzz2mQyUbt27XxrOnjwIM2bN88J2gD+/v54eXlx4MABOnfu\nXKBzs7OzY/ny5XkuB9i7dy8xMTEsWbIkZ53VaiU9PZ0TJ07g4+PDAw88wMKFC9m/fz/Hjh1j7969\nwOUgf6uuPv+9e/dy7NixXJ/rn73Uhw8fzjNsAzRo0ICpU6diGAb79+/nt99+Y9GiRQwfPpw1a9aw\nZ88eAB555JFc77NYLNd8T/80dOhQRowYQXBwMK1ataJjx4707t0bJyenWz5fESkfFLZFpMyxs7Nj\nypQpPPjgg8ycOfOG2+cVEPMamePPu7jXO+7fWa1WHB0dcXR0BGDGjBm5QjyQK3ybzeacbfPi7Oyc\n53Kr1ZorgBfE1XX8nYODA8OGDeP++++/Zl21atU4cOAAjz/+OC1atCA4OJiQkBCysrJ4+umnb6qG\nrKysXK+vPn8HBwceeOABhg8ffs1787pjnpqayjvvvMOjjz5Kw4YNMZlMNG7cmMaNG9O9e3fuvfde\ntm3blvNZLVmy5JrPNL/Pv3Xr1qxfv56NGzeyceNGFi9ezCeffMIXX3yRc3dcRCQv6tkWkTKpQYMG\nPPPMM3z66ae5HmT8M2ilpqbmLDt69GihHPPPO6YAiYmJHDlyhAYNGuDr64uDgwPx8fH4+vrm/Pfd\nd9/d1J13f39/YmJiyMzMzFl26NAhLl68iL+/f6GcA0D9+vU5evRorloPHDjAu+++C8DSpUupUaMG\nc+bMYejQoXTs2JH4+HjgrzvPV/9g4uDgQEpKSs5rq9VKbGzsDes4fPhwrjoSEhKYPn16ru/fn1xc\nXPj+++/54osvrlnn4eEBQOXKlXPC8fnz53Pte8GCBfzyyy951v/hhx+yfft2unfvzqRJk/jpp59w\ncHC4ppVIRORqCtsiUmaFhobi7+/P6dOnc5ZVrVqVWrVqsWDBAv744w8iIyN57733bnjXuiDeeust\n1q9fz/79+3n55ZepXLkyISEhuLi4MGjQIN5++21++OEHYmNjWbRoER999FG+/dl5eeKJJ0hOTmbs\n2LEcPHiQyMhIXn75ZRo3bkxwcPBt1/+nZ555hpUrVzJr1iyOHj3KunXrGD9+PM7Ozjg6OlK9enVO\nnDjBpk2bOHHiBN9++21OEP+zDcPV1ZW4uDhOnDgBQMuWLdmwYQMbNmzg6NGjTJo0iaSkpOvWMXz4\ncH7//XemTp3K4cOH2bp1K6+88grJycl53tk2m8289NJLfPbZZ0yePJldu3YRGxvL+vXrGTlyJEFB\nQbRu3RpfX19CQkJ4/fXXWb9+PcePH+fdd99lyZIlOT+0uLq6AhATE0NqaionTpxg0qRJbNmyhRMn\nTrBixQqSk5Np0aJFoX3uIlI2qY1ERMosBwcHpk6dSt++fXOWmUwm3nzzTaZMmULv3r3x9fVl7Nix\nhIaG3vbxRowYwb///W9OnTpFmzZtmDNnTk5bwosvvoiDgwNvvvkm586do06dOoSFhd3UrI2VK1dm\n3rx5vPXWWzz88MO4uLjQtWtXxowZc9NtJNdz99138+abbzJr1iw++OADvL29eeCBBxg1ahQAAwcO\n5PDhw4waNYrs7Gz8/f2ZNGkSY8eOJSYmBn9/fx5//HFefvllQkJCWLNmDUOGDOH48eM8//zzODo6\n0qdPnxtOeNOoUSM+/fRT3n//fT7//HPc3d3p0qVLvsMiwuU+7MqVK7Nw4UKGDh1KampqzuQ6f29z\nmTx5Mm+//Tbjxo0jOTkZf39/ZsyYkfNDS1BQEG3btqV///689NJLvPbaa0yfPp2XXnqJxMREfH19\nmTp1as4DsyIi+TEZGrlfRERERKRIqI1ERERERKSIKGyLiIiIiBQRhW0RERERkSKisC0iIiIiUkQU\ntkVEREREiojCtoiIiIhIEVHYFhEREREpIgrbIiIiIiJF5P8B7tbfkL/coscAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d50ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FONT_SIZE = 15\n",
    "\n",
    "df = by_feat_size\n",
    "\n",
    "STYLE = \"whitegrid\"\n",
    "sns.set_style(STYLE)\n",
    "sns.set_style(STYLE, {\"xtick.major.size\": 1})\n",
    "\n",
    "fig = plt.figure(figsize=(12,6.5))\n",
    "\n",
    "x = df[\"count\"].values\n",
    "y_cb = df[\"micro_f1_score_CB\"].values\n",
    "y_sc = df[\"micro_f1_score_SC\"].values\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.plot(x,y_cb, label=\"Coral Bleaching\")\n",
    "ax1.plot(x,y_sc, label=\"Skin Cancer\")\n",
    "\n",
    "legend = ax1.legend(loc='upper left', shadow=True, fontsize=FONT_SIZE)\n",
    "\n",
    "ax1.set_xlim([1, 6])\n",
    "#ax1.set_ylim([0.695, 0.77])\n",
    "ax1.set_xlabel('Number of Feature Sets', fontsize=FONT_SIZE)\n",
    "ax1.set_ylabel('Micro F1 Score', fontsize=FONT_SIZE)\n",
    "\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 1.0), fontsize=10)\n",
    "sns.despine()\n",
    "\n",
    "# plt.savefig(\"/Users/simon.hughes/BitBucket/Dissertation/Dissertation/images/sr_parser_f1_score_by_num_feats.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rows for LaTex Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score As Individual Features are Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & pos wd feats stemmed offset:4 & 0.2276 & & pos wd feats offset:2 & 0.2206\\\\\n",
      "2 & pos ngram feat stemmed ngram size:2offset:4 & 0.2494 & & bow ngram feat ngram size:2offset:2 & 0.2712\\\\\n",
      "3 & pos POS feats offset:4 & 0.2699 & & bow ngram feat ngram size:1offset:2 & 0.2867\\\\\n",
      "4 & bow ngram feat ngram size:1offset:4 & 0.2851 & & pos ngram feat ngram size:2offset:2 & 0.2987\\\\\n",
      "5 & pos ngram feat stemmed ngram size:3offset:4 & 0.2991 & & pos POS feats offset:2 & 0.3072\\\\\n",
      "6 & bow ngram feat ngram size:2offset:4 & 0.2918 & & pos ngram feat ngram size:3offset:2 & 0.3196\\\\\n"
     ]
    }
   ],
   "source": [
    "for i, row in df_f1_score_by_feat_size.iterrows():\n",
    "    #pprint(row)\n",
    "    \n",
    "    feats_CB = format_lbl(row[\"new_feat_CB\"])\n",
    "    micro_f1_score_CB = row[\"micro_f1_score_CB\"]\n",
    "    \n",
    "    feats_SC = format_lbl(str(row[\"new_feat_SC\"]))\n",
    "    if feats_SC == \"nan\":\n",
    "        feats_SC = \"-\"\n",
    "        \n",
    "    micro_f1_score_SC = row[\"micro_f1_score_SC\"]\n",
    "    if str(micro_f1_score_SC) != \"nan\":\n",
    "        micro_f1_score_SC = \"{0:0.4f}\".format(micro_f1_score_SC)\n",
    "    else:\n",
    "        micro_f1_score_SC = \"-\"\n",
    "    count = row[\"count\"]\n",
    "    print(\"{count} & {feat_cb} & {cb_f1:0.4f} & & {feat_sc} & {sc_f1}\\\\\\\\\"\\\n",
    "          .format(count=count,feat_cb=feats_CB, cb_f1=micro_f1_score_CB,\n",
    "                  feat_sc=feats_SC, sc_f1=micro_f1_score_SC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check - Do Any Datasets have Duplicate Feature Sets with Different F1 Scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SH: There were some issues with the CB_VD dataset initially for a couple of collections\n",
    "for df in [cb_td_df, cb_vd_df, sc_td_df, sc_vd_df]:\n",
    "    gb = group_by(df, bycols=[\"hs_feats\"], agg_map=[\n",
    "        (\"micro_f1_score\", \"count\"),\n",
    "        (\"micro_f1_score\", \"min\"),\n",
    "        (\"micro_f1_score\", \"max\"),\n",
    "    ])\n",
    "    gb = gb[gb[\"count(micro_f1_score)\"] > 1]\n",
    "    miss_match = gb[gb[\"min(micro_f1_score)\"] != gb[\"max(micro_f1_score)\"]]\n",
    "    \n",
    "    assert len(miss_match) == 0, \"Some errors occurred during data capture\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Reduction in Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = cb_vd_df\n",
    "# best_row = df.sort_values(\"micro_f1_score\").tail(1)\n",
    "\n",
    "# max_feats = best_row[\"count\"].values[0]\n",
    "\n",
    "# sub = df[df[\"count\"] == max_feats-1].sort_values(\"micro_f1_score\")\n",
    "# feats = sub.tail(1)[\"feats\"].values[0]\n",
    "# num_feats = sub.tail(1)[\"num_feats\"].values[0]\n",
    "\n",
    "# max_ft_df = (df[df[\"count\"] == max_feats]).copy()\n",
    "# max_ft_df[\"diff\"] = max_ft_df[\"num_feats\"] - num_feats\n",
    "# diffs = max_ft_df[\"diff\"].sum()\n",
    "# total_feats = diffs + num_feats\n",
    "# # diffs, total_feats\n",
    "# act_feats = best_row[\"num_feats\"].values[0]\n",
    "# act_feats,total_feats, act_feats/total_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = sc_vd_df\n",
    "# best_row = df.sort_values(\"micro_f1_score\").tail(1)\n",
    "\n",
    "# max_feats = df[\"count\"].max()\n",
    "\n",
    "# sub = df[df[\"count\"] == max_feats-1].sort_values(\"micro_f1_score\")\n",
    "# #feats = sub.tail(1)[\"feats\"].values[0]\n",
    "# num_feats = sub.tail(1)[\"num_feats\"].values[0]\n",
    "\n",
    "# max_ft_df = (df[df[\"count\"] == max_feats]).copy()\n",
    "# max_ft_df[\"diff\"] = max_ft_df[\"num_feats\"] - num_feats\n",
    "# diffs = max_ft_df[\"diff\"].sum()\n",
    "# total_feats = diffs + num_feats\n",
    "# # diffs, total_feats\n",
    "# act_feats = best_row[\"num_feats\"].values[0]\n",
    "# act_feats,total_feats,act_feats/total_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the Optimal Feat Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>feats</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...</td>\n",
       "      <td>0.299145</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.205882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                              feats  micro_f1_score  \\\n",
       "0      5  [fn_pos_wd_feats_stemmed[offset:4], fn_pos_ngr...        0.299145   \n",
       "\n",
       "   micro_precision  micro_recall  \n",
       "0         0.546875      0.205882  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_vd_df.sort_values(\"micro_f1_score\", ascending=False).head(1)\\\n",
    "[[\"count\",\"feats\",\"micro_f1_score\",\"micro_precision\",\"micro_recall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fn_pos_wd_feats_stemmed[offset:4]',\n",
       " 'fn_pos_ngram_feat_stemmed[ngram_size:2 offset:4]',\n",
       " 'fn_pos_POS_feats[offset:4]',\n",
       " 'fn_bow_ngram_feat[ngram_size:1 offset:4]',\n",
       " 'fn_pos_ngram_feat_stemmed[ngram_size:3 offset:4]']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_vd_df.sort_values(\"micro_f1_score\", ascending=False).head(1)[\"feats\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>feats</th>\n",
       "      <th>micro_f1_score</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...</td>\n",
       "      <td>0.31962</td>\n",
       "      <td>0.643312</td>\n",
       "      <td>0.212632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                              feats  micro_f1_score  \\\n",
       "0      6  [fn_pos_wd_feats[offset:2], fn_bow_ngram_feat[...         0.31962   \n",
       "\n",
       "   micro_precision  micro_recall  \n",
       "0         0.643312      0.212632  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_vd_df.sort_values(\"micro_f1_score\", ascending=False).head(1)\\\n",
    "[[\"count\",\"feats\",\"micro_f1_score\",\"micro_precision\",\"micro_recall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fn_pos_wd_feats[offset:2]',\n",
       " 'fn_bow_ngram_feat[ngram_size:2 offset:2]',\n",
       " 'fn_bow_ngram_feat[ngram_size:1 offset:2]',\n",
       " 'fn_pos_ngram_feat[ngram_size:2 offset:2]',\n",
       " 'fn_pos_POS_feats[offset:2]',\n",
       " 'fn_pos_ngram_feat[ngram_size:3 offset:2]']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_vd_df.sort_values(\"micro_f1_score\", ascending=False).head(1)[\"feats\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
