{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - Take the merged predictions and evaluate the prediction accuracy using the 2 different approaches\n",
    " 1. Look at the anaphora tags and then cross-reference co-reference labels\n",
    " 2. Use the co-reference chains directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from FindFiles import find_files\n",
    "from Settings import Settings\n",
    "from CoRefHelper import EMPTY\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "PARTITION = \"Training\" # Training | Test\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "merged_predictions_folder = root_folder + \"CoReference/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_files = find_files(merged_predictions_folder)\n",
    "if PARTITION == \"Training\":\n",
    "    essay_files = [e for e in essay_files if \"train\" in e]\n",
    "assert len(essay_files) == 1\n",
    "with open(essay_files[0], \"rb\") as f:\n",
    "    essays = dill.load(f)\n",
    "len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/training_processed.dill']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in essays:    \n",
    "    # map coref ids to sent_ix, wd_ix tuples\n",
    "    # now look for ana tags that are also corefs, and cross reference\n",
    "    for sent_ix in range(len(e.sentences)):\n",
    "        sent     = e.sentences[sent_ix]\n",
    "        ana_tags = e.ana_tagged_sentences[sent_ix]\n",
    "        coref_ids= e.pred_corefids[sent_ix]\n",
    "        ner_tags = e.pred_ner_tags_sentences[sent_ix]\n",
    "        pos_tags = e.pred_pos_tags_sentences[sent_ix]\n",
    "        ptags    = e.pred_tagged_sentences[sent_ix]\n",
    "        \n",
    "        assert len(sent) == len(coref_ids)\n",
    "                \n",
    "        assert len(sent) == len(ana_tags) == len(coref_ids) == len(ner_tags) == len(pos_tags) == len(ptags),\\\n",
    "            (len(sent), len(ana_tags), len(coref_ids), len(ner_tags), len(pos_tags), len(ptags), e.name, sent_ix)\n",
    "        assert len(sent) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anaphor:[11]', 6),\n",
       " ('Anaphor:[12]', 11),\n",
       " ('Anaphor:[13]', 31),\n",
       " ('Anaphor:[14]', 28),\n",
       " ('Anaphor:[1]', 68),\n",
       " ('Anaphor:[2]', 9),\n",
       " ('Anaphor:[3]', 39),\n",
       " ('Anaphor:[4]', 13),\n",
       " ('Anaphor:[50]', 44),\n",
       " ('Anaphor:[5]', 15),\n",
       " ('Anaphor:[5b]', 7),\n",
       " ('Anaphor:[6]', 18),\n",
       " ('Anaphor:[7]', 55)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "for e in essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:                \n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "sorted(cc_tally.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chain(e):\n",
    "    corefid_2_chain = defaultdict(list)\n",
    "    for sent_ix in range(len(e.sentences)):\n",
    "        sent     = e.sentences[sent_ix]\n",
    "        coref_ids= e.pred_corefids[sent_ix]\n",
    "        for wd_ix in range(len(sent)):\n",
    "            wd_coref_ids = coref_ids[wd_ix] # Set[str]\n",
    "            for cr_id in wd_coref_ids:\n",
    "                pair = (sent_ix, wd_ix)\n",
    "                corefid_2_chain[cr_id].append(pair)\n",
    "    return corefid_2_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processessays import Essay\n",
    "\n",
    "tally = defaultdict(int)\n",
    "\n",
    "ana_tagged_essays = []\n",
    "for eix, e in enumerate(essays):\n",
    "    \n",
    "    ana_tagged_e = Essay(e.name, e.sentences)\n",
    "    ana_tagged_e.pred_tagged_sentences = []\n",
    "    ana_tagged_essays.append(ana_tagged_e)\n",
    "    \n",
    "    # map coref ids to sent_ix, wd_ix tuples\n",
    "    corefid_2_chain = build_chain(e)\n",
    "    \n",
    "    # now look for ana tags that are also corefs, and cross reference\n",
    "    for sent_ix in range(len(e.sentences)):\n",
    "        ana_tagged_sent = []\n",
    "        ana_tagged_e.pred_tagged_sentences.append(ana_tagged_sent)\n",
    "        \n",
    "        sent     = e.sentences[sent_ix]\n",
    "        ana_tags = e.ana_tagged_sentences[sent_ix]\n",
    "        coref_ids= e.pred_corefids[sent_ix]\n",
    "        ner_tags = e.pred_ner_tags_sentences[sent_ix]\n",
    "        pos_tags = e.pred_pos_tags_sentences[sent_ix]\n",
    "        ptags    = e.pred_tagged_sentences[sent_ix]    \n",
    "        \n",
    "        for wd_ix in range(len(sent)):\n",
    "            word = sent[wd_ix]\n",
    "            is_ana_tag = ana_tags[wd_ix] == ANAPHORA\n",
    "            wd_coref_ids = coref_ids[wd_ix] # Set[str]\n",
    "            word, wd_tags = sent[wd_ix]\n",
    "            pred_cc_tag = ptags[wd_ix]\n",
    "            \n",
    "            wd_ptags = set()\n",
    "            if pred_cc_tag != EMPTY:\n",
    "                wd_ptags.add(pred_cc_tag)\n",
    "                \n",
    "            ana_tagged_sent.append(wd_ptags)\n",
    "            if is_ana_tag and len(wd_coref_ids) >= 1:\n",
    "                for cr_id in wd_coref_ids:            \n",
    "                    chain = corefid_2_chain[cr_id]\n",
    "                    if len(chain) > 0:                        \n",
    "                        for ch_sent_ix, ch_wd_ix in chain:\n",
    "                            # if it's the current word, skip\n",
    "                            if ch_sent_ix == sent_ix and ch_wd_ix == wd_ix:\n",
    "                                continue\n",
    "                            # for anaphors only - only look at chain ixs before the current word\n",
    "                            # if's it's after the current word in the essay, skip\n",
    "                            if ch_sent_ix > sent_ix or (ch_sent_ix == sent_ix and ch_wd_ix >= wd_ix):\n",
    "                                continue\n",
    "                            \n",
    "                            chain_wd, chain_tags = e.sentences[ch_sent_ix][ch_wd_ix]\n",
    "                            chain_ptag = e.pred_tagged_sentences[ch_sent_ix][ch_wd_ix]\n",
    "                            if chain_ptag != EMPTY:\n",
    "                                formatted_code =  \"{anaphora}:[{code}]\".format(\n",
    "                                    anaphora=ANAPHORA, code=chain_ptag)\n",
    "                                wd_ptags.add(formatted_code)\n",
    "                                tally[formatted_code] +=1\n",
    "                                \n",
    "                                assert len(ana_ptags) <=1, ana_ptags\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in ana_tagged_essays:\n",
    "    assert len(e.sentences) == len(e.pred_tagged_sentences)\n",
    "    for ix in range(len(e.sentences)):\n",
    "        assert len(e.sentences[ix]) == len(e.pred_tagged_sentences[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Anaphor:[11]', 2),\n",
      " ('Anaphor:[14]', 33),\n",
      " ('Anaphor:[1]', 23),\n",
      " ('Anaphor:[3]', 3),\n",
      " ('Anaphor:[50]', 22),\n",
      " ('Anaphor:[6]', 7)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(sorted(tally.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set(),\n",
       "  {'50'},\n",
       "  set(),\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(),\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [{'Anaphor:[50]'},\n",
       "  {'50'},\n",
       "  {'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  {'7'},\n",
       "  {'7'},\n",
       "  {'7'},\n",
       "  {'7'},\n",
       "  {'7'},\n",
       "  {'7'},\n",
       "  set()],\n",
       " [{'50'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana_tagged_essays[35].pred_tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
