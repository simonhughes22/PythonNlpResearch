{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - Take the merged predictions and evaluate the prediction accuracy using the 2 different approaches\n",
    " 1. Look at the anaphora tags and then cross-reference co-reference labels\n",
    " 2. Use the co-reference chains directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "from FindFiles import find_files\n",
    "from Settings import Settings\n",
    "from CoRefHelper import EMPTY\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "PARTITION = \"Training\" # Training | Test\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "merged_predictions_folder = root_folder + \"CoReference/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_files = find_files(merged_predictions_folder)\n",
    "if PARTITION == \"Training\":\n",
    "    essay_files = [e for e in essay_files if \"train\" in e]\n",
    "assert len(essay_files) == 1\n",
    "with open(essay_files[0], \"rb\") as f:\n",
    "    essays = dill.load(f)\n",
    "len(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/training_processed.dill']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in essays:    \n",
    "    # map coref ids to sent_ix, wd_ix tuples\n",
    "    # now look for ana tags that are also corefs, and cross reference\n",
    "    for sent_ix in range(len(e.sentences)):\n",
    "        sent     = e.sentences[sent_ix]\n",
    "        ana_tags = e.ana_tagged_sentences[sent_ix]\n",
    "        coref_ids= e.pred_corefids[sent_ix]\n",
    "        ner_tags = e.pred_ner_tags_sentences[sent_ix]\n",
    "        pos_tags = e.pred_pos_tags_sentences[sent_ix]\n",
    "        ptags    = e.pred_tagged_sentences[sent_ix]\n",
    "        \n",
    "        assert len(sent) == len(coref_ids)\n",
    "                \n",
    "        assert len(sent) == len(ana_tags) == len(coref_ids) == len(ner_tags) == len(pos_tags) == len(ptags),\\\n",
    "            (len(sent), len(ana_tags), len(coref_ids), len(ner_tags), len(pos_tags), len(ptags), e.name, sent_ix)\n",
    "        assert len(sent) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anaphor:[11]', 6),\n",
       " ('Anaphor:[12]', 11),\n",
       " ('Anaphor:[13]', 31),\n",
       " ('Anaphor:[14]', 28),\n",
       " ('Anaphor:[1]', 68),\n",
       " ('Anaphor:[2]', 9),\n",
       " ('Anaphor:[3]', 39),\n",
       " ('Anaphor:[4]', 13),\n",
       " ('Anaphor:[50]', 44),\n",
       " ('Anaphor:[5]', 15),\n",
       " ('Anaphor:[5b]', 7),\n",
       " ('Anaphor:[6]', 18),\n",
       " ('Anaphor:[7]', 55)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "reg_tally = defaultdict(int)\n",
    "for e in essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "sorted(cc_tally.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chain(e):\n",
    "    corefid_2_chain = defaultdict(list)\n",
    "    for sent_ix in range(len(e.sentences)):\n",
    "        sent     = e.sentences[sent_ix]\n",
    "        coref_ids= e.pred_corefids[sent_ix]\n",
    "        for wd_ix in range(len(sent)):\n",
    "            wd_coref_ids = coref_ids[wd_ix] # Set[str]\n",
    "            for cr_id in wd_coref_ids:\n",
    "                pair = (sent_ix, wd_ix)\n",
    "                corefid_2_chain[cr_id].append(pair)\n",
    "    return corefid_2_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processessays import Essay\n",
    "\n",
    "def get_ana_tagged_essays(essays, format_ana_tags=True):\n",
    "    ana_tagged_essays = []\n",
    "    for eix, e in enumerate(essays):\n",
    "\n",
    "        ana_tagged_e = Essay(e.name, e.sentences)\n",
    "        ana_tagged_e.pred_tagged_sentences = []\n",
    "        ana_tagged_essays.append(ana_tagged_e)\n",
    "\n",
    "        # map coref ids to sent_ix, wd_ix tuples\n",
    "        corefid_2_chain = build_chain(e)\n",
    "\n",
    "        # now look for ana tags that are also corefs, and cross reference\n",
    "        for sent_ix in range(len(e.sentences)):\n",
    "            ana_tagged_sent = []\n",
    "            ana_tagged_e.pred_tagged_sentences.append(ana_tagged_sent)\n",
    "\n",
    "            sent     = e.sentences[sent_ix]\n",
    "            ana_tags = e.ana_tagged_sentences[sent_ix]\n",
    "            coref_ids= e.pred_corefids[sent_ix]\n",
    "            ner_tags = e.pred_ner_tags_sentences[sent_ix]\n",
    "            pos_tags = e.pred_pos_tags_sentences[sent_ix]\n",
    "            ptags    = e.pred_tagged_sentences[sent_ix]    \n",
    "\n",
    "            for wd_ix in range(len(sent)):\n",
    "                word = sent[wd_ix]\n",
    "                is_ana_tag = ana_tags[wd_ix] == ANAPHORA\n",
    "                wd_coref_ids = coref_ids[wd_ix] # Set[str]\n",
    "                word, wd_tags = sent[wd_ix]\n",
    "                pred_cc_tag = ptags[wd_ix]\n",
    "\n",
    "                wd_ptags = set()\n",
    "                if pred_cc_tag != EMPTY:\n",
    "                    wd_ptags.add(pred_cc_tag)\n",
    "\n",
    "                ana_tagged_sent.append(wd_ptags)\n",
    "                if is_ana_tag and len(wd_coref_ids) >= 1:\n",
    "                    for cr_id in wd_coref_ids:            \n",
    "                        chain = corefid_2_chain[cr_id]\n",
    "                        if len(chain) > 0:                        \n",
    "                            for ch_sent_ix, ch_wd_ix in chain:\n",
    "                                # if it's the current word, skip\n",
    "                                if ch_sent_ix == sent_ix and ch_wd_ix == wd_ix:\n",
    "                                    continue\n",
    "                                # for anaphors only - only look at chain ixs before the current word\n",
    "                                # if's it's after the current word in the essay, skip\n",
    "                                if ch_sent_ix > sent_ix or (ch_sent_ix == sent_ix and ch_wd_ix >= wd_ix):\n",
    "                                    continue\n",
    "\n",
    "                                chain_wd, chain_tags = e.sentences[ch_sent_ix][ch_wd_ix]\n",
    "                                chain_ptag = e.pred_tagged_sentences[ch_sent_ix][ch_wd_ix]\n",
    "                                if chain_ptag != EMPTY:\n",
    "                                    code = chain_ptag\n",
    "                                    if format_ana_tags:\n",
    "                                        code =  \"{anaphora}:[{code}]\".format(\n",
    "                                            anaphora=ANAPHORA, code=chain_ptag)\n",
    "                                    wd_ptags.add(code)\n",
    "    # validation check    \n",
    "    #   check essay and sent lengths align\n",
    "    for e in ana_tagged_essays:\n",
    "        assert len(e.sentences) == len(e.pred_tagged_sentences)\n",
    "        for ix in range(len(e.sentences)):\n",
    "            assert len(e.sentences[ix]) == len(e.pred_tagged_sentences[ix])\n",
    "    return ana_tagged_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 10.2 ms, total: 430 ms\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ana_tagged_essays = get_ana_tagged_essays(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map new tags to existing labels, not anaphora labels\n",
    "collapsed_ana_tagged_essays = get_ana_tagged_essays(essays, format_ana_tags=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_procesor import ResultsProcessor\n",
    "\n",
    "# Modify this function from the Resultsprocessor so that it works with Set[str] of predicted tags \n",
    "# as well as scalar strings\n",
    "def get_wd_level_preds(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sentix in range(len(e.sentences)):\n",
    "            p_ccodes = e.pred_tagged_sentences[sentix]\n",
    "            for wordix in range(len(p_ccodes)):\n",
    "                ptag_set = set(p_ccodes[wordix])  \n",
    "                for exp_tag in expected_tags:\n",
    "                    ysbycode[exp_tag].append(ResultsProcessor._ResultsProcessor__get_label_(exp_tag, ptag_set))\n",
    "    return ysbycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaphor:[11]',\n",
       " 'Anaphor:[12]',\n",
       " 'Anaphor:[13]',\n",
       " 'Anaphor:[14]',\n",
       " 'Anaphor:[1]',\n",
       " 'Anaphor:[2]',\n",
       " 'Anaphor:[3]',\n",
       " 'Anaphor:[4]',\n",
       " 'Anaphor:[50]',\n",
       " 'Anaphor:[5]',\n",
       " 'Anaphor:[5b]',\n",
       " 'Anaphor:[6]',\n",
       " 'Anaphor:[7]']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_tags = sorted(reg_tally.keys())\n",
    "all_ana_tags = sorted(cc_tally.keys())\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on Anaphora Tags Only - Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_procesor import metrics_to_df\n",
    "\n",
    "def get_df(mean_metrics):\n",
    "    df = metrics_to_df(mean_metrics)\n",
    "    df = df[[\"code\",\"recall\",\"precision\",\"f1_score\",\"data_points\"]]\n",
    "    df = df.sort_values(\"code\")\n",
    "    return df[~df.code.str.contains(\"MEAN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>data_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anaphor:[11]</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anaphor:[12]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Anaphor:[13]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anaphor:[14]</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Anaphor:[1]</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anaphor:[2]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anaphor:[3]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anaphor:[4]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anaphor:[50]</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anaphor:[5]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Anaphor:[5b]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anaphor:[6]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anaphor:[7]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MACRO_F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MICRO_F1</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>1783158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            code    recall  precision  f1_score  data_points\n",
       "2   Anaphor:[11]  0.166667   1.000000  0.285714     137166.0\n",
       "6   Anaphor:[12]  0.000000   0.000000  0.000000     137166.0\n",
       "10  Anaphor:[13]  0.000000   0.000000  0.000000     137166.0\n",
       "0   Anaphor:[14]  0.107143   0.500000  0.176471     137166.0\n",
       "12   Anaphor:[1]  0.014706   0.100000  0.025641     137166.0\n",
       "1    Anaphor:[2]  0.000000   0.000000  0.000000     137166.0\n",
       "5    Anaphor:[3]  0.000000   0.000000  0.000000     137166.0\n",
       "8    Anaphor:[4]  0.000000   0.000000  0.000000     137166.0\n",
       "9   Anaphor:[50]  0.045455   0.200000  0.074074     137166.0\n",
       "3    Anaphor:[5]  0.000000   0.000000  0.000000     137166.0\n",
       "11  Anaphor:[5b]  0.000000   0.000000  0.000000     137166.0\n",
       "4    Anaphor:[6]  0.000000   0.000000  0.000000     137166.0\n",
       "7    Anaphor:[7]  0.000000   0.000000  0.000000     137166.0\n",
       "18      MACRO_F1       NaN        NaN       NaN          NaN\n",
       "17      MICRO_F1  0.020349   0.241379  0.037534    1783158.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_ys_bycode  = ResultsProcessor.get_wd_level_lbs(ana_tagged_essays,  expected_tags=all_ana_tags)\n",
    "pred_ys_bycode = get_wd_level_preds(ana_tagged_essays, expected_tags=all_ana_tags)\n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(act_ys_bycode, pred_ys_bycode)\n",
    "\n",
    "get_df(mean_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with No Anaphora Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>data_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MICRO_F1</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.833163</td>\n",
       "      <td>1783158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code    recall  precision  f1_score  data_points\n",
       "17  MICRO_F1  0.820049   0.846703  0.833163    1783158.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_metrics = ResultsProcessor.compute_mean_metrics_from_tagged_essays(essays, expected_tags=reg_tags)\n",
    "df = get_df(reg_metrics)\n",
    "df[df.code == \"MICRO_F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy with Anaphora Tagging (Adding in Ana Tags as Regular Tags, not Anaphora[xyz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>data_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MICRO_F1</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>0.84602</td>\n",
       "      <td>0.832832</td>\n",
       "      <td>1783158.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code    recall  precision  f1_score  data_points\n",
       "17  MICRO_F1  0.820049    0.84602  0.832832    1783158.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_ys_bycode  = ResultsProcessor.get_wd_level_lbs(collapsed_ana_tagged_essays,  expected_tags=reg_tags)\n",
    "pred_ys_bycode = get_wd_level_preds(collapsed_ana_tagged_essays, expected_tags=reg_tags)\n",
    "mean_metrics = ResultsProcessor.compute_mean_metrics(act_ys_bycode, pred_ys_bycode)\n",
    "\n",
    "df = get_df(mean_metrics)\n",
    "df[df.code == \"MICRO_F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For CB Training Data, it Mildly Hurts the F1 Score (very slighly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
