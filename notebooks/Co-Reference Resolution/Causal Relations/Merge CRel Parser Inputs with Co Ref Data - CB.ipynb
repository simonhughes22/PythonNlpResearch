{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "from window_based_tagger_config import get_config\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shared code from the results folder\n",
    "import sys\n",
    "sys.path.append(\"/Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/notebooks/Co-Reference Resolution/Results\")\n",
    "\n",
    "from results_common import get_essays, validate_essays, tally_essay_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "settings = Settings()\n",
    "\n",
    "DATASET = \"CoralBleaching\"  # SkinCancer\n",
    "\n",
    "root_folder = settings.data_directory +  DATASET + \"/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "rnn_predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-SEARN/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "results_processor = ResultsProcessor(dbname=\"metrics_causal_FIXED\")\n",
    "\n",
    "# Get Test Data In Order to Get Test CRELS\n",
    "# load the test essays to make sure we compute metrics over the test CR labels\n",
    "test_config = get_config(test_folder)\n",
    "\n",
    "stanford_coref_predictions_folder = root_folder + \"CoReference/\"\n",
    "berkeley_coref_predictions_folder = root_folder + \"CoReference/Berkeley/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Optimal Parameters (from Hyper Parameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berkeley best for CB\n",
    "coref_predictions_folder = berkeley_coref_predictions_folder\n",
    "\n",
    "# set optimal parameters\n",
    "filter_to_predicted_tags=True\n",
    "\n",
    "nearest_ref_only = True\n",
    "pos_ana_key =     \"None\"\n",
    "pos_ch_key  =     \"None\"\n",
    "max_ana_phrase_len = None\n",
    "max_cref_phrase_len = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-Ref folder: /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/\n",
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/training_processed.dill\n",
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/test_processed.dill\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Co-Ref folder:\", coref_predictions_folder)\n",
    "\n",
    "coref_train_essays = get_essays(coref_predictions_folder, \"Training\")\n",
    "coref_test_essays = get_essays(coref_predictions_folder, \"Test\")\n",
    "\n",
    "len(coref_train_essays), len(coref_test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fname = rnn_predictions_folder + \"essays_train_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(train_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_train = dill.load(f)\n",
    "\n",
    "test_fname = rnn_predictions_folder + \"essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\"\n",
    "with open(test_fname, \"rb\") as f:\n",
    "    pred_tagged_essays_test = dill.load(f)\n",
    "    \n",
    "len(pred_tagged_essays_train), len(pred_tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "reg_tally = defaultdict(int)\n",
    "crel_tally = defaultdict(int)\n",
    "crel_ana_tally = defaultdict(int)\n",
    "for e in pred_tagged_essays_train + pred_tagged_essays_test:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                t_lower = t.lower()\n",
    "                if \"rhet\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "                    continue\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if \"->\" in t and (\"ana\" not in t_lower and \n",
    "                                  \"other\" not in t_lower and \n",
    "                                  \"rhet\" not in t_lower and \n",
    "                                  \"change\" not in t_lower):\n",
    "                    crel_tally[t] += 1\n",
    "                if \"->\" in t and ANAPHORA in t:\n",
    "                    crel_ana_tally[t] += 1\n",
    "                    \n",
    "\n",
    "reg_tags = sorted(reg_tally.keys())\n",
    "crel_tags = sorted(crel_tally.keys())\n",
    "\n",
    "cc_crel_tags_filter = set(reg_tags + crel_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_the_same(essay_sets):\n",
    "    unique_fnames = [] # list of sets of str (fnames)\n",
    "    for essay_collection in essay_sets:\n",
    "        names = set()\n",
    "        for e in essay_collection:\n",
    "            names.add(e.name)\n",
    "        unique_fnames.append(names)\n",
    "    for a in unique_fnames:\n",
    "        print(len(a))\n",
    "        for b in unique_fnames:\n",
    "            assert len(a) == len(b), \"lens don't match\"\n",
    "            assert a == b, \"don't match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essays_2_hash_map(essays):\n",
    "    lu = {}\n",
    "    for e in essays:\n",
    "        lu[e.name] = e\n",
    "    return lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks the number of words and sentences are the same for 2 sets of essays\n",
    "def validate_tagged_essays(essays_a, essays_b, tags_filter):\n",
    "    # make sure obj is not the same\n",
    "    assert essays_a != essays_b\n",
    "    print(\"Validating\", len(essays_a), \"essays\")\n",
    "    assert len(essays_a) == len(essays_b), \"Lens don't match\"\n",
    "    \n",
    "    a_hmap = essays_2_hash_map(essays_a)\n",
    "    b_hmap = essays_2_hash_map(essays_b)\n",
    "    \n",
    "    # same essays?\n",
    "    assert a_hmap.keys() == b_hmap.keys()\n",
    "    intersect = set(a_hmap.keys()).intersection(b_hmap.keys())\n",
    "    assert len(intersect) == len(a_hmap.keys())\n",
    "    assert len(a_hmap.keys()) > 1    \n",
    "    assert len(a_hmap.keys()) == len(b_hmap.keys())\n",
    "    \n",
    "    word_misses = 0\n",
    "    \n",
    "    for key, a_essay in a_hmap.items():\n",
    "        b_essay = b_hmap[key]\n",
    "        # assert NOT the same obj ref\n",
    "        assert a_essay != b_essay\n",
    "        assert len(a_essay.sentences) == len(b_essay.sentences)\n",
    "        assert len(a_essay.sentences) > 0\n",
    "        assert len(b_essay.sentences) > 0\n",
    "        for i in range(len(a_essay.sentences)):\n",
    "            a_sent = a_essay.sentences[i]\n",
    "            b_sent = b_essay.sentences[i]\n",
    "            # the same lists?\n",
    "            #assert a_sent == b_sent\n",
    "            assert len(a_sent) == len(b_sent)\n",
    "            if not len(a_sent) == len(b_sent):\n",
    "                print(key, \"\\tsent-ix:\", i, \"lens\", len(a_sent), len(b_sent))\n",
    "            for wd_ix, (a_wd, a_tags) in enumerate(a_sent):\n",
    "                b_wd, b_tags = b_sent[wd_ix]\n",
    "                if a_wd != b_wd:\n",
    "                    word_misses+=1\n",
    "                assert a_wd   == b_wd,   \\\n",
    "                    \"Words don't match: '{a}' - '{b}', Esssay: {essay} Sent Ix: {i}\".format(\n",
    "                            a=a_wd, b=b_wd, essay=key, i=i)\n",
    "                \n",
    "                # SH - Make conditional, as untagged essays contain new anaphora tags\n",
    "                filtered_a_tags = tags_filter.intersection(a_tags)\n",
    "                filtered_b_tags = tags_filter.intersection(b_tags)\n",
    "\n",
    "                assert filtered_a_tags == filtered_b_tags, \\\n",
    "                    \"Tags don't match: '{a}' - '{b}', Esssay: {essay} Sent Ix: {i}\".format(\n",
    "                        a=str(a_tags), b=str(b_tags), essay=key, i=i)                \n",
    "                        \n",
    "    if word_misses:\n",
    "        print(\"Word miss-matches: \", word_misses)\n",
    "    print(\"Validation Passed\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Non Anaphora Labels for Comparison (Should Match Across Essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "902\n"
     ]
    }
   ],
   "source": [
    "names_the_same([coref_train_essays, pred_tagged_essays_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "names_the_same([coref_test_essays, pred_tagged_essays_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating 902 essays\n",
      "Validation Passed\n"
     ]
    }
   ],
   "source": [
    "validate_tagged_essays(essays_a=coref_train_essays, essays_b=pred_tagged_essays_train,\n",
    "                       tags_filter=cc_crel_tags_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating 226 essays\n",
      "Validation Passed\n"
     ]
    }
   ],
   "source": [
    "validate_tagged_essays(essays_a=coref_test_essays, essays_b=pred_tagged_essays_test,\n",
    "                       tags_filter=cc_crel_tags_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Predictions from Crel Essays with CoRef Data from CoRef Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the coref essays (used for predictions), and copy over the prediction tags from the \n",
    "# crel essays. We do this as we also need the Anaphora labels from the CoRef data\n",
    "def combine_essays(crel_essays, coref_essays):\n",
    "    \n",
    "    crel_hmap = essays_2_hash_map(crel_essays)\n",
    "    coref_hmap = essays_2_hash_map(coref_essays)\n",
    "    \n",
    "    new_essays = []\n",
    "    for key, crel_essay in crel_hmap.items():\n",
    "        coref_essay = coref_hmap[key]\n",
    "        # clone from coref essay so we grab the anaphora labels (not present in those essays)\n",
    "        new_essay = coref_essay.clone()\n",
    "        \n",
    "        # copy coref data from coref essay\n",
    "        new_essay.ana_tagged_sentences    = coref_essay.ana_tagged_sentences\n",
    "        new_essay.pred_corefids           = coref_essay.pred_corefids\n",
    "        new_essay.pred_ner_tags_sentences = coref_essay.pred_ner_tags_sentences\n",
    "        new_essay.pred_pos_tags_sentences = coref_essay.pred_pos_tags_sentences\n",
    "        \n",
    "        # BUT copy predictions from the crel essay\n",
    "        new_essay.pred_tagged_sentences = crel_essay.pred_tagged_sentences\n",
    "        new_essays.append(new_essay)\n",
    "    return new_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train_essays = combine_essays(crel_essays=pred_tagged_essays_train, coref_essays=coref_train_essays)\n",
    "merged_test_essays  = combine_essays(crel_essays=pred_tagged_essays_test, coref_essays=coref_test_essays)\n",
    "len(merged_train_essays), len(merged_test_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Anaphora Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaphor:[11]',\n",
       " 'Anaphor:[12]',\n",
       " 'Anaphor:[13]',\n",
       " 'Anaphor:[14]',\n",
       " 'Anaphor:[1]',\n",
       " 'Anaphor:[2]',\n",
       " 'Anaphor:[3]',\n",
       " 'Anaphor:[4]',\n",
       " 'Anaphor:[50]',\n",
       " 'Anaphor:[5]',\n",
       " 'Anaphor:[5b]',\n",
       " 'Anaphor:[6]',\n",
       " 'Anaphor:[7]']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana_tally = defaultdict(int)\n",
    "all_merged_essays = merged_train_essays + merged_test_essays\n",
    "for e in all_merged_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:                \n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"Anaphor:[\" in t and \"rhetorical\" not in t and \"->\" not in t:\n",
    "                        ana_tally[t] += 1\n",
    "\n",
    "all_ana_tags = sorted(ana_tally.keys())\n",
    "assert len(all_ana_tags) == len(reg_tags), \"Number of anaphora tags doesn't match the number of regular tags\"\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "crel_ana_nested_tags = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "for e in all_merged_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                t_lower = t.lower()\n",
    "                if \"rhet\" in t_lower or \"change\" in t_lower or \"other\" in t_lower:\n",
    "                    continue\n",
    "                if \"->\" in t and ANAPHORA in t:\n",
    "                    crel_ana_tally[t] += 1\n",
    "                    ana_tags = tags.intersection(all_ana_tags)\n",
    "                    for ana_t in ana_tags:\n",
    "                        crel_ana_nested_tags[t][ana_t] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causer:1->Result:Anaphor[3]              Causer:1->Result:3                       1 3\n",
      "Causer:1->Result:Anaphor[50]             Causer:1->Result:50                      1 50\n",
      "Causer:11->Result:Anaphor[14]            Causer:11->Result:14                     11 14\n",
      "Causer:11->Result:Anaphor[1]             Causer:11->Result:1                      11 1\n",
      "Causer:11->Result:Anaphor[50]            Causer:11->Result:50                     11 50\n",
      "Causer:13->Result:Anaphor[14]            Causer:13->Result:14                     13 14\n",
      "Causer:13->Result:Anaphor[50]            Causer:13->Result:50                     13 50\n",
      "Causer:2->Result:Anaphor[50]             Causer:2->Result:50                      2 50\n",
      "Causer:3->Result:Anaphor[4]              Causer:3->Result:4                       3 4\n",
      "Causer:3->Result:Anaphor[50]             Causer:3->Result:50                      3 50\n",
      "Causer:3->Result:Anaphor[7]              Causer:3->Result:7                       3 7\n",
      "Causer:4->Result:Anaphor[50]             Causer:4->Result:50                      4 50\n",
      "Causer:4->Result:Anaphor[5]              Causer:4->Result:5                       4 5\n",
      "Causer:5->Result:Anaphor[50]             Causer:5->Result:50                      5 50\n",
      "Causer:5b->Result:Anaphor[14]            Causer:5b->Result:14                     5b 14\n",
      "Causer:6->Result:Anaphor[50]             Causer:6->Result:50                      6 50\n",
      "Causer:6->Result:Anaphor[7]              Causer:6->Result:7                       6 7\n",
      "Causer:7->Result:Anaphor[50]             Causer:7->Result:50                      7 50\n",
      "Causer:7->Result:Anaphor[6]              Causer:7->Result:6                       7 6\n",
      "Causer:Anaphor[11]->Result:12            Causer:11->Result:12                     11 12\n",
      "Causer:Anaphor[11]->Result:13            Causer:11->Result:13                     11 13\n",
      "Causer:Anaphor[11]->Result:50            Causer:11->Result:50                     11 50\n",
      "Causer:Anaphor[12]->Result:13            Causer:12->Result:13                     12 13\n",
      "Causer:Anaphor[12]->Result:14            Causer:12->Result:14                     12 14\n",
      "Causer:Anaphor[12]->Result:50            Causer:12->Result:50                     12 50\n",
      "Causer:Anaphor[13]->Result:14            Causer:13->Result:14                     13 14\n",
      "Causer:Anaphor[13]->Result:50            Causer:13->Result:50                     13 50\n",
      "Causer:Anaphor[14]->Result:11            Causer:14->Result:11                     14 11\n",
      "Causer:Anaphor[14]->Result:50            Causer:14->Result:50                     14 50\n",
      "Causer:Anaphor[14]->Result:6             Causer:14->Result:6                      14 6\n",
      "Causer:Anaphor[1]->Result:2              Causer:1->Result:2                       1 2\n",
      "Causer:Anaphor[1]->Result:3              Causer:1->Result:3                       1 3\n",
      "Causer:Anaphor[1]->Result:4              Causer:1->Result:4                       1 4\n",
      "Causer:Anaphor[1]->Result:50             Causer:1->Result:50                      1 50\n",
      "Causer:Anaphor[1]->Result:6              Causer:1->Result:6                       1 6\n",
      "Causer:Anaphor[2]->Result:3              Causer:2->Result:3                       2 3\n",
      "Causer:Anaphor[2]->Result:4              Causer:2->Result:4                       2 4\n",
      "Causer:Anaphor[2]->Result:50             Causer:2->Result:50                      2 50\n",
      "Causer:Anaphor[2]->Result:6              Causer:2->Result:6                       2 6\n",
      "Causer:Anaphor[2]->Result:7              Causer:2->Result:7                       2 7\n",
      "Causer:Anaphor[3]->Result:14             Causer:3->Result:14                      3 14\n",
      "Causer:Anaphor[3]->Result:4              Causer:3->Result:4                       3 4\n",
      "Causer:Anaphor[3]->Result:5              Causer:3->Result:5                       3 5\n",
      "Causer:Anaphor[3]->Result:50             Causer:3->Result:50                      3 50\n",
      "Causer:Anaphor[3]->Result:6              Causer:3->Result:6                       3 6\n",
      "Causer:Anaphor[3]->Result:7              Causer:3->Result:7                       3 7\n",
      "Causer:Anaphor[4]->Result:13             Causer:4->Result:13                      4 13\n",
      "Causer:Anaphor[4]->Result:14             Causer:4->Result:14                      4 14\n",
      "Causer:Anaphor[4]->Result:3              Causer:4->Result:3                       4 3\n",
      "Causer:Anaphor[4]->Result:50             Causer:4->Result:50                      4 50\n",
      "Causer:Anaphor[4]->Result:5b             Causer:4->Result:5b                      4 5b\n",
      "Causer:Anaphor[4]->Result:6              Causer:4->Result:6                       4 6\n",
      "Causer:Anaphor[4]->Result:7              Causer:4->Result:7                       4 7\n",
      "Causer:Anaphor[5]->Result:50             Causer:5->Result:50                      5 50\n",
      "Causer:Anaphor[5]->Result:5b             Causer:5->Result:5b                      5 5b\n",
      "Causer:Anaphor[5]->Result:7              Causer:5->Result:7                       5 7\n",
      "Causer:Anaphor[5b]->Result:50            Causer:5b->Result:50                     5b 50\n",
      "Causer:Anaphor[6]->Result:14             Causer:6->Result:14                      6 14\n",
      "Causer:Anaphor[6]->Result:50             Causer:6->Result:50                      6 50\n",
      "Causer:Anaphor[6]->Result:7              Causer:6->Result:7                       6 7\n",
      "Causer:Anaphor[7]->Result:14             Causer:7->Result:14                      7 14\n",
      "Causer:Anaphor[7]->Result:50             Causer:7->Result:50                      7 50\n",
      "Causer:Anaphor[7]->Result:5b             Causer:7->Result:5b                      7 5b\n",
      "Causer:Anaphor[7]->Result:6              Causer:7->Result:6                       7 6\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(crel_ana_nested_tags.keys()):\n",
    "    prefix = \"Anaphor[\"\n",
    "    if \"Anaphor[\" in k:\n",
    "        k_fixed = k.replace(prefix, \"\").replace(\"]\",\"\")\n",
    "        if ANAPHORA not in k_fixed:\n",
    "            l,r = k_fixed.split(\"->\")\n",
    "            l_code = l.replace(\"Causer:\",\"\")\n",
    "            r_code = r.replace(\"Result:\",\"\")\n",
    "            assert is_a_regular_code(l_code)\n",
    "            assert is_a_regular_code(r_code)\n",
    "            print(k.ljust(40), k_fixed.ljust(40), l_code, r_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "def get_anaphora_crel_codes(tags):\n",
    "    additional_codes = set()\n",
    "    prefix = \"Anaphor[\"\n",
    "    \n",
    "    for k in tags:        \n",
    "        if prefix in k:\n",
    "            k_fixed = k.replace(prefix, \"\").replace(\"]\",\"\")\n",
    "            if ANAPHORA not in k_fixed:\n",
    "                l,r = k_fixed.split(\"->\")\n",
    "                l_code = l.replace(\"Causer:\",\"\")\n",
    "                r_code = r.replace(\"Result:\",\"\")\n",
    "                assert is_a_regular_code(l_code)\n",
    "                assert is_a_regular_code(r_code)\n",
    "                additional_codes.add(k_fixed)\n",
    "    return additional_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crel_codes = get_anaphora_crel_codes(crel_ana_nested_tags.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Causer:11->Result:1',\n",
       " 'Causer:14->Result:11',\n",
       " 'Causer:2->Result:4',\n",
       " 'Causer:2->Result:7',\n",
       " 'Causer:7->Result:6'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_crel_codes - set(crel_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tally = tally_essay_attributes(all_merged_essays, attribute_name=\"pred_pos_tags_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NN', 'NNP', 'NNPS', 'NNS'},\n",
       " {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
       " {'PRP', 'PRP$', 'WP', 'WP$'},\n",
       " {'DT', 'PDT', 'WDT'},\n",
       " {'DT', 'PDT', 'PRP', 'PRP$', 'WDT', 'WP', 'WP$'})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nouns = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"NN\"])\n",
    "pos_verbs = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"VB\"])\n",
    "pos_pronouns = {\"PRP\",\"PRP$\", \"WP\", \"WP$\"}\n",
    "pos_determiners = {\"DT\",\"WDT\",\"PDT\"} # the, a, which, that, etc\n",
    "pos_pron_dt = pos_pronouns | pos_determiners\n",
    "# for meaning of pen treebank tags - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "pos_nouns, pos_verbs, pos_pronouns, pos_determiners, pos_pron_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_filter = {\n",
    "            \"None\": None,\n",
    "            \"PRN\": pos_pronouns,\n",
    "            \"DT\": pos_determiners,\n",
    "            \"PRN+DT\": pos_pron_dt\n",
    "}\n",
    "\n",
    "dict_pos_ch_filter = {\n",
    "    \"None\": None,\n",
    "    \"NN\": pos_nouns,\n",
    "    \"VB\": pos_verbs,\n",
    "    \"NN+VB\": pos_nouns | pos_verbs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Well Would Ana Resolution work with the CRel Predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>data_points</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>num_codes</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999804</td>\n",
       "      <td>1783158.0</td>\n",
       "      <td>0.059299</td>\n",
       "      <td>344.0</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.031977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  data_points  f1_score  num_codes  precision    recall\n",
       "0  0.999804    1783158.0  0.059299      344.0   0.407407  0.031977"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_essays_coref import get_coref_processed_essays\n",
    "from metrics import get_metrics_raw\n",
    "\n",
    "format_ana_tags = True # use this as true to eval performance, but then change to False for the actual exercise\n",
    "filter_to_predicted_tags = True # filter based on the anaphora predictions from the other RNN\n",
    "\n",
    "pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "processed_train_essays_ana = get_coref_processed_essays(\n",
    "                            essays=merged_train_essays, \n",
    "                            format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "\n",
    "metrics = get_metrics_raw(processed_train_essays, expected_tags=all_ana_tags,  micro_only=True)    \n",
    "pd.DataFrame([metrics[\"MICRO_F1\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Final Set of Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_ana_tags = False # Set to false so Anaphora codes are merged in with the regular codes\n",
    "processed_train_essays_full = get_coref_processed_essays(\n",
    "                            essays=merged_train_essays, \n",
    "                            format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "\n",
    "processed_test_essays_full = get_coref_processed_essays(\n",
    "                            essays=merged_test_essays, \n",
    "                            format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate there are Differences in the New Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set() {'50'} Anaphor\n",
      "set() {'1'} Anaphor\n",
      "set() {'1'} Anaphor\n",
      "set() {'7'} Anaphor\n",
      "set() {'14'} Anaphor\n",
      "set() {'13'} Anaphor\n",
      "set() {'13'} Anaphor\n",
      "set() {'50'} Anaphor\n",
      "set() {'50'} Anaphor\n",
      "set() {'1'} Anaphor\n",
      "set() {'3'} Anaphor\n",
      "set() {'3'} Anaphor\n",
      "set() {'14'} Anaphor\n",
      "set() {'50'} Anaphor\n",
      "set() {'1'} Anaphor\n",
      "set() {'13'} Anaphor\n",
      "set() {'6'} Anaphor\n",
      "set() {'14'} Anaphor\n",
      "set() {'7'} Anaphor\n",
      "set() {'50'} Anaphor\n",
      "set() {'11'} Anaphor\n",
      "set() {'14'} Anaphor\n",
      "set() {'1'} Anaphor\n",
      "set() {'13'} Anaphor\n",
      "set() {'1'} Anaphor\n"
     ]
    }
   ],
   "source": [
    "EMPTY = 'Empty'\n",
    "for a,b in zip(merged_train_essays, processed_train_essays_full):\n",
    "    assert len(a.sentences)  == len(b.sentences)\n",
    "    assert a.name == b.name\n",
    "    \n",
    "    assert len(a.pred_tagged_sentences) == len(b.pred_tagged_sentences)\n",
    "    \n",
    "    sent_ix =- 1\n",
    "    for atag_sent, btag_sent in zip(a.pred_tagged_sentences, b.pred_tagged_sentences):        \n",
    "        sent_ix += 1\n",
    "        word_ix = -1\n",
    "        for atags, btags in zip(atag_sent, btag_sent):\n",
    "            word_ix+=1\n",
    "            atags = set([atags])\n",
    "            if EMPTY in atags:\n",
    "                atags.remove(EMPTY)\n",
    "            if atags != btags:\n",
    "                print(atags, btags, b.ana_tagged_sentences[sent_ix][word_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO - Update the tags in the Essays to Swap the Anaphora Crels for Regular Crels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
