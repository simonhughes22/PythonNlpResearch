{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on this code: https://github.com/codekansas/keras-language-modeling/blob/master/keras_models.py\n",
    "and also on this code: https://github.com/simonhughes22/PythonNlpResearch/blob/master/notebooks/SEARN/CB%20-%20Keras%20-%20Train%20Tagger%20and%20Save%20CV%20Predictions%20For%20Word%20Tags-NO%20EXPLICIT.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "* The reason this nbook exists is that the tags used in the SEARN model and thus also the CoRef model do not seem to have been generated by the best model (they are well below the best reported results)\n",
    "* I am attempting to rectify this here, and if it works, can potentially re-run SEARN experiments also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Change to use 128 hidden units not 256 (was actually optimal settings)\n",
    "* Then Validate accuracy\n",
    "* Is that doesn't work, drop max len and ignore test data for the purposes of the CV run (on training data), then re-institute for training test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check mongo is running\n",
    "# import pymongo\n",
    "# client = pymongo.MongoClient()\n",
    "# db = client.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - To Get this working:\n",
    "\n",
    "* Install CUDA and associated libraries, setup path\n",
    "* Install bleeding edge theano (from src)\n",
    "* Make sure the THEANO_FLAGS are set correctly via the environment var, or via the ~/.theanorc file\n",
    "* Install and compile bleeding edge Keras (from src)\n",
    "* `export KERAS_BACKEND=theano`\n",
    "* `export KERAS_IMAGE_DIM_ORDERING='th'`\n",
    "* `sh <project_root>/shell_scipts/setup_environment.sh` to install additional dependencies\n",
    "* **DO NOT SET UNROLL=True** when creating RNN's - causes max recursion issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouble-Shooting\n",
    "\n",
    "* You may need to clean the theano cache. To do so thoroughly, run this command from the shell:\n",
    " * `theano-cache purge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import dill\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from Metrics import rpf1\n",
    "from load_data import load_process_essays\n",
    "from wordtagginghelper import merge_dictionaries\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from DirUtils import dir_exists\n",
    "from IdGenerator import IdGenerator as idGen\n",
    "from results_procesor import ResultsProcessor, __MICRO_F1__\n",
    "from Rpfa import micro_rpfa\n",
    "from collections import defaultdict\n",
    "\n",
    "import Settings\n",
    "import logging\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre-Process Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "WARNING - No db name specified - should be either 'metrics_causal' or 'metrics'. Defaulting to 'metrics' \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from Settings import Settings\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "training_folder = root_folder + \"Training\" + \"/\"\n",
    "test_folder = root_folder + \"Test\" + \"/\"\n",
    "training_pickled = settings.data_directory + \"CoralBleaching/Thesis_Dataset/training.pl\"\n",
    "models_folder = root_folder + \"Models/CoRef/Bi-LSTM-4-CC-Tagging/\"\n",
    "predictions_folder = root_folder + \"Predictions/CoRef/Bi-LSTM-4-CC-Tagging/\"\n",
    "cv_folder = root_folder + \"CV_Data_Pickled_CoRef_CC_Tagging/\"\n",
    "\n",
    "config = get_config(training_folder)\n",
    "processor = ResultsProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Folders are Valid and Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/CoRef/Bi-LSTM-4-CC-Tagging/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Models/CoRef/Bi-LSTM-4-CC-Tagging/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CV_Data_Pickled_CoRef_CC_Tagging/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "assert dir_exists(predictions_folder)\n",
    "print(\"Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "assert dir_exists(models_folder)\n",
    "print(\"Valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "assert dir_exists(cv_folder)\n",
    "print(\"Valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Essays"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "config = get_config(training_folder)\n",
    "tagged_essays_tmp = load_process_essays(**config)\n",
    "\n",
    "with open(training_pickled, \"wb+\") as f:\n",
    "    pickle.dump(tagged_essays_tmp, f)\n",
    "del tagged_essays_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(training_pickled, \"rb+\") as f:\n",
    "    tagged_essays = pickle.load(f)\n",
    "len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 files found\n",
      "226 essays processed\n"
     ]
    }
   ],
   "source": [
    "test_config = get_config(test_folder)\n",
    "tagged_essays_test = load_process_essays(**test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2018-08-07 17:10:09.839493\n"
     ]
    }
   ],
   "source": [
    "import datetime, logging\n",
    "print(\"Started at: \" + str(datetime.datetime.now()))\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "#shuffle(tagged_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677, 88)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = defaultdict(int)\n",
    "unique_words = set()\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            unique_words.add(word)\n",
    "            for tag in tags:\n",
    "                tag_freq[tag] += 1\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit()))\n",
    "#regular_tags = list((t for t in tag_freq.keys() if t[0].isdigit() or t == \"explicit\"))\n",
    "cr_tags = list((t for t in tag_freq.keys() if ( \"->\" in t) and not \"Anaphor\" in t and not \"other\" in t and not \"rhetorical\" in t))\n",
    "\n",
    "vtags = set(regular_tags)\n",
    "vtags.add(EMPTY_TAG)\n",
    "\n",
    "len(unique_words), len(cr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '11', '12', '13', '14', '2', '3', '4', '5', '50', '5b', '6', '7']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(regular_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '50',\n",
       " '5b',\n",
       " '6',\n",
       " '7',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Essays into Training Data (Word Ids)\n",
    "\n",
    "* Computes `xs`, `ys`, `ys_bytag` and `seq_lens`\n",
    "* `ys_bytag` includes **all tags** and does **not** focus only on the most common tag\n",
    "* `ys` only includes the most common tag (so we can use cross entropy)\n",
    "* `seq_lens` is without the start and end tags included (so we have to map back and forth to maintain mappings)\n",
    "* `ys_bytag` also excludes the START and END tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Max Sequence Length, Generate All Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2tag = {}\n",
    "for ix, t in enumerate(vtags):\n",
    "    ix2tag[ix] = t\n",
    "    \n",
    "generator = idGen(seed=1) # important as we zero pad sequences\n",
    "\n",
    "maxlen = 0\n",
    "for essay in tagged_essays:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "        \n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "        maxlen = max(maxlen, len(sentence) + 2)\n",
    "\n",
    "def ids2tags(ids):\n",
    "    return [generator.get_key(j) for j in ids]\n",
    "\n",
    "def lbls2tags(ixs):\n",
    "    return [ix2tag[ix] for ix in ixs]\n",
    "        \n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"<start>\"\n",
    "END   = \"<end>\"\n",
    "\n",
    "def get_training_data(tessays):\n",
    "    # outputs\n",
    "    xs = []\n",
    "    ys = []\n",
    "    seq_lens = []\n",
    "    ys_bytag_concept_sent = defaultdict(list)\n",
    "\n",
    "    # cut texts after this number of words (among top max_features most common words)\n",
    "    for essay in tessays:\n",
    "        for sentence in essay.sentences:\n",
    "            row = []\n",
    "            y_found = False\n",
    "            y_seq = []\n",
    "            unique_tags = set() # get all unique tags in sentence\n",
    "            for word, tags in [(START, set())] + sentence + [(END, set())]:\n",
    "                id = generator.get_id(word) #starts at 0, but 0 used to pad sequences\n",
    "                row.append(id)\n",
    "                \n",
    "                # Make sure to include Causer:<num> and Result:<num> tags\n",
    "                tags = set([t.replace(\"Causer:\",\"\").replace(\"Result:\",\"\") for t in tags])\n",
    "                unique_tags.update(tags)\n",
    "                \n",
    "                # remove unwanted tags, filter to concept tags\n",
    "                concept_tags = vtags.intersection(tags)\n",
    "\n",
    "                # encode ys with most common tag only\n",
    "                if len(concept_tags) > 1:\n",
    "                    # if multiple, choose concept over explicit\n",
    "                    if \"explicit\" in concept_tags:\n",
    "                        concept_tags.remove(\"explicit\")\n",
    "                    most_common = max(concept_tags, key=lambda t: tag_freq[t])\n",
    "                    concept_tags = set([most_common])\n",
    "                if len(concept_tags) == 0:\n",
    "                    concept_tags.add(EMPTY_TAG)\n",
    "\n",
    "                one_hot = []\n",
    "                for t in vtags:\n",
    "                    if t in concept_tags:\n",
    "                        one_hot.append(1)\n",
    "                    else:\n",
    "                        one_hot.append(0)\n",
    "                y_seq.append(one_hot)\n",
    "                #end for each word\n",
    "\n",
    "            # sentence level tags\n",
    "            for tag in vtags:\n",
    "                if tag in unique_tags:\n",
    "                    ys_bytag_concept_sent[tag].append(1)\n",
    "                else:\n",
    "                    ys_bytag_concept_sent[tag].append(0)            \n",
    "            \n",
    "            seq_lens.append(len(row)-2)\n",
    "            ys.append(y_seq)\n",
    "            xs.append(row)\n",
    "    \n",
    "    xs = sequence.pad_sequences(xs, maxlen=maxlen)\n",
    "    ys = sequence.pad_sequences(ys, maxlen=maxlen)\n",
    "    assert xs.shape[0] == ys.shape[0], \"Sequences should have the same number of rows\"\n",
    "    assert xs.shape[1] == ys.shape[1] == maxlen, \"Sequences should have the same lengths\"\n",
    "    return xs, ys, ys_bytag_concept_sent, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        for pred_tag in pred_ys:\n",
    "            pred_ys_by_tag[pred_tag].append(1)\n",
    "            # for all other tags, a 0\n",
    "            for tag in(vtags - set([EMPTY_TAG, pred_tag])):\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def collapse_results_sentence_level(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = set(pred_ys[1:-1])\n",
    "        for tag in vtags:\n",
    "            if tag == EMPTY_TAG:\n",
    "                continue\n",
    "            if tag in pred_ys:\n",
    "                pred_ys_by_tag[tag].append(1)\n",
    "            else:\n",
    "                pred_ys_by_tag[tag].append(0)\n",
    "        if EMPTY_TAG in pred_ys_by_tag:\n",
    "            del pred_ys_by_tag[EMPTY_TAG]\n",
    "    return pred_ys_by_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_split(lst, dev_split, randomize=True):\n",
    "    # random shuffle\n",
    "    if randomize:\n",
    "        shuffle(lst)\n",
    "    num_training = int((1.0 - dev_split) * len(lst))\n",
    "    return lst[:num_training], lst[num_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', set()),\n",
       " ('leads', set()),\n",
       " ('to', set()),\n",
       " ('differences', set()),\n",
       " ('in', set()),\n",
       " ('the', set()),\n",
       " ('rates', set()),\n",
       " ('of', set()),\n",
       " ('coral', {'50'}),\n",
       " ('bleaching', {'50'}),\n",
       " ('.', set())]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tagged_essays[0]\n",
    "e.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.44 s, sys: 506 ms, total: 5.94 s\n",
      "Wall time: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# use this name for a different function later\n",
    "from CrossValidation import cross_validation as cv\n",
    "\n",
    "folds = cv(tagged_essays, CV_FOLDS)\n",
    "fold2training_data = {}\n",
    "fold2dev_data = {}\n",
    "fold2test_data = {}\n",
    "\n",
    "fold2training_essays = {}\n",
    "fold2dev_essays = {}\n",
    "fold2test_essays = {}\n",
    "\n",
    "for i, (essays_TD, essays_VD) in enumerate(folds):\n",
    "    # further split into train and dev test\n",
    "    essays_train, essays_dev = train_dev_split(essays_TD, DEV_SPLIT)\n",
    "    fold2training_data[i] = get_training_data(essays_train)\n",
    "    fold2dev_data[i]      = get_training_data(essays_dev)\n",
    "    # Test Data\n",
    "    fold2test_data[i]     = get_training_data(essays_VD)\n",
    "    \n",
    "    # also store essays\n",
    "    fold2training_essays[i] = essays_train\n",
    "    fold2dev_essays[i]      = essays_dev\n",
    "    fold2test_essays[i]     = essays_VD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the generator is incremented on the test data too\n",
    "_,_,_,_ = get_training_data(tagged_essays)\n",
    "_,_,_,_ = get_training_data(tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cv_folder + \"td.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_data, f)\n",
    "\n",
    "with open(cv_folder + \"td_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2training_essays, f)\n",
    "\n",
    "with open(cv_folder + \"devd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_data, f)\n",
    "\n",
    "with open(cv_folder + \"devd_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2dev_essays, f)\n",
    "    \n",
    "with open(cv_folder + \"vd.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_data, f)\n",
    "    \n",
    "with open(cv_folder + \"vd_essays.dill\", \"wb\") as f:\n",
    "    dill.dump(fold2test_essays, f)\n",
    "    \n",
    "with open(cv_folder + \"generator.dill\", \"wb\") as f:\n",
    "    dill.dump(generator, f)\n",
    "\n",
    "with open(cv_folder + \"vtags.dill\", \"wb\") as f:\n",
    "    dill.dump(vtags, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 'coral')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.get_id(\"coral\"), generator.get_key(generator.get_id(\"coral\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Glove 100 Dim Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see /Users/simon.hughes/GitHub/NlpResearch/PythonNlpResearch/DeepLearning/WordVectors/pickle_glove_embedding.py\n",
    "# for creating pre-filtered embeddings file\n",
    "import pickle, os\n",
    "from numpy.linalg import norm\n",
    "\n",
    "embeddings_file = \"/Users/simon.hughes/data/word_embeddings/glove.6B/cb_dict_glove.6B.100d.txt\"\n",
    "# read data file\n",
    "with open(embeddings_file, \"rb+\") as f:\n",
    "    cb_emb_index = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 1677 2.5 %\n"
     ]
    }
   ],
   "source": [
    "missed = set()\n",
    "for wd in unique_words:\n",
    "    if wd not in cb_emb_index:\n",
    "        missed.add(wd)\n",
    "print(len(missed), len(unique_words), 100.0 * round(len(missed)/  len(unique_words),4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = list(cb_emb_index.values())[0].shape[0]\n",
    "\n",
    "def get_embedding_matrix(words, idgenerator, max_features, init='uniform', unit_length=False):\n",
    "    embedding_dim = list(cb_emb_index.values())[0].shape[0]\n",
    "    # initialize with a uniform distribution\n",
    "    if init == 'uniform':\n",
    "        # NOTE: the max norms for these is quite low relative to the embeddings\n",
    "        embedding_matrix = np.random.uniform(low=-0.05, high=0.05,size=(max_features, embedding_dim))\n",
    "    elif init =='zeros':\n",
    "        embedding_matrix = np.zeros(shape=(max_features, embedding_dim), dtype=np.float32)\n",
    "    elif init == 'normal':\n",
    "        embedding_matrix = np.random.normal(mean, sd, size=(max_features, embedding_dim))\n",
    "    else:\n",
    "        raise Exception(\"Unknown init type\")\n",
    "    for word in words:\n",
    "        i = idgenerator.get_id(word)\n",
    "        embedding_vector = cb_emb_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    if unit_length:\n",
    "        norms = np.linalg.norm(embedding_matrix, axis=1,keepdims=True)\n",
    "        # remove 0 norms to prevent divide by zero\n",
    "        norms[norms == 0.0] = 1.0\n",
    "        embedding_matrix = embedding_matrix / norms\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_predictions(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict_classes(xs, batch_size=batch_size, verbose=0)   \n",
    "    pred_ys_by_tag = collapse_results_sentence_level(seq_len, preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_predictions_to_dict(preds):\n",
    "    pred_ys_by_tag = defaultdict(list)\n",
    "    for i in range(preds.shape[0]):\n",
    "        row = preds[i]\n",
    "        for tag_ix, pred in enumerate(row):\n",
    "            tag = ix2crtag[tag_ix]\n",
    "            pred_ys_by_tag[tag].append(pred)\n",
    "    return pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_predictions_sent_level(model, xs, ys_by_tag, seq_len):\n",
    "    preds = model.predict(xs, batch_size=batch_size, verbose=0)\n",
    "    preds = np.where(preds >= 0.5, 1, 0)\n",
    "    pred_ys_by_tag = pivot_predictions_to_dict(preds)\n",
    "    class2metrics = ResultsProcessor.compute_metrics(ys_by_tag, pred_ys_by_tag)\n",
    "    micro_metrics = micro_rpfa(class2metrics.values())\n",
    "    return micro_metrics, pred_ys_by_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2018-08-07 23:22:06.660978', '20180807_232206_661010')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "def get_ts():\n",
    "    # something screws up import so making local\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "def get_file_ts():\n",
    "    # something screws up import so making local\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "\n",
    "embedding_size = EMBEDDING_DIM\n",
    "hidden_size    = 128\n",
    "out_size = len(vtags)\n",
    "batch_size = 128\n",
    "\n",
    "get_ts(), get_file_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Bi-Directional LSTM With Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=len(generator.get_ids())+2 #Need plus one maybe due to masking of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Models/CoRef/Bi-LSTM-4-CC-Tagging/fold_ix-0_bi_directional-True_hidden_size-128_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.h5'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_file_signature(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    lcls = locals()\n",
    "    s = \"\"\n",
    "    for k, val in sorted(lcls.items(), key = lambda tpl: (0,tpl[0]) if tpl[0] == 'fold_ix' else (1,tpl[0])):\n",
    "        if val is not None:\n",
    "            s += \"{key}-{val}_\".format(key=k, val=str(val))\n",
    "    return s[:-1]\n",
    "\n",
    "def get_file_name(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fsig = get_file_signature(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return models_folder + fsig + \".h5\"\n",
    "\n",
    "get_file_name(0, True, True, 2, \"sum\", hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_fold(fold_ix, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "\n",
    "    if use_pretrained_embedding:\n",
    "        embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "        embedding_layer = Embedding(max_features,\n",
    "                                EMBEDDING_DIM,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=maxlen,\n",
    "                                trainable=True,\n",
    "                                mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    else:\n",
    "        embedding_layer = Embedding(max_features, embedding_size, input_length=maxlen, trainable=True, mask_zero=True)\n",
    "\n",
    "    if bi_directional:\n",
    "        rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "    else:\n",
    "        rnn_layer_fact = lambda : GRU(hidden_size, return_sequences=True, consume_less=\"cpu\")\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "    \n",
    "    # this is the newer way of doing this\n",
    "    model.add(TimeDistributed(Dense(out_size)))\n",
    "    #model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    X_train, y_train, train_ys_bytag_con_sent, seq_len_train = fold2training_data[fold_ix]\n",
    "    X_dev,   y_dev,   dev_ys_bytag_con_sent,   seq_len_dev   = fold2dev_data[fold_ix]\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "    #for i in range(10):\n",
    "        print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        epochs = 1 # epochs per training instance\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        #print(micro_metrics)\n",
    "        #print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fold2model = {}\n",
    "    for i in range(CV_FOLDS):\n",
    "        model = evaluate_fold(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        fname = get_file_name(i, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "        model.save(fname)    \n",
    "        fold2model[i] = model\n",
    "    return fold2model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Params 2018-08-07 23:22:14.533742 - Embeddings=True, Bi-Direct=True Num_Rnns=2 Hidden_Size=128\n",
      "2018-08-07 23:22:17.170898: Epoch=0\n",
      "2018-08-07 23:23:18.509374: Epoch=1\n",
      "2018-08-07 23:24:09.361460: Epoch=2\n",
      "2018-08-07 23:25:03.009668: Epoch=3\n",
      "2018-08-07 23:25:57.497160: Epoch=4\n",
      "2018-08-07 23:26:51.723056: Epoch=5\n",
      "2018-08-07 23:27:45.583298: Epoch=6\n",
      "2018-08-07 23:28:39.292219: Epoch=7\n",
      "Fold[0] - Best F1 Score=0.9053558327219369\n",
      "2018-08-07 23:29:34.512978: Epoch=0\n",
      "2018-08-07 23:30:34.627556: Epoch=1\n",
      "2018-08-07 23:31:26.461787: Epoch=2\n",
      "2018-08-07 23:32:18.160606: Epoch=3\n",
      "2018-08-07 23:33:09.613970: Epoch=4\n",
      "2018-08-07 23:34:01.658654: Epoch=5\n",
      "2018-08-07 23:34:52.898117: Epoch=6\n",
      "Fold[1] - Best F1 Score=0.8792270531400965\n",
      "2018-08-07 23:35:45.761206: Epoch=0\n",
      "2018-08-07 23:36:42.214343: Epoch=1\n",
      "2018-08-07 23:37:28.651189: Epoch=2\n",
      "2018-08-07 23:38:18.134406: Epoch=3\n",
      "2018-08-07 23:39:07.427801: Epoch=4\n",
      "2018-08-07 23:39:56.975211: Epoch=5\n",
      "2018-08-07 23:40:46.140999: Epoch=6\n",
      "2018-08-07 23:41:33.980751: Epoch=7\n",
      "2018-08-07 23:42:23.117445: Epoch=8\n",
      "2018-08-07 23:43:13.781333: Epoch=9\n",
      "2018-08-07 23:44:03.068237: Epoch=10\n",
      "Fold[2] - Best F1 Score=0.9059701492537312\n",
      "2018-08-07 23:44:55.738120: Epoch=0\n",
      "2018-08-07 23:45:54.682164: Epoch=1\n",
      "2018-08-07 23:46:46.390947: Epoch=2\n",
      "2018-08-07 23:47:37.561194: Epoch=3\n",
      "2018-08-07 23:48:30.015855: Epoch=4\n",
      "2018-08-07 23:49:21.828229: Epoch=5\n",
      "2018-08-07 23:50:13.774460: Epoch=6\n",
      "2018-08-07 23:51:05.390865: Epoch=7\n",
      "2018-08-07 23:51:56.700663: Epoch=8\n",
      "2018-08-07 23:52:48.200575: Epoch=9\n",
      "2018-08-07 23:53:39.761107: Epoch=10\n",
      "2018-08-07 23:54:31.699036: Epoch=11\n",
      "2018-08-07 23:55:23.358278: Epoch=12\n",
      "2018-08-07 23:56:14.873858: Epoch=13\n",
      "2018-08-07 23:57:06.467216: Epoch=14\n",
      "2018-08-07 23:57:57.942689: Epoch=15\n",
      "2018-08-07 23:58:49.532939: Epoch=16\n",
      "2018-08-07 23:59:41.626093: Epoch=17\n",
      "2018-08-08 00:00:33.375965: Epoch=18\n",
      "Fold[3] - Best F1 Score=0.8982558139534884\n",
      "2018-08-08 00:01:29.657668: Epoch=0\n",
      "2018-08-08 00:02:28.895648: Epoch=1\n",
      "2018-08-08 00:03:18.987176: Epoch=2\n",
      "2018-08-08 00:04:09.915648: Epoch=3\n",
      "2018-08-08 00:05:01.141588: Epoch=4\n",
      "2018-08-08 00:05:52.195187: Epoch=5\n",
      "2018-08-08 00:06:43.233480: Epoch=6\n",
      "2018-08-08 00:07:34.266732: Epoch=7\n",
      "2018-08-08 00:08:25.627324: Epoch=8\n",
      "Fold[4] - Best F1 Score=0.9048991354466858\n",
      "[1] Params 2018-08-08 00:09:19.442991 - Embeddings=True, Bi-Direct=True Num_Rnns=2 Hidden_Size=128\n",
      "CPU times: user 4h 32min 27s, sys: 41min 49s, total: 5h 14min 17s\n",
      "Wall time: 47min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "use_pretrained_embedding = True\n",
    "bi_directional = True\n",
    "num_rnns = 2\n",
    "merge_mode = \"sum\"\n",
    "hidden_size = 128 # NOT 256 !!!!\n",
    "\n",
    "\"\"\"\n",
    "use_pretrained_embedding = True\n",
    "bi_directional = False\n",
    "num_rnns = 1\n",
    "merge_mode = \"sum\"\n",
    "hidden_size = 32\n",
    "\"\"\"\n",
    "\n",
    "i += 1\n",
    "print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "      .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))\n",
    "fold2model = cross_validation(use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "#print(\"MicroF1={micro_f1}\".format(micro_f1=micro_f1))\n",
    "print(\"[{i}] Params {ts} - Embeddings={use_pretrained_embedding}, Bi-Direct={bi_directional} Num_Rnns={num_rnns} Hidden_Size={hidden_size}\"\\\n",
    "      .format(i=i, ts=get_ts(), use_pretrained_embedding=use_pretrained_embedding, bi_directional=bi_directional, num_rnns=num_rnns, hidden_size=hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_by_fold = {}\n",
    "for fold_ix in range(CV_FOLDS):\n",
    "    X_test,  y_test,  test_ys_bytag_con_sent,  seq_len_test  = fold2test_data[fold_ix]\n",
    "    model = fold2model[fold_ix]\n",
    "    probs = model.predict_classes(X_test)\n",
    "    predicts_by_fold[fold_ix] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_fname(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size):\n",
    "    fsig = get_file_signature(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    return predictions_folder + fsig + \".dill\"\n",
    "\n",
    "for fold, preds in predicts_by_fold.items():\n",
    "    fname = get_predictions_fname(fold, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size)\n",
    "    with open(fname, \"wb\") as f:\n",
    "        dill.dump(preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def predictions_to_tags(seq_lens, preds):\n",
    "    assert len(seq_lens) == preds.shape[0], \"Axis 1 size does not align\"\n",
    "    sentence_tags = []\n",
    "    for i in range(len(seq_lens)):\n",
    "        row_ixs = preds[i,:]\n",
    "        len_of_sequence = seq_lens[i] + 2\n",
    "        # sequences are padded from the left, take the preds from the end of the seq\n",
    "        pred_ys = [ix2tag[j] for j in row_ixs[-len_of_sequence:]]\n",
    "        # skip the start and end label\n",
    "        pred_ys = pred_ys[1:-1]\n",
    "        sentence_tags.append(pred_ys)\n",
    "    return sentence_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Predicted Tags to Essay Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tags_to_essays(essays, preds, seq_len):\n",
    "    pred_tags = predictions_to_tags(seq_len, preds)\n",
    "    sent_ix = 0\n",
    "    for essay in essays:\n",
    "        ptagged_sentences = []\n",
    "        for sent in essay.sentences:\n",
    "            ptags = pred_tags[sent_ix]\n",
    "            assert len(ptags) == len(sent), \"Sentence and tags don't align - ntags %i , len(sentence) %i\" % ((len(ptags),len(sent)))\n",
    "            ptagged_sentences.append(ptags)\n",
    "            sent_ix += 1\n",
    "        assert len(ptagged_sentences) == len(essay.sentences), \"Lens differ\"\n",
    "        essay.pred_tagged_sentences = ptagged_sentences\n",
    "    assert sent_ix == len(pred_tags), \"Predictions don't align with sequence lens\"\n",
    "\n",
    "all_ptagged_essays = []\n",
    "for fold in fold2test_essays.keys():\n",
    "    essays = fold2test_essays[fold]\n",
    "    preds = predicts_by_fold[fold]\n",
    "    _,_,_,seq_len = fold2test_data[fold]\n",
    "    assign_tags_to_essays(essays, preds, seq_len)\n",
    "    all_ptagged_essays.extend(essays)\n",
    "\n",
    "fname = predictions_folder + \"essays_train_\" + get_file_signature(None, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size) + \".dill\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    dill.dump(all_ptagged_essays, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_ptagged_essays) == len(tagged_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " 'Empty',\n",
       " '50',\n",
       " '50',\n",
       " 'Empty']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay = all_ptagged_essays[0]\n",
    "essay.pred_tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_mode is Bi-Directional only\n",
    "def evaluate_test(num_rnns, merge_mode, hidden_size):\n",
    "    embedding_matrix = get_embedding_matrix(unique_words, generator, max_features, init='uniform', unit_length=False)\n",
    "    embedding_layer = Embedding(max_features,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True) # If false, initialize unfound words with all 0's\n",
    "    rnn_layer_fact = lambda : Bidirectional(GRU(hidden_size, return_sequences=True, consume_less=\"cpu\"), merge_mode=merge_mode)\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    for i in range(num_rnns):\n",
    "        model.add(rnn_layer_fact())\n",
    "\n",
    "    model.add(TimeDistributed(Dense(out_size)))\n",
    "    # model.add(TimeDistributedDense(out_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', sample_weight_mode=\"temporal\")\n",
    "    \n",
    "    essays_train, essays_dev = train_dev_split(tagged_essays, DEV_SPLIT)\n",
    "    X_train, y_train,  train_ys_bytag_con_sent,  seq_len_train = get_training_data(essays_train)\n",
    "    X_dev,   y_dev,    dev_ys_bytag_con_sent,    seq_len_dev   = get_training_data(essays_dev)\n",
    "\n",
    "    # init loop vars\n",
    "    f1_scores = [-1]\n",
    "    num_since_best_score = 0\n",
    "    patience = 3\n",
    "    best_weights = None\n",
    "\n",
    "    for i in range(30):\n",
    "    #for i in range(10):\n",
    "        print(\"{ts}: Epoch={epoch}\".format(ts=get_ts(), epoch=i))\n",
    "        results = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1, validation_split=0.0, verbose=0)\n",
    "        micro_metrics,_ = score_predictions(model, X_dev, dev_ys_bytag_con_sent, seq_len_dev)\n",
    "\n",
    "        print(micro_metrics)\n",
    "        print()\n",
    "\n",
    "        f1_score = micro_metrics.f1_score\n",
    "        best_f1_score = max(f1_scores)\n",
    "        if f1_score <= best_f1_score:\n",
    "            num_since_best_score += 1\n",
    "        else: # score improved\n",
    "            num_since_best_score = 0\n",
    "            best_weights = model.get_weights()\n",
    "\n",
    "        f1_scores.append(f1_score)\n",
    "        if num_since_best_score >= patience:\n",
    "            #print(\"Too long since an improvement, stopping\")\n",
    "            break\n",
    "    \n",
    "    print(\"Fold[{ix}] - Best F1 Score={f1}\".format(ix=fold_ix, f1=best_f1_score))\n",
    "    \n",
    "    # load best weights\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sum 128\n",
      "2018-08-08 00:31:29.551240: Epoch=0\n",
      "Recall: 0.7851, Precision: 0.8066, F1: 0.7957, Accuracy: 0.9681, Codes:   898\n",
      "\n",
      "2018-08-08 00:32:43.050719: Epoch=1\n",
      "Recall: 0.8708, Precision: 0.8806, F1: 0.8757, Accuracy: 0.9804, Codes:   898\n",
      "\n",
      "2018-08-08 00:33:45.882700: Epoch=2\n",
      "Recall: 0.8920, Precision: 0.8950, F1: 0.8935, Accuracy: 0.9832, Codes:   898\n",
      "\n",
      "2018-08-08 00:34:49.125421: Epoch=3\n",
      "Recall: 0.9265, Precision: 0.8568, F1: 0.8903, Accuracy: 0.9819, Codes:   898\n",
      "\n",
      "2018-08-08 00:35:51.556150: Epoch=4\n",
      "Recall: 0.9031, Precision: 0.8854, F1: 0.8942, Accuracy: 0.9831, Codes:   898\n",
      "\n",
      "2018-08-08 00:36:54.141657: Epoch=5\n",
      "Recall: 0.8998, Precision: 0.8860, F1: 0.8928, Accuracy: 0.9829, Codes:   898\n",
      "\n",
      "2018-08-08 00:37:56.844402: Epoch=6\n",
      "Recall: 0.8931, Precision: 0.9032, F1: 0.8981, Accuracy: 0.9839, Codes:   898\n",
      "\n",
      "2018-08-08 00:38:58.804363: Epoch=7\n",
      "Recall: 0.9265, Precision: 0.8685, F1: 0.8966, Accuracy: 0.9831, Codes:   898\n",
      "\n",
      "2018-08-08 00:39:59.694619: Epoch=8\n",
      "Recall: 0.9020, Precision: 0.8990, F1: 0.9005, Accuracy: 0.9842, Codes:   898\n",
      "\n",
      "2018-08-08 00:41:01.025597: Epoch=9\n",
      "Recall: 0.9321, Precision: 0.8737, F1: 0.9019, Accuracy: 0.9839, Codes:   898\n",
      "\n",
      "2018-08-08 00:42:03.904105: Epoch=10\n"
     ]
    }
   ],
   "source": [
    "#test_model = evaluate_test(2, \"sum\", 256)\n",
    "print(num_rnns, merge_mode, hidden_size)\n",
    "test_model = evaluate_test(num_rnns, merge_mode, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,  y_test,   test_ys_bytag_con_sent,   seq_len_test = get_training_data(tagged_essays_test)\n",
    "test_preds = test_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.shape, len(test_ys_bytag_con_sent['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_tags_to_essays(tagged_essays_test, test_preds, seq_len_test)\n",
    "\n",
    "fname = predictions_folder + \"essays_test_\" + get_file_signature(None, use_pretrained_embedding, bi_directional, num_rnns, merge_mode, hidden_size) + \".dill\"\n",
    "with open(fname, \"wb\") as f:\n",
    "    dill.dump(tagged_essays_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = tagged_essays_test[0]\n",
    "list(zip(e.sentences[0],e.pred_tagged_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tagged_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_essays_test\n",
    "\n",
    "stag_freq = defaultdict(int)\n",
    "\n",
    "for essay in tagged_essays_test:\n",
    "    for sentence in essay.sentences:\n",
    "        for word, tags in sentence:\n",
    "            for tag in tags:\n",
    "                stag_freq[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
