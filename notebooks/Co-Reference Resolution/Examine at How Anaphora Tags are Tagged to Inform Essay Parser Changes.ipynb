{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "def find_files_recursively(folder, fname_filter):\n",
    "    files = []\n",
    "    for root, directories, filenames in os.walk(folder):       \n",
    "        for filename in filenames:\n",
    "            if filename == fname_filter:\n",
    "                files.append((root, filename))\n",
    "    return sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from Settings import Settings\n",
    "from FindFiles import find_files\n",
    "\n",
    "DATASET = \"CoralBleaching\"\n",
    "#DATASET = \"SkinCancer\"\n",
    "\n",
    "EMPTY_TAG = \"Empty\"\n",
    "ANAPHORA = \"Anaphor\"\n",
    "\n",
    "settings = Settings()\n",
    "training_pickled = settings.data_directory + DATASET + \"/Thesis_Dataset/training.pl\"\n",
    "training_data_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/Training\"\n",
    "# root of all files for the corpus dataset\n",
    "root_essay_dir = settings.data_directory + DATASET + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do I need to do this? good for validation below, but not needed otherwise\n",
    "with open(training_pickled, \"rb+\") as f:\n",
    "    untagged_essays_train = pickle.load(f)\n",
    "\n",
    "len(untagged_essays_train)# 902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# list some essays with ana tags\n",
    "name2essay = {}\n",
    "ana_tag_locations = []\n",
    "\n",
    "essay2ana_sent_ixs = defaultdict(set)\n",
    "\n",
    "for e in untagged_essays_train:\n",
    "    name2essay[e.name] = e\n",
    "    # heuristic for usefulness of essay - number of distinct tags\n",
    "    unique_tags = set()    \n",
    "    for sentix, sent in enumerate(e.sentences):\n",
    "        for wdix, (wd, tags) in enumerate(sent):\n",
    "            unique_tags.update(tags)\n",
    "    \n",
    "    for sentix, sent in enumerate(e.sentences):\n",
    "        for wdix, (wd, tags) in enumerate(sent):\n",
    "            if ANAPHORA in tags:\n",
    "                ana_tag_locations.append((e.name, sentix, wdix, len(unique_tags)))\n",
    "                essay2ana_sent_ixs[e.name].add(sentix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('EBA1415_LZBA_4_CB_ES-05530.ann', 0, 15, 49)),\n",
       " (1, ('EBA1415_LZBA_4_CB_ES-05530.ann', 0, 16, 49)),\n",
       " (2, ('EBA1415_LZBA_4_CB_ES-05530.ann', 6, 1, 49)),\n",
       " (3, ('EBA1415_BLRW_3_CB_ES-05173.ann', 6, 0, 48)),\n",
       " (4, ('EBA1415_LZBA_3_CB_ES-05505.ann', 5, 0, 45)),\n",
       " (5, ('EBA1415_RCGJ_4a_CB_ES-04684.ann', 7, 0, 43)),\n",
       " (6, ('EBA1415_SERS_1314_CB_ES-05098.ann', 7, 0, 43)),\n",
       " (7, ('EBA1415_KYNS_4_CB_ES-05390.ann', 10, 1, 42)),\n",
       " (8, ('EBA1415_LZBA_4_CB_ES-05531.ann', 3, 0, 41)),\n",
       " (9, ('EBA1415_LZBA_4_CB_ES-05531.ann', 12, 0, 41)),\n",
       " (10, ('EBA1415_LZBA_4_CB_ES-05531.ann', 12, 1, 41)),\n",
       " (11, ('EBA1415_SDMK_4_CB_ES-04758.ann', 5, 0, 41)),\n",
       " (12, ('EBA1415_SDMK_6_CB_ES-04773.ann', 1, 0, 41)),\n",
       " (13, ('EBA1415_SDMK_6_CB_ES-04773.ann', 5, 19, 41)),\n",
       " (14, ('EBA1415_SDMK_6_CB_ES-04773.ann', 12, 0, 41)),\n",
       " (15, ('EBA1415_TFHC_1_CB_ES-05941.ann', 3, 5, 41)),\n",
       " (16, ('EBA1415_TFHC_1_CB_ES-05941.ann', 6, 0, 41)),\n",
       " (17, ('EBA1415_TFHC_1_CB_ES-05941.ann', 8, 5, 41)),\n",
       " (18, ('EBA1415_TFHC_1_CB_ES-05941.ann', 14, 0, 41)),\n",
       " (19, ('EBA1415_BLHT_5_CB_ES-05205.ann', 10, 1, 39))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srted_ana_tag_locations = sorted(ana_tag_locations, key = lambda tpl: -tpl[3])[:20]\n",
    "list(enumerate(srted_ana_tag_locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_TRJB_2_CB_ES-05021.ann\n",
      "\n",
      "2 this {'Anaphor'}\n",
      "Sentence No: 17\n",
      "        in         []\n",
      "        conclusion []\n",
      "******* this       ['Anaphor']\n",
      "        is         []\n",
      "        why        []\n",
      "        they       ['50']\n",
      "        turn       ['50']\n",
      "        white      ['50', 'COMPILED']\n",
      "        .          []\n",
      "--------------------------------------------------------------------------------\n",
      "0 under {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:2'}\n",
      "1 these {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:2'}\n",
      "2 circumstances {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:2'}\n",
      "Sentence No: 13\n",
      "******* under         ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:2']\n",
      "******* these         ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:2']\n",
      "******* circumstances ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:2']\n",
      "        ,             ['explicit']\n",
      "        warm          ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        surface       ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        waters        ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        are           ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        dragged       ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        INFREQUENT    ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        towards       ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        south         ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        america       ['2', 'Result', 'Result:2', 'Causer:Anaphor->Result:2']\n",
      "        .             []\n",
      "--------------------------------------------------------------------------------\n",
      "0 all {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:6'}\n",
      "1 of {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:6'}\n",
      "2 these {'Anaphor', 'Causer', 'Causer:Anaphor', 'Causer:Anaphor->Result:6'}\n",
      "3 changes {'Causer:Anaphor', 'Anaphor', 'Causer:Anaphor->Result:6', 'Causer', 'explicit'}\n",
      "Sentence No: 14\n",
      "******* all      ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:6']\n",
      "******* of       ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:6']\n",
      "******* these    ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:6']\n",
      "******* changes  ['Causer', 'Anaphor', 'explicit', 'Causer:Anaphor', 'Causer:Anaphor->Result:6']\n",
      "        stresses ['6', 'Result', 'Result:6', 'Causer:Anaphor->Result:6']\n",
      "        the      ['6', 'Result', 'Result:6', 'Causer:Anaphor->Result:6']\n",
      "        coral    ['6', 'Result', 'Result:6', 'Causer:Anaphor->Result:6']\n",
      "        out      ['6', 'Result', 'Result:6', 'Causer:Anaphor->Result:6']\n",
      "        .        []\n",
      "--------------------------------------------------------------------------------\n",
      "0 all {'Causer:Anaphor->Result:50', 'Causer', 'Causer:Anaphor', 'Anaphor'}\n",
      "1 of {'Causer:Anaphor->Result:50', 'Causer', 'Causer:Anaphor', 'Anaphor'}\n",
      "2 these {'Causer:Anaphor->Result:50', 'Causer', 'Causer:Anaphor', 'Anaphor'}\n",
      "3 changes {'Causer:Anaphor->Result:50', 'Causer', 'Causer:Anaphor', 'Anaphor'}\n",
      "Sentence No: 16\n",
      "******* all        ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:50']\n",
      "******* of         ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:50']\n",
      "******* these      ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:50']\n",
      "******* changes    ['Causer', 'Anaphor', 'Causer:Anaphor', 'Causer:Anaphor->Result:50']\n",
      "        INFREQUENT ['explicit', 'Causer:Anaphor->Result:50']\n",
      "        and        ['explicit', 'Causer:Anaphor->Result:50']\n",
      "        INFREQUENT ['explicit', 'Causer:Anaphor->Result:50']\n",
      "        the        ['Causer:Anaphor->Result:50']\n",
      "        coral      ['50', 'Result', 'Result:50', 'Causer:Anaphor->Result:50']\n",
      "        and        ['50', 'Result', 'Result:50', 'Causer:Anaphor->Result:50']\n",
      "        they       ['50', 'Result', 'Result:50', 'Causer:Anaphor->Result:50']\n",
      "        turn       ['50', 'Result', 'Result:50', 'Causer:Anaphor->Result:50']\n",
      "        white      ['50', 'Result', 'Result:50', 'Causer:Anaphor->Result:50']\n",
      "        .          []\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "File:\n",
      "EBA1415_TRJB_2_CB_ES-05021.ann\n",
      "\n",
      "Directories:\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_BRAT_CB_5-15-15\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_BRAT_CB_5-15-15/backup\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/BrattData/EBA1415_Merged_OLD\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/All_Files\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Training\n"
     ]
    }
   ],
   "source": [
    "PREFIX_LEN = 7\n",
    "ix = 0\n",
    "\n",
    "# essay_name, _, _, _ = srted_ana_tag_locations[ix]\n",
    "essay_name = 'EBA1415_TRJB_2_CB_ES-05021.ann'\n",
    "print(essay_name)\n",
    "print()\n",
    "\n",
    "e = name2essay[essay_name]\n",
    "        \n",
    "sents = essay2ana_sent_ixs[essay_name]\n",
    "\n",
    "for sentix in sents:\n",
    "    sent = e.sentences[sentix]\n",
    "    \n",
    "    max_wd_len = 0\n",
    "    ana_tag_ixs = set()\n",
    "    for wdix, (wd,tags) in list(enumerate(sent)):\n",
    "        max_wd_len = max(len(wd), max_wd_len)\n",
    "        if ANAPHORA in tags:\n",
    "            ana_tag_ixs.add(wdix)\n",
    "            print(wdix,wd,tags)\n",
    "\n",
    "    # print sentence\n",
    "    print(\"Sentence No:\", sentix+1)\n",
    "    for wdix, (wd,tags) in list(enumerate(sent)):\n",
    "        prefix = \" \" * PREFIX_LEN\n",
    "        if wdix in ana_tag_ixs:\n",
    "            prefix = \"*\" * PREFIX_LEN\n",
    "        print(prefix + \" \" + wd.ljust(max_wd_len+1) + str(sorted(tags, key = lambda tag: (len(tag),tag))))\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "print()\n",
    "# list all locations that this file is found (for locating in Bratt)\n",
    "\n",
    "files = find_files_recursively(root_essay_dir, essay_name)\n",
    "print(\"File:\")\n",
    "print(essay_name)\n",
    "print()\n",
    "print(\"Directories:\")\n",
    "for f in list(zip(*files))[0]:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_TRJB_2_CB_ES-05021.ann\n",
      "Anaphora tags:{'T29', 'T26', 'T30', 'T34'}\n",
      "\n",
      "Contents\n",
      "        T1\t50 29 44\tcoral bleaching\n",
      "        T2\t11 81 90\tbad storm\n",
      "        T3\t6 102 125\tstressors the coral out\n",
      "        T4\t50 133 148\tloses its color\n",
      "        A1\tVague T4\n",
      "        T5\texplicit 76 78;99 101\tIf it\n",
      "        E1\texplicit:T5 Causer:T2 Result:T3\n",
      "        T6\texplicit 130 132\tit\n",
      "        E2\texplicit:T6 Causer:T3 Result:T4\n",
      "        T7\t50 229 264\talgae helps the coral get its color\n",
      "        A2\tNormal T7\n",
      "        T8\t6 273 292\tcoral is stress out\n",
      "        T9\t7 302 327\tcoral won't eat the algae\n",
      "        A3\tVague T9\n",
      "        T10\t50 336 393\tcoral won't get its color for which is why it turns white\n",
      "        T11\texplicit 266 268;293 297\tIf then\n",
      "        E3\texplicit:T11 Causer:T8 Result:T9\n",
      "        T12\texplicit 328 331\tand\n",
      "        E4\texplicit:T12 Causer:T9 Result:T10\n",
      "        T13\t3 454 472\twater temperatures\n",
      "        A4\tVague T13\n",
      "        T14\t1 477 488\ttrade winds\n",
      "        A5\tVague T14\n",
      "        T15\t3 499 524\twater temperature changes\n",
      "        A6\tVague T15\n",
      "        T16\t6 529 547\tcoral stresses out\n",
      "        T17\t50 555 566\tlose colors\n",
      "        A7\tVague T17\n",
      "        T18\texplicit 490 494;525 528\tWhen The\n",
      "        E5\texplicit:T18 Causer:T15 Result:T16\n",
      "        T19\texplicit 548 551\tand\n",
      "        E6\texplicit:T19 Causer:T16 Result:T17\n",
      "        T20\t1 605 616\ttrade winds\n",
      "        A8\tVague T20\n",
      "        T21\texplicit 590 600\tbecause of\n",
      "        E7\texplicit:T21 Result:T17 Causer:T20\n",
      "        T22\t1 785 824\tEvery few years trade winds are altered\n",
      "        A9\tVague T22\n",
      "        T23\t1 826 907\tThe trade winds weaken or reverese direction completely to blow from west to east\n",
      "        T24\t6 1022 1045\tstresses the coral out.\n",
      "        T25\t6 1065 1088\tstressors the coral out\n",
      "******* T26\tAnaphor 1117 1137\tAll of these changes\n",
      "        T27\t50 1159 1184\tcoral and they turn white\n",
      "        T28\t50 1212 1227\tthey turn white\n",
      "******* T29\tAnaphor 1200 1204\tthis\n",
      "******* T30\tAnaphor 909 934\tUnder these circumstances\n",
      "R: T30  R1\tantecedent Arg1:T30 Arg2:T23\n",
      "        T31\t2 936 999\twarm surface waters are dragged eastwards towards South America\n",
      "        T32\texplicit 934 935\t,\n",
      "R: T30  E8\texplicit:T32 Causer:T30 Result:T31\n",
      "        T33\t3 699 783\teastern Pacific causes surface waters to be colder than those in the western pacific\n",
      "        A10\tNormal T33\n",
      "******* T34\tAnaphor 1001 1021\tAll of these changes\n",
      "R: T34  R2\tantecedent Arg1:T34 Arg2:T31\n",
      "        T35\texplicit 1014 1021\tchanges\n",
      "R: T34  E9\texplicit:T35 Causer:T34 Result:T24\n",
      "R: T26  R3\tantecedent Arg1:T26 Arg2:T25\n",
      "        T36\texplicit 1138 1154\tbother and annoy\n",
      "R: T26  E10\texplicit:T36 Causer:T26 Result:T27\n",
      "        T37\tCOMPILED 1222 1227\twhite\n",
      "        #1\tAnnotatorNotes T37\t1 - 2 - 6 - 50; 11 - 6 -  50\n"
     ]
    }
   ],
   "source": [
    "print(essay_name)\n",
    "full_path = os.path.join(training_data_folder, essay_name)\n",
    "with open(full_path) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "references = set()\n",
    "for line in lines:\n",
    "    if ANAPHORA in line:\n",
    "        tag = line.split(\"\\t\")[0].strip()\n",
    "        references.add(tag)\n",
    "        \n",
    "print(\"Anaphora tags:\" + str(references))\n",
    "print()\n",
    "\n",
    "print(\"Contents\")\n",
    "for line in lines:\n",
    "    prefix = \" \" * PREFIX_LEN     \n",
    "    if ANAPHORA in line:\n",
    "        prefix = \"*\" * PREFIX_LEN\n",
    "    else:\n",
    "        for tag in references:\n",
    "            if tag + \" \" in line or line.strip().endswith(tag):\n",
    "                 prefix = (\"R: \" + tag).ljust(PREFIX_LEN)\n",
    "    print(prefix + \" \" + line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine How the Relation Codes Are Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = sorted(find_files(training_data_folder, \".*.ann\"))\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_ships = defaultdict(int)\n",
    "for f in all_files:\n",
    "    with open(f) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for l in lines:\n",
    "        l = l.strip()\n",
    "        if not l:\n",
    "            continue\n",
    "        if l[0] == \"R\":\n",
    "            rel_ships[l]+=1\n",
    "len(rel_ships)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_srtd = sorted(rel_ships.items(), key = lambda tpl: -tpl[1])\n",
    "l_srtd[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, freq in l_srtd:\n",
    "    assert \"antecedent\" in l, l\n",
    "    tokens = l.replace(\"\\t\",\" \").split()\n",
    "    assert len(tokens) == 4, len(tokens)\n",
    "    id, ante, arg1, arg2 = tokens\n",
    "    assert arg1.startswith(\"Arg1\")\n",
    "    assert arg2.startswith(\"Arg2\")\n",
    "    arg1_code = arg1.split(\":\")[1]\n",
    "    arg2_code = arg2.split(\":\")[1]\n",
    "    print(l, \"\\t CODES:\\t\", arg1_code, arg2_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* The anaphora tags are denoted as 'T' tags\n",
    "* They occur in the E (Event) tags under a causal relation\n",
    "* They always seem to be accompanied by both a causal relation, and an 'R' (relation) tag which denotes the antecedent relationship\n",
    "\n",
    "## Recommended TODOs\n",
    "* Use the antecedent relation to look up the arg2 tag, and use that to resolve the concept code\n",
    "* Add new concept codes and crels to denote the resolved anaphoric refs\n",
    "* Resolve these as (\"Anaphor-\" + code) to differentiate them from the regular tags, so we don't pull them in as normal tags accidentally when re-running previous code.\n",
    "* i.e. treat these as entirely new tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    " * Are all anaphora tags part of a causal relation? My earlier analysis seemed to contradict this.\n",
    " * Study output of the SC Bi-LSTM 'fixed' concept code tagger by computing error metrics over them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
