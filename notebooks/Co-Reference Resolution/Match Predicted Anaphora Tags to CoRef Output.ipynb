{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "Predictions: /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/Bi-LSTM-4-Anaphora_Tags-Binary-Fixed/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "#from gensim.models import Word2Vec\n",
    "from window_based_tagger_config import get_config\n",
    "from Rpfa import micro_rpfa\n",
    "\n",
    "import logging\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from CrossValidation import cross_validation\n",
    "from BrattEssay import load_bratt_essays\n",
    "from load_data import load_process_essays\n",
    "from collections import defaultdict\n",
    "from IterableFP import flatten\n",
    "from Settings import Settings\n",
    "from FindFiles import find_files\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + \"CoralBleaching/Thesis_Dataset/\"\n",
    "predictions_folder = root_folder + \"Predictions/Bi-LSTM-4-Anaphora_Tags-Binary-Fixed/\"\n",
    "print(\"Predictions: \" + predictions_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CoRef Parsed Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_folder_train = root_folder + \"CoReference/Training\"\n",
    "coref_files_train = find_files(coref_folder_train, \".*\\.tagged\")\n",
    "len(coref_files_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_folder_test = root_folder + \"CoReference/Test\"\n",
    "coref_files_test = find_files(coref_folder_test, \".*\\.tagged\")\n",
    "len(coref_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stanfordnlp_tagged_essays(coref_files):\n",
    "    DELIM = \"->\"\n",
    "    DELIM_TAG = \"|||\"\n",
    "\n",
    "    essay2tagged = {}\n",
    "    for fname in coref_files:\n",
    "        with open(fname) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        tagged_lines = []\n",
    "        for line in lines:\n",
    "            tagged_words = []\n",
    "            line = line.strip()\n",
    "            wds = []\n",
    "            for t_token in line.split(\" \"):\n",
    "                ##print(t_token)\n",
    "\n",
    "                word, tags = t_token.split(DELIM)\n",
    "                if word == \"-lrb-\":\n",
    "                    word = \"(\"\n",
    "                if word == \"-rrb-\":\n",
    "                    word = \")\"\n",
    "                if word == \"\\'\\'\":\n",
    "                    word = \"\\\"\"\n",
    "                # if word == \"not\" and len(wds) > 0 and wds[-1] == \"can\":\n",
    "                #     last_wd, tag_dict = tagged_words[-1]\n",
    "                #     tagged_words[-1] = (\"cannot\", tag_dict)\n",
    "                #     wds[-1] = \"cannot\"\n",
    "                #     continue\n",
    "\n",
    "                wds.append(word)\n",
    "                tag_dict = {}\n",
    "                for tag in tags.split(DELIM_TAG):\n",
    "                    if not tag:\n",
    "                        continue\n",
    "                    splt = tag.split(\":\")\n",
    "                    if len(splt) == 2:\n",
    "                        key, val = splt\n",
    "                        tag_dict[key] = val\n",
    "                    else:\n",
    "                        raise Exception(\"Error\")\n",
    "                if word == \"...\":\n",
    "                    tagged_words.append((\".\", tag_dict))\n",
    "                    tagged_words.append((\".\", tag_dict))\n",
    "                    tagged_words.append((\".\", tag_dict))\n",
    "                else:\n",
    "                    tagged_words.append((word, tag_dict))\n",
    "            tagged_lines.append(tagged_words)\n",
    "        essay2tagged[fname.split(\"/\")[-1].split(\".\")[0]] = tagged_lines\n",
    "    return essay2tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n"
     ]
    }
   ],
   "source": [
    "essay2coref_train = parse_stanfordnlp_tagged_essays(coref_files_train)\n",
    "print(len(essay2coref_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', {'NER': 'O', 'POS': 'WDT'}),\n",
       " ('leads', {'NER': 'O', 'POS': 'VBZ'}),\n",
       " ('to', {'NER': 'O', 'POS': 'TO'}),\n",
       " ('differences', {'NER': 'O', 'POS': 'NNS'}),\n",
       " ('in', {'NER': 'O', 'POS': 'IN'}),\n",
       " ('the', {'NER': 'O', 'POS': 'DT'}),\n",
       " ('rates', {'NER': 'O', 'POS': 'NNS'}),\n",
       " ('of', {'NER': 'O', 'POS': 'IN'}),\n",
       " ('coral', {'COREF_ID': '2', 'NER': 'O', 'POS': 'NN'}),\n",
       " ('bleaching', {'COREF_ID': '2', 'NER': 'O', 'POS': 'NN'}),\n",
       " ('.', {'NER': 'O', 'POS': '.'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = essay2coref_train[\"EBA1415_AEKD_4_CB_ES-05568\"]\n",
    "e[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Datastructure\n",
    "- Dictionary of esssays, keyed by name\n",
    "- Each essay is a list of sentences\n",
    "- Each sentence is a list of words\n",
    "- words are mapped to a tag dict\n",
    "  - tag dict - contains\n",
    "    - NER tag (most are O - none)\n",
    "    - POS tag\n",
    "    - If a Co-Reference such as an anaphor (mostly pronouns)\n",
    "      - COREF_PHRASE - phrase referred to by coref\n",
    "      - COREF_REF - Id of referenced phrase\n",
    "    - else if it is a phrase that is referenced:\n",
    "      - COREF_ID - id of the co-reference, referenced in the COREF_REF tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "essay2coref_test = parse_stanfordnlp_tagged_essays(coref_files_test)\n",
    "print(len(essay2coref_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tagged Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagged essays\n",
    "def load_tagged_essays(folder):\n",
    "    files = find_files(folder, \"essay.*.dill\")\n",
    "    # multiple runs with different hidden layer sizes?\n",
    "    if len(files) > 2:        \n",
    "        files = find_files(folder, \"essays.*256.*.dill\")\n",
    "    for f in files:\n",
    "        print(f)\n",
    "    assert len(files) == 2, \"Wrong number of tagged files:\" + str(len(files))\n",
    "    for f in files:\n",
    "        assert \"_train_\" in f or \"_test_\" in f, \"Wrong files matched\"\n",
    "    train_tagged_fname = [f for file in files if \"_train_\" in f][0]\n",
    "    test_tagged_fname = list(set(files).difference([train_tagged_fname]))[0]\n",
    "\n",
    "    # NOTE - is this throws an error, upgrade to dill 2.8.2. Version 2.6 had a bug in it\n",
    "    with open(train_tagged_fname, \"rb\") as f:\n",
    "        tagged_essays_train = dill.load(f)\n",
    "    with open(test_tagged_fname, \"rb\") as f:\n",
    "        tagged_essays_test  = dill.load(f)\n",
    "    return (tagged_essays_train, tagged_essays_test)\n",
    "\n",
    "def essays_2_hash_map(essays):\n",
    "    lu = {}\n",
    "    for e in essays:\n",
    "        # remove the extension\n",
    "        lu[e.name.replace(\".ann\",\"\")] = e\n",
    "    return lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/Bi-LSTM-4-Anaphora_Tags-Binary-Fixed/essays_test_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/Bi-LSTM-4-Anaphora_Tags-Binary-Fixed/essays_train_bi_directional-True_hidden_size-256_merge_mode-sum_num_rnns-2_use_pretrained_embedding-True.dill\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(902, 226)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana_tagged_train, ana_tagged_test = load_tagged_essays(predictions_folder)\n",
    "len(ana_tagged_train), len(ana_tagged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay2ana_train = essays_2_hash_map(ana_tagged_train)\n",
    "essay2ana_test  = essays_2_hash_map(ana_tagged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(coref_files_train) == len(ana_tagged_train)\n",
    "assert len(coref_files_test) == len(ana_tagged_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(15, 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0ebeaaac0f8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mana_essay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref_essay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mana_essay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref_essay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmatch_essays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay2ana_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0messay2coref_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-0ebeaaac0f8c>\u001b[0m in \u001b[0;36mmatch_essays\u001b[0;34m(ana_tagged, coref)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mana_essay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mana_tagged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcoref_essay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mana_essay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref_essay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mana_essay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref_essay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmatch_essays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay2ana_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0messay2coref_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: (15, 14)"
     ]
    }
   ],
   "source": [
    "def match_essays(ana_tagged, coref):\n",
    "    \n",
    "    for ename in ana_tagged.keys():\n",
    "        assert ename in coref, ename\n",
    "        ana_essay = ana_tagged[ename]\n",
    "        coref_essay = coref[ename]\n",
    "        assert len(ana_essay.sentences) == len(coref_essay), (len(ana_essay.sentences) ,len(coref_essay))\n",
    "        \n",
    "match_essays(essay2ana_train, essay2coref_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
