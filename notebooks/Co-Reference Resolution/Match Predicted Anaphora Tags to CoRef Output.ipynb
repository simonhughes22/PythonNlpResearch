{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "from CoRefHelper import parse_stanfordnlp_tagged_essays\n",
    "from FindFiles import find_files\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "\n",
    "CV_FOLDS = 5\n",
    "DEV_SPLIT = 0.1\n",
    "\n",
    "\"\"\" Begin Settings \"\"\"\n",
    "DATASET = \"CoralBleaching\"\n",
    "PARTITION = \"Training\" # Training | Test\n",
    "SCAN_LENGTH = 3\n",
    "\"\"\" END Settings \"\"\"\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "merged_predictions_folder = root_folder + \"Predictions/CoRef/MergedTags/\"\n",
    "\n",
    "coref_root = root_folder + \"CoReference/\"\n",
    "coref_folder = coref_root + PARTITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Merged Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 training essays loaded from:\n",
      "/Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/Predictions/CoRef/MergedTags/merged_essays_train.dill\n"
     ]
    }
   ],
   "source": [
    "##override this so we don't replace INFREQUENT words\n",
    "#config[\"min_df\"] = 0\n",
    "\n",
    "if PARTITION.lower() == \"training\":\n",
    "    merged_essays_fname =  \"merged_essays_train.dill\"\n",
    "elif PARTITION.lower() == \"test\":\n",
    "    merged_essays_fname = \"merged_essays_test.dill\"\n",
    "else:\n",
    "    raise Exception(\"Invalid partition: \" + PARTITION)\n",
    "\n",
    "merged_essays_fname = merged_predictions_folder + merged_essays_fname\n",
    "with open(merged_essays_fname, \"rb+\") as f:\n",
    "    tagged_essays = dill.load(f)\n",
    "\n",
    "# map parsed essays to essay name\n",
    "essay2tagged = {}\n",
    "for e in tagged_essays:\n",
    "    essay2tagged[e.name.split(\".\")[0]] = e\n",
    "\n",
    "print(\"{0} training essays loaded from:\\n{1}\".format(len(tagged_essays), merged_essays_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CoRef Parsed Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 co-ref tagged files loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load CoRef Parsed Essays\n",
    "coref_files = find_files(coref_folder, \".*\\.tagged\")\n",
    "print(\"{0} co-ref tagged files loaded\".format(len(coref_files)))\n",
    "essay2coref_tagged = parse_stanfordnlp_tagged_essays(coref_files)\n",
    "assert len(coref_files) == len(tagged_essays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Same Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATE THE SAME SET OF ESSAYS\n",
    "assert essay2tagged.keys() == essay2coref_tagged.keys()\n",
    "intersect = set(essay2tagged.keys()).intersection(essay2coref_tagged.keys())\n",
    "assert len(intersect) == len(essay2tagged.keys())\n",
    "assert len(essay2tagged.keys()) > 1\n",
    "assert len(essay2tagged.keys()) == len(essay2coref_tagged.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on CoRef Datastructure\n",
    "- Dictionary of esssays, keyed by name\n",
    "- Each essay is a list of sentences\n",
    "- Each sentence is a list of words\n",
    "- words are mapped to a tag dict: Dict[str, Set[str]]]\n",
    "  - tag dict - contains\n",
    "    - NER tag (most are O - none)\n",
    "    - POS tag\n",
    "    - If a Co-Reference such as an anaphor (mostly pronouns)\n",
    "      - COREF_PHRASE - phrase referred to by coref\n",
    "      - COREF_REF - Id of referenced phrase\n",
    "    - else if it is a phrase that is referenced:\n",
    "      - COREF_ID - id of the co-reference, referenced in the COREF_REF tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "COREF_PHRASE = \"COREF_PHRASE\"\n",
    "COREF_ID     = \"COREF_ID\"\n",
    "COREF_REF    = \"COREF_REF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EBA1415_AEKD_4_CB_ES-05568'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_coref_essay_sentence(essay2coref_tagged):\n",
    "    for ename, list_sent in list(essay2coref_tagged.items()):\n",
    "        for ix, sent in enumerate(list_sent):\n",
    "            found_id = False\n",
    "            found_ref = False\n",
    "            for wd, tag_dict in sent:\n",
    "                if COREF_ID in tag_dict:\n",
    "                    found_id = True\n",
    "                if COREF_REF in tag_dict:\n",
    "                    found_ref = True\n",
    "            if found_id and found_ref:\n",
    "                return ename\n",
    "    return None\n",
    "\n",
    "ename = find_coref_essay_sentence(essay2coref_tagged)\n",
    "ename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA1415_AEKD_4_CB_ES-05568\n",
      "\n",
      "0   what                 \n",
      "1   leads                \n",
      "2   to                   \n",
      "3   differences          \n",
      "4   in                   \n",
      "5   the                  \n",
      "6   rates                \n",
      "7   of                   \n",
      "8   coral                \n",
      "9   bleaching            \n",
      "10  .                    \n",
      "********************************************************************************\n",
      "11  coral                \n",
      "12  is                   \n",
      "13  often                \n",
      "14  mistaken             \n",
      "15  for                  \n",
      "16  a                    {'COREF_ID': {'1'}}\n",
      "17  rock                 {'COREF_ID': {'1'}}\n",
      "18  but                  \n",
      "19  it                   {'COREF_REF': {'1'}, 'COREF_PHRASE': {'a_rock'}}\n",
      "20  is                   \n",
      "21  made                 \n",
      "22  up                   \n",
      "23  of                   \n",
      "24  tiny                 \n",
      "25  animals              \n",
      "26  called               \n",
      "27  polyps               \n",
      "28  .                    \n",
      "********************************************************************************\n",
      "29  coral                \n",
      "30  bleaching            \n",
      "31  shows                \n",
      "32  bleaching            \n",
      "33  and                  \n",
      "34  healthy              \n",
      "35  bleaching            \n",
      "36  event                \n",
      "37  that                 \n",
      "38  makes                \n",
      "39  coral                \n",
      "40  vulnerable           \n",
      "41  to                   \n",
      "42  disease              \n",
      "43  and                  \n",
      "44  starvation           \n",
      "45  .                    \n",
      "********************************************************************************\n",
      "46  coral                \n",
      "47  bleaching            \n",
      "48  is                   \n",
      "49  almost               \n",
      "50  noticeable           \n",
      "51  in                   \n",
      "52  the                  \n",
      "53  pacific              \n",
      "54  ocean                \n",
      "55  .                    \n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(ename)\n",
    "print()\n",
    "wd_ix = -1\n",
    "for sent in essay2coref_tagged[ename]: #[:matching_ix+1]:\n",
    "    for wd, tag_dict in sent:\n",
    "        wd_ix+=1\n",
    "        copy = dict([(k,v) for k,v in tag_dict.items() if k in {COREF_ID, COREF_REF, COREF_PHRASE}])\n",
    "        print(str(wd_ix).ljust(3), wd.ljust(20), copy if copy else \"\")\n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match CoRef Tagged to Consolidated Tagged Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tagged_words_to_word_ixs(tagged_essay):\n",
    "\n",
    "    tagged_wds = []\n",
    "    taggedwd2sentixs = {}\n",
    "    for sent_ix, sent in enumerate(tagged_essay.sentences):\n",
    "        for wd_ix, (wd, tags) in enumerate(sent):\n",
    "            taggedwd2sentixs[len(tagged_wds)] = (sent_ix, wd_ix)\n",
    "            if wd == \"\\'\\'\":\n",
    "                wd = \"\\\"\"\n",
    "            tagged_wds.append(wd)\n",
    "    return tagged_wds, taggedwd2sentixs\n",
    "\n",
    "def replace_underscore(mention):\n",
    "    return set(map(lambda s: s.replace(\"_\",\" \"), mention))\n",
    "\n",
    "def map_mentions_to_word_ixs(coref_essay, keys):\n",
    "    #TODO - fix this, it assume one mention per word, but we can have multiple\n",
    "    coref_wd2_tags = []\n",
    "    coref_ids_2_wd_ixs = defaultdict(list) # maps a coref id to a list of set of ixs\n",
    "    for sent_ix, sent in enumerate(coref_essay):\n",
    "        current_coref_ids = set()\n",
    "        for wd_ix, (wd, tag_dict) in enumerate(sent):\n",
    "            coref_wd2_tags.append((wd,tag_dict))\n",
    "\n",
    "            wd_coref_ids = set()\n",
    "            for k in keys:\n",
    "                wd_coref_ids.update(tag_dict[k])\n",
    "\n",
    "            for cref_id in wd_coref_ids:\n",
    "                prev_ixs = coref_ids_2_wd_ixs[cref_id]\n",
    "                # continuation of existing sequence\n",
    "                wd_essay_ix = len(coref_wd2_tags)-1\n",
    "                if cref_id in current_coref_ids:\n",
    "                    if len(prev_ixs) == 0:\n",
    "                        prev_ixs.append(set())\n",
    "                    prev_ixs[-1].add(wd_essay_ix)\n",
    "                else:\n",
    "                    # else create a new set and add it\n",
    "                    prev_ixs.append({wd_essay_ix})\n",
    "\n",
    "            current_coref_ids = wd_coref_ids\n",
    "    return coref_wd2_tags, coref_ids_2_wd_ixs\n",
    "\n",
    "def map_words_between_essays(tagged_wds, coref_wd2_tags):\n",
    "    errors = []\n",
    "\n",
    "    ix_tagd, ix_coref = 0, 0\n",
    "    ixtagd_2_ixcoref = {}\n",
    "    ixcoref_2_ixtagd = {}\n",
    "\n",
    "    while ix_tagd < (len(tagged_wds) - 1) and ix_coref < (len(coref_wd2_tags) - 1):\n",
    "        wd_tagd = tagged_wds[ix_tagd]\n",
    "        wd_coref, btag_dict = coref_wd2_tags[ix_coref]\n",
    "\n",
    "        if wd_tagd == wd_coref or wd_tagd == \"cannot\" and wd_coref == \"can\":\n",
    "            ixtagd_2_ixcoref[ix_tagd] = ix_coref\n",
    "            ixcoref_2_ixtagd[ix_coref] = ix_tagd\n",
    "            ix_tagd += 1\n",
    "            ix_coref += 1\n",
    "        else:\n",
    "            # look ahead in wds2 for item that matches next a\n",
    "            found_match = False\n",
    "            for offseta, aa in enumerate(tagged_wds[ix_tagd: ix_tagd + 1 + SCAN_LENGTH]):\n",
    "                for offsetb, (bb, _) in enumerate(coref_wd2_tags[ix_coref:ix_coref + 1 + SCAN_LENGTH]):\n",
    "                    if aa == bb:\n",
    "                        if offseta == offsetb:\n",
    "                            for i in range(ix_tagd, ix_tagd + offseta):\n",
    "                                if i not in ixtagd_2_ixcoref:\n",
    "                                    ixtagd_2_ixcoref[i] = i\n",
    "\n",
    "                        ix_tagd = ix_tagd + offseta\n",
    "                        ix_coref = ix_coref + offsetb\n",
    "                        ixtagd_2_ixcoref[ix_tagd] = ix_coref\n",
    "                        ixcoref_2_ixtagd[ix_coref] = ix_tagd\n",
    "                        found_match = True\n",
    "                        break\n",
    "                if found_match:\n",
    "                    break\n",
    "            if not found_match:\n",
    "                errors.append((ename, wd_tagd, wd_coref, ix_tagd, ix_coref))\n",
    "                break\n",
    "    return ixtagd_2_ixcoref, ixcoref_2_ixtagd, errors\n",
    "\n",
    "def map_wds_to_coref_ids(coref_ids_2_wd_ixs, ixcoref_2_ixtagd, coref_wd2_tags, tagged_wds, taggedwd2sentixs):\n",
    "    sent_wdix_2_corefids = defaultdict(set)\n",
    "    for coref_id, list_wd_ix_seq in coref_ids_2_wd_ixs.items():\n",
    "        for wd_ixs in list_wd_ix_seq:\n",
    "\n",
    "            first_ix = min(wd_ixs)\n",
    "            is_fuzzy = False\n",
    "            if first_ix not in ixcoref_2_ixtagd:\n",
    "                while first_ix > 0 and first_ix not in ixcoref_2_ixtagd:\n",
    "                    first_ix -= 1\n",
    "                if first_ix not in ixcoref_2_ixtagd:\n",
    "                    e_first_wd_ix = 0\n",
    "                # one past last matching index\n",
    "                else:\n",
    "                    e_first_wd_ix = min(len(tagged_wds) - 1, ixcoref_2_ixtagd[first_ix] + 1)\n",
    "                is_fuzzy = True\n",
    "            else:\n",
    "                e_first_wd_ix = ixcoref_2_ixtagd[first_ix]\n",
    "\n",
    "            last_ix = max(wd_ixs)\n",
    "            if last_ix not in ixcoref_2_ixtagd:\n",
    "                while last_ix < len(coref_wd2_tags) and last_ix not in ixcoref_2_ixtagd:\n",
    "                    last_ix += 1\n",
    "                if last_ix not in ixcoref_2_ixtagd:\n",
    "                    e_last_wd_ix = len(tagged_wds) - 1\n",
    "                else:\n",
    "                    e_last_wd_ix = max(0, ixcoref_2_ixtagd[last_ix] - 1)\n",
    "                is_fuzzy = True\n",
    "            else:\n",
    "                e_last_wd_ix = ixcoref_2_ixtagd[last_ix]\n",
    "\n",
    "            for e_wd_ix in range(e_first_wd_ix, e_last_wd_ix + 1):\n",
    "                sent_ix, sent_wd_ix = taggedwd2sentixs[e_wd_ix]\n",
    "                sent_wdix_2_corefids[(sent_ix, sent_wd_ix)].add(coref_id)\n",
    "    return sent_wdix_2_corefids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_essays = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_essay  = essay2coref_tagged[ename]\n",
    "tagged_essay = essay2tagged[ename]\n",
    "\n",
    "tagged_wds, taggedwd2sentixs = map_tagged_words_to_word_ixs(tagged_essay)\n",
    "coref_wd2_tags, coref_ids_2_wd_ixs = map_mentions_to_word_ixs(coref_essay, keys={COREF_ID, COREF_REF})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtagd_2_ixcoref, ixcoref_2_ixtagd, errors = map_words_between_essays(tagged_wds, coref_wd2_tags)\n",
    "if errors:\n",
    "    # Print errors\n",
    "    for ename, wd_tagd, wd_coref, ix_tagd, ix_coref in errors:\n",
    "        failed_cnt += 1\n",
    "        print(\"Failed: \" + ename, wd_tagd, wd_coref, ix_tagd, ix_coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_wdix_2_corefids = map_wds_to_coref_ids(coref_ids_2_wd_ixs=coref_ids_2_wd_ixs,\n",
    "                                                ixcoref_2_ixtagd=ixcoref_2_ixtagd,\n",
    "                                                coref_wd2_tags=coref_wd2_tags,\n",
    "                                                tagged_wds=tagged_wds,\n",
    "                                                taggedwd2sentixs=taggedwd2sentixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_corefids_sentences = []\n",
    "for sent_ix, sent in enumerate(tagged_essay.sentences):\n",
    "    changed_ix = -1\n",
    "\n",
    "    predicted_coref_ids_wds = []\n",
    "    predicted_corefids_sentences.append(predicted_coref_ids_wds)\n",
    "\n",
    "    for wd_ix in range(len((sent))):\n",
    "        wd_coref_ids = sent_wdix_2_corefids[(sent_ix, wd_ix)]\n",
    "        predicted_coref_ids_wds.append(wd_coref_ids)\n",
    "\n",
    "tagged_essay.predicted_corefids = predicted_corefids_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_essays.append(tagged_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': [{6, 7}, {10}],\n",
      " '2': [{68, 69, 70, 71, 72, 73, 74}, {83, 84}, {101}],\n",
      " '3': [{42, 43, 44}, {46, 47}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dict(coref_ids_2_wd_ixs.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('well',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'UH'}})),\n",
       "  ('based',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBN'}})),\n",
       "  ('on',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('what',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'WP'}})),\n",
       "  ('i',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'FW'}})),\n",
       "  ('read',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VB'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'1'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('corals',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'1'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('are',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBP'}})),\n",
       "  ('loosing',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBG'}})),\n",
       "  ('their',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'the_corals'},\n",
       "                'COREF_REF': {'1'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'PRP$'}})),\n",
       "  ('colors',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  (',',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {','}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('bleaching',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('are',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBP'}})),\n",
       "  ('a',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('serious',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('problem',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('with',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('a',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('serious',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('impact',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('on',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('worlds',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('reefs',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('.',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'.'}}))],\n",
       " [('this',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('is',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBZ'}})),\n",
       "  ('a',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('serious',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('problem',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('because',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('bleaching',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('is',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBZ'}})),\n",
       "  ('most',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'RBS'}})),\n",
       "  ('noticeable',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('in',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'3'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('pacific',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'3'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('ocean',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'3'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  (',',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {','}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'the_pacific_ocean'},\n",
       "                'COREF_REF': {'3'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('ocean',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'the_pacific_ocean'},\n",
       "                'COREF_REF': {'3'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('covers',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBZ'}})),\n",
       "  ('about',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('0',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'NUMBER'},\n",
       "                'POS': {'CD'}})),\n",
       "  ('0',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'NUMBER'},\n",
       "                'POS': {'CD'}})),\n",
       "  ('of',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('entire',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('globe',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  (',',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {','}})),\n",
       "  ('some',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('corals',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('are',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBP'}})),\n",
       "  ('sensitive',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('to',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'TO'}})),\n",
       "  ('how',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'WRB'}})),\n",
       "  ('salty',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('water',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('us',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'PRP'}})),\n",
       "  ('.',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'.'}}))],\n",
       " [('a',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('massive',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('bleaching',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('event',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('in',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('0000',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': {'2'},\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'DATE'},\n",
       "                'POS': {'CD'}})),\n",
       "  ('is',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBZ'}})),\n",
       "  ('one',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'NUMBER'},\n",
       "                'POS': {'CD'}})),\n",
       "  ('of',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('worst',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJS'}})),\n",
       "  ('ever',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'RB'}})),\n",
       "  ('obscure',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  (',',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {','}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'a_massive_coral_bleaching_event_in_0000'},\n",
       "                'COREF_REF': {'2'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('event',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'a_massive_coral_bleaching_event_in_0000'},\n",
       "                'COREF_REF': {'2'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('resulted',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBD'}})),\n",
       "  ('in',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('death',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('of',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('00',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'PERCENT'},\n",
       "                'POS': {'CD'}})),\n",
       "  ('%',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'PERCENT'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('of',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('the',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('worlds',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('reefs',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  (',',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {','}})),\n",
       "  ('thus',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'RB'}})),\n",
       "  ('very',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'RB'}})),\n",
       "  ('serious',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'JJ'}})),\n",
       "  ('it',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_PHRASE': {'a_massive_coral_bleaching_event_in_0000'},\n",
       "                'COREF_REF': {'2'},\n",
       "                'NER': {'O'},\n",
       "                'POS': {'PRP'}})),\n",
       "  ('killed',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'VBD'}})),\n",
       "  ('a',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'DT'}})),\n",
       "  ('lot',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('of',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'IN'}})),\n",
       "  ('coral',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NN'}})),\n",
       "  ('reefs',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'NNS'}})),\n",
       "  ('.',\n",
       "   defaultdict(set,\n",
       "               {'COREF_ID': set(),\n",
       "                'COREF_REF': set(),\n",
       "                'NER': {'O'},\n",
       "                'POS': {'.'}}))]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well                 Empty      set()\n",
      "based                Empty      set()\n",
      "on                   Empty      set()\n",
      "what                 Empty      set()\n",
      "i                    Empty      set()\n",
      "read                 Empty      set()\n",
      "the                  Empty      {'1'}\n",
      "corals               Empty      {'1'}\n",
      "are                  Empty      set()\n",
      "INFREQUENT           Empty      set()\n",
      "their                Empty      {'1'}\n",
      "colors               50         set()\n",
      ",                    Empty      set()\n",
      "coral                50         set()\n",
      "bleaching            50         set()\n",
      "are                  Empty      set()\n",
      "a                    Empty      set()\n",
      "serious              Empty      set()\n",
      "problem              Empty      set()\n",
      "with                 Empty      set()\n",
      "a                    Empty      set()\n",
      "serious              Empty      set()\n",
      "impact               Empty      set()\n",
      "on                   Empty      set()\n",
      "the                  Empty      set()\n",
      "worlds               Empty      set()\n",
      "coral                Empty      set()\n",
      "reefs                Empty      set()\n",
      ".                    Empty      set()\n",
      "this                 Empty      set()\n",
      "is                   Empty      set()\n",
      "a                    Empty      set()\n",
      "serious              Empty      set()\n",
      "problem              Empty      set()\n",
      "because              Empty      set()\n",
      "the                  Empty      set()\n",
      "coral                50         set()\n",
      "bleaching            50         set()\n",
      "is                   Empty      set()\n",
      "most                 Empty      set()\n",
      "noticeable           Empty      set()\n",
      "in                   Empty      set()\n",
      "the                  Empty      {'3'}\n",
      "pacific              Empty      {'3'}\n",
      "ocean                Empty      {'3'}\n",
      ",                    Empty      set()\n",
      "the                  Empty      {'3'}\n",
      "ocean                Empty      {'3'}\n",
      "covers               Empty      set()\n",
      "about                Empty      set()\n",
      "0                    Empty      set()\n",
      "0                    Empty      set()\n",
      "of                   Empty      set()\n",
      "the                  Empty      set()\n",
      "entire               Empty      set()\n",
      "globe                Empty      set()\n",
      ",                    Empty      set()\n",
      "some                 Empty      set()\n",
      "corals               Empty      set()\n",
      "are                  Empty      set()\n",
      "sensitive            Empty      set()\n",
      "to                   Empty      set()\n",
      "how                  13         set()\n",
      "salty                13         set()\n",
      "the                  13         set()\n",
      "water                13         set()\n",
      "us                   13         set()\n",
      ".                    Empty      set()\n",
      "a                    Empty      {'2'}\n",
      "massive              Empty      {'2'}\n",
      "coral                50         {'2'}\n",
      "bleaching            50         {'2'}\n",
      "event                50         {'2'}\n",
      "in                   Empty      {'2'}\n",
      "0000                 Empty      {'2'}\n",
      "is                   Empty      set()\n",
      "one                  Empty      set()\n",
      "of                   Empty      set()\n",
      "the                  Empty      set()\n",
      "worst                Empty      set()\n",
      "ever                 Empty      set()\n",
      "INFREQUENT           Empty      set()\n",
      ",                    Empty      set()\n",
      "the                  Empty      {'2'}\n",
      "event                Empty      {'2'}\n",
      "resulted             Empty      set()\n",
      "in                   Empty      set()\n",
      "the                  Empty      set()\n",
      "death                Empty      set()\n",
      "of                   Empty      set()\n",
      "00                   Empty      set()\n",
      "%                    Empty      set()\n",
      "of                   Empty      set()\n",
      "the                  Empty      set()\n",
      "worlds               Empty      set()\n",
      "coral                Empty      set()\n",
      "reefs                Empty      set()\n",
      ",                    Empty      set()\n",
      "thus                 Empty      set()\n",
      "very                 Empty      set()\n",
      "serious              Empty      set()\n",
      "it                   Empty      {'2'}\n",
      "killed               Empty      set()\n",
      "a                    Empty      set()\n",
      "lot                  Empty      set()\n",
      "of                   Empty      set()\n",
      "coral                Empty      set()\n",
      "reefs                Empty      set()\n",
      ".                    Empty      set()\n"
     ]
    }
   ],
   "source": [
    "for sent_ix, sent in enumerate(tagged_essay.sentences):\n",
    "    \n",
    "    pred_tags = tagged_essay.pred_tagged_sentences[sent_ix]\n",
    "    corefid_sent = tagged_essay.predicted_corefids[sent_ix]\n",
    "    for wd_ix in range(len(sent)):\n",
    "        wd = sent[wd_ix][0]\n",
    "        \n",
    "        cref_ids = corefid_sent[wd_ix]\n",
    "        tag = pred_tags[wd_ix]\n",
    "        print(wd.ljust(20), tag.ljust(10), cref_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
