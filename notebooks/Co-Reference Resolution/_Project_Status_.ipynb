{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Status and Work Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Approach and Thoughts\n",
    "* My initial approach focused on training a fast word based tagging model. A full set of feature extraction and hyper parameter tuning was conducted\n",
    "  * However the results were un satisfactory (see the non RNN  so I switched to an RNN model)\n",
    "  * Also note that the mongo collections have been renamed to differentiate this fix - metrics_coref_word_tagger are the original word-based tagging model work, which are valid\n",
    "* Switching to the RNN model, I made some initital mistakes:\n",
    " 1. I didn't have it choose the Anaphora tag but instead chose the most common tag (which isn't always the anaphora tag)\n",
    " 2. There seems to be some issues with the way the initial RNN's trained, e.g. compare the numbers under the Anaphora.data_points. This is correct in the word tagging model and the later RNN tagger (see \"_fixed\") but not in the initial RNN tagger work\n",
    "* To remedy this I switched to newer code, copied from different notebooks, and the results of that are seen under the \"coref_new_fixed\" collection\n",
    "* I also moved to having the models spit out tagged data points, and then re-computing the metrics directly from that data. This then allows us to interrogate those predictions at a later date as needed, not just the raw numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mongo Collection Naming\n",
    "-  9/15/2018 Deleted - metrics_coref_broken\n",
    "        - Initial RNN tagger work with non-optimal model\n",
    "        \n",
    "- metrics_coref_old\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the Bratt Essay Parsing Logic to Resolve Anaphora Tags\n",
    "* Next I adjusted the BrattEssay file to resolve the anaphora tags with their antecedents when provided\n",
    "* These get resolved as Anaphora:[{code}] where {code} is one of the 13 or 9 concept codes, e.g. Anaphora:[50]\n",
    "* Analysis of how anaphora tags are initially tagged -  see 'Examine at How Anaphora Tags are Tagged to Inform Essay Parser Changes' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "* Hyper parameter tune the fixed, binary RNNs\n",
    " - Done for CB, but no results in mongo for SC (do i need to sync to old mac?)\n",
    "* Validate the bratt parser logic\n",
    "    * See \"Test Bratt Essay Changes to include Anaphora Tags\"\n",
    "* Load the predictions and reconcile with the co-ref parser output\n",
    "* Evaluate 2 things:\n",
    "    1. Taking the predicted tags, look for intersections in co-ref output, and evaluate accuracy of the resolved anaphora concept codes\n",
    "    2. Use the stanford co-reference parser alone to implement this logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "- Are the Co-references only present for concept codes? \n",
    " - No (and see ans to next qu)\n",
    " - Also, some anaphora tags have no antecedent\n",
    "- Are they only present for concept codes that form part of a causal relation?\n",
    " - No, not all anaphora tags have causal relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Measure of Success - Considerations\n",
    "  * Accuracy at detecting anaphora tags\n",
    "  * Accuracy at detecting anaphora tags and correctly resolving the associated concept(s)\n",
    "      1. Using the ML model's predictions to filter\n",
    "      2. Using the stanford output alone\n",
    "  * Impact on other metrics when incorporated into a single solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
