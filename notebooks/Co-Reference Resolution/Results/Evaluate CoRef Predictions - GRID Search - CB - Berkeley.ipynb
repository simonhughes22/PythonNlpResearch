{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - Take the merged predictions and evaluate the prediction accuracy using the 2 different approaches\n",
    " 1. Look at the anaphora tags and then cross-reference co-reference labels\n",
    " 2. Use the co-reference chains directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "CoRef Data:  /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "from results_common import get_essays, validate_essays, tally_essay_attributes\n",
    "from process_essays_coref import get_coref_processed_essays\n",
    "from metrics import get_metrics_raw\n",
    "\n",
    "# progress bar widget\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "stanford_coref_predictions_folder = root_folder + \"CoReference/\"\n",
    "berkeley_coref_predictions_folder = root_folder + \"CoReference/Berkeley/\"\n",
    "# Which algorithm?\n",
    "coref_predictions_folder = berkeley_coref_predictions_folder\n",
    "print(\"CoRef Data: \", stanford_coref_predictions_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/training_processed.dill\n"
     ]
    }
   ],
   "source": [
    "training_essays = get_essays(coref_predictions_folder, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_essays = get_essays(coref_predictions_folder, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = training_essays + test_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_essays(training_essays)\n",
    "validate_essays(test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_ner_tags_sentences\")\n",
    "pos_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_pos_tags_sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "reg_tally = defaultdict(int)\n",
    "for e in all_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "\n",
    "reg_tags = sorted(reg_tally.keys())\n",
    "all_ana_tags = sorted(cc_tally.keys())\n",
    "assert len(reg_tags) == len(all_ana_tags)\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAREST_REF_ONLY = \"Nearest reference\"\n",
    "MAX_ANA_PHRASE = \"Max ana phrase\"\n",
    "MAX_CHAIN_PHRASE = \"Max chain phrase\"\n",
    "POS_ANA_FLTR = \"POS ana filter\"\n",
    "POS_CHAIN_FLTR = \"Pos chain filter\"\n",
    "\n",
    "def blank_if_none(val):\n",
    "    return \"-\" if (val is None or not val or str(val).lower() == \"none\") else val\n",
    "\n",
    "def replace_if_blank(val, replace):\n",
    "    if val == \"\" or val == \"-\":\n",
    "        return replace\n",
    "    return val\n",
    "\n",
    "def process_sort_results(df_results):\n",
    "    df_disp = df_results[[\"f1_score\",\"precision\",\"recall\", \n",
    "                          NEAREST_REF_ONLY, MAX_ANA_PHRASE, MAX_CHAIN_PHRASE, POS_ANA_FLTR, POS_CHAIN_FLTR]]\n",
    "    return df_disp.sort_values(\"f1_score\", ascending=False)\n",
    "\n",
    "def filter_test_results_to_best_training_results(df_train_raw, df_test_raw):\n",
    "    # make sure sorted to the top result\n",
    "    df_train_raw_sorted = df_train_raw.sort_values(\"f1_score\", ascending=False, inplace=False)\n",
    "    top_row = df_train_raw_sorted.iloc[0]\n",
    "    filtered_df = df_test_raw[df_test_raw[NEAREST_REF_ONLY] == top_row[NEAREST_REF_ONLY]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_ANA_PHRASE]   == top_row[MAX_ANA_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_CHAIN_PHRASE] == top_row[MAX_CHAIN_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_ANA_FLTR]     == top_row[POS_ANA_FLTR]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_CHAIN_FLTR]   == top_row[POS_CHAIN_FLTR]]\n",
    "    print(len(filtered_df))\n",
    "    return process_sort_results(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare POS Tag Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nouns = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"NN\"])\n",
    "pos_verbs = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"VB\"])\n",
    "pos_pronouns = {\"PRP\",\"PRP$\", \"WP\", \"WP$\"}\n",
    "pos_determiners = {\"DT\",\"WDT\",\"PDT\"} # the, a, which, that, etc\n",
    "pos_pron_dt = pos_pronouns | pos_determiners\n",
    "# for meaning of pen treebank tags - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "pos_nouns, pos_verbs, pos_pronouns, pos_determiners, pos_pron_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_filter = {\n",
    "            \"None\": None,\n",
    "            \"PRN\": pos_pronouns,\n",
    "            \"DT\": pos_determiners,\n",
    "            \"PRN+DT\": pos_pron_dt\n",
    "}\n",
    "\n",
    "dict_pos_ch_filter = {\n",
    "    \"None\": None,\n",
    "    \"NN\": pos_nouns,\n",
    "    \"VB\": pos_verbs,\n",
    "    \"NN+VB\": pos_nouns | pos_verbs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = [None,1,2,3,5,10,20]\n",
    "nearest_ref_only_values = [True,False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search With Anaphora Prediction Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(essays, format_ana_tags, filter_to_predicted_tags, expected_tags):\n",
    "\n",
    "    # set up progress bar\n",
    "    max_count = len(nearest_ref_only_values) * len(phrase_len) * len(phrase_len) * len(dict_pos_filter) * len(dict_pos_ch_filter)\n",
    "    iprogress_bar = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    display(iprogress_bar) # display the bar\n",
    "\n",
    "    rows_ana = []\n",
    "    \n",
    "    for nearest_ref_only in nearest_ref_only_values:\n",
    "        for pos_ana_key, pos_ana_filter in dict_pos_filter.items():\n",
    "            for pos_ch_key, pos_ch_filter in dict_pos_ch_filter.items():                \n",
    "                for max_ana_phrase_len in phrase_len:\n",
    "                    for max_cref_phrase_len in phrase_len:\n",
    "\n",
    "                        proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "                        metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "                        row = metrics[\"MICRO_F1\"]\n",
    "                        row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "                        row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "                        row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "                        row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "                        row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "                        rows_ana.append(row)\n",
    "                        iprogress_bar.value += 1\n",
    "\n",
    "    df_results = pd.DataFrame(rows_ana)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics_with_optimal_settings(train_essays, test_essays, filter_to_predicted_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "\n",
    "    # Anaphora tags train and test\n",
    "    expected_tags = all_ana_tags\n",
    "    format_ana_tags=True\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy without Anaphora Resolution\n",
    "    expected_tags = reg_tags\n",
    "    format_ana_tags = True # Set this to true so that we ignore anaphora resolution for the next 2\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy with Anaphora Resolution\n",
    "    format_ana_tags=False\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df_concat = pd.concat([\n",
    "        df_train, df_test,\n",
    "        df_train_cc_reg, df_train_cc_ana,\n",
    "        df_test_cc_reg, df_test_cc_ana,\n",
    "    ])\n",
    "    df_concat= df_concat[[\"f1_score\",\"precision\", \"recall\"]]\n",
    "    \n",
    "    experiment_type = \"Ana\" if filter_to_predicted_tags else \"Cref\"\n",
    "    df_concat[\"Data Set\"] = [experiment_type +\" Train\", experiment_type + \" Test\", \n",
    "                             \"CC Train Reg\", \"CC Train \" + experiment_type,\n",
    "                             \"CC Test Reg\", \"CC Test \" + experiment_type]\n",
    "    return df_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(essays, format_ana_tags, filter_to_predicted_tags, expected_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "    \n",
    "    pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "    pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "    proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "    metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "    row = metrics[\"MICRO_F1\"]\n",
    "    row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "    row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "    row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "    row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "    row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "    df_results = pd.DataFrame([row])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags = True\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw = grid_search(essays=training_essays, \n",
    "                           expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_results = process_sort_results(df_train_raw)\n",
    "df_train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_ana_predictions.csv\"\n",
    "df_train_results.to_csv(train_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = df_train_results.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"], \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=True\n",
    "\n",
    "df_all_ana = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"Ana Train\", \"Ana Test\" - Train/Test with Anaphor predicted tags\n",
    "\n",
    "\"CC Train Reg\",  \"CC Test Reg\" - Concept codes withour anaphora tagging\n",
    "\"CC Train Ana\", \"CC Test Ana\"  - Concept codes with anaphora tagging\n",
    "\"\"\"\n",
    "df_all_ana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search without Anaphora Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags = False\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw_cref = grid_search(essays=training_essays, \n",
    "                                expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cref = process_sort_results(df_train_raw_cref)\n",
    "df_train_cref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_cref_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_cref.csv\"\n",
    "df_train_cref.to_csv(train_cref_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = df_train_cref.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"],   \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)\n",
    "\n",
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=False\n",
    "\n",
    "df_all_cref = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- ~~Make look-back-only always true~~\n",
    "  - **instead, add an option to pick the nearest preceding referent only**\n",
    "- ~~add a length filter to look at the length of the anaphor as well as the antecedents~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
