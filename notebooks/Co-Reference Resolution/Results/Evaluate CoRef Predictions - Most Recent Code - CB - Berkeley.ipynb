{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - The other techniques for finding anaphoric concept codes did not work well. Why not instead use the anaphora tagging model and just use the most recently predicted concept code as the antecedent to grad the code from? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "CoRef Data:  /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "from results_common import get_essays, validate_essays, tally_essay_attributes\n",
    "from process_essays_coref import get_coref_processed_essays\n",
    "from metrics import get_metrics_raw\n",
    "\n",
    "# progress bar widget\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "stanford_coref_predictions_folder = root_folder + \"CoReference/\"\n",
    "berkeley_coref_predictions_folder = root_folder + \"CoReference/Berkeley/\"\n",
    "# Which algorithm?\n",
    "coref_predictions_folder = berkeley_coref_predictions_folder\n",
    "print(\"CoRef Data: \", stanford_coref_predictions_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/training_processed.dill\n"
     ]
    }
   ],
   "source": [
    "training_essays = get_essays(coref_predictions_folder, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/test_processed.dill\n"
     ]
    }
   ],
   "source": [
    "test_essays = get_essays(coref_predictions_folder, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = training_essays + test_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essays validated\n",
      "Essays validated\n"
     ]
    }
   ],
   "source": [
    "validate_essays(training_essays)\n",
    "validate_essays(test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_ner_tags_sentences\")\n",
    "pos_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_pos_tags_sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaphor:[11]',\n",
       " 'Anaphor:[12]',\n",
       " 'Anaphor:[13]',\n",
       " 'Anaphor:[14]',\n",
       " 'Anaphor:[1]',\n",
       " 'Anaphor:[2]',\n",
       " 'Anaphor:[3]',\n",
       " 'Anaphor:[4]',\n",
       " 'Anaphor:[50]',\n",
       " 'Anaphor:[5]',\n",
       " 'Anaphor:[5b]',\n",
       " 'Anaphor:[6]',\n",
       " 'Anaphor:[7]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "reg_tally = defaultdict(int)\n",
    "for e in all_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "\n",
    "reg_tags = sorted(reg_tally.keys())\n",
    "all_ana_tags = sorted(cc_tally.keys())\n",
    "assert len(reg_tags) == len(all_ana_tags)\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAREST_REF_ONLY = \"Nearest reference\"\n",
    "MAX_ANA_PHRASE = \"Max ana phrase\"\n",
    "MAX_CHAIN_PHRASE = \"Max chain phrase\"\n",
    "POS_ANA_FLTR = \"POS ana filter\"\n",
    "POS_CHAIN_FLTR = \"Pos chain filter\"\n",
    "\n",
    "def blank_if_none(val):\n",
    "    return \"-\" if (val is None or not val or str(val).lower() == \"none\") else val\n",
    "\n",
    "def replace_if_blank(val, replace):\n",
    "    if val == \"\" or val == \"-\":\n",
    "        return replace\n",
    "    return val\n",
    "\n",
    "def process_sort_results(df_results):\n",
    "    df_disp = df_results[[\"f1_score\",\"precision\",\"recall\", \n",
    "                          NEAREST_REF_ONLY, MAX_ANA_PHRASE, MAX_CHAIN_PHRASE, POS_ANA_FLTR, POS_CHAIN_FLTR]]\n",
    "    return df_disp.sort_values(\"f1_score\", ascending=False)\n",
    "\n",
    "def filter_test_results_to_best_training_results(df_train_raw, df_test_raw):\n",
    "    # make sure sorted to the top result\n",
    "    df_train_raw_sorted = df_train_raw.sort_values(\"f1_score\", ascending=False, inplace=False)\n",
    "    top_row = df_train_raw_sorted.iloc[0]\n",
    "    filtered_df = df_test_raw[df_test_raw[NEAREST_REF_ONLY] == top_row[NEAREST_REF_ONLY]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_ANA_PHRASE]   == top_row[MAX_ANA_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_CHAIN_PHRASE] == top_row[MAX_CHAIN_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_ANA_FLTR]     == top_row[POS_ANA_FLTR]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_CHAIN_FLTR]   == top_row[POS_CHAIN_FLTR]]\n",
    "    print(len(filtered_df))\n",
    "    return process_sort_results(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare POS Tag Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NN', 'NNP', 'NNPS', 'NNS'},\n",
       " {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
       " {'PRP', 'PRP$', 'WP', 'WP$'},\n",
       " {'DT', 'PDT', 'WDT'},\n",
       " {'DT', 'PDT', 'PRP', 'PRP$', 'WDT', 'WP', 'WP$'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nouns = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"NN\"])\n",
    "pos_verbs = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"VB\"])\n",
    "pos_pronouns = {\"PRP\",\"PRP$\", \"WP\", \"WP$\"}\n",
    "pos_determiners = {\"DT\",\"WDT\",\"PDT\"} # the, a, which, that, etc\n",
    "pos_pron_dt = pos_pronouns | pos_determiners\n",
    "# for meaning of pen treebank tags - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "pos_nouns, pos_verbs, pos_pronouns, pos_determiners, pos_pron_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_filter = {\n",
    "            \"None\": None,\n",
    "            \"PRN\": pos_pronouns,\n",
    "            \"DT\": pos_determiners,\n",
    "            \"PRN+DT\": pos_pron_dt\n",
    "}\n",
    "\n",
    "dict_pos_ch_filter = {\n",
    "    \"None\": None,\n",
    "    \"NN\": pos_nouns,\n",
    "    \"VB\": pos_verbs,\n",
    "    \"NN+VB\": pos_nouns | pos_verbs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = [None,1,2,3,5,10,20]\n",
    "nearest_ref_only_values = [True,False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search With Anaphora Prediction Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(essays, format_ana_tags, filter_to_predicted_tags, expected_tags):\n",
    "\n",
    "    # set up progress bar\n",
    "    max_count = len(nearest_ref_only_values) * len(phrase_len) * len(phrase_len) * len(dict_pos_filter) * len(dict_pos_ch_filter)\n",
    "    iprogress_bar = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    display(iprogress_bar) # display the bar\n",
    "\n",
    "    rows_ana = []\n",
    "    \n",
    "    for nearest_ref_only in nearest_ref_only_values:\n",
    "        for pos_ana_key, pos_ana_filter in dict_pos_filter.items():\n",
    "            for pos_ch_key, pos_ch_filter in dict_pos_ch_filter.items():                \n",
    "                for max_ana_phrase_len in phrase_len:\n",
    "                    for max_cref_phrase_blen in phrase_len:\n",
    "\n",
    "                        proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "                        metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "                        row = metrics[\"MICRO_F1\"]\n",
    "                        row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "                        row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "                        row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "                        row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "                        row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "                        rows_ana.append(row)\n",
    "                        iprogress_bar.value += 1\n",
    "\n",
    "    df_results = pd.DataFrame(rows_ana)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics_with_optimal_settings(train_essays, test_essays, filter_to_predicted_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "\n",
    "    # Anaphora tags train and test\n",
    "    expected_tags = all_ana_tags\n",
    "    format_ana_tags=True\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy without Anaphora Resolution\n",
    "    expected_tags = reg_tags\n",
    "    format_ana_tags = True # Set this to true so that we ignore anaphora resolution for the next 2\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy with Anaphora Resolution\n",
    "    format_ana_tags=False\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df_concat = pd.concat([\n",
    "        df_train, df_test,\n",
    "        df_train_cc_reg, df_train_cc_ana,\n",
    "        df_test_cc_reg, df_test_cc_ana,\n",
    "    ])\n",
    "    df_concat= df_concat[[\"f1_score\",\"precision\", \"recall\"]]\n",
    "    \n",
    "    experiment_type = \"Ana\" if filter_to_predicted_tags else \"Cref\"\n",
    "    df_concat[\"Data Set\"] = [experiment_type +\" Train\", experiment_type + \" Test\", \n",
    "                             \"CC Train Reg\", \"CC Train \" + experiment_type,\n",
    "                             \"CC Test Reg\", \"CC Test \" + experiment_type]\n",
    "    return df_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(essays, format_ana_tags, filter_to_predicted_tags, expected_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "    \n",
    "    pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "    pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "    proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "    metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "    row = metrics[\"MICRO_F1\"]\n",
    "    row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "    row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "    row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "    row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "    row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "    df_results = pd.DataFrame([row])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254173cf98244d7c88f02ab537036a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=1568)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_to_predicted_tags = True\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw = grid_search(essays=training_essays, \n",
    "                           expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Nearest reference</th>\n",
       "      <th>Max ana phrase</th>\n",
       "      <th>Max chain phrase</th>\n",
       "      <th>POS ana filter</th>\n",
       "      <th>Pos chain filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1_score  precision    recall Nearest reference Max ana phrase  \\\n",
       "0    0.058981    0.37931  0.031977              True              -   \n",
       "632  0.058981    0.37931  0.031977              True             20   \n",
       "622  0.058981    0.37931  0.031977              True              5   \n",
       "623  0.058981    0.37931  0.031977              True             10   \n",
       "625  0.058981    0.37931  0.031977              True             10   \n",
       "\n",
       "    Max chain phrase POS ana filter Pos chain filter  \n",
       "0                  -              -                -  \n",
       "632                2         PRN+DT                -  \n",
       "622               20         PRN+DT                -  \n",
       "623                -         PRN+DT                -  \n",
       "625                2         PRN+DT                -  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_results = process_sort_results(df_train_raw)\n",
    "df_train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_ana_predictions.csv\"\n",
    "df_train_results.to_csv(train_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = df_train_results.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"], \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'None', 'None', None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=True\n",
    "\n",
    "df_all_ana = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Data Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>Ana Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>Ana Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833163</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>CC Train Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832875</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.820079</td>\n",
       "      <td>CC Train Ana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849007</td>\n",
       "      <td>0.848632</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Ana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall      Data Set\n",
       "0  0.058981   0.379310  0.031977     Ana Train\n",
       "0  0.045455   0.200000  0.025641      Ana Test\n",
       "0  0.833163   0.846703  0.820049  CC Train Reg\n",
       "0  0.832875   0.846077  0.820079  CC Train Ana\n",
       "0  0.849319   0.849257  0.849382   CC Test Reg\n",
       "0  0.849007   0.848632  0.849382   CC Test Ana"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"Ana Train\", \"Ana Test\" - Train/Test with Anaphor predicted tags\n",
    "\n",
    "\"CC Train Reg\",  \"CC Test Reg\" - Concept codes withour anaphora tagging\n",
    "\"CC Train Ana\", \"CC Test Ana\"  - Concept codes with anaphora tagging\n",
    "\"\"\"\n",
    "df_all_ana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search without Anaphora Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd0c764f6da4f3d836b2a7da8836584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=1568)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_to_predicted_tags = False\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw_cref = grid_search(essays=training_essays, \n",
    "                                expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Nearest reference</th>\n",
       "      <th>Max ana phrase</th>\n",
       "      <th>Max chain phrase</th>\n",
       "      <th>POS ana filter</th>\n",
       "      <th>Pos chain filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.035162</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>True</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.035162</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.035162</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.035162</td>\n",
       "      <td>0.023191</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1_score  precision    recall Nearest reference Max ana phrase  \\\n",
       "603  0.035211   0.023234  0.072674              True              2   \n",
       "589  0.035162   0.023191  0.072674              True              -   \n",
       "610  0.035162   0.023191  0.072674              True              3   \n",
       "617  0.035162   0.023191  0.072674              True              5   \n",
       "624  0.035162   0.023191  0.072674              True             10   \n",
       "\n",
       "    Max chain phrase POS ana filter Pos chain filter  \n",
       "603                1         PRN+DT                -  \n",
       "589                1         PRN+DT                -  \n",
       "610                1         PRN+DT                -  \n",
       "617                1         PRN+DT                -  \n",
       "624                1         PRN+DT                -  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cref = process_sort_results(df_train_raw_cref)\n",
    "df_train_cref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_cref_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_cref.csv\"\n",
    "df_train_cref.to_csv(train_cref_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'PRN+DT', 'None', 2, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_row = df_train_cref.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"],   \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)\n",
    "\n",
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=False\n",
    "\n",
    "df_all_cref = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Data Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.023234</td>\n",
       "      <td>0.072674</td>\n",
       "      <td>Cref Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>Cref Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833163</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>CC Train Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823513</td>\n",
       "      <td>0.825666</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>CC Train Cref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.839881</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.851443</td>\n",
       "      <td>CC Test Cref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall       Data Set\n",
       "0  0.035211   0.023234  0.072674     Cref Train\n",
       "0  0.007353   0.004292  0.025641      Cref Test\n",
       "0  0.833163   0.846703  0.820049   CC Train Reg\n",
       "0  0.823513   0.825666  0.821372  CC Train Cref\n",
       "0  0.849319   0.849257  0.849382    CC Test Reg\n",
       "0  0.839881   0.828629  0.851443   CC Test Cref"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_cref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- ~~Make look-back-only always true~~\n",
    "  - **instead, add an option to pick the nearest preceding referent only**\n",
    "- ~~add a length filter to look at the length of the anaphor as well as the antecedents~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
