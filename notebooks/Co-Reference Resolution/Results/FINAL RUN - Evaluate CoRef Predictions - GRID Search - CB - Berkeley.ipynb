{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - Take the merged predictions and evaluate the prediction accuracy using the 2 different approaches\n",
    " 1. Look at the anaphora tags and then cross-reference co-reference labels\n",
    " 2. Use the co-reference chains directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "CoRef Data:  /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "from results_common import get_essays, validate_essays, tally_essay_attributes\n",
    "from process_essays_coref import get_coref_processed_essays\n",
    "from results_procesor import ResultsProcessor\n",
    "\n",
    "# progress bar widget\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "stanford_coref_predictions_folder = root_folder + \"CoReference/\"\n",
    "berkeley_coref_predictions_folder = root_folder + \"CoReference/Berkeley/\"\n",
    "# Which algorithm?\n",
    "coref_predictions_folder = berkeley_coref_predictions_folder\n",
    "print(\"CoRef Data: \", stanford_coref_predictions_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/training_processed.dill\n"
     ]
    }
   ],
   "source": [
    "training_essays = get_essays(coref_predictions_folder, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/Berkeley/test_processed.dill\n"
     ]
    }
   ],
   "source": [
    "test_essays = get_essays(coref_predictions_folder, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = training_essays + test_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essays validated\n",
      "Essays validated\n"
     ]
    }
   ],
   "source": [
    "validate_essays(training_essays)\n",
    "validate_essays(test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_ner_tags_sentences\")\n",
    "pos_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_pos_tags_sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaphor:[11]',\n",
       " 'Anaphor:[12]',\n",
       " 'Anaphor:[13]',\n",
       " 'Anaphor:[14]',\n",
       " 'Anaphor:[1]',\n",
       " 'Anaphor:[2]',\n",
       " 'Anaphor:[3]',\n",
       " 'Anaphor:[4]',\n",
       " 'Anaphor:[50]',\n",
       " 'Anaphor:[5]',\n",
       " 'Anaphor:[5b]',\n",
       " 'Anaphor:[6]',\n",
       " 'Anaphor:[7]']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "reg_tally = defaultdict(int)\n",
    "for e in all_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "\n",
    "reg_tags = sorted(reg_tally.keys())\n",
    "all_ana_tags = sorted(cc_tally.keys())\n",
    "assert len(reg_tags) == len(all_ana_tags)\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAREST_REF_ONLY = \"Nearest reference\"\n",
    "MAX_ANA_PHRASE = \"Max ana phrase\"\n",
    "MAX_CHAIN_PHRASE = \"Max chain phrase\"\n",
    "POS_ANA_FLTR = \"POS ana filter\"\n",
    "POS_CHAIN_FLTR = \"Pos chain filter\"\n",
    "\n",
    "def blank_if_none(val):\n",
    "    return \"-\" if (val is None or not val or str(val).lower() == \"none\") else val\n",
    "\n",
    "def replace_if_blank(val, replace):\n",
    "    if val == \"\" or val == \"-\":\n",
    "        return replace\n",
    "    return val\n",
    "\n",
    "def process_sort_results(df_results):\n",
    "    df_disp = df_results[[\"f1_score\",\"precision\",\"recall\", \n",
    "                          NEAREST_REF_ONLY, MAX_ANA_PHRASE, MAX_CHAIN_PHRASE, POS_ANA_FLTR, POS_CHAIN_FLTR]]\n",
    "    return df_disp.sort_values(\"f1_score\", ascending=False)\n",
    "\n",
    "def filter_test_results_to_best_training_results(df_train_raw, df_test_raw):\n",
    "    # make sure sorted to the top result\n",
    "    df_train_raw_sorted = df_train_raw.sort_values(\"f1_score\", ascending=False, inplace=False)\n",
    "    top_row = df_train_raw_sorted.iloc[0]\n",
    "    filtered_df = df_test_raw[df_test_raw[NEAREST_REF_ONLY] == top_row[NEAREST_REF_ONLY]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_ANA_PHRASE]   == top_row[MAX_ANA_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_CHAIN_PHRASE] == top_row[MAX_CHAIN_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_ANA_FLTR]     == top_row[POS_ANA_FLTR]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_CHAIN_FLTR]   == top_row[POS_CHAIN_FLTR]]\n",
    "    print(len(filtered_df))\n",
    "    return process_sort_results(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare POS Tag Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NN', 'NNP', 'NNPS', 'NNS'},\n",
       " {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
       " {'PRP', 'PRP$', 'WP', 'WP$'},\n",
       " {'DT', 'PDT', 'WDT'},\n",
       " {'DT', 'PDT', 'PRP', 'PRP$', 'WDT', 'WP', 'WP$'})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nouns = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"NN\"])\n",
    "pos_verbs = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"VB\"])\n",
    "pos_pronouns = {\"PRP\",\"PRP$\", \"WP\", \"WP$\"}\n",
    "pos_determiners = {\"DT\",\"WDT\",\"PDT\"} # the, a, which, that, etc\n",
    "pos_pron_dt = pos_pronouns | pos_determiners\n",
    "# for meaning of pen treebank tags - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "pos_nouns, pos_verbs, pos_pronouns, pos_determiners, pos_pron_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_filter = {\n",
    "            \"None\": None,\n",
    "            \"PRN\": pos_pronouns,\n",
    "            \"DT\": pos_determiners,\n",
    "            \"PRN+DT\": pos_pron_dt\n",
    "}\n",
    "\n",
    "dict_pos_ch_filter = {\n",
    "    \"None\": None,\n",
    "    \"NN\": pos_nouns,\n",
    "    \"VB\": pos_verbs,\n",
    "    \"NN+VB\": pos_nouns | pos_verbs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = [None,1,2,3,5,10,20]\n",
    "nearest_ref_only_values = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics_with_optimal_settings(train_essays, test_essays, filter_to_predicted_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "\n",
    "    # Anaphora tags train and test\n",
    "    expected_tags = all_ana_tags\n",
    "    format_ana_tags=True\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy without Anaphora Resolution\n",
    "    expected_tags = reg_tags\n",
    "    format_ana_tags = True # Set this to true so that we ignore anaphora resolution for the next 2\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy with Anaphora Resolution\n",
    "    format_ana_tags=False\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df_concat = pd.concat([\n",
    "        df_train, df_test,\n",
    "        df_train_cc_reg, df_train_cc_ana,\n",
    "        df_test_cc_reg, df_test_cc_ana,\n",
    "    ])\n",
    "    df_concat= df_concat[[\"f1_score\",\"precision\", \"recall\"]]\n",
    "    \n",
    "    experiment_type = \"Ana\" if filter_to_predicted_tags else \"Cref\"\n",
    "    df_concat[\"Data Set\"] = [experiment_type +\" Train\", experiment_type + \" Test\", \n",
    "                             \"CC Train Reg\", \"CC Train \" + experiment_type,\n",
    "                             \"CC Test Reg\", \"CC Test \" + experiment_type]\n",
    "    return df_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(essays, format_ana_tags, filter_to_predicted_tags, expected_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "    \n",
    "    pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "    pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "    proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "    act_ys_bycode  = ResultsProcessor.get_wd_level_lbs(proc_essays,  expected_tags=expected_tags)\n",
    "    pred_ys_bycode = get_wd_level_preds(proc_essays, expected_tags=expected_tags)\n",
    "    return act_ys_bycode, pred_ys_bycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(essays, format_ana_tags, filter_to_predicted_tags, expected_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "    \n",
    "    pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "    pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "    proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "    metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags)\n",
    "    row = metrics[\"MICRO_F1\"]\n",
    "    row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "    row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "    row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "    row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "    row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "    df_results = pd.DataFrame([row])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wd_level_preds(essays, expected_tags):\n",
    "    expected_tags = set(expected_tags)\n",
    "    ysbycode = defaultdict(list)\n",
    "    for e in essays:\n",
    "        for sentix in range(len(e.sentences)):\n",
    "            p_ccodes = e.pred_tagged_sentences[sentix]\n",
    "            for wordix in range(len(p_ccodes)):\n",
    "                tags = p_ccodes[wordix]\n",
    "                if type(tags) == str:\n",
    "                    ptag_set = {tags}\n",
    "                elif type(tags) in (set,list):\n",
    "                    ptag_set = set(tags)   \n",
    "                else:\n",
    "                    raise Exception(\"Unrecognized tag type\")\n",
    "                for exp_tag in expected_tags:\n",
    "                    ysbycode[exp_tag].append(ResultsProcessor._ResultsProcessor__get_label_(exp_tag, ptag_set))\n",
    "    return ysbycode\n",
    "\n",
    "def get_metrics_raw(essays, expected_tags):\n",
    "    act_ys_bycode  = ResultsProcessor.get_wd_level_lbs(essays,  expected_tags=expected_tags)\n",
    "    pred_ys_bycode = get_wd_level_preds(essays, expected_tags=expected_tags)\n",
    "    mean_metrics = ResultsProcessor.compute_mean_metrics(act_ys_bycode, pred_ys_bycode)\n",
    "    return mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len = (True, 'None', 'None', None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=True\n",
    "\n",
    "df_all_ana = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>Data Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>Ana Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Ana Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833163</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>CC Train Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832875</td>\n",
       "      <td>0.820079</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>CC Train Ana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>CC Test Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849007</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>0.848632</td>\n",
       "      <td>CC Test Ana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score    recall  precision      Data Set\n",
       "0  0.058981  0.031977   0.379310     Ana Train\n",
       "0  0.045455  0.025641   0.200000      Ana Test\n",
       "0  0.833163  0.820049   0.846703  CC Train Reg\n",
       "0  0.832875  0.820079   0.846077  CC Train Ana\n",
       "0  0.849319  0.849382   0.849257   CC Test Reg\n",
       "0  0.849007  0.849382   0.848632   CC Test Ana"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"Ana Train\", \"Ana Test\" - Train/Test with Anaphor predicted tags\n",
    "\n",
    "\"CC Train Reg\",  \"CC Test Reg\" - Concept codes withour anaphora tagging\n",
    "\"CC Train Ana\", \"CC Test Ana\"  - Concept codes with anaphora tagging\n",
    "\"\"\"\n",
    "df_all_ana[[\"f1_score\", \"recall\", \"precision\", \"Data Set\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_tags = all_ana_tags\n",
    "format_ana_tags=True\n",
    "    \n",
    "tr_ysbycode, tr_predsbycode = get_predictions(essays=training_essays, expected_tags=expected_tags, \n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_tags = all_ana_tags\n",
    "format_ana_tags=True\n",
    "    \n",
    "test_ysbycode, test_predsbycode = get_predictions(essays=test_essays, expected_tags=expected_tags, \n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.03197674418604651,\n",
       " 'precision': 0.3793103448275862,\n",
       " 'f1_score': 0.05898123324396783,\n",
       " 'accuracy': 0.9998031582170509,\n",
       " 'num_codes': 344.0,\n",
       " 'data_points': 1783158.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics = ResultsProcessor.compute_mean_metrics(tr_ysbycode, tr_predsbycode)\n",
    "mean_metrics[\"MICRO_F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.02564102564102564,\n",
       " 'precision': 0.2,\n",
       " 'f1_score': 0.045454545454545456,\n",
       " 'accuracy': 0.9998947597892189,\n",
       " 'num_codes': 39.0,\n",
       " 'data_points': 399087.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_metrics = ResultsProcessor.compute_mean_metrics(test_ysbycode, test_predsbycode)\n",
    "mean_metrics[\"MICRO_F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsProcessor.persist_predictions(\"COREF_CB_GRID_BERKELEY_TD\", tr_predsbycode,   tr_ysbycode)\n",
    "ResultsProcessor.persist_predictions(\"COREF_CB_GRID_BERKELEY_VD\", test_predsbycode, test_ysbycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
