{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    " - Take the merged predictions and evaluate the prediction accuracy using the 2 different approaches\n",
    " 1. Look at the anaphora tags and then cross-reference co-reference labels\n",
    " 2. Use the co-reference chains directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir: /Users/simon.hughes/Google Drive/Phd/Results/\n",
      "Data Dir:    /Users/simon.hughes/Google Drive/Phd/Data/\n",
      "Root Dir:    /Users/simon.hughes/GitHub/NlpResearch/\n",
      "Public Data: /Users/simon.hughes/GitHub/NlpResearch/Data/PublicDatasets/\n",
      "CoRef Data:  /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "from Settings import Settings\n",
    "from collections import defaultdict\n",
    "from BrattEssay import ANAPHORA\n",
    "\n",
    "from results_common import get_essays, validate_essays, tally_essay_attributes\n",
    "from process_essays_coref import get_coref_processed_essays\n",
    "from metrics import get_metrics_raw\n",
    "\n",
    "# progress bar widget\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "DATASET = \"CoralBleaching\" # CoralBleaching | SkinCancer\n",
    "\n",
    "settings = Settings()\n",
    "root_folder = settings.data_directory + DATASET + \"/Thesis_Dataset/\"\n",
    "stanford_coref_predictions_folder = root_folder + \"CoReference/\"\n",
    "berkeley_coref_predictions_folder = root_folder + \"CoReference/Berkeley/\"\n",
    "# Which algorithm?\n",
    "coref_predictions_folder = stanford_coref_predictions_folder\n",
    "print(\"CoRef Data: \", stanford_coref_predictions_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/training_processed.dill\n"
     ]
    }
   ],
   "source": [
    "training_essays = get_essays(coref_predictions_folder, \"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file /Users/simon.hughes/Google Drive/Phd/Data/CoralBleaching/Thesis_Dataset/CoReference/test_processed.dill\n"
     ]
    }
   ],
   "source": [
    "test_essays = get_essays(coref_predictions_folder, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = training_essays + test_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essays validated\n",
      "Essays validated\n"
     ]
    }
   ],
   "source": [
    "validate_essays(training_essays)\n",
    "validate_essays(test_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_ner_tags_sentences\")\n",
    "pos_tally = tally_essay_attributes(all_essays, attribute_name=\"pred_pos_tags_sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Anaphor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anaphor:[11]',\n",
       " 'Anaphor:[12]',\n",
       " 'Anaphor:[13]',\n",
       " 'Anaphor:[14]',\n",
       " 'Anaphor:[1]',\n",
       " 'Anaphor:[2]',\n",
       " 'Anaphor:[3]',\n",
       " 'Anaphor:[4]',\n",
       " 'Anaphor:[50]',\n",
       " 'Anaphor:[5]',\n",
       " 'Anaphor:[5b]',\n",
       " 'Anaphor:[6]',\n",
       " 'Anaphor:[7]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from results_procesor import is_a_regular_code\n",
    "\n",
    "cc_tally = defaultdict(int)\n",
    "cr_tally = defaultdict(int)\n",
    "reg_tally = defaultdict(int)\n",
    "for e in all_essays:\n",
    "    for sent in e.sentences:\n",
    "        for wd, tags in sent:\n",
    "            for t in tags:\n",
    "                if is_a_regular_code(t):\n",
    "                    reg_tally[t] += 1\n",
    "                if ANAPHORA in t and \"other\" not in t:\n",
    "                    if \"->\" in t:\n",
    "                        cr_tally[t] += 1\n",
    "                    elif \"Anaphor:[\" in t:\n",
    "                        cc_tally[t] += 1\n",
    "\n",
    "reg_tags = sorted(reg_tally.keys())\n",
    "all_ana_tags = sorted(cc_tally.keys())\n",
    "assert len(reg_tags) == len(all_ana_tags)\n",
    "all_ana_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEAREST_REF_ONLY = \"Nearest reference\"\n",
    "MAX_ANA_PHRASE = \"Max ana phrase\"\n",
    "MAX_CHAIN_PHRASE = \"Max chain phrase\"\n",
    "POS_ANA_FLTR = \"POS ana filter\"\n",
    "POS_CHAIN_FLTR = \"Pos chain filter\"\n",
    "\n",
    "def blank_if_none(val):\n",
    "    return \"-\" if (val is None or not val or str(val).lower() == \"none\") else val\n",
    "\n",
    "def replace_if_blank(val, replace):\n",
    "    if val == \"\" or val == \"-\":\n",
    "        return replace\n",
    "    return val\n",
    "\n",
    "def process_sort_results(df_results):\n",
    "    df_disp = df_results[[\"f1_score\",\"precision\",\"recall\", \n",
    "                          NEAREST_REF_ONLY, MAX_ANA_PHRASE, MAX_CHAIN_PHRASE, POS_ANA_FLTR, POS_CHAIN_FLTR]]\n",
    "    return df_disp.sort_values(\"f1_score\", ascending=False)\n",
    "\n",
    "def filter_test_results_to_best_training_results(df_train_raw, df_test_raw):\n",
    "    # make sure sorted to the top result\n",
    "    df_train_raw_sorted = df_train_raw.sort_values(\"f1_score\", ascending=False, inplace=False)\n",
    "    top_row = df_train_raw_sorted.iloc[0]\n",
    "    filtered_df = df_test_raw[df_test_raw[NEAREST_REF_ONLY] == top_row[NEAREST_REF_ONLY]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_ANA_PHRASE]   == top_row[MAX_ANA_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[MAX_CHAIN_PHRASE] == top_row[MAX_CHAIN_PHRASE]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_ANA_FLTR]     == top_row[POS_ANA_FLTR]]\n",
    "    filtered_df = filtered_df[filtered_df[POS_CHAIN_FLTR]   == top_row[POS_CHAIN_FLTR]]\n",
    "    print(len(filtered_df))\n",
    "    return process_sort_results(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare POS Tag Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NN', 'NNP', 'NNPS', 'NNS'},\n",
       " {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'},\n",
       " {'PRP', 'PRP$', 'WP', 'WP$'},\n",
       " {'DT', 'PDT', 'WDT'},\n",
       " {'DT', 'PDT', 'PRP', 'PRP$', 'WDT', 'WP', 'WP$'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nouns = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"NN\"])\n",
    "pos_verbs = set([pos for pos in pos_tally.keys() if pos.strip()[:2] == \"VB\"])\n",
    "pos_pronouns = {\"PRP\",\"PRP$\", \"WP\", \"WP$\"}\n",
    "pos_determiners = {\"DT\",\"WDT\",\"PDT\"} # the, a, which, that, etc\n",
    "pos_pron_dt = pos_pronouns | pos_determiners\n",
    "# for meaning of pen treebank tags - https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "pos_nouns, pos_verbs, pos_pronouns, pos_determiners, pos_pron_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pos_filter = {\n",
    "            \"None\": None,\n",
    "            \"PRN\": pos_pronouns,\n",
    "            \"DT\": pos_determiners,\n",
    "            \"PRN+DT\": pos_pron_dt\n",
    "}\n",
    "\n",
    "dict_pos_ch_filter = {\n",
    "    \"None\": None,\n",
    "    \"NN\": pos_nouns,\n",
    "    \"VB\": pos_verbs,\n",
    "    \"NN+VB\": pos_nouns | pos_verbs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = [None,1,2,3,5,10,20]\n",
    "nearest_ref_only_values = [True,False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search With Anaphora Prediction Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(essays, format_ana_tags, filter_to_predicted_tags, expected_tags):\n",
    "\n",
    "    # set up progress bar\n",
    "    max_count = len(nearest_ref_only_values) * len(phrase_len) * len(phrase_len) * len(dict_pos_filter) * len(dict_pos_ch_filter)\n",
    "    iprogress_bar = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "    display(iprogress_bar) # display the bar\n",
    "\n",
    "    rows_ana = []\n",
    "    \n",
    "    for nearest_ref_only in nearest_ref_only_values:\n",
    "        for pos_ana_key, pos_ana_filter in dict_pos_filter.items():\n",
    "            for pos_ch_key, pos_ch_filter in dict_pos_ch_filter.items():                \n",
    "                for max_ana_phrase_len in phrase_len:\n",
    "                    for max_cref_phrase_len in phrase_len:\n",
    "\n",
    "                        proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "                        metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "                        row = metrics[\"MICRO_F1\"]\n",
    "                        row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "                        row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "                        row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "                        row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "                        row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "                        rows_ana.append(row)\n",
    "                        iprogress_bar.value += 1\n",
    "\n",
    "    df_results = pd.DataFrame(rows_ana)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics_with_optimal_settings(train_essays, test_essays, filter_to_predicted_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "\n",
    "    # Anaphora tags train and test\n",
    "    expected_tags = all_ana_tags\n",
    "    format_ana_tags=True\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy without Anaphora Resolution\n",
    "    expected_tags = reg_tags\n",
    "    format_ana_tags = True # Set this to true so that we ignore anaphora resolution for the next 2\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_reg = process_sort_results(df)\n",
    "    \n",
    "    # CC Accuracy with Anaphora Resolution\n",
    "    format_ana_tags=False\n",
    "    \n",
    "    df = get_metrics(essays=train_essays, \n",
    "                     expected_tags=expected_tags, \n",
    "                     format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_train_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df = get_metrics(essays=test_essays, \n",
    "                    expected_tags=expected_tags,\n",
    "                    format_ana_tags=format_ana_tags,\n",
    "                    filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                    nearest_ref_only=nearest_ref_only, pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "                               max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)\n",
    "    df_test_cc_ana = process_sort_results(df)\n",
    "    \n",
    "    df_concat = pd.concat([\n",
    "        df_train, df_test,\n",
    "        df_train_cc_reg, df_train_cc_ana,\n",
    "        df_test_cc_reg, df_test_cc_ana,\n",
    "    ])\n",
    "    df_concat= df_concat[[\"f1_score\",\"precision\", \"recall\"]]\n",
    "    \n",
    "    experiment_type = \"Ana\" if filter_to_predicted_tags else \"Cref\"\n",
    "    df_concat[\"Data Set\"] = [experiment_type +\" Train\", experiment_type + \" Test\", \n",
    "                             \"CC Train Reg\", \"CC Train \" + experiment_type,\n",
    "                             \"CC Test Reg\", \"CC Test \" + experiment_type]\n",
    "    return df_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(essays, format_ana_tags, filter_to_predicted_tags, expected_tags,\n",
    "                    nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len):\n",
    "    \n",
    "    pos_ana_filter = dict_pos_filter[pos_ana_key]\n",
    "    pos_ch_filter  = dict_pos_ch_filter[pos_ch_key]\n",
    "    \n",
    "    proc_essays = get_coref_processed_essays(\n",
    "                            essays=essays, format_ana_tags=format_ana_tags, \n",
    "                            ner_ch_filter=None, look_back_only=True,\n",
    "                            filter_to_predicted_tags=filter_to_predicted_tags, \n",
    "                            max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len, \n",
    "                            pos_ana_filter=pos_ana_filter, pos_ch_filter=pos_ch_filter, \n",
    "                            nearest_ref_only=nearest_ref_only)\n",
    "                        \n",
    "    metrics = get_metrics_raw(proc_essays, expected_tags=expected_tags,  micro_only=True)\n",
    "    row = metrics[\"MICRO_F1\"]\n",
    "    row[NEAREST_REF_ONLY] = blank_if_none(nearest_ref_only)\n",
    "    row[MAX_ANA_PHRASE]   = blank_if_none(max_ana_phrase_len)\n",
    "    row[MAX_CHAIN_PHRASE] = blank_if_none(max_cref_phrase_len)\n",
    "    row[POS_ANA_FLTR]     = blank_if_none(pos_ana_key)\n",
    "    row[POS_CHAIN_FLTR]   = blank_if_none(pos_ch_key)\n",
    "    df_results = pd.DataFrame([row])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01203d82c6864748be6d5bae0b855c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=1568)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_to_predicted_tags = True\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw = grid_search(essays=training_essays, \n",
    "                           expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Nearest reference</th>\n",
       "      <th>Max ana phrase</th>\n",
       "      <th>Max chain phrase</th>\n",
       "      <th>POS ana filter</th>\n",
       "      <th>Pos chain filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>PRN+DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1_score  precision    recall Nearest reference Max ana phrase  \\\n",
       "14   0.038043   0.291667  0.020349              True              2   \n",
       "602  0.038043   0.291667  0.020349              True              2   \n",
       "607  0.038043   0.291667  0.020349              True              2   \n",
       "608  0.038043   0.291667  0.020349              True              2   \n",
       "20   0.038043   0.291667  0.020349              True              2   \n",
       "\n",
       "    Max chain phrase POS ana filter Pos chain filter  \n",
       "14                 -              -                -  \n",
       "602                -         PRN+DT                -  \n",
       "607               10         PRN+DT                -  \n",
       "608               20         PRN+DT                -  \n",
       "20                20              -                -  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_results = process_sort_results(df_train_raw)\n",
    "df_train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_ana_predictions.csv\"\n",
    "df_train_results.to_csv(train_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_row = df_train_results.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"], \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'None', 'None', 2, None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=True\n",
    "\n",
    "df_all_ana = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Data Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>Ana Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>Ana Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833163</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>CC Train Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832896</td>\n",
       "      <td>0.846151</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>CC Train Ana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849132</td>\n",
       "      <td>0.848882</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Ana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall      Data Set\n",
       "0  0.038043   0.291667  0.020349     Ana Train\n",
       "0  0.047619   0.333333  0.025641      Ana Test\n",
       "0  0.833163   0.846703  0.820049  CC Train Reg\n",
       "0  0.832896   0.846151  0.820049  CC Train Ana\n",
       "0  0.849319   0.849257  0.849382   CC Test Reg\n",
       "0  0.849132   0.848882  0.849382   CC Test Ana"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\"Ana Train\", \"Ana Test\" - Train/Test with Anaphor predicted tags\n",
    "\n",
    "\"CC Train Reg\",  \"CC Test Reg\" - Concept codes withour anaphora tagging\n",
    "\"CC Train Ana\", \"CC Test Ana\"  - Concept codes with anaphora tagging\n",
    "\"\"\"\n",
    "df_all_ana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search without Anaphora Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2dacfd35234e3abddd4bf53eeb582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=1568)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_to_predicted_tags = False\n",
    "format_ana_tags=True # Format tags with Anaphora[xyz]\n",
    "\n",
    "df_train_raw_cref = grid_search(essays=training_essays, \n",
    "                                expected_tags=all_ana_tags,\n",
    "                           filter_to_predicted_tags=filter_to_predicted_tags, format_ana_tags=format_ana_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Nearest reference</th>\n",
       "      <th>Max ana phrase</th>\n",
       "      <th>Max chain phrase</th>\n",
       "      <th>POS ana filter</th>\n",
       "      <th>Pos chain filter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.032934</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.032353</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.031977</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN+VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.032345</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>DT</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1_score  precision    recall Nearest reference Max ana phrase  \\\n",
       "411  0.033333   0.031915  0.034884              True              2   \n",
       "460  0.032448   0.032934  0.031977              True              2   \n",
       "558  0.032353   0.032738  0.031977              True              2   \n",
       "412  0.032345   0.030151  0.034884              True              2   \n",
       "406  0.032172   0.029851  0.034884              True              2   \n",
       "\n",
       "    Max chain phrase POS ana filter Pos chain filter  \n",
       "411               10             DT                -  \n",
       "460               10             DT               NN  \n",
       "558               10             DT            NN+VB  \n",
       "412               20             DT                -  \n",
       "406                -             DT                -  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cref = process_sort_results(df_train_raw_cref)\n",
    "df_train_cref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist results\n",
    "train_cref_res_fname = coref_predictions_folder + \"concept_codes_train_grid_search_cref.csv\"\n",
    "df_train_cref.to_csv(train_cref_res_fname, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'DT', 'None', 2, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_row = df_train_cref.iloc[0]\n",
    "\n",
    "# set optimal parameters\n",
    "nearest_ref_only = replace_if_blank(top_row[\"Nearest reference\"],False)\n",
    "pos_ana_key =     replace_if_blank(top_row[\"POS ana filter\"],   \"None\")\n",
    "pos_ch_key  =     replace_if_blank(top_row[\"Pos chain filter\"], \"None\")\n",
    "max_ana_phrase_len = replace_if_blank(top_row[\"Max ana phrase\"], None)\n",
    "max_cref_phrase_len = replace_if_blank(top_row[\"Max chain phrase\"], None)\n",
    "\n",
    "nearest_ref_only, pos_ana_key, pos_ch_key, max_ana_phrase_len, max_cref_phrase_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_to_predicted_tags=False\n",
    "\n",
    "df_all_cref = get_all_metrics_with_optimal_settings(train_essays=training_essays, test_essays=test_essays,\n",
    "        filter_to_predicted_tags=filter_to_predicted_tags, nearest_ref_only=nearest_ref_only, \n",
    "        pos_ana_key=pos_ana_key, pos_ch_key=pos_ch_key, \n",
    "        max_ana_phrase_len=max_ana_phrase_len, max_cref_phrase_len=max_cref_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Data Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>Cref Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>Cref Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833163</td>\n",
       "      <td>0.846703</td>\n",
       "      <td>0.820049</td>\n",
       "      <td>CC Train Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.829524</td>\n",
       "      <td>0.838623</td>\n",
       "      <td>0.820620</td>\n",
       "      <td>CC Train Cref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.849257</td>\n",
       "      <td>0.849382</td>\n",
       "      <td>CC Test Reg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845945</td>\n",
       "      <td>0.841814</td>\n",
       "      <td>0.850118</td>\n",
       "      <td>CC Test Cref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_score  precision    recall       Data Set\n",
       "0  0.033333   0.031915  0.034884     Cref Train\n",
       "0  0.017699   0.013514  0.025641      Cref Test\n",
       "0  0.833163   0.846703  0.820049   CC Train Reg\n",
       "0  0.829524   0.838623  0.820620  CC Train Cref\n",
       "0  0.849319   0.849257  0.849382    CC Test Reg\n",
       "0  0.845945   0.841814  0.850118   CC Test Cref"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_cref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- ~~Make look-back-only always true~~\n",
    "  - **instead, add an option to pick the nearest preceding referent only**\n",
    "- ~~add a length filter to look at the length of the anaphor as well as the antecedents~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phd_py36]",
   "language": "python",
   "name": "conda-env-phd_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
